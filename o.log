checkpoint restored from output/bert_v2.ckpt
epoch-1 step 100/3451022 - loss: 0.038226 val_loss: 0.038500	recall: 0.496732 precision: 0.892368

model exported!

epoch-1 step 200/3451022 - loss: 0.037292 val_loss: 0.036057	recall: 0.467656 precision: 0.840000
epoch-1 step 300/3451022 - loss: 0.034644 val_loss: 0.036557	recall: 0.525539 precision: 0.893822
epoch-1 step 400/3451022 - loss: 0.035621 val_loss: 0.041645	recall: 0.485893 precision: 0.890805
epoch-1 step 500/3451022 - loss: 0.034667 val_loss: 0.036718	recall: 0.472892 precision: 0.898855
epoch-1 step 600/3451022 - loss: 0.036888 val_loss: 0.041633	recall: 0.492942 precision: 0.883268
epoch-1 step 700/3451022 - loss: 0.037532 val_loss: 0.035080	recall: 0.514477 precision: 0.897087
epoch-1 step 800/3451022 - loss: 0.035299 val_loss: 0.041551	recall: 0.514130 precision: 0.890772
epoch-1 step 900/3451022 - loss: 0.036559 val_loss: 0.039396	recall: 0.501092 precision: 0.889535
epoch-1 step 1000/3451022 - loss: 0.035887 val_loss: 0.034619	recall: 0.496150 precision: 0.874031

checkpoint saved

epoch-1 step 1100/3451022 - loss: 0.033963 val_loss: 0.040618	recall: 0.489947 precision: 0.909627
epoch-1 step 1200/3451022 - loss: 0.039634 val_loss: 0.034221	recall: 0.523649 precision: 0.908203
epoch-1 step 1300/3451022 - loss: 0.034568 val_loss: 0.039121	recall: 0.503289 precision: 0.882692
epoch-1 step 1400/3451022 - loss: 0.036430 val_loss: 0.035889	recall: 0.502110 precision: 0.893058
epoch-1 step 1500/3451022 - loss: 0.036133 val_loss: 0.039313	recall: 0.466598 precision: 0.874759
epoch-1 step 1600/3451022 - loss: 0.045616 val_loss: 0.036290	recall: 0.490526 precision: 0.882576
epoch-1 step 1700/3451022 - loss: 0.036312 val_loss: 0.037653	recall: 0.481319 precision: 0.883065
epoch-1 step 1800/3451022 - loss: 0.035925 val_loss: 0.036950	recall: 0.500543 precision: 0.896887
epoch-1 step 1900/3451022 - loss: 0.036484 val_loss: 0.035149	recall: 0.527533 precision: 0.915870
epoch-1 step 2000/3451022 - loss: 0.035077 val_loss: 0.036065	recall: 0.484749 precision: 0.859073

checkpoint saved

epoch-1 step 2100/3451022 - loss: 0.036504 val_loss: 0.035158	recall: 0.508215 precision: 0.894027

model exported!

epoch-1 step 2200/3451022 - loss: 0.035472 val_loss: 0.035693	recall: 0.489526 precision: 0.891566
epoch-1 step 2300/3451022 - loss: 0.037218 val_loss: 0.035678	recall: 0.486598 precision: 0.909441
epoch-1 step 2400/3451022 - loss: 0.035761 val_loss: 0.044811	recall: 0.495103 precision: 0.900990
epoch-1 step 2500/3451022 - loss: 0.037555 val_loss: 0.038946	recall: 0.502738 precision: 0.914343
epoch-1 step 2600/3451022 - loss: 0.043613 val_loss: 0.042781	recall: 0.495228 precision: 0.905039
epoch-1 step 2700/3451022 - loss: 0.037187 val_loss: 0.038866	recall: 0.497360 precision: 0.911025
epoch-1 step 2800/3451022 - loss: 0.035988 val_loss: 0.035684	recall: 0.497303 precision: 0.891683
epoch-1 step 2900/3451022 - loss: 0.035072 val_loss: 0.036510	recall: 0.494658 precision: 0.890385
epoch-1 step 3000/3451022 - loss: 0.039778 val_loss: 0.034587	recall: 0.472050 precision: 0.875240

checkpoint saved

epoch-1 step 3100/3451022 - loss: 0.043774 val_loss: 0.036940	recall: 0.515987 precision: 0.900000
epoch-1 step 3200/3451022 - loss: 0.036718 val_loss: 0.044269	recall: 0.476546 precision: 0.888668
epoch-1 step 3300/3451022 - loss: 0.038960 val_loss: 0.040882	recall: 0.496381 precision: 0.917782
epoch-1 step 3400/3451022 - loss: 0.035398 val_loss: 0.034687	recall: 0.508343 precision: 0.897839
epoch-1 step 3500/3451022 - loss: 0.036884 val_loss: 0.034105	recall: 0.520833 precision: 0.924125
epoch-1 step 3600/3451022 - loss: 0.036402 val_loss: 0.036258	recall: 0.478624 precision: 0.869318
epoch-1 step 3700/3451022 - loss: 0.036896 val_loss: 0.038941	recall: 0.497326 precision: 0.915354
epoch-1 step 3800/3451022 - loss: 0.034713 val_loss: 0.035959	recall: 0.485325 precision: 0.893822
epoch-1 step 3900/3451022 - loss: 0.038319 val_loss: 0.042058	recall: 0.476395 precision: 0.874016
epoch-1 step 4000/3451022 - loss: 0.037747 val_loss: 0.038698	recall: 0.497250 precision: 0.898608

checkpoint saved

epoch-1 step 4100/3451022 - loss: 0.036942 val_loss: 0.034674	recall: 0.524573 precision: 0.902574

model exported!

epoch-1 step 4200/3451022 - loss: 0.034039 val_loss: 0.038562	recall: 0.494229 precision: 0.904031
epoch-1 step 4300/3451022 - loss: 0.058611 val_loss: 0.034573	recall: 0.529801 precision: 0.932039
epoch-1 step 4400/3451022 - loss: 0.038742 val_loss: 0.036752	recall: 0.494080 precision: 0.892996
epoch-1 step 4500/3451022 - loss: 0.035940 val_loss: 0.035242	recall: 0.491649 precision: 0.900574
epoch-1 step 4600/3451022 - loss: 0.040810 val_loss: 0.034346	recall: 0.491210 precision: 0.915222
epoch-1 step 4700/3451022 - loss: 0.039265 val_loss: 0.039441	recall: 0.490683 precision: 0.911538
epoch-1 step 4800/3451022 - loss: 0.038984 val_loss: 0.035552	recall: 0.480249 precision: 0.880000
epoch-1 step 4900/3451022 - loss: 0.035263 val_loss: 0.038297	recall: 0.479055 precision: 0.862669
epoch-1 step 5000/3451022 - loss: 0.036850 val_loss: 0.040469	recall: 0.491543 precision: 0.909980

checkpoint saved

epoch-1 step 5100/3451022 - loss: 0.035881 val_loss: 0.036144	recall: 0.494703 precision: 0.887833
epoch-1 step 5200/3451022 - loss: 0.036888 val_loss: 0.034647	recall: 0.509310 precision: 0.890805
epoch-1 step 5300/3451022 - loss: 0.050339 val_loss: 0.038540	recall: 0.503282 precision: 0.884615
epoch-1 step 5400/3451022 - loss: 0.039216 val_loss: 0.034910	recall: 0.488770 precision: 0.892578
epoch-1 step 5500/3451022 - loss: 0.036298 val_loss: 0.051713	recall: 0.484110 precision: 0.868821
epoch-1 step 5600/3451022 - loss: 0.035513 val_loss: 0.041465	recall: 0.480331 precision: 0.885496
epoch-1 step 5700/3451022 - loss: 0.038133 val_loss: 0.050218	recall: 0.483624 precision: 0.877228
epoch-1 step 5800/3451022 - loss: 0.035272 val_loss: 0.034870	recall: 0.504722 precision: 0.895717
epoch-1 step 5900/3451022 - loss: 0.035168 val_loss: 0.034931	recall: 0.512459 precision: 0.904398
epoch-1 step 6000/3451022 - loss: 0.039335 val_loss: 0.036665	recall: 0.483422 precision: 0.884540

checkpoint saved

epoch-1 step 6100/3451022 - loss: 0.035938 val_loss: 0.041897	recall: 0.485746 precision: 0.870334

model exported!

epoch-1 step 6200/3451022 - loss: 0.035175 val_loss: 0.040744	recall: 0.518919 precision: 0.909091
epoch-1 step 6300/3451022 - loss: 0.036449 val_loss: 0.040179	recall: 0.511983 precision: 0.907336
epoch-1 step 6400/3451022 - loss: 0.046553 val_loss: 0.034838	recall: 0.488575 precision: 0.871845
epoch-1 step 6500/3451022 - loss: 0.037051 val_loss: 0.042274	recall: 0.479438 precision: 0.922780
epoch-1 step 6600/3451022 - loss: 0.036638 val_loss: 0.038463	recall: 0.455775 precision: 0.865613
epoch-1 step 6700/3451022 - loss: 0.034725 val_loss: 0.045903	recall: 0.505985 precision: 0.894231
epoch-1 step 6800/3451022 - loss: 0.035937 val_loss: 0.035021	recall: 0.493435 precision: 0.884314
epoch-1 step 6900/3451022 - loss: 0.034807 val_loss: 0.037797	recall: 0.480086 precision: 0.866019
epoch-1 step 7000/3451022 - loss: 0.041397 val_loss: 0.037848	recall: 0.484979 precision: 0.852830

checkpoint saved

epoch-1 step 7100/3451022 - loss: 0.036240 val_loss: 0.034368	recall: 0.522272 precision: 0.879925
epoch-1 step 7200/3451022 - loss: 0.033947 val_loss: 0.037290	recall: 0.469990 precision: 0.909449
epoch-1 step 7300/3451022 - loss: 0.040751 val_loss: 0.036923	recall: 0.473514 precision: 0.876000
epoch-1 step 7400/3451022 - loss: 0.039468 val_loss: 0.036666	recall: 0.521300 precision: 0.908203
epoch-1 step 7500/3451022 - loss: 0.034148 val_loss: 0.036964	recall: 0.507559 precision: 0.885122
epoch-1 step 7600/3451022 - loss: 0.038605 val_loss: 0.039683	recall: 0.485567 precision: 0.895437
epoch-1 step 7700/3451022 - loss: 0.044037 val_loss: 0.035645	recall: 0.487648 precision: 0.884990
epoch-1 step 7800/3451022 - loss: 0.038914 val_loss: 0.036977	recall: 0.526147 precision: 0.916357
epoch-1 step 7900/3451022 - loss: 0.035422 val_loss: 0.034665	recall: 0.501080 precision: 0.892308
epoch-1 step 8000/3451022 - loss: 0.037271 val_loss: 0.035720	recall: 0.527088 precision: 0.912109

checkpoint saved

epoch-1 step 8100/3451022 - loss: 0.040836 val_loss: 0.035034	recall: 0.469388 precision: 0.884615

model exported!

epoch-1 step 8200/3451022 - loss: 0.035706 val_loss: 0.037093	recall: 0.468657 precision: 0.888679
epoch-1 step 8300/3451022 - loss: 0.034956 val_loss: 0.040060	recall: 0.497984 precision: 0.906422
epoch-1 step 8400/3451022 - loss: 0.043776 val_loss: 0.034606	recall: 0.508976 precision: 0.895911
epoch-1 step 8500/3451022 - loss: 0.038685 val_loss: 0.035983	recall: 0.493697 precision: 0.900383
epoch-1 step 8600/3451022 - loss: 0.033735 val_loss: 0.038588	recall: 0.502646 precision: 0.911708
epoch-1 step 8700/3451022 - loss: 0.034572 val_loss: 0.036236	recall: 0.518931 precision: 0.885932
epoch-1 step 8800/3451022 - loss: 0.041593 val_loss: 0.034249	recall: 0.507246 precision: 0.900990
epoch-1 step 8900/3451022 - loss: 0.034540 val_loss: 0.036082	recall: 0.469409 precision: 0.862403
epoch-1 step 9000/3451022 - loss: 0.037424 val_loss: 0.041671	recall: 0.490670 precision: 0.912245

checkpoint saved

epoch-1 step 9100/3451022 - loss: 0.034760 val_loss: 0.035752	recall: 0.488706 precision: 0.893058
epoch-1 step 9200/3451022 - loss: 0.044361 val_loss: 0.035665	recall: 0.468915 precision: 0.859073
epoch-1 step 9300/3451022 - loss: 0.036211 val_loss: 0.034521	recall: 0.498382 precision: 0.900585
epoch-1 step 9400/3451022 - loss: 0.034730 val_loss: 0.034584	recall: 0.480000 precision: 0.893360
epoch-1 step 9500/3451022 - loss: 0.037771 val_loss: 0.035855	recall: 0.488033 precision: 0.896750
epoch-1 step 9600/3451022 - loss: 0.037762 val_loss: 0.035184	recall: 0.518681 precision: 0.904215
epoch-1 step 9700/3451022 - loss: 0.035014 val_loss: 0.037183	recall: 0.503145 precision: 0.926641
epoch-1 step 9800/3451022 - loss: 0.035371 val_loss: 0.036622	recall: 0.469072 precision: 0.885214
epoch-1 step 9900/3451022 - loss: 0.037854 val_loss: 0.038206	recall: 0.533113 precision: 0.916509
epoch-1 step 10000/3451022 - loss: 0.036053 val_loss: 0.035240	recall: 0.499456 precision: 0.901768

checkpoint saved

epoch-1 step 10100/3451022 - loss: 0.034344 val_loss: 0.036401	recall: 0.498925 precision: 0.888889

model exported!

epoch-1 step 10200/3451022 - loss: 0.035919 val_loss: 0.038325	recall: 0.503363 precision: 0.865125
epoch-1 step 10300/3451022 - loss: 0.038515 val_loss: 0.036035	recall: 0.505051 precision: 0.891089
epoch-1 step 10400/3451022 - loss: 0.035719 val_loss: 0.036738	recall: 0.515487 precision: 0.910156
epoch-1 step 10500/3451022 - loss: 0.034537 val_loss: 0.034545	recall: 0.507625 precision: 0.903101
epoch-1 step 10600/3451022 - loss: 0.040668 val_loss: 0.046893	recall: 0.516685 precision: 0.890538
epoch-1 step 10700/3451022 - loss: 0.037988 val_loss: 0.036140	recall: 0.502110 precision: 0.904943
epoch-1 step 10800/3451022 - loss: 0.037155 val_loss: 0.036473	recall: 0.515987 precision: 0.919450
epoch-1 step 10900/3451022 - loss: 0.037352 val_loss: 0.035190	recall: 0.507559 precision: 0.910853
epoch-1 step 11000/3451022 - loss: 0.056763 val_loss: 0.037579	recall: 0.483051 precision: 0.897638

checkpoint saved

epoch-1 step 11100/3451022 - loss: 0.035497 val_loss: 0.038601	recall: 0.519252 precision: 0.925490
epoch-1 step 11200/3451022 - loss: 0.039701 val_loss: 0.037937	recall: 0.503212 precision: 0.888469
epoch-1 step 11300/3451022 - loss: 0.037663 val_loss: 0.035083	recall: 0.497332 precision: 0.872659
epoch-1 step 11400/3451022 - loss: 0.035528 val_loss: 0.038456	recall: 0.501629 precision: 0.911243
epoch-1 step 11500/3451022 - loss: 0.036578 val_loss: 0.034863	recall: 0.485138 precision: 0.882239
epoch-1 step 11600/3451022 - loss: 0.047896 val_loss: 0.036414	recall: 0.514583 precision: 0.940952
epoch-1 step 11700/3451022 - loss: 0.040858 val_loss: 0.038937	recall: 0.516164 precision: 0.912381
epoch-1 step 11800/3451022 - loss: 0.037400 val_loss: 0.035674	recall: 0.518359 precision: 0.905660
epoch-1 step 11900/3451022 - loss: 0.036190 val_loss: 0.040758	recall: 0.491767 precision: 0.894212
epoch-1 step 12000/3451022 - loss: 0.035626 val_loss: 0.037445	recall: 0.504274 precision: 0.888889

checkpoint saved

epoch-1 step 12100/3451022 - loss: 0.041301 val_loss: 0.037822	recall: 0.498396 precision: 0.879245

model exported!

epoch-1 step 12200/3451022 - loss: 0.037400 val_loss: 0.039758	recall: 0.534937 precision: 0.915686
epoch-1 step 12300/3451022 - loss: 0.036819 val_loss: 0.040230	recall: 0.531178 precision: 0.916335
epoch-1 step 12400/3451022 - loss: 0.036930 val_loss: 0.035638	recall: 0.497773 precision: 0.857965
epoch-1 step 12500/3451022 - loss: 0.035496 val_loss: 0.040081	recall: 0.489730 precision: 0.867816
epoch-1 step 12600/3451022 - loss: 0.036636 val_loss: 0.034203	recall: 0.500537 precision: 0.906615
epoch-1 step 12700/3451022 - loss: 0.036816 val_loss: 0.036188	recall: 0.498901 precision: 0.906188
epoch-1 step 12800/3451022 - loss: 0.033929 val_loss: 0.034385	recall: 0.532525 precision: 0.913043
epoch-1 step 12900/3451022 - loss: 0.041408 val_loss: 0.034859	recall: 0.521739 precision: 0.905222
epoch-1 step 13000/3451022 - loss: 0.034661 val_loss: 0.038778	recall: 0.496304 precision: 0.905588

checkpoint saved

epoch-1 step 13100/3451022 - loss: 0.035322 val_loss: 0.037870	recall: 0.524537 precision: 0.916190
epoch-1 step 13200/3451022 - loss: 0.034892 val_loss: 0.035742	recall: 0.493063 precision: 0.888462
epoch-1 step 13300/3451022 - loss: 0.036115 val_loss: 0.039908	recall: 0.483904 precision: 0.908382
epoch-1 step 13400/3451022 - loss: 0.037418 val_loss: 0.035757	recall: 0.505759 precision: 0.894444
epoch-1 step 13500/3451022 - loss: 0.035749 val_loss: 0.036476	recall: 0.501574 precision: 0.908745
epoch-1 step 13600/3451022 - loss: 0.034677 val_loss: 0.039424	recall: 0.507527 precision: 0.892250
epoch-1 step 13700/3451022 - loss: 0.034815 val_loss: 0.035819	recall: 0.523707 precision: 0.915254
epoch-1 step 13800/3451022 - loss: 0.036186 val_loss: 0.041032	recall: 0.484725 precision: 0.910134
epoch-1 step 13900/3451022 - loss: 0.039856 val_loss: 0.037478	recall: 0.502132 precision: 0.900574
epoch-1 step 14000/3451022 - loss: 0.034900 val_loss: 0.035109	recall: 0.506772 precision: 0.903421

checkpoint saved

epoch-1 step 14100/3451022 - loss: 0.038292 val_loss: 0.037709	recall: 0.502198 precision: 0.890838

model exported!

epoch-1 step 14200/3451022 - loss: 0.045751 val_loss: 0.044035	recall: 0.462500 precision: 0.879208
epoch-1 step 14300/3451022 - loss: 0.041112 val_loss: 0.037184	recall: 0.519355 precision: 0.916509
epoch-1 step 14400/3451022 - loss: 0.034854 val_loss: 0.035577	recall: 0.493989 precision: 0.888016
epoch-1 step 14500/3451022 - loss: 0.045520 val_loss: 0.035347	recall: 0.460302 precision: 0.867424
epoch-1 step 14600/3451022 - loss: 0.036059 val_loss: 0.045565	recall: 0.484816 precision: 0.886905
epoch-1 step 14700/3451022 - loss: 0.038842 val_loss: 0.033917	recall: 0.511853 precision: 0.918762
epoch-1 step 14800/3451022 - loss: 0.042241 val_loss: 0.049092	recall: 0.531357 precision: 0.899614
epoch-1 step 14900/3451022 - loss: 0.036881 val_loss: 0.035291	recall: 0.484342 precision: 0.902724
epoch-1 step 15000/3451022 - loss: 0.035256 val_loss: 0.039130	recall: 0.534216 precision: 0.921905

checkpoint saved

epoch-1 step 15100/3451022 - loss: 0.036494 val_loss: 0.046073	recall: 0.498368 precision: 0.898039
epoch-1 step 15200/3451022 - loss: 0.040902 val_loss: 0.036564	recall: 0.484785 precision: 0.904110
epoch-1 step 15300/3451022 - loss: 0.038568 val_loss: 0.037070	recall: 0.486911 precision: 0.901163
epoch-1 step 15400/3451022 - loss: 0.038055 val_loss: 0.042408	recall: 0.483042 precision: 0.878505
epoch-1 step 15500/3451022 - loss: 0.035957 val_loss: 0.035755	recall: 0.518559 precision: 0.909962
epoch-1 step 15600/3451022 - loss: 0.036153 val_loss: 0.040992	recall: 0.487701 precision: 0.897638
epoch-1 step 15700/3451022 - loss: 0.040734 val_loss: 0.036359	recall: 0.491718 precision: 0.906489
epoch-1 step 15800/3451022 - loss: 0.042340 val_loss: 0.036190	recall: 0.490446 precision: 0.916667
epoch-1 step 15900/3451022 - loss: 0.038192 val_loss: 0.035660	recall: 0.512093 precision: 0.918868
epoch-1 step 16000/3451022 - loss: 0.037245 val_loss: 0.048011	recall: 0.493684 precision: 0.903661

checkpoint saved

epoch-1 step 16100/3451022 - loss: 0.034890 val_loss: 0.036344	recall: 0.463812 precision: 0.897436

model exported!

epoch-1 step 16200/3451022 - loss: 0.040279 val_loss: 0.039538	recall: 0.506694 precision: 0.914498
epoch-1 step 16300/3451022 - loss: 0.035493 val_loss: 0.034790	recall: 0.495268 precision: 0.918129
epoch-1 step 16400/3451022 - loss: 0.036626 val_loss: 0.035654	recall: 0.520045 precision: 0.894636
epoch-1 step 16500/3451022 - loss: 0.039981 val_loss: 0.037763	recall: 0.472050 precision: 0.892368
epoch-1 step 16600/3451022 - loss: 0.034418 val_loss: 0.034168	recall: 0.508754 precision: 0.908088
epoch-1 step 16700/3451022 - loss: 0.037179 val_loss: 0.034801	recall: 0.521253 precision: 0.894434
epoch-1 step 16800/3451022 - loss: 0.038776 val_loss: 0.037755	recall: 0.501068 precision: 0.895038
epoch-1 step 16900/3451022 - loss: 0.036280 val_loss: 0.036577	recall: 0.497286 precision: 0.887597
epoch-1 step 17000/3451022 - loss: 0.036788 val_loss: 0.034798	recall: 0.498908 precision: 0.867173

checkpoint saved

epoch-1 step 17100/3451022 - loss: 0.035103 val_loss: 0.035173	recall: 0.498915 precision: 0.891473
epoch-1 step 17200/3451022 - loss: 0.036505 val_loss: 0.038138	recall: 0.463235 precision: 0.861328
epoch-1 step 17300/3451022 - loss: 0.037118 val_loss: 0.047794	recall: 0.497763 precision: 0.891784
epoch-1 step 17400/3451022 - loss: 0.035945 val_loss: 0.038888	recall: 0.485106 precision: 0.883721
epoch-1 step 17500/3451022 - loss: 0.035959 val_loss: 0.035011	recall: 0.495135 precision: 0.898039
epoch-1 step 17600/3451022 - loss: 0.038683 val_loss: 0.034764	recall: 0.524719 precision: 0.903288
epoch-1 step 17700/3451022 - loss: 0.036806 val_loss: 0.045745	recall: 0.482613 precision: 0.885880
epoch-1 step 17800/3451022 - loss: 0.037567 val_loss: 0.036745	recall: 0.491507 precision: 0.883588
epoch-1 step 17900/3451022 - loss: 0.041534 val_loss: 0.035152	recall: 0.509677 precision: 0.906310
epoch-1 step 18000/3451022 - loss: 0.041141 val_loss: 0.036022	recall: 0.482418 precision: 0.907025

checkpoint saved

epoch-1 step 18100/3451022 - loss: 0.048388 val_loss: 0.034064	recall: 0.484624 precision: 0.892578

model exported!

epoch-1 step 18200/3451022 - loss: 0.037802 val_loss: 0.044545	recall: 0.523282 precision: 0.877323
epoch-1 step 18300/3451022 - loss: 0.036596 val_loss: 0.036157	recall: 0.511526 precision: 0.915521
epoch-1 step 18400/3451022 - loss: 0.035804 val_loss: 0.036794	recall: 0.482897 precision: 0.905660
epoch-1 step 18500/3451022 - loss: 0.038219 val_loss: 0.034711	recall: 0.509009 precision: 0.870906
epoch-1 step 18600/3451022 - loss: 0.035194 val_loss: 0.035573	recall: 0.493107 precision: 0.884030
epoch-1 step 18700/3451022 - loss: 0.034722 val_loss: 0.035894	recall: 0.497349 precision: 0.921415
epoch-1 step 18800/3451022 - loss: 0.037720 val_loss: 0.037846	recall: 0.521111 precision: 0.912451
epoch-1 step 18900/3451022 - loss: 0.036349 val_loss: 0.034708	recall: 0.516667 precision: 0.902913
epoch-1 step 19000/3451022 - loss: 0.036776 val_loss: 0.044891	recall: 0.533181 precision: 0.889313

checkpoint saved

epoch-1 step 19100/3451022 - loss: 0.035407 val_loss: 0.034603	recall: 0.512222 precision: 0.900391
epoch-1 step 19200/3451022 - loss: 0.041923 val_loss: 0.035748	recall: 0.519824 precision: 0.893939
epoch-1 step 19300/3451022 - loss: 0.040706 val_loss: 0.035199	recall: 0.502217 precision: 0.877907
epoch-1 step 19400/3451022 - loss: 0.040158 val_loss: 0.035616	recall: 0.526906 precision: 0.895238
epoch-1 step 19500/3451022 - loss: 0.035261 val_loss: 0.034555	recall: 0.515251 precision: 0.911368
epoch-1 step 19600/3451022 - loss: 0.035945 val_loss: 0.035663	recall: 0.512849 precision: 0.892996
epoch-1 step 19700/3451022 - loss: 0.035878 val_loss: 0.035449	recall: 0.496855 precision: 0.906310
epoch-1 step 19800/3451022 - loss: 0.036375 val_loss: 0.036827	recall: 0.499461 precision: 0.885277
epoch-1 step 19900/3451022 - loss: 0.037906 val_loss: 0.035878	recall: 0.518960 precision: 0.902072
epoch-1 step 20000/3451022 - loss: 0.036737 val_loss: 0.036579	recall: 0.538031 precision: 0.923225

checkpoint saved

epoch-1 step 20100/3451022 - loss: 0.038764 val_loss: 0.034896	recall: 0.500000 precision: 0.897087

model exported!

epoch-1 step 20200/3451022 - loss: 0.036869 val_loss: 0.036896	recall: 0.497712 precision: 0.857988
epoch-1 step 20300/3451022 - loss: 0.043715 val_loss: 0.035287	recall: 0.513631 precision: 0.907514
epoch-1 step 20400/3451022 - loss: 0.041798 val_loss: 0.035599	recall: 0.497868 precision: 0.903288
epoch-1 step 20500/3451022 - loss: 0.034410 val_loss: 0.036193	recall: 0.501116 precision: 0.899800
epoch-1 step 20600/3451022 - loss: 0.039087 val_loss: 0.034911	recall: 0.519168 precision: 0.913295
epoch-1 step 20700/3451022 - loss: 0.036775 val_loss: 0.035850	recall: 0.488033 precision: 0.900192
epoch-1 step 20800/3451022 - loss: 0.039370 val_loss: 0.034551	recall: 0.531390 precision: 0.927593
epoch-1 step 20900/3451022 - loss: 0.037878 val_loss: 0.039545	recall: 0.509372 precision: 0.890173
epoch-1 step 21000/3451022 - loss: 0.042767 val_loss: 0.039730	recall: 0.535342 precision: 0.909449

checkpoint saved

epoch-1 step 21100/3451022 - loss: 0.035217 val_loss: 0.041637	recall: 0.487859 precision: 0.878728
epoch-1 step 21200/3451022 - loss: 0.034112 val_loss: 0.035026	recall: 0.494658 precision: 0.920477
epoch-1 step 21300/3451022 - loss: 0.036648 val_loss: 0.035382	recall: 0.503219 precision: 0.916016
epoch-1 step 21400/3451022 - loss: 0.035118 val_loss: 0.035858	recall: 0.496746 precision: 0.891051
epoch-1 step 21500/3451022 - loss: 0.037400 val_loss: 0.037644	recall: 0.494715 precision: 0.898273
epoch-1 step 21600/3451022 - loss: 0.033904 val_loss: 0.042538	recall: 0.523596 precision: 0.910156
epoch-1 step 21700/3451022 - loss: 0.058635 val_loss: 0.040782	recall: 0.509091 precision: 0.904943
epoch-1 step 21800/3451022 - loss: 0.038107 val_loss: 0.036069	recall: 0.504338 precision: 0.887405
epoch-1 step 21900/3451022 - loss: 0.035150 val_loss: 0.034699	recall: 0.509804 precision: 0.917647
epoch-1 step 22000/3451022 - loss: 0.035660 val_loss: 0.038629	recall: 0.507903 precision: 0.918095

checkpoint saved

epoch-1 step 22100/3451022 - loss: 0.036722 val_loss: 0.036042	recall: 0.519101 precision: 0.900585

model exported!

epoch-1 step 22200/3451022 - loss: 0.034870 val_loss: 0.038064	recall: 0.508715 precision: 0.892925
epoch-1 step 22300/3451022 - loss: 0.035904 val_loss: 0.035718	recall: 0.503842 precision: 0.884393
epoch-1 step 22400/3451022 - loss: 0.035205 val_loss: 0.040536	recall: 0.513514 precision: 0.901328
epoch-1 step 22500/3451022 - loss: 0.035884 val_loss: 0.036116	recall: 0.543800 precision: 0.901887
epoch-1 step 22600/3451022 - loss: 0.036091 val_loss: 0.039044	recall: 0.466520 precision: 0.872690
epoch-1 step 22700/3451022 - loss: 0.039693 val_loss: 0.035260	recall: 0.496054 precision: 0.878244
epoch-1 step 22800/3451022 - loss: 0.039396 val_loss: 0.043580	recall: 0.509476 precision: 0.899606
epoch-1 step 22900/3451022 - loss: 0.036460 val_loss: 0.035507	recall: 0.535918 precision: 0.883459
epoch-1 step 23000/3451022 - loss: 0.034996 val_loss: 0.035336	recall: 0.545035 precision: 0.927308

checkpoint saved

epoch-1 step 23100/3451022 - loss: 0.036435 val_loss: 0.038128	recall: 0.532423 precision: 0.879699
epoch-1 step 23200/3451022 - loss: 0.037285 val_loss: 0.035778	recall: 0.515590 precision: 0.890385
epoch-1 step 23300/3451022 - loss: 0.042455 val_loss: 0.036604	recall: 0.521338 precision: 0.893281
epoch-1 step 23400/3451022 - loss: 0.048374 val_loss: 0.035972	recall: 0.496216 precision: 0.898239
epoch-1 step 23500/3451022 - loss: 0.039562 val_loss: 0.042536	recall: 0.540295 precision: 0.924272
epoch-1 step 23600/3451022 - loss: 0.035570 val_loss: 0.036086	recall: 0.508380 precision: 0.908184
epoch-1 step 23700/3451022 - loss: 0.039311 val_loss: 0.037127	recall: 0.510474 precision: 0.893822
epoch-1 step 23800/3451022 - loss: 0.038988 val_loss: 0.036422	recall: 0.500000 precision: 0.884692
epoch-1 step 23900/3451022 - loss: 0.035296 val_loss: 0.039389	recall: 0.494143 precision: 0.880455
epoch-1 step 24000/3451022 - loss: 0.035348 val_loss: 0.039259	recall: 0.516129 precision: 0.907372

checkpoint saved

epoch-1 step 24100/3451022 - loss: 0.036064 val_loss: 0.039251	recall: 0.502222 precision: 0.893281

model exported!

epoch-1 step 24200/3451022 - loss: 0.034922 val_loss: 0.036449	recall: 0.509395 precision: 0.880866
epoch-1 step 24300/3451022 - loss: 0.036619 val_loss: 0.035231	recall: 0.497807 precision: 0.888454
epoch-1 step 24400/3451022 - loss: 0.035273 val_loss: 0.038052	recall: 0.535550 precision: 0.908560
epoch-1 step 24500/3451022 - loss: 0.036733 val_loss: 0.036596	recall: 0.520131 precision: 0.910476
epoch-1 step 24600/3451022 - loss: 0.034862 val_loss: 0.036187	recall: 0.522222 precision: 0.903846
epoch-1 step 24700/3451022 - loss: 0.035691 val_loss: 0.036126	recall: 0.499431 precision: 0.878000
epoch-1 step 24800/3451022 - loss: 0.048316 val_loss: 0.045571	recall: 0.506303 precision: 0.906015
epoch-1 step 24900/3451022 - loss: 0.036254 val_loss: 0.035180	recall: 0.473795 precision: 0.875969
epoch-1 step 25000/3451022 - loss: 0.036403 val_loss: 0.050184	recall: 0.507812 precision: 0.878378

checkpoint saved

epoch-1 step 25100/3451022 - loss: 0.042039 val_loss: 0.035293	recall: 0.507848 precision: 0.911469
epoch-1 step 25200/3451022 - loss: 0.040008 val_loss: 0.035794	recall: 0.516793 precision: 0.901701
epoch-1 step 25300/3451022 - loss: 0.035358 val_loss: 0.037860	recall: 0.504525 precision: 0.876228
epoch-1 step 25400/3451022 - loss: 0.039426 val_loss: 0.037190	recall: 0.532222 precision: 0.912381
epoch-1 step 25500/3451022 - loss: 0.037434 val_loss: 0.036772	recall: 0.492723 precision: 0.909789
epoch-1 step 25600/3451022 - loss: 0.041923 val_loss: 0.035378	recall: 0.490052 precision: 0.894837
epoch-1 step 25700/3451022 - loss: 0.037530 val_loss: 0.035427	recall: 0.502726 precision: 0.888247
epoch-1 step 25800/3451022 - loss: 0.047297 val_loss: 0.035657	recall: 0.523973 precision: 0.891262
epoch-1 step 25900/3451022 - loss: 0.041747 val_loss: 0.049701	recall: 0.534002 precision: 0.912381
epoch-1 step 26000/3451022 - loss: 0.035913 val_loss: 0.042561	recall: 0.502165 precision: 0.894027

checkpoint saved

epoch-1 step 26100/3451022 - loss: 0.035220 val_loss: 0.037356	recall: 0.486200 precision: 0.877395

model exported!

epoch-1 step 26200/3451022 - loss: 0.035797 val_loss: 0.035567	recall: 0.522826 precision: 0.916190
epoch-1 step 26300/3451022 - loss: 0.038127 val_loss: 0.035487	recall: 0.494118 precision: 0.924000
epoch-1 step 26400/3451022 - loss: 0.037231 val_loss: 0.041448	recall: 0.473843 precision: 0.882022
epoch-1 step 26500/3451022 - loss: 0.034190 val_loss: 0.036864	recall: 0.501650 precision: 0.895874
epoch-1 step 26600/3451022 - loss: 0.035121 val_loss: 0.035740	recall: 0.517857 precision: 0.920635
epoch-1 step 26700/3451022 - loss: 0.038099 val_loss: 0.039294	recall: 0.478541 precision: 0.879684
epoch-1 step 26800/3451022 - loss: 0.036208 val_loss: 0.034621	recall: 0.492958 precision: 0.890411
epoch-1 step 26900/3451022 - loss: 0.039699 val_loss: 0.038749	recall: 0.488147 precision: 0.881323
epoch-1 step 27000/3451022 - loss: 0.039054 val_loss: 0.036011	recall: 0.498913 precision: 0.898239

checkpoint saved

epoch-1 step 27100/3451022 - loss: 0.040470 val_loss: 0.045259	recall: 0.539665 precision: 0.923518
epoch-1 step 27200/3451022 - loss: 0.037274 val_loss: 0.044162	recall: 0.508957 precision: 0.913043
epoch-1 step 27300/3451022 - loss: 0.035663 val_loss: 0.038773	recall: 0.503219 precision: 0.921415
epoch-1 step 27400/3451022 - loss: 0.035179 val_loss: 0.038119	recall: 0.511752 precision: 0.902072
epoch-1 step 27500/3451022 - loss: 0.037830 val_loss: 0.038536	recall: 0.514009 precision: 0.906844
epoch-1 step 27600/3451022 - loss: 0.035931 val_loss: 0.034391	recall: 0.497415 precision: 0.919694
epoch-1 step 27700/3451022 - loss: 0.039256 val_loss: 0.047486	recall: 0.510661 precision: 0.905482
epoch-1 step 27800/3451022 - loss: 0.037106 val_loss: 0.037651	recall: 0.523128 precision: 0.922330
epoch-1 step 27900/3451022 - loss: 0.039156 val_loss: 0.035528	recall: 0.502188 precision: 0.882692
epoch-1 step 28000/3451022 - loss: 0.036604 val_loss: 0.045127	recall: 0.502169 precision: 0.886973

checkpoint saved

epoch-1 step 28100/3451022 - loss: 0.040999 val_loss: 0.033718	recall: 0.530425 precision: 0.895349

model exported!

epoch-1 step 28200/3451022 - loss: 0.035471 val_loss: 0.034928	recall: 0.486570 precision: 0.912791
epoch-1 step 28300/3451022 - loss: 0.035314 val_loss: 0.034372	recall: 0.466395 precision: 0.892788
epoch-1 step 28400/3451022 - loss: 0.036559 val_loss: 0.038344	recall: 0.505423 precision: 0.894434
epoch-1 step 28500/3451022 - loss: 0.036245 val_loss: 0.036410	recall: 0.493078 precision: 0.892100
epoch-1 step 28600/3451022 - loss: 0.036076 val_loss: 0.038353	recall: 0.518837 precision: 0.916350
epoch-1 step 28700/3451022 - loss: 0.035052 val_loss: 0.034883	recall: 0.524076 precision: 0.886364
epoch-1 step 28800/3451022 - loss: 0.034599 val_loss: 0.035904	recall: 0.500530 precision: 0.885553
epoch-1 step 28900/3451022 - loss: 0.039870 val_loss: 0.035606	recall: 0.527211 precision: 0.894231
epoch-1 step 29000/3451022 - loss: 0.035103 val_loss: 0.035515	recall: 0.489707 precision: 0.888016

checkpoint saved

epoch-1 step 29100/3451022 - loss: 0.042638 val_loss: 0.036490	recall: 0.492818 precision: 0.888446
epoch-1 step 29200/3451022 - loss: 0.034417 val_loss: 0.036035	recall: 0.483770 precision: 0.902344
epoch-1 step 29300/3451022 - loss: 0.042565 val_loss: 0.040557	recall: 0.473520 precision: 0.901186
epoch-1 step 29400/3451022 - loss: 0.035588 val_loss: 0.038898	recall: 0.516667 precision: 0.901163
epoch-1 step 29500/3451022 - loss: 0.033921 val_loss: 0.042023	recall: 0.518944 precision: 0.893281
epoch-1 step 29600/3451022 - loss: 0.034857 val_loss: 0.037463	recall: 0.501037 precision: 0.907895
epoch-1 step 29700/3451022 - loss: 0.036859 val_loss: 0.036058	recall: 0.510730 precision: 0.911877
epoch-1 step 29800/3451022 - loss: 0.035862 val_loss: 0.034757	recall: 0.500515 precision: 0.886861
epoch-1 step 29900/3451022 - loss: 0.036436 val_loss: 0.042647	recall: 0.478712 precision: 0.876426
epoch-1 step 30000/3451022 - loss: 0.035557 val_loss: 0.035231	recall: 0.511013 precision: 0.883810

checkpoint saved

epoch-1 step 30100/3451022 - loss: 0.038565 val_loss: 0.035173	recall: 0.537694 precision: 0.899814

model exported!

epoch-1 step 30200/3451022 - loss: 0.034288 val_loss: 0.043016	recall: 0.508215 precision: 0.904483
epoch-1 step 30300/3451022 - loss: 0.036517 val_loss: 0.036897	recall: 0.508316 precision: 0.902214
epoch-1 step 30400/3451022 - loss: 0.038089 val_loss: 0.036910	recall: 0.497831 precision: 0.891262
epoch-1 step 30500/3451022 - loss: 0.034904 val_loss: 0.038765	recall: 0.518757 precision: 0.914934
epoch-1 step 30600/3451022 - loss: 0.037225 val_loss: 0.037291	recall: 0.514439 precision: 0.910985
epoch-1 step 30700/3451022 - loss: 0.034689 val_loss: 0.034968	recall: 0.517014 precision: 0.905769
epoch-1 step 30800/3451022 - loss: 0.034862 val_loss: 0.035141	recall: 0.481076 precision: 0.906191
epoch-1 step 30900/3451022 - loss: 0.036175 val_loss: 0.036009	recall: 0.492958 precision: 0.895669
epoch-1 step 31000/3451022 - loss: 0.036081 val_loss: 0.035749	recall: 0.512568 precision: 0.898467

checkpoint saved

epoch-1 step 31100/3451022 - loss: 0.035006 val_loss: 0.036736	recall: 0.510965 precision: 0.892720
epoch-1 step 31200/3451022 - loss: 0.035075 val_loss: 0.035630	recall: 0.498934 precision: 0.883019
epoch-1 step 31300/3451022 - loss: 0.034641 val_loss: 0.041531	recall: 0.468915 precision: 0.867446
epoch-1 step 31400/3451022 - loss: 0.042907 val_loss: 0.034974	recall: 0.495781 precision: 0.903846
epoch-1 step 31500/3451022 - loss: 0.035098 val_loss: 0.036869	recall: 0.487069 precision: 0.882812
epoch-1 step 31600/3451022 - loss: 0.037003 val_loss: 0.035963	recall: 0.487020 precision: 0.879925
epoch-1 step 31700/3451022 - loss: 0.035175 val_loss: 0.034618	recall: 0.513830 precision: 0.901119
epoch-1 step 31800/3451022 - loss: 0.037916 val_loss: 0.036198	recall: 0.495366 precision: 0.900749
epoch-1 step 31900/3451022 - loss: 0.035342 val_loss: 0.037107	recall: 0.500560 precision: 0.892216
epoch-1 step 32000/3451022 - loss: 0.035374 val_loss: 0.035435	recall: 0.508324 precision: 0.906931

checkpoint saved

epoch-1 step 32100/3451022 - loss: 0.034453 val_loss: 0.037908	recall: 0.529859 precision: 0.905380

model exported!

epoch-1 step 32200/3451022 - loss: 0.036732 val_loss: 0.034436	recall: 0.523864 precision: 0.925703
epoch-1 step 32300/3451022 - loss: 0.036250 val_loss: 0.036617	recall: 0.495177 precision: 0.893617
epoch-1 step 32400/3451022 - loss: 0.035005 val_loss: 0.041308	recall: 0.480465 precision: 0.899209
epoch-1 step 32500/3451022 - loss: 0.041829 val_loss: 0.037532	recall: 0.506593 precision: 0.909270
epoch-1 step 32600/3451022 - loss: 0.034947 val_loss: 0.040446	recall: 0.489496 precision: 0.910156
epoch-1 step 32700/3451022 - loss: 0.034539 val_loss: 0.035157	recall: 0.523095 precision: 0.888235
epoch-1 step 32800/3451022 - loss: 0.038189 val_loss: 0.045493	recall: 0.521445 precision: 0.885057
epoch-1 step 32900/3451022 - loss: 0.035282 val_loss: 0.036955	recall: 0.504494 precision: 0.866795
epoch-1 step 33000/3451022 - loss: 0.035495 val_loss: 0.039720	recall: 0.499459 precision: 0.891892

checkpoint saved

epoch-1 step 33100/3451022 - loss: 0.038714 val_loss: 0.035654	recall: 0.482759 precision: 0.880000
epoch-1 step 33200/3451022 - loss: 0.033951 val_loss: 0.034310	recall: 0.528342 precision: 0.926829
epoch-1 step 33300/3451022 - loss: 0.036177 val_loss: 0.036276	recall: 0.497225 precision: 0.887129
epoch-1 step 33400/3451022 - loss: 0.034334 val_loss: 0.035133	recall: 0.550691 precision: 0.896811
epoch-1 step 33500/3451022 - loss: 0.035838 val_loss: 0.034903	recall: 0.501661 precision: 0.884766
epoch-1 step 33600/3451022 - loss: 0.034239 val_loss: 0.036255	recall: 0.500000 precision: 0.882012
epoch-1 step 33700/3451022 - loss: 0.036075 val_loss: 0.039038	recall: 0.521552 precision: 0.902985
epoch-1 step 33800/3451022 - loss: 0.035242 val_loss: 0.037222	recall: 0.503859 precision: 0.887379
epoch-1 step 33900/3451022 - loss: 0.035424 val_loss: 0.038322	recall: 0.550282 precision: 0.922348
epoch-1 step 34000/3451022 - loss: 0.040875 val_loss: 0.039704	recall: 0.503834 precision: 0.889749

checkpoint saved

epoch-1 step 34100/3451022 - loss: 0.043277 val_loss: 0.034546	recall: 0.505580 precision: 0.884766

model exported!

epoch-1 step 34200/3451022 - loss: 0.041562 val_loss: 0.042940	recall: 0.537939 precision: 0.920543
epoch-1 step 34300/3451022 - loss: 0.035257 val_loss: 0.035796	recall: 0.531603 precision: 0.918129
epoch-1 step 34400/3451022 - loss: 0.034163 val_loss: 0.035412	recall: 0.539160 precision: 0.901328
epoch-1 step 34500/3451022 - loss: 0.037302 val_loss: 0.036675	recall: 0.540632 precision: 0.883764
epoch-1 step 34600/3451022 - loss: 0.037660 val_loss: 0.039440	recall: 0.503178 precision: 0.922330
epoch-1 step 34700/3451022 - loss: 0.036994 val_loss: 0.034929	recall: 0.522075 precision: 0.882463
epoch-1 step 34800/3451022 - loss: 0.036193 val_loss: 0.033989	recall: 0.492473 precision: 0.884170
epoch-1 step 34900/3451022 - loss: 0.036702 val_loss: 0.037633	recall: 0.524017 precision: 0.893855
epoch-1 step 35000/3451022 - loss: 0.034787 val_loss: 0.043697	recall: 0.514444 precision: 0.883588

checkpoint saved

epoch-1 step 35100/3451022 - loss: 0.035324 val_loss: 0.039682	recall: 0.477223 precision: 0.890688
epoch-1 step 35200/3451022 - loss: 0.034797 val_loss: 0.034182	recall: 0.503333 precision: 0.888235
epoch-1 step 35300/3451022 - loss: 0.038711 val_loss: 0.039996	recall: 0.490031 precision: 0.910331
epoch-1 step 35400/3451022 - loss: 0.035147 val_loss: 0.036204	recall: 0.488698 precision: 0.904382
epoch-1 step 35500/3451022 - loss: 0.035260 val_loss: 0.042228	recall: 0.529089 precision: 0.925144
epoch-1 step 35600/3451022 - loss: 0.042193 val_loss: 0.035758	recall: 0.471698 precision: 0.894632
epoch-1 step 35700/3451022 - loss: 0.037082 val_loss: 0.035531	recall: 0.493048 precision: 0.902153
epoch-1 step 35800/3451022 - loss: 0.035394 val_loss: 0.036713	recall: 0.488095 precision: 0.891304
epoch-1 step 35900/3451022 - loss: 0.037369 val_loss: 0.036278	recall: 0.487097 precision: 0.895257
epoch-1 step 36000/3451022 - loss: 0.037079 val_loss: 0.035554	recall: 0.506438 precision: 0.907692

checkpoint saved

epoch-1 step 36100/3451022 - loss: 0.035334 val_loss: 0.035826	recall: 0.520652 precision: 0.903774

model exported!

epoch-1 step 36200/3451022 - loss: 0.039142 val_loss: 0.035033	recall: 0.540664 precision: 0.920078
epoch-1 step 36300/3451022 - loss: 0.037141 val_loss: 0.039299	recall: 0.494080 precision: 0.886100
epoch-1 step 36400/3451022 - loss: 0.038445 val_loss: 0.041368	recall: 0.499473 precision: 0.877778
epoch-1 step 36500/3451022 - loss: 0.036843 val_loss: 0.035980	recall: 0.511879 precision: 0.909789
epoch-1 step 36600/3451022 - loss: 0.038341 val_loss: 0.045958	recall: 0.512459 precision: 0.920233
epoch-1 step 36700/3451022 - loss: 0.042903 val_loss: 0.034613	recall: 0.514819 precision: 0.896750
epoch-1 step 36800/3451022 - loss: 0.035136 val_loss: 0.036637	recall: 0.508004 precision: 0.908397
epoch-1 step 36900/3451022 - loss: 0.038267 val_loss: 0.034804	recall: 0.527132 precision: 0.903226
epoch-1 step 37000/3451022 - loss: 0.041791 val_loss: 0.036469	recall: 0.500541 precision: 0.900778

checkpoint saved

epoch-1 step 37100/3451022 - loss: 0.038053 val_loss: 0.037365	recall: 0.538991 precision: 0.927022
epoch-1 step 37200/3451022 - loss: 0.037111 val_loss: 0.035370	recall: 0.516447 precision: 0.904031
epoch-1 step 37300/3451022 - loss: 0.037940 val_loss: 0.035340	recall: 0.517799 precision: 0.907372
epoch-1 step 37400/3451022 - loss: 0.035573 val_loss: 0.034859	recall: 0.510158 precision: 0.898608
epoch-1 step 37500/3451022 - loss: 0.037276 val_loss: 0.037256	recall: 0.513043 precision: 0.895636
epoch-1 step 37600/3451022 - loss: 0.036151 val_loss: 0.039183	recall: 0.520270 precision: 0.927711
epoch-1 step 37700/3451022 - loss: 0.042606 val_loss: 0.040633	recall: 0.490405 precision: 0.905512
epoch-1 step 37800/3451022 - loss: 0.038245 val_loss: 0.039758	recall: 0.523810 precision: 0.897533
epoch-1 step 37900/3451022 - loss: 0.034239 val_loss: 0.038611	recall: 0.537430 precision: 0.907547
epoch-1 step 38000/3451022 - loss: 0.034917 val_loss: 0.036180	recall: 0.490239 precision: 0.888016

checkpoint saved

epoch-1 step 38100/3451022 - loss: 0.042972 val_loss: 0.039111	recall: 0.506550 precision: 0.895753

model exported!

epoch-1 step 38200/3451022 - loss: 0.045994 val_loss: 0.034442	recall: 0.485623 precision: 0.882012
epoch-1 step 38300/3451022 - loss: 0.038131 val_loss: 0.036475	recall: 0.502738 precision: 0.900000
epoch-1 step 38400/3451022 - loss: 0.034697 val_loss: 0.038193	recall: 0.493151 precision: 0.908738
epoch-1 step 38500/3451022 - loss: 0.036874 val_loss: 0.035711	recall: 0.513043 precision: 0.905950
epoch-1 step 38600/3451022 - loss: 0.036342 val_loss: 0.036397	recall: 0.491821 precision: 0.896620
epoch-1 step 38700/3451022 - loss: 0.034478 val_loss: 0.036452	recall: 0.502651 precision: 0.911538
epoch-1 step 38800/3451022 - loss: 0.035960 val_loss: 0.035766	recall: 0.511501 precision: 0.886148
epoch-1 step 38900/3451022 - loss: 0.040089 val_loss: 0.034278	recall: 0.529412 precision: 0.935728
epoch-1 step 39000/3451022 - loss: 0.034787 val_loss: 0.037429	recall: 0.480477 precision: 0.900407

checkpoint saved

epoch-1 step 39100/3451022 - loss: 0.038394 val_loss: 0.036778	recall: 0.516447 precision: 0.905769
epoch-1 step 39200/3451022 - loss: 0.036262 val_loss: 0.035993	recall: 0.514161 precision: 0.909441
epoch-1 step 39300/3451022 - loss: 0.034475 val_loss: 0.036590	recall: 0.520474 precision: 0.904494
epoch-1 step 39400/3451022 - loss: 0.034472 val_loss: 0.039127	recall: 0.531780 precision: 0.929630
epoch-1 step 39500/3451022 - loss: 0.037678 val_loss: 0.040075	recall: 0.520343 precision: 0.898336
epoch-1 step 39600/3451022 - loss: 0.034559 val_loss: 0.038640	recall: 0.489818 precision: 0.915832
epoch-1 step 39700/3451022 - loss: 0.034974 val_loss: 0.035443	recall: 0.518477 precision: 0.904297
epoch-1 step 39800/3451022 - loss: 0.035964 val_loss: 0.036294	recall: 0.483938 precision: 0.891221
epoch-1 step 39900/3451022 - loss: 0.042658 val_loss: 0.035012	recall: 0.514950 precision: 0.917160
epoch-1 step 40000/3451022 - loss: 0.038997 val_loss: 0.038883	recall: 0.501092 precision: 0.891262

checkpoint saved

epoch-1 step 40100/3451022 - loss: 0.035922 val_loss: 0.035574	recall: 0.480932 precision: 0.874759

model exported!

epoch-1 step 40200/3451022 - loss: 0.035562 val_loss: 0.036462	recall: 0.484504 precision: 0.889943
epoch-1 step 40300/3451022 - loss: 0.036957 val_loss: 0.035625	recall: 0.513173 precision: 0.899598
epoch-1 step 40400/3451022 - loss: 0.035643 val_loss: 0.035202	recall: 0.482030 precision: 0.906561
epoch-1 step 40500/3451022 - loss: 0.035044 val_loss: 0.039893	recall: 0.497297 precision: 0.910891
epoch-1 step 40600/3451022 - loss: 0.037878 val_loss: 0.035316	recall: 0.513100 precision: 0.917969
epoch-1 step 40700/3451022 - loss: 0.036562 val_loss: 0.035204	recall: 0.510686 precision: 0.902584
epoch-1 step 40800/3451022 - loss: 0.037311 val_loss: 0.035768	recall: 0.484615 precision: 0.907407
epoch-1 step 40900/3451022 - loss: 0.036141 val_loss: 0.035647	recall: 0.517915 precision: 0.896617
epoch-1 step 41000/3451022 - loss: 0.036073 val_loss: 0.035966	recall: 0.517817 precision: 0.894231

checkpoint saved

epoch-1 step 41100/3451022 - loss: 0.034917 val_loss: 0.036329	recall: 0.511450 precision: 0.907157
epoch-1 step 41200/3451022 - loss: 0.036464 val_loss: 0.035674	recall: 0.540479 precision: 0.909789
epoch-1 step 41300/3451022 - loss: 0.035348 val_loss: 0.034668	recall: 0.492834 precision: 0.883399
epoch-1 step 41400/3451022 - loss: 0.037654 val_loss: 0.034994	recall: 0.497802 precision: 0.876209
epoch-1 step 41500/3451022 - loss: 0.034538 val_loss: 0.039979	recall: 0.527192 precision: 0.911708
epoch-1 step 41600/3451022 - loss: 0.035056 val_loss: 0.036265	recall: 0.494553 precision: 0.893701
epoch-1 step 41700/3451022 - loss: 0.036477 val_loss: 0.039577	recall: 0.475410 precision: 0.873494
epoch-1 step 41800/3451022 - loss: 0.043321 val_loss: 0.034858	recall: 0.498357 precision: 0.881783
epoch-1 step 41900/3451022 - loss: 0.034721 val_loss: 0.034949	recall: 0.507987 precision: 0.948310
epoch-1 step 42000/3451022 - loss: 0.038377 val_loss: 0.035653	recall: 0.497797 precision: 0.881092

checkpoint saved

epoch-1 step 42100/3451022 - loss: 0.035777 val_loss: 0.041176	recall: 0.501636 precision: 0.881226

model exported!

epoch-1 step 42200/3451022 - loss: 0.038064 val_loss: 0.044562	recall: 0.518973 precision: 0.897683
epoch-1 step 42300/3451022 - loss: 0.039332 val_loss: 0.035259	recall: 0.530864 precision: 0.931102
epoch-1 step 42400/3451022 - loss: 0.034499 val_loss: 0.040660	recall: 0.468041 precision: 0.891945
epoch-1 step 42500/3451022 - loss: 0.038308 val_loss: 0.034116	recall: 0.533776 precision: 0.921606
epoch-1 step 42600/3451022 - loss: 0.037167 val_loss: 0.043200	recall: 0.519274 precision: 0.898039
epoch-1 step 42700/3451022 - loss: 0.036448 val_loss: 0.043176	recall: 0.527072 precision: 0.901701
epoch-1 step 42800/3451022 - loss: 0.038383 val_loss: 0.036747	recall: 0.490771 precision: 0.902196
epoch-1 step 42900/3451022 - loss: 0.048695 val_loss: 0.034350	recall: 0.522552 precision: 0.892857
epoch-1 step 43000/3451022 - loss: 0.041776 val_loss: 0.036579	recall: 0.506736 precision: 0.902214

checkpoint saved

epoch-1 step 43100/3451022 - loss: 0.037659 val_loss: 0.038324	recall: 0.491361 precision: 0.883495
epoch-1 step 43200/3451022 - loss: 0.038109 val_loss: 0.037386	recall: 0.493617 precision: 0.885496
epoch-1 step 43300/3451022 - loss: 0.034225 val_loss: 0.035740	recall: 0.514501 precision: 0.905482
epoch-1 step 43400/3451022 - loss: 0.037592 val_loss: 0.036876	recall: 0.500554 precision: 0.893281
epoch-1 step 43500/3451022 - loss: 0.039135 val_loss: 0.034016	recall: 0.514983 precision: 0.906250
epoch-1 step 43600/3451022 - loss: 0.037505 val_loss: 0.047477	recall: 0.507151 precision: 0.902153
epoch-1 step 43700/3451022 - loss: 0.037336 val_loss: 0.035175	recall: 0.517467 precision: 0.904580
epoch-1 step 43800/3451022 - loss: 0.035064 val_loss: 0.041450	recall: 0.507307 precision: 0.910112
epoch-1 step 43900/3451022 - loss: 0.034508 val_loss: 0.036403	recall: 0.484912 precision: 0.924603
epoch-1 step 44000/3451022 - loss: 0.036276 val_loss: 0.035815	recall: 0.539519 precision: 0.912791

checkpoint saved

epoch-1 step 44100/3451022 - loss: 0.036171 val_loss: 0.035426	recall: 0.501597 precision: 0.895437

model exported!

epoch-1 step 44200/3451022 - loss: 0.036012 val_loss: 0.036046	recall: 0.507511 precision: 0.895833
epoch-1 step 44300/3451022 - loss: 0.040557 val_loss: 0.041681	recall: 0.511653 precision: 0.906191
epoch-1 step 44400/3451022 - loss: 0.034354 val_loss: 0.039146	recall: 0.516830 precision: 0.904943
epoch-1 step 44500/3451022 - loss: 0.035094 val_loss: 0.037207	recall: 0.513187 precision: 0.892925
epoch-1 step 44600/3451022 - loss: 0.036201 val_loss: 0.037482	recall: 0.491821 precision: 0.884314
epoch-1 step 44700/3451022 - loss: 0.035978 val_loss: 0.035738	recall: 0.493136 precision: 0.881132
epoch-1 step 44800/3451022 - loss: 0.039805 val_loss: 0.034378	recall: 0.524336 precision: 0.908046
epoch-1 step 44900/3451022 - loss: 0.034763 val_loss: 0.035463	recall: 0.517915 precision: 0.912046
epoch-1 step 45000/3451022 - loss: 0.038327 val_loss: 0.044200	recall: 0.511777 precision: 0.910476

checkpoint saved

epoch-1 step 45100/3451022 - loss: 0.034633 val_loss: 0.036945	recall: 0.491081 precision: 0.891429
epoch-1 step 45200/3451022 - loss: 0.037666 val_loss: 0.037821	recall: 0.513627 precision: 0.910781
epoch-1 step 45300/3451022 - loss: 0.041232 val_loss: 0.045268	recall: 0.461924 precision: 0.902153
epoch-1 step 45400/3451022 - loss: 0.036695 val_loss: 0.037042	recall: 0.500534 precision: 0.916016
epoch-1 step 45500/3451022 - loss: 0.036731 val_loss: 0.038372	recall: 0.480620 precision: 0.871486
epoch-1 step 45600/3451022 - loss: 0.036307 val_loss: 0.035470	recall: 0.516165 precision: 0.888676
epoch-1 step 45700/3451022 - loss: 0.039075 val_loss: 0.034305	recall: 0.497291 precision: 0.886100
epoch-1 step 45800/3451022 - loss: 0.037735 val_loss: 0.041278	recall: 0.503319 precision: 0.881783
epoch-1 step 45900/3451022 - loss: 0.035868 val_loss: 0.035563	recall: 0.500000 precision: 0.912281
epoch-1 step 46000/3451022 - loss: 0.034799 val_loss: 0.035893	recall: 0.507973 precision: 0.881423

checkpoint saved

epoch-1 step 46100/3451022 - loss: 0.035403 val_loss: 0.036548	recall: 0.490302 precision: 0.883495

model exported!

epoch-1 step 46200/3451022 - loss: 0.037054 val_loss: 0.038693	recall: 0.495763 precision: 0.923077
epoch-1 step 46300/3451022 - loss: 0.040088 val_loss: 0.039131	recall: 0.471287 precision: 0.876611
epoch-1 step 46400/3451022 - loss: 0.036638 val_loss: 0.037840	recall: 0.506565 precision: 0.918651
epoch-1 step 46500/3451022 - loss: 0.037279 val_loss: 0.043709	recall: 0.500549 precision: 0.885437
epoch-1 step 46600/3451022 - loss: 0.036958 val_loss: 0.035511	recall: 0.500000 precision: 0.911153
epoch-1 step 46700/3451022 - loss: 0.037961 val_loss: 0.034539	recall: 0.518878 precision: 0.916190
epoch-1 step 46800/3451022 - loss: 0.035087 val_loss: 0.044049	recall: 0.519523 precision: 0.912381
epoch-1 step 46900/3451022 - loss: 0.039400 val_loss: 0.034641	recall: 0.500522 precision: 0.893657
epoch-1 step 47000/3451022 - loss: 0.043532 val_loss: 0.035879	recall: 0.508547 precision: 0.904943

checkpoint saved

epoch-1 step 47100/3451022 - loss: 0.035064 val_loss: 0.038993	recall: 0.511254 precision: 0.898305
epoch-1 step 47200/3451022 - loss: 0.039756 val_loss: 0.034582	recall: 0.488273 precision: 0.880769
epoch-1 step 47300/3451022 - loss: 0.037180 val_loss: 0.041266	recall: 0.508324 precision: 0.875717
epoch-1 step 47400/3451022 - loss: 0.040930 val_loss: 0.040018	recall: 0.500000 precision: 0.918762
epoch-1 step 47500/3451022 - loss: 0.035772 val_loss: 0.040958	recall: 0.514595 precision: 0.901515
epoch-1 step 47600/3451022 - loss: 0.036984 val_loss: 0.037286	recall: 0.488248 precision: 0.885659
epoch-1 step 47700/3451022 - loss: 0.039320 val_loss: 0.044109	recall: 0.507576 precision: 0.896750
epoch-1 step 47800/3451022 - loss: 0.034447 val_loss: 0.037977	recall: 0.526375 precision: 0.907157
epoch-1 step 47900/3451022 - loss: 0.035440 val_loss: 0.034152	recall: 0.485325 precision: 0.885277
epoch-1 step 48000/3451022 - loss: 0.034462 val_loss: 0.035578	recall: 0.543405 precision: 0.912879

checkpoint saved

epoch-1 step 48100/3451022 - loss: 0.036023 val_loss: 0.038690	recall: 0.500000 precision: 0.908549

model exported!

epoch-1 step 48200/3451022 - loss: 0.035236 val_loss: 0.034711	recall: 0.546154 precision: 0.934211
epoch-1 step 48300/3451022 - loss: 0.037658 val_loss: 0.043048	recall: 0.486316 precision: 0.880000
epoch-1 step 48400/3451022 - loss: 0.034597 val_loss: 0.036935	recall: 0.519126 precision: 0.935039
epoch-1 step 48500/3451022 - loss: 0.036347 val_loss: 0.034879	recall: 0.525219 precision: 0.915870
epoch-1 step 48600/3451022 - loss: 0.035942 val_loss: 0.035428	recall: 0.504692 precision: 0.918406
epoch-1 step 48700/3451022 - loss: 0.034547 val_loss: 0.037552	recall: 0.521111 precision: 0.905405
epoch-1 step 48800/3451022 - loss: 0.039606 val_loss: 0.037691	recall: 0.486081 precision: 0.893701
epoch-1 step 48900/3451022 - loss: 0.034941 val_loss: 0.039566	recall: 0.498375 precision: 0.882917
epoch-1 step 49000/3451022 - loss: 0.041916 val_loss: 0.034728	recall: 0.506383 precision: 0.906667

checkpoint saved

epoch-1 step 49100/3451022 - loss: 0.035490 val_loss: 0.042629	recall: 0.470405 precision: 0.902390
epoch-1 step 49200/3451022 - loss: 0.042533 val_loss: 0.048977	recall: 0.497886 precision: 0.892045
epoch-1 step 49300/3451022 - loss: 0.036464 val_loss: 0.034488	recall: 0.504386 precision: 0.882917
epoch-1 step 49400/3451022 - loss: 0.036324 val_loss: 0.039153	recall: 0.490155 precision: 0.927451
epoch-1 step 49500/3451022 - loss: 0.034448 val_loss: 0.037057	recall: 0.502151 precision: 0.910331
epoch-1 step 49600/3451022 - loss: 0.036344 val_loss: 0.035469	recall: 0.490625 precision: 0.902299
epoch-1 step 49700/3451022 - loss: 0.034236 val_loss: 0.035212	recall: 0.535433 precision: 0.929688
epoch-1 step 49800/3451022 - loss: 0.038793 val_loss: 0.038367	recall: 0.495662 precision: 0.906746
epoch-1 step 49900/3451022 - loss: 0.037521 val_loss: 0.034436	recall: 0.521595 precision: 0.893738
epoch-1 step 50000/3451022 - loss: 0.039262 val_loss: 0.035264	recall: 0.528944 precision: 0.894434

checkpoint saved

epoch-1 step 50100/3451022 - loss: 0.034560 val_loss: 0.040412	recall: 0.520092 precision: 0.889980

model exported!

epoch-1 step 50200/3451022 - loss: 0.040594 val_loss: 0.035744	recall: 0.496192 precision: 0.890625
epoch-1 step 50300/3451022 - loss: 0.035777 val_loss: 0.039701	recall: 0.497360 precision: 0.898855
epoch-1 step 50400/3451022 - loss: 0.035677 val_loss: 0.034976	recall: 0.497382 precision: 0.892857
epoch-1 step 50500/3451022 - loss: 0.036888 val_loss: 0.035566	recall: 0.506667 precision: 0.908367
epoch-1 step 50600/3451022 - loss: 0.036011 val_loss: 0.036328	recall: 0.492325 precision: 0.887352
epoch-1 step 50700/3451022 - loss: 0.038207 val_loss: 0.036980	recall: 0.517838 precision: 0.898687
epoch-1 step 50800/3451022 - loss: 0.039402 val_loss: 0.037724	recall: 0.491323 precision: 0.893491
epoch-1 step 50900/3451022 - loss: 0.044421 val_loss: 0.036864	recall: 0.489270 precision: 0.882012
epoch-1 step 51000/3451022 - loss: 0.038792 val_loss: 0.035336	recall: 0.523605 precision: 0.922495

checkpoint saved

epoch-1 step 51100/3451022 - loss: 0.036311 val_loss: 0.037976	recall: 0.503834 precision: 0.907298
epoch-1 step 51200/3451022 - loss: 0.034605 val_loss: 0.035449	recall: 0.533333 precision: 0.908752
epoch-1 step 51300/3451022 - loss: 0.036953 val_loss: 0.035066	recall: 0.520921 precision: 0.900542
epoch-1 step 51400/3451022 - loss: 0.038203 val_loss: 0.040824	recall: 0.527542 precision: 0.915441
epoch-1 step 51500/3451022 - loss: 0.044366 val_loss: 0.035341	recall: 0.513393 precision: 0.905512
epoch-1 step 51600/3451022 - loss: 0.037881 val_loss: 0.034648	recall: 0.496183 precision: 0.895669
epoch-1 step 51700/3451022 - loss: 0.037376 val_loss: 0.037946	recall: 0.534002 precision: 0.924710
epoch-1 step 51800/3451022 - loss: 0.034699 val_loss: 0.034832	recall: 0.519553 precision: 0.918972
epoch-1 step 51900/3451022 - loss: 0.041566 val_loss: 0.035980	recall: 0.522419 precision: 0.917582
epoch-1 step 52000/3451022 - loss: 0.034916 val_loss: 0.040486	recall: 0.493107 precision: 0.887405

checkpoint saved

epoch-1 step 52100/3451022 - loss: 0.034273 val_loss: 0.041081	recall: 0.513998 precision: 0.898239

model exported!

epoch-1 step 52200/3451022 - loss: 0.066971 val_loss: 0.042262	recall: 0.509761 precision: 0.905588
epoch-1 step 52300/3451022 - loss: 0.035222 val_loss: 0.045316	recall: 0.504702 precision: 0.914773
epoch-1 step 52400/3451022 - loss: 0.040742 val_loss: 0.035139	recall: 0.494635 precision: 0.911067
epoch-1 step 52500/3451022 - loss: 0.039617 val_loss: 0.044970	recall: 0.508929 precision: 0.882012
epoch-1 step 52600/3451022 - loss: 0.034680 val_loss: 0.036275	recall: 0.485972 precision: 0.918561
epoch-1 step 52700/3451022 - loss: 0.037014 val_loss: 0.038796	recall: 0.497320 precision: 0.916996
epoch-1 step 52800/3451022 - loss: 0.035459 val_loss: 0.042148	recall: 0.492912 precision: 0.905812
epoch-1 step 52900/3451022 - loss: 0.041291 val_loss: 0.037782	recall: 0.467213 precision: 0.901186
epoch-1 step 53000/3451022 - loss: 0.036559 val_loss: 0.036713	recall: 0.467098 precision: 0.867735

checkpoint saved

epoch-1 step 53100/3451022 - loss: 0.036558 val_loss: 0.039091	recall: 0.479409 precision: 0.900794
epoch-1 step 53200/3451022 - loss: 0.036704 val_loss: 0.035661	recall: 0.514563 precision: 0.913793
epoch-1 step 53300/3451022 - loss: 0.038499 val_loss: 0.037435	recall: 0.504348 precision: 0.890595
epoch-1 step 53400/3451022 - loss: 0.035205 val_loss: 0.037608	recall: 0.504301 precision: 0.896750
epoch-1 step 53500/3451022 - loss: 0.035207 val_loss: 0.038837	recall: 0.534368 precision: 0.899254
epoch-1 step 53600/3451022 - loss: 0.037485 val_loss: 0.040975	recall: 0.507119 precision: 0.895551
epoch-1 step 53700/3451022 - loss: 0.045257 val_loss: 0.042641	recall: 0.491005 precision: 0.908023
epoch-1 step 53800/3451022 - loss: 0.045558 val_loss: 0.036274	recall: 0.490751 precision: 0.893069
epoch-1 step 53900/3451022 - loss: 0.036343 val_loss: 0.047770	recall: 0.492130 precision: 0.910680
epoch-1 step 54000/3451022 - loss: 0.038501 val_loss: 0.036791	recall: 0.497899 precision: 0.897727

checkpoint saved

epoch-1 step 54100/3451022 - loss: 0.035401 val_loss: 0.037788	recall: 0.495671 precision: 0.905138

model exported!

epoch-1 step 54200/3451022 - loss: 0.042263 val_loss: 0.038065	recall: 0.490890 precision: 0.880769
epoch-1 step 54300/3451022 - loss: 0.035115 val_loss: 0.042803	recall: 0.477534 precision: 0.899606
epoch-1 step 54400/3451022 - loss: 0.035316 val_loss: 0.041415	recall: 0.540632 precision: 0.903774
epoch-1 step 54500/3451022 - loss: 0.036610 val_loss: 0.034926	recall: 0.518602 precision: 0.909091
epoch-1 step 54600/3451022 - loss: 0.035990 val_loss: 0.037538	recall: 0.488722 precision: 0.897436
epoch-1 step 54700/3451022 - loss: 0.040266 val_loss: 0.035501	recall: 0.495208 precision: 0.904669
epoch-1 step 54800/3451022 - loss: 0.047408 val_loss: 0.036441	recall: 0.493347 precision: 0.918095
epoch-1 step 54900/3451022 - loss: 0.038450 val_loss: 0.038040	recall: 0.465285 precision: 0.912602
epoch-1 step 55000/3451022 - loss: 0.041134 val_loss: 0.036343	recall: 0.515442 precision: 0.930769

checkpoint saved

epoch-1 step 55100/3451022 - loss: 0.034508 val_loss: 0.035934	recall: 0.507495 precision: 0.916828
epoch-1 step 55200/3451022 - loss: 0.037251 val_loss: 0.038537	recall: 0.517572 precision: 0.927481
epoch-1 step 55300/3451022 - loss: 0.035596 val_loss: 0.037772	recall: 0.517241 precision: 0.885714
epoch-1 step 55400/3451022 - loss: 0.036881 val_loss: 0.035204	recall: 0.507166 precision: 0.888031
epoch-1 step 55500/3451022 - loss: 0.041845 val_loss: 0.037640	recall: 0.501080 precision: 0.892308
epoch-1 step 55600/3451022 - loss: 0.040586 val_loss: 0.035365	recall: 0.524946 precision: 0.897959
epoch-1 step 55700/3451022 - loss: 0.036887 val_loss: 0.035461	recall: 0.482937 precision: 0.886148
epoch-1 step 55800/3451022 - loss: 0.034841 val_loss: 0.039581	recall: 0.480558 precision: 0.884404
epoch-1 step 55900/3451022 - loss: 0.039045 val_loss: 0.035471	recall: 0.508791 precision: 0.875236
epoch-1 step 56000/3451022 - loss: 0.036140 val_loss: 0.034658	recall: 0.488095 precision: 0.880859

checkpoint saved

epoch-1 step 56100/3451022 - loss: 0.037066 val_loss: 0.038176	recall: 0.540000 precision: 0.910112

model exported!

epoch-1 step 56200/3451022 - loss: 0.040743 val_loss: 0.037747	recall: 0.505882 precision: 0.879182
epoch-1 step 56300/3451022 - loss: 0.040404 val_loss: 0.035577	recall: 0.505017 precision: 0.886497
epoch-1 step 56400/3451022 - loss: 0.040626 val_loss: 0.040063	recall: 0.486688 precision: 0.877159
epoch-1 step 56500/3451022 - loss: 0.042506 val_loss: 0.044596	recall: 0.528177 precision: 0.924565
epoch-1 step 56600/3451022 - loss: 0.047943 val_loss: 0.042089	recall: 0.523008 precision: 0.897881
epoch-1 step 56700/3451022 - loss: 0.040126 val_loss: 0.037438	recall: 0.515608 precision: 0.903774
epoch-1 step 56800/3451022 - loss: 0.034578 val_loss: 0.037907	recall: 0.502720 precision: 0.891892
epoch-1 step 56900/3451022 - loss: 0.037252 val_loss: 0.034293	recall: 0.508475 precision: 0.903955
epoch-1 step 57000/3451022 - loss: 0.034389 val_loss: 0.034515	recall: 0.511628 precision: 0.904110

checkpoint saved

epoch-1 step 57100/3451022 - loss: 0.034443 val_loss: 0.035343	recall: 0.493576 precision: 0.889961
epoch-1 step 57200/3451022 - loss: 0.036371 val_loss: 0.035592	recall: 0.480519 precision: 0.865497
epoch-1 step 57300/3451022 - loss: 0.037106 val_loss: 0.035035	recall: 0.507973 precision: 0.877953
epoch-1 step 57400/3451022 - loss: 0.038212 val_loss: 0.035701	recall: 0.469957 precision: 0.862205
epoch-1 step 57500/3451022 - loss: 0.036617 val_loss: 0.035857	recall: 0.515952 precision: 0.921415
epoch-1 step 57600/3451022 - loss: 0.035246 val_loss: 0.034860	recall: 0.497859 precision: 0.897683
epoch-1 step 57700/3451022 - loss: 0.035649 val_loss: 0.036860	recall: 0.495317 precision: 0.924272
epoch-1 step 57800/3451022 - loss: 0.034640 val_loss: 0.035077	recall: 0.539301 precision: 0.946360
epoch-1 step 57900/3451022 - loss: 0.035173 val_loss: 0.035180	recall: 0.511376 precision: 0.900763
epoch-1 step 58000/3451022 - loss: 0.043927 val_loss: 0.033973	recall: 0.541096 precision: 0.887640

checkpoint saved

epoch-1 step 58100/3451022 - loss: 0.036449 val_loss: 0.039041	recall: 0.517475 precision: 0.882692

model exported!

epoch-1 step 58200/3451022 - loss: 0.037609 val_loss: 0.036265	recall: 0.536313 precision: 0.909091
epoch-1 step 58300/3451022 - loss: 0.039842 val_loss: 0.054571	recall: 0.502726 precision: 0.914683
epoch-1 step 58400/3451022 - loss: 0.040601 val_loss: 0.034347	recall: 0.520325 precision: 0.876712
epoch-1 step 58500/3451022 - loss: 0.038260 val_loss: 0.047822	recall: 0.525366 precision: 0.911937
epoch-1 step 58600/3451022 - loss: 0.038134 val_loss: 0.034216	recall: 0.496696 precision: 0.879142
epoch-1 step 58700/3451022 - loss: 0.035152 val_loss: 0.045256	recall: 0.511338 precision: 0.887795
epoch-1 step 58800/3451022 - loss: 0.036477 val_loss: 0.043189	recall: 0.524892 precision: 0.913371
epoch-1 step 58900/3451022 - loss: 0.037338 val_loss: 0.042877	recall: 0.508691 precision: 0.886869
epoch-1 step 59000/3451022 - loss: 0.036030 val_loss: 0.035003	recall: 0.523649 precision: 0.908203

checkpoint saved

epoch-1 step 59100/3451022 - loss: 0.035883 val_loss: 0.035651	recall: 0.508233 precision: 0.927856
epoch-1 step 59200/3451022 - loss: 0.037104 val_loss: 0.040792	recall: 0.507119 precision: 0.897287
epoch-1 step 59300/3451022 - loss: 0.045201 val_loss: 0.034936	recall: 0.512936 precision: 0.890625
epoch-1 step 59400/3451022 - loss: 0.034358 val_loss: 0.037413	recall: 0.501055 precision: 0.911708
epoch-1 step 59500/3451022 - loss: 0.036575 val_loss: 0.035449	recall: 0.498368 precision: 0.896282
epoch-1 step 59600/3451022 - loss: 0.035280 val_loss: 0.035426	recall: 0.506077 precision: 0.892788
epoch-1 step 59700/3451022 - loss: 0.036555 val_loss: 0.037165	recall: 0.496774 precision: 0.905882
epoch-1 step 59800/3451022 - loss: 0.041908 val_loss: 0.041742	recall: 0.532453 precision: 0.920152
epoch-1 step 59900/3451022 - loss: 0.038199 val_loss: 0.040221	recall: 0.494041 precision: 0.910180
epoch-1 step 60000/3451022 - loss: 0.035261 val_loss: 0.034870	recall: 0.521595 precision: 0.918129

checkpoint saved

epoch-1 step 60100/3451022 - loss: 0.036015 val_loss: 0.035549	recall: 0.496224 precision: 0.894942

model exported!

epoch-1 step 60200/3451022 - loss: 0.035626 val_loss: 0.036558	recall: 0.492616 precision: 0.892925
epoch-1 step 60300/3451022 - loss: 0.036910 val_loss: 0.037414	recall: 0.496288 precision: 0.912281
epoch-1 step 60400/3451022 - loss: 0.037296 val_loss: 0.034430	recall: 0.501059 precision: 0.894140
epoch-1 step 60500/3451022 - loss: 0.034921 val_loss: 0.035172	recall: 0.500000 precision: 0.881657
epoch-1 step 60600/3451022 - loss: 0.036723 val_loss: 0.035411	recall: 0.499444 precision: 0.905242
epoch-1 step 60700/3451022 - loss: 0.039166 val_loss: 0.038397	recall: 0.491927 precision: 0.892578
epoch-1 step 60800/3451022 - loss: 0.034615 val_loss: 0.037619	recall: 0.513216 precision: 0.885932
epoch-1 step 60900/3451022 - loss: 0.038616 val_loss: 0.041136	recall: 0.520087 precision: 0.902072
epoch-1 step 61000/3451022 - loss: 0.037430 val_loss: 0.041222	recall: 0.505028 precision: 0.888016

checkpoint saved

epoch-1 step 61100/3451022 - loss: 0.039013 val_loss: 0.037346	recall: 0.519868 precision: 0.909266
epoch-1 step 61200/3451022 - loss: 0.038622 val_loss: 0.035418	recall: 0.504193 precision: 0.930368
epoch-1 step 61300/3451022 - loss: 0.038364 val_loss: 0.037359	recall: 0.506011 precision: 0.900778
epoch-1 step 61400/3451022 - loss: 0.035461 val_loss: 0.038821	recall: 0.508056 precision: 0.897533
epoch-1 step 61500/3451022 - loss: 0.038659 val_loss: 0.034538	recall: 0.515660 precision: 0.891683
epoch-1 step 61600/3451022 - loss: 0.036458 val_loss: 0.033748	recall: 0.486229 precision: 0.916168
epoch-1 step 61700/3451022 - loss: 0.035376 val_loss: 0.043282	recall: 0.502165 precision: 0.890595
epoch-1 step 61800/3451022 - loss: 0.035546 val_loss: 0.034857	recall: 0.500000 precision: 0.900188
epoch-1 step 61900/3451022 - loss: 0.037687 val_loss: 0.035887	recall: 0.475309 precision: 0.916667
epoch-1 step 62000/3451022 - loss: 0.043941 val_loss: 0.034437	recall: 0.497886 precision: 0.919922

checkpoint saved

epoch-1 step 62100/3451022 - loss: 0.038481 val_loss: 0.044023	recall: 0.510360 precision: 0.903475

model exported!

epoch-1 step 62200/3451022 - loss: 0.036320 val_loss: 0.035543	recall: 0.483402 precision: 0.894434
epoch-1 step 62300/3451022 - loss: 0.035906 val_loss: 0.034583	recall: 0.524444 precision: 0.900763
epoch-1 step 62400/3451022 - loss: 0.037317 val_loss: 0.037057	recall: 0.529755 precision: 0.881553
epoch-1 step 62500/3451022 - loss: 0.037526 val_loss: 0.040586	recall: 0.537190 precision: 0.924797
epoch-1 step 62600/3451022 - loss: 0.039642 val_loss: 0.039657	recall: 0.530973 precision: 0.912548
epoch-1 step 62700/3451022 - loss: 0.038411 val_loss: 0.035607	recall: 0.495754 precision: 0.896353
epoch-1 step 62800/3451022 - loss: 0.037501 val_loss: 0.038604	recall: 0.483736 precision: 0.920160
epoch-1 step 62900/3451022 - loss: 0.034095 val_loss: 0.036599	recall: 0.515917 precision: 0.905588
epoch-1 step 63000/3451022 - loss: 0.037643 val_loss: 0.047922	recall: 0.479581 precision: 0.887597

checkpoint saved

epoch-1 step 63100/3451022 - loss: 0.042828 val_loss: 0.044750	recall: 0.521348 precision: 0.899225
epoch-1 step 63200/3451022 - loss: 0.036911 val_loss: 0.044447	recall: 0.498375 precision: 0.884615
epoch-1 step 63300/3451022 - loss: 0.037662 val_loss: 0.043673	recall: 0.523333 precision: 0.898855
epoch-1 step 63400/3451022 - loss: 0.034598 val_loss: 0.035928	recall: 0.492616 precision: 0.879473
epoch-1 step 63500/3451022 - loss: 0.037659 val_loss: 0.037871	recall: 0.496809 precision: 0.910331
epoch-1 step 63600/3451022 - loss: 0.034442 val_loss: 0.037235	recall: 0.495082 precision: 0.883041
epoch-1 step 63700/3451022 - loss: 0.039161 val_loss: 0.036182	recall: 0.516165 precision: 0.899029
epoch-1 step 63800/3451022 - loss: 0.035052 val_loss: 0.034927	recall: 0.497377 precision: 0.890977
epoch-1 step 63900/3451022 - loss: 0.035177 val_loss: 0.034934	recall: 0.519210 precision: 0.907869
epoch-1 step 64000/3451022 - loss: 0.039628 val_loss: 0.039176	recall: 0.535260 precision: 0.888676

checkpoint saved

epoch-1 step 64100/3451022 - loss: 0.040420 val_loss: 0.036236	recall: 0.485169 precision: 0.906931

model exported!

epoch-1 step 64200/3451022 - loss: 0.038478 val_loss: 0.040204	recall: 0.529809 precision: 0.887006
epoch-1 step 64300/3451022 - loss: 0.036802 val_loss: 0.034744	recall: 0.495268 precision: 0.918129
epoch-1 step 64400/3451022 - loss: 0.035675 val_loss: 0.034899	recall: 0.503619 precision: 0.929389
epoch-1 step 64500/3451022 - loss: 0.037635 val_loss: 0.037494	recall: 0.501080 precision: 0.895753
epoch-1 step 64600/3451022 - loss: 0.037217 val_loss: 0.035115	recall: 0.498927 precision: 0.884030
epoch-1 step 64700/3451022 - loss: 0.037835 val_loss: 0.037645	recall: 0.500518 precision: 0.909605
epoch-1 step 64800/3451022 - loss: 0.036591 val_loss: 0.035400	recall: 0.489119 precision: 0.930966
epoch-1 step 64900/3451022 - loss: 0.037967 val_loss: 0.039246	recall: 0.513333 precision: 0.918489
epoch-1 step 65000/3451022 - loss: 0.040391 val_loss: 0.035494	recall: 0.488033 precision: 0.893333

checkpoint saved

epoch-1 step 65100/3451022 - loss: 0.035448 val_loss: 0.036426	recall: 0.537143 precision: 0.888469
epoch-1 step 65200/3451022 - loss: 0.039600 val_loss: 0.034709	recall: 0.504940 precision: 0.889749
epoch-1 step 65300/3451022 - loss: 0.034355 val_loss: 0.044649	recall: 0.504950 precision: 0.898239
epoch-1 step 65400/3451022 - loss: 0.036770 val_loss: 0.035268	recall: 0.497231 precision: 0.880392
epoch-1 step 65500/3451022 - loss: 0.042981 val_loss: 0.035704	recall: 0.544248 precision: 0.912801
epoch-1 step 65600/3451022 - loss: 0.036986 val_loss: 0.037833	recall: 0.539071 precision: 0.908397
epoch-1 step 65700/3451022 - loss: 0.040536 val_loss: 0.035182	recall: 0.518477 precision: 0.895551
epoch-1 step 65800/3451022 - loss: 0.035226 val_loss: 0.039876	recall: 0.509868 precision: 0.882353
epoch-1 step 65900/3451022 - loss: 0.039501 val_loss: 0.034442	recall: 0.548499 precision: 0.931373
epoch-1 step 66000/3451022 - loss: 0.034444 val_loss: 0.036298	recall: 0.537430 precision: 0.910985

checkpoint saved

epoch-1 step 66100/3451022 - loss: 0.038139 val_loss: 0.038133	recall: 0.513333 precision: 0.911243

model exported!

epoch-1 step 66200/3451022 - loss: 0.035244 val_loss: 0.037488	recall: 0.496320 precision: 0.911197
epoch-1 step 66300/3451022 - loss: 0.038346 val_loss: 0.037704	recall: 0.503151 precision: 0.912381
epoch-1 step 66400/3451022 - loss: 0.034931 val_loss: 0.034761	recall: 0.500000 precision: 0.897338
epoch-1 step 66500/3451022 - loss: 0.034798 val_loss: 0.040113	recall: 0.518717 precision: 0.908240
epoch-1 step 66600/3451022 - loss: 0.038414 val_loss: 0.035123	recall: 0.536026 precision: 0.905904
epoch-1 step 66700/3451022 - loss: 0.035122 val_loss: 0.035417	recall: 0.504376 precision: 0.884837
epoch-1 step 66800/3451022 - loss: 0.037085 val_loss: 0.037102	recall: 0.519868 precision: 0.911025
epoch-1 step 66900/3451022 - loss: 0.037041 val_loss: 0.043752	recall: 0.484234 precision: 0.866935
epoch-1 step 67000/3451022 - loss: 0.036894 val_loss: 0.034302	recall: 0.489685 precision: 0.907445

checkpoint saved

epoch-1 step 67100/3451022 - loss: 0.034951 val_loss: 0.034732	recall: 0.529025 precision: 0.928846
epoch-1 step 67200/3451022 - loss: 0.036583 val_loss: 0.035717	recall: 0.482239 precision: 0.876712
epoch-1 step 67300/3451022 - loss: 0.034720 val_loss: 0.036950	recall: 0.533708 precision: 0.894539
epoch-1 step 67400/3451022 - loss: 0.038426 val_loss: 0.041949	recall: 0.472551 precision: 0.860784
epoch-1 step 67500/3451022 - loss: 0.035255 val_loss: 0.034410	recall: 0.499494 precision: 0.901460
epoch-1 step 67600/3451022 - loss: 0.034494 val_loss: 0.036139	recall: 0.515837 precision: 0.897638
epoch-1 step 67700/3451022 - loss: 0.035549 val_loss: 0.040543	recall: 0.512141 precision: 0.894027
epoch-1 step 67800/3451022 - loss: 0.040139 val_loss: 0.046158	recall: 0.497845 precision: 0.900585
epoch-1 step 67900/3451022 - loss: 0.034903 val_loss: 0.049293	recall: 0.535991 precision: 0.923664
epoch-1 step 68000/3451022 - loss: 0.033906 val_loss: 0.040954	recall: 0.497872 precision: 0.886364

checkpoint saved

epoch-1 step 68100/3451022 - loss: 0.035360 val_loss: 0.046183	recall: 0.501075 precision: 0.896154

model exported!

epoch-1 step 68200/3451022 - loss: 0.038431 val_loss: 0.034812	recall: 0.526602 precision: 0.906542
epoch-1 step 68300/3451022 - loss: 0.036124 val_loss: 0.038807	recall: 0.518814 precision: 0.880077
epoch-1 step 68400/3451022 - loss: 0.035230 val_loss: 0.039459	recall: 0.514029 precision: 0.885880
epoch-1 step 68500/3451022 - loss: 0.035017 val_loss: 0.035631	recall: 0.526659 precision: 0.906367
epoch-1 step 68600/3451022 - loss: 0.035850 val_loss: 0.039182	recall: 0.510783 precision: 0.898204
epoch-1 step 68700/3451022 - loss: 0.049073 val_loss: 0.038567	recall: 0.478769 precision: 0.870656
epoch-1 step 68800/3451022 - loss: 0.035264 val_loss: 0.042952	recall: 0.520904 precision: 0.889961
epoch-1 step 68900/3451022 - loss: 0.035214 val_loss: 0.037965	recall: 0.496809 precision: 0.894636
epoch-1 step 69000/3451022 - loss: 0.036994 val_loss: 0.037366	recall: 0.525330 precision: 0.901701

checkpoint saved

epoch-1 step 69100/3451022 - loss: 0.035429 val_loss: 0.034412	recall: 0.522602 precision: 0.901141
epoch-1 step 69200/3451022 - loss: 0.035737 val_loss: 0.037036	recall: 0.493333 precision: 0.889780
epoch-1 step 69300/3451022 - loss: 0.037215 val_loss: 0.037504	recall: 0.505330 precision: 0.911538
epoch-1 step 69400/3451022 - loss: 0.038668 val_loss: 0.040379	recall: 0.537378 precision: 0.913444
epoch-1 step 69500/3451022 - loss: 0.035062 val_loss: 0.035872	recall: 0.510135 precision: 0.900596
epoch-1 step 69600/3451022 - loss: 0.034472 val_loss: 0.037346	recall: 0.490870 precision: 0.892578
epoch-1 step 69700/3451022 - loss: 0.049085 val_loss: 0.036468	recall: 0.557714 precision: 0.903704
epoch-1 step 69800/3451022 - loss: 0.035717 val_loss: 0.034549	recall: 0.521231 precision: 0.907579
epoch-1 step 69900/3451022 - loss: 0.037854 val_loss: 0.038946	recall: 0.509033 precision: 0.910646
epoch-1 step 70000/3451022 - loss: 0.038143 val_loss: 0.034656	recall: 0.509249 precision: 0.894837

checkpoint saved

epoch-1 step 70100/3451022 - loss: 0.036045 val_loss: 0.043948	recall: 0.504484 precision: 0.892857

model exported!

epoch-1 step 70200/3451022 - loss: 0.045862 val_loss: 0.040461	recall: 0.498899 precision: 0.877907
epoch-1 step 70300/3451022 - loss: 0.035598 val_loss: 0.038623	recall: 0.516094 precision: 0.914449
epoch-1 step 70400/3451022 - loss: 0.041567 val_loss: 0.034348	recall: 0.529148 precision: 0.904215
epoch-1 step 70500/3451022 - loss: 0.041016 val_loss: 0.036575	recall: 0.471241 precision: 0.894636
epoch-1 step 70600/3451022 - loss: 0.043380 val_loss: 0.035604	recall: 0.495633 precision: 0.899010
epoch-1 step 70700/3451022 - loss: 0.035377 val_loss: 0.039296	recall: 0.498389 precision: 0.880455
epoch-1 step 70800/3451022 - loss: 0.034968 val_loss: 0.035869	recall: 0.501066 precision: 0.912621
epoch-1 step 70900/3451022 - loss: 0.035976 val_loss: 0.037540	recall: 0.523438 precision: 0.886578
epoch-1 step 71000/3451022 - loss: 0.037314 val_loss: 0.034801	recall: 0.495726 precision: 0.895753

checkpoint saved

epoch-1 step 71100/3451022 - loss: 0.034793 val_loss: 0.038813	recall: 0.524416 precision: 0.908088
epoch-1 step 71200/3451022 - loss: 0.036179 val_loss: 0.035159	recall: 0.517778 precision: 0.880907
epoch-1 step 71300/3451022 - loss: 0.040950 val_loss: 0.040875	recall: 0.491657 precision: 0.891129
epoch-1 step 71400/3451022 - loss: 0.037353 val_loss: 0.037339	recall: 0.527497 precision: 0.916179
epoch-1 step 71500/3451022 - loss: 0.042394 val_loss: 0.035207	recall: 0.501109 precision: 0.911290
epoch-1 step 71600/3451022 - loss: 0.034421 val_loss: 0.037336	recall: 0.506329 precision: 0.917782
epoch-1 step 71700/3451022 - loss: 0.035411 val_loss: 0.035088	recall: 0.496141 precision: 0.882353
epoch-1 step 71800/3451022 - loss: 0.042496 val_loss: 0.036302	recall: 0.502217 precision: 0.891732
epoch-1 step 71900/3451022 - loss: 0.038901 val_loss: 0.037334	recall: 0.527778 precision: 0.911708
epoch-1 step 72000/3451022 - loss: 0.044192 val_loss: 0.038317	recall: 0.517544 precision: 0.902486

checkpoint saved

epoch-1 step 72100/3451022 - loss: 0.034226 val_loss: 0.035992	recall: 0.518559 precision: 0.904762

model exported!

epoch-1 step 72200/3451022 - loss: 0.036326 val_loss: 0.034475	recall: 0.528281 precision: 0.921105
epoch-1 step 72300/3451022 - loss: 0.034953 val_loss: 0.036196	recall: 0.503311 precision: 0.875240
epoch-1 step 72400/3451022 - loss: 0.035725 val_loss: 0.036343	recall: 0.523707 precision: 0.923954
epoch-1 step 72500/3451022 - loss: 0.040167 val_loss: 0.035910	recall: 0.492927 precision: 0.891732
epoch-1 step 72600/3451022 - loss: 0.042836 val_loss: 0.035382	recall: 0.535714 precision: 0.884030
epoch-1 step 72700/3451022 - loss: 0.040821 val_loss: 0.038454	recall: 0.510248 precision: 0.902672
epoch-1 step 72800/3451022 - loss: 0.037459 val_loss: 0.035991	recall: 0.517058 precision: 0.949119
epoch-1 step 72900/3451022 - loss: 0.046203 val_loss: 0.038376	recall: 0.511111 precision: 0.909605
epoch-1 step 73000/3451022 - loss: 0.036761 val_loss: 0.037252	recall: 0.508403 precision: 0.904673

checkpoint saved

epoch-1 step 73100/3451022 - loss: 0.046039 val_loss: 0.039794	recall: 0.500527 precision: 0.908222
epoch-1 step 73200/3451022 - loss: 0.037441 val_loss: 0.035428	recall: 0.495125 precision: 0.863894
epoch-1 step 73300/3451022 - loss: 0.038435 val_loss: 0.036712	recall: 0.501508 precision: 0.915596
epoch-1 step 73400/3451022 - loss: 0.040740 val_loss: 0.036041	recall: 0.504301 precision: 0.903661
epoch-1 step 73500/3451022 - loss: 0.035025 val_loss: 0.034657	recall: 0.512596 precision: 0.912281
epoch-1 step 73600/3451022 - loss: 0.036991 val_loss: 0.042119	recall: 0.487958 precision: 0.887619
epoch-1 step 73700/3451022 - loss: 0.036914 val_loss: 0.035268	recall: 0.497886 precision: 0.898855
epoch-1 step 73800/3451022 - loss: 0.037090 val_loss: 0.034298	recall: 0.498947 precision: 0.913295
epoch-1 step 73900/3451022 - loss: 0.038185 val_loss: 0.038932	recall: 0.491979 precision: 0.891473
epoch-1 step 74000/3451022 - loss: 0.036067 val_loss: 0.036840	recall: 0.495604 precision: 0.891304

checkpoint saved

epoch-1 step 74100/3451022 - loss: 0.037841 val_loss: 0.040080	recall: 0.508696 precision: 0.900000

model exported!

epoch-1 step 74200/3451022 - loss: 0.035470 val_loss: 0.035885	recall: 0.521834 precision: 0.924565
epoch-1 step 74300/3451022 - loss: 0.037117 val_loss: 0.035750	recall: 0.513187 precision: 0.908560
epoch-1 step 74400/3451022 - loss: 0.037803 val_loss: 0.035966	recall: 0.505400 precision: 0.919450
epoch-1 step 74500/3451022 - loss: 0.036018 val_loss: 0.039010	recall: 0.471698 precision: 0.905433
epoch-1 step 74600/3451022 - loss: 0.036548 val_loss: 0.041068	recall: 0.496249 precision: 0.929719
epoch-1 step 74700/3451022 - loss: 0.036770 val_loss: 0.039140	recall: 0.502623 precision: 0.931907
epoch-1 step 74800/3451022 - loss: 0.039283 val_loss: 0.035815	recall: 0.504237 precision: 0.918919
epoch-1 step 74900/3451022 - loss: 0.035958 val_loss: 0.036208	recall: 0.496257 precision: 0.908023
epoch-1 step 75000/3451022 - loss: 0.035567 val_loss: 0.035148	recall: 0.519535 precision: 0.921348

checkpoint saved

epoch-1 step 75100/3451022 - loss: 0.037386 val_loss: 0.036801	recall: 0.512848 precision: 0.907197
epoch-1 step 75200/3451022 - loss: 0.040055 val_loss: 0.035795	recall: 0.500522 precision: 0.931907
epoch-1 step 75300/3451022 - loss: 0.039735 val_loss: 0.036785	recall: 0.493548 precision: 0.894737
epoch-1 step 75400/3451022 - loss: 0.035200 val_loss: 0.039476	recall: 0.500000 precision: 0.897143
epoch-1 step 75500/3451022 - loss: 0.035246 val_loss: 0.038683	recall: 0.534642 precision: 0.897287
epoch-1 step 75600/3451022 - loss: 0.039693 val_loss: 0.034718	recall: 0.509494 precision: 0.906191
epoch-1 step 75700/3451022 - loss: 0.035630 val_loss: 0.038094	recall: 0.529540 precision: 0.928983
epoch-1 step 75800/3451022 - loss: 0.037384 val_loss: 0.036734	recall: 0.470711 precision: 0.892857
epoch-1 step 75900/3451022 - loss: 0.040656 val_loss: 0.036031	recall: 0.508677 precision: 0.910680
epoch-1 step 76000/3451022 - loss: 0.036960 val_loss: 0.034326	recall: 0.510226 precision: 0.915058

checkpoint saved

epoch-1 step 76100/3451022 - loss: 0.045000 val_loss: 0.036679	recall: 0.478215 precision: 0.878906

model exported!

epoch-1 step 76200/3451022 - loss: 0.036915 val_loss: 0.035924	recall: 0.504950 precision: 0.901768
epoch-1 step 76300/3451022 - loss: 0.034897 val_loss: 0.042902	recall: 0.515625 precision: 0.905882
epoch-1 step 76400/3451022 - loss: 0.033881 val_loss: 0.044575	recall: 0.490870 precision: 0.901381
epoch-1 step 76500/3451022 - loss: 0.034403 val_loss: 0.036291	recall: 0.492030 precision: 0.904297
epoch-1 step 76600/3451022 - loss: 0.036661 val_loss: 0.041221	recall: 0.501661 precision: 0.900596
epoch-1 step 76700/3451022 - loss: 0.038733 val_loss: 0.035472	recall: 0.529944 precision: 0.923228
epoch-1 step 76800/3451022 - loss: 0.048380 val_loss: 0.037497	recall: 0.524083 precision: 0.908549
epoch-1 step 76900/3451022 - loss: 0.040518 val_loss: 0.047084	recall: 0.528970 precision: 0.909594
epoch-1 step 77000/3451022 - loss: 0.034600 val_loss: 0.035603	recall: 0.512936 precision: 0.904762

checkpoint saved

epoch-1 step 77100/3451022 - loss: 0.035412 val_loss: 0.040378	recall: 0.544956 precision: 0.923792
epoch-1 step 77200/3451022 - loss: 0.036583 val_loss: 0.041386	recall: 0.509677 precision: 0.897727
epoch-1 step 77300/3451022 - loss: 0.044441 val_loss: 0.041540	recall: 0.522573 precision: 0.929719
epoch-1 step 77400/3451022 - loss: 0.038524 val_loss: 0.036114	recall: 0.482723 precision: 0.893411
epoch-1 step 77500/3451022 - loss: 0.036232 val_loss: 0.037768	recall: 0.507042 precision: 0.883019
epoch-1 step 77600/3451022 - loss: 0.035566 val_loss: 0.037354	recall: 0.513363 precision: 0.878095
epoch-1 step 77700/3451022 - loss: 0.039861 val_loss: 0.037484	recall: 0.503800 precision: 0.913386
epoch-1 step 77800/3451022 - loss: 0.037076 val_loss: 0.038076	recall: 0.524390 precision: 0.911368
epoch-1 step 77900/3451022 - loss: 0.034645 val_loss: 0.035743	recall: 0.511088 precision: 0.937984
epoch-1 step 78000/3451022 - loss: 0.035499 val_loss: 0.035581	recall: 0.493320 precision: 0.917782

checkpoint saved

epoch-1 step 78100/3451022 - loss: 0.034739 val_loss: 0.034645	recall: 0.533024 precision: 0.882917

model exported!

epoch-1 step 78200/3451022 - loss: 0.036867 val_loss: 0.051268	recall: 0.478964 precision: 0.896970
epoch-1 step 78300/3451022 - loss: 0.036668 val_loss: 0.038766	recall: 0.498399 precision: 0.891221
epoch-1 step 78400/3451022 - loss: 0.036376 val_loss: 0.036035	recall: 0.522484 precision: 0.912150
epoch-1 step 78500/3451022 - loss: 0.034960 val_loss: 0.035820	recall: 0.501099 precision: 0.902970
epoch-1 step 78600/3451022 - loss: 0.039590 val_loss: 0.038508	recall: 0.491342 precision: 0.900794
epoch-1 step 78700/3451022 - loss: 0.037113 val_loss: 0.038886	recall: 0.519126 precision: 0.911708
epoch-1 step 78800/3451022 - loss: 0.039073 val_loss: 0.036313	recall: 0.529885 precision: 0.909270
epoch-1 step 78900/3451022 - loss: 0.035834 val_loss: 0.035377	recall: 0.504175 precision: 0.928846
epoch-1 step 79000/3451022 - loss: 0.035455 val_loss: 0.039717	recall: 0.516930 precision: 0.889320

checkpoint saved

epoch-1 step 79100/3451022 - loss: 0.035444 val_loss: 0.038185	recall: 0.479701 precision: 0.889109
epoch-1 step 79200/3451022 - loss: 0.037917 val_loss: 0.036401	recall: 0.501618 precision: 0.892514
epoch-1 step 79300/3451022 - loss: 0.043342 val_loss: 0.039965	recall: 0.490022 precision: 0.864971
epoch-1 step 79400/3451022 - loss: 0.035042 val_loss: 0.035309	recall: 0.513340 precision: 0.925000
epoch-1 step 79500/3451022 - loss: 0.035362 val_loss: 0.035710	recall: 0.506356 precision: 0.908745
epoch-1 step 79600/3451022 - loss: 0.035272 val_loss: 0.040337	recall: 0.511732 precision: 0.917836
epoch-1 step 79700/3451022 - loss: 0.036097 val_loss: 0.037057	recall: 0.528446 precision: 0.920000
epoch-1 step 79800/3451022 - loss: 0.035022 val_loss: 0.033896	recall: 0.462019 precision: 0.893360
epoch-1 step 79900/3451022 - loss: 0.036783 val_loss: 0.035118	recall: 0.477250 precision: 0.885553
epoch-1 step 80000/3451022 - loss: 0.035930 val_loss: 0.034882	recall: 0.507119 precision: 0.902534

checkpoint saved

epoch-1 step 80100/3451022 - loss: 0.038908 val_loss: 0.038080	recall: 0.525330 precision: 0.926214

model exported!

epoch-1 step 80200/3451022 - loss: 0.037329 val_loss: 0.036977	recall: 0.516779 precision: 0.911243
epoch-1 step 80300/3451022 - loss: 0.036069 val_loss: 0.051358	recall: 0.516484 precision: 0.909091
epoch-1 step 80400/3451022 - loss: 0.035755 val_loss: 0.039264	recall: 0.514950 precision: 0.885714
epoch-1 step 80500/3451022 - loss: 0.035020 val_loss: 0.034586	recall: 0.522453 precision: 0.915547
epoch-1 step 80600/3451022 - loss: 0.047027 val_loss: 0.038260	recall: 0.496224 precision: 0.900196
epoch-1 step 80700/3451022 - loss: 0.038064 val_loss: 0.035115	recall: 0.519031 precision: 0.894632
epoch-1 step 80800/3451022 - loss: 0.033656 val_loss: 0.035297	recall: 0.502174 precision: 0.905882
epoch-1 step 80900/3451022 - loss: 0.035740 val_loss: 0.034561	recall: 0.510182 precision: 0.908397
epoch-1 step 81000/3451022 - loss: 0.041683 val_loss: 0.041490	recall: 0.498934 precision: 0.924901

checkpoint saved

epoch-1 step 81100/3451022 - loss: 0.038824 val_loss: 0.036276	recall: 0.525481 precision: 0.922465
epoch-1 step 81200/3451022 - loss: 0.038408 val_loss: 0.037557	recall: 0.500526 precision: 0.922481
epoch-1 step 81300/3451022 - loss: 0.042265 val_loss: 0.043747	recall: 0.493697 precision: 0.898662
epoch-1 step 81400/3451022 - loss: 0.045494 val_loss: 0.037884	recall: 0.500525 precision: 0.883333
epoch-1 step 81500/3451022 - loss: 0.036419 val_loss: 0.037998	recall: 0.546875 precision: 0.929791
epoch-1 step 81600/3451022 - loss: 0.034959 val_loss: 0.035173	recall: 0.497904 precision: 0.899621
epoch-1 step 81700/3451022 - loss: 0.035787 val_loss: 0.034611	recall: 0.541528 precision: 0.905556
epoch-1 step 81800/3451022 - loss: 0.039801 val_loss: 0.039781	recall: 0.526140 precision: 0.880819
epoch-1 step 81900/3451022 - loss: 0.036862 val_loss: 0.036389	recall: 0.508658 precision: 0.917969
epoch-1 step 82000/3451022 - loss: 0.035637 val_loss: 0.041970	recall: 0.502222 precision: 0.860952

checkpoint saved

epoch-1 step 82100/3451022 - loss: 0.034961 val_loss: 0.036043	recall: 0.512273 precision: 0.903955

model exported!

epoch-1 step 82200/3451022 - loss: 0.037593 val_loss: 0.038434	recall: 0.501618 precision: 0.897683
epoch-1 step 82300/3451022 - loss: 0.036888 val_loss: 0.038455	recall: 0.502793 precision: 0.882353
epoch-1 step 82400/3451022 - loss: 0.036491 val_loss: 0.040742	recall: 0.493603 precision: 0.890385
epoch-1 step 82500/3451022 - loss: 0.035776 val_loss: 0.036042	recall: 0.485468 precision: 0.898406
epoch-1 step 82600/3451022 - loss: 0.041834 val_loss: 0.035550	recall: 0.516866 precision: 0.927734
epoch-1 step 82700/3451022 - loss: 0.042109 val_loss: 0.039870	recall: 0.521930 precision: 0.911877
epoch-1 step 82800/3451022 - loss: 0.048164 val_loss: 0.040708	recall: 0.510112 precision: 0.902584
epoch-1 step 82900/3451022 - loss: 0.039546 val_loss: 0.035910	recall: 0.523482 precision: 0.897839
epoch-1 step 83000/3451022 - loss: 0.035226 val_loss: 0.049940	recall: 0.502208 precision: 0.880077

checkpoint saved

epoch-1 step 83100/3451022 - loss: 0.034833 val_loss: 0.035325	recall: 0.515882 precision: 0.902299
epoch-1 step 83200/3451022 - loss: 0.036063 val_loss: 0.035433	recall: 0.488889 precision: 0.865169
epoch-1 step 83300/3451022 - loss: 0.034083 val_loss: 0.037071	recall: 0.506342 precision: 0.919386
epoch-1 step 83400/3451022 - loss: 0.039875 val_loss: 0.035722	recall: 0.481323 precision: 0.886051
epoch-1 step 83500/3451022 - loss: 0.034776 val_loss: 0.035946	recall: 0.507119 precision: 0.899029
epoch-1 step 83600/3451022 - loss: 0.035741 val_loss: 0.036439	recall: 0.495208 precision: 0.869159
epoch-1 step 83700/3451022 - loss: 0.034657 val_loss: 0.037035	recall: 0.515766 precision: 0.892788
epoch-1 step 83800/3451022 - loss: 0.036343 val_loss: 0.039962	recall: 0.506967 precision: 0.918447
epoch-1 step 83900/3451022 - loss: 0.035645 val_loss: 0.035637	recall: 0.516520 precision: 0.895038
epoch-1 step 84000/3451022 - loss: 0.035615 val_loss: 0.035409	recall: 0.500000 precision: 0.882353

checkpoint saved

epoch-1 step 84100/3451022 - loss: 0.034853 val_loss: 0.036242	recall: 0.497925 precision: 0.926641

model exported!

epoch-1 step 84200/3451022 - loss: 0.036413 val_loss: 0.036376	recall: 0.505519 precision: 0.882466
epoch-1 step 84300/3451022 - loss: 0.041477 val_loss: 0.036463	recall: 0.487288 precision: 0.876190
epoch-1 step 84400/3451022 - loss: 0.037549 val_loss: 0.036246	recall: 0.508811 precision: 0.897087
epoch-1 step 84500/3451022 - loss: 0.035254 val_loss: 0.034488	recall: 0.485531 precision: 0.877907
epoch-1 step 84600/3451022 - loss: 0.039563 val_loss: 0.033941	recall: 0.530134 precision: 0.913462
epoch-1 step 84700/3451022 - loss: 0.038573 val_loss: 0.036360	recall: 0.515991 precision: 0.908068
epoch-1 step 84800/3451022 - loss: 0.037120 val_loss: 0.035008	recall: 0.513304 precision: 0.902534
epoch-1 step 84900/3451022 - loss: 0.038964 val_loss: 0.035706	recall: 0.528649 precision: 0.924386
epoch-1 step 85000/3451022 - loss: 0.034383 val_loss: 0.035319	recall: 0.504255 precision: 0.892655

checkpoint saved

epoch-1 step 85100/3451022 - loss: 0.036006 val_loss: 0.046933	recall: 0.472107 precision: 0.908549
epoch-1 step 85200/3451022 - loss: 0.037495 val_loss: 0.035612	recall: 0.502646 precision: 0.899621
epoch-1 step 85300/3451022 - loss: 0.036785 val_loss: 0.037254	recall: 0.528825 precision: 0.898305
epoch-1 step 85400/3451022 - loss: 0.036074 val_loss: 0.036887	recall: 0.495298 precision: 0.925781
epoch-1 step 85500/3451022 - loss: 0.035545 val_loss: 0.034732	recall: 0.497338 precision: 0.889524
epoch-1 step 85600/3451022 - loss: 0.034019 val_loss: 0.037052	recall: 0.473788 precision: 0.877289
epoch-1 step 85700/3451022 - loss: 0.036809 val_loss: 0.035722	recall: 0.500000 precision: 0.898438
epoch-1 step 85800/3451022 - loss: 0.036621 val_loss: 0.038955	recall: 0.544622 precision: 0.915385
epoch-1 step 85900/3451022 - loss: 0.040876 val_loss: 0.035571	recall: 0.498389 precision: 0.897485
epoch-1 step 86000/3451022 - loss: 0.035264 val_loss: 0.038428	recall: 0.503226 precision: 0.903475

checkpoint saved

epoch-1 step 86100/3451022 - loss: 0.035985 val_loss: 0.036324	recall: 0.482105 precision: 0.898039

model exported!

epoch-1 step 86200/3451022 - loss: 0.038395 val_loss: 0.039148	recall: 0.512876 precision: 0.933594
epoch-1 step 86300/3451022 - loss: 0.037139 val_loss: 0.037895	recall: 0.510917 precision: 0.893130
epoch-1 step 86400/3451022 - loss: 0.037189 val_loss: 0.046936	recall: 0.504310 precision: 0.894837
epoch-1 step 86500/3451022 - loss: 0.040086 val_loss: 0.035144	recall: 0.515251 precision: 0.884112
epoch-1 step 86600/3451022 - loss: 0.038114 val_loss: 0.037146	recall: 0.504274 precision: 0.904215
epoch-1 step 86700/3451022 - loss: 0.035646 val_loss: 0.036609	recall: 0.498416 precision: 0.909441
epoch-1 step 86800/3451022 - loss: 0.034352 val_loss: 0.041572	recall: 0.486458 precision: 0.910331
epoch-1 step 86900/3451022 - loss: 0.037472 val_loss: 0.034863	recall: 0.535274 precision: 0.913958
epoch-1 step 87000/3451022 - loss: 0.037711 val_loss: 0.034847	recall: 0.513966 precision: 0.903733

checkpoint saved

epoch-1 step 87100/3451022 - loss: 0.040123 val_loss: 0.040053	recall: 0.494635 precision: 0.909270
epoch-1 step 87200/3451022 - loss: 0.034821 val_loss: 0.041989	recall: 0.510360 precision: 0.928571
epoch-1 step 87300/3451022 - loss: 0.038067 val_loss: 0.034341	recall: 0.507088 precision: 0.918972
epoch-1 step 87400/3451022 - loss: 0.036334 val_loss: 0.038373	recall: 0.481363 precision: 0.886275
epoch-1 step 87500/3451022 - loss: 0.035680 val_loss: 0.036230	recall: 0.502714 precision: 0.904297
epoch-1 step 87600/3451022 - loss: 0.036132 val_loss: 0.038950	recall: 0.497840 precision: 0.900391
epoch-1 step 87700/3451022 - loss: 0.034111 val_loss: 0.035893	recall: 0.508361 precision: 0.904762
epoch-1 step 87800/3451022 - loss: 0.041289 val_loss: 0.035529	recall: 0.536249 precision: 0.892720
epoch-1 step 87900/3451022 - loss: 0.035131 val_loss: 0.038049	recall: 0.520442 precision: 0.895437
epoch-1 step 88000/3451022 - loss: 0.036999 val_loss: 0.040102	recall: 0.523013 precision: 0.917431

checkpoint saved

epoch-1 step 88100/3451022 - loss: 0.035503 val_loss: 0.039097	recall: 0.519144 precision: 0.923848

model exported!

epoch-1 step 88200/3451022 - loss: 0.036258 val_loss: 0.037204	recall: 0.498343 precision: 0.867308
epoch-1 step 88300/3451022 - loss: 0.043745 val_loss: 0.034963	recall: 0.551253 precision: 0.892989
epoch-1 step 88400/3451022 - loss: 0.035556 val_loss: 0.034631	recall: 0.529477 precision: 0.917148
epoch-1 step 88500/3451022 - loss: 0.037017 val_loss: 0.036507	recall: 0.509249 precision: 0.908738
epoch-1 step 88600/3451022 - loss: 0.036037 val_loss: 0.035686	recall: 0.500000 precision: 0.894636
epoch-1 step 88700/3451022 - loss: 0.036849 val_loss: 0.035515	recall: 0.500000 precision: 0.915663
epoch-1 step 88800/3451022 - loss: 0.036099 val_loss: 0.041058	recall: 0.519058 precision: 0.902534
epoch-1 step 88900/3451022 - loss: 0.036235 val_loss: 0.036437	recall: 0.548350 precision: 0.916350
epoch-1 step 89000/3451022 - loss: 0.035676 val_loss: 0.036101	recall: 0.513636 precision: 0.881092

checkpoint saved

epoch-1 step 89100/3451022 - loss: 0.036453 val_loss: 0.035092	recall: 0.542857 precision: 0.909962
epoch-1 step 89200/3451022 - loss: 0.037986 val_loss: 0.036957	recall: 0.482255 precision: 0.871698
epoch-1 step 89300/3451022 - loss: 0.035599 val_loss: 0.041668	recall: 0.506104 precision: 0.892368
epoch-1 step 89400/3451022 - loss: 0.035243 val_loss: 0.034282	recall: 0.522629 precision: 0.941748
epoch-1 step 89500/3451022 - loss: 0.044628 val_loss: 0.038782	recall: 0.506864 precision: 0.902256
epoch-1 step 89600/3451022 - loss: 0.038102 val_loss: 0.034945	recall: 0.494092 precision: 0.905512
epoch-1 step 89700/3451022 - loss: 0.034903 val_loss: 0.037353	recall: 0.513771 precision: 0.929119
epoch-1 step 89800/3451022 - loss: 0.037268 val_loss: 0.034232	recall: 0.540839 precision: 0.933333
epoch-1 step 89900/3451022 - loss: 0.033901 val_loss: 0.034685	recall: 0.526092 precision: 0.911439
epoch-1 step 90000/3451022 - loss: 0.036214 val_loss: 0.035208	recall: 0.486688 precision: 0.890838

checkpoint saved

epoch-1 step 90100/3451022 - loss: 0.036678 val_loss: 0.038020	recall: 0.501066 precision: 0.921569

model exported!

epoch-1 step 90200/3451022 - loss: 0.035823 val_loss: 0.033939	recall: 0.507151 precision: 0.914683
epoch-1 step 90300/3451022 - loss: 0.038131 val_loss: 0.035712	recall: 0.522976 precision: 0.924565
epoch-1 step 90400/3451022 - loss: 0.035577 val_loss: 0.034752	recall: 0.504792 precision: 0.897727
epoch-1 step 90500/3451022 - loss: 0.034616 val_loss: 0.036332	recall: 0.477949 precision: 0.889313
epoch-1 step 90600/3451022 - loss: 0.040045 val_loss: 0.035371	recall: 0.526894 precision: 0.916031
epoch-1 step 90700/3451022 - loss: 0.034298 val_loss: 0.033901	recall: 0.505470 precision: 0.909449
epoch-1 step 90800/3451022 - loss: 0.038826 val_loss: 0.042662	recall: 0.500517 precision: 0.901304
epoch-1 step 90900/3451022 - loss: 0.034056 val_loss: 0.039914	recall: 0.464431 precision: 0.880539
epoch-1 step 91000/3451022 - loss: 0.035715 val_loss: 0.039226	recall: 0.498436 precision: 0.912214

checkpoint saved

epoch-1 step 91100/3451022 - loss: 0.036930 val_loss: 0.036050	recall: 0.514408 precision: 0.909434
epoch-1 step 91200/3451022 - loss: 0.036736 val_loss: 0.035358	recall: 0.507119 precision: 0.907843
epoch-1 step 91300/3451022 - loss: 0.037679 val_loss: 0.038784	recall: 0.514100 precision: 0.906310
epoch-1 step 91400/3451022 - loss: 0.037523 val_loss: 0.035132	recall: 0.526257 precision: 0.921722
epoch-1 step 91500/3451022 - loss: 0.040663 val_loss: 0.044072	recall: 0.492424 precision: 0.871648
epoch-1 step 91600/3451022 - loss: 0.043975 val_loss: 0.041305	recall: 0.520624 precision: 0.892925
epoch-1 step 91700/3451022 - loss: 0.038591 val_loss: 0.036333	recall: 0.474843 precision: 0.889980
epoch-1 step 91800/3451022 - loss: 0.041907 val_loss: 0.036328	recall: 0.499459 precision: 0.891892
epoch-1 step 91900/3451022 - loss: 0.034640 val_loss: 0.042693	recall: 0.508143 precision: 0.903475
epoch-1 step 92000/3451022 - loss: 0.038542 val_loss: 0.036512	recall: 0.478170 precision: 0.896686

checkpoint saved

epoch-1 step 92100/3451022 - loss: 0.040422 val_loss: 0.051269	recall: 0.506466 precision: 0.900383

model exported!

epoch-1 step 92200/3451022 - loss: 0.035111 val_loss: 0.035486	recall: 0.510337 precision: 0.912451
epoch-1 step 92300/3451022 - loss: 0.036406 val_loss: 0.035337	recall: 0.531216 precision: 0.899814
epoch-1 step 92400/3451022 - loss: 0.037303 val_loss: 0.036814	recall: 0.516930 precision: 0.916000
epoch-1 step 92500/3451022 - loss: 0.038467 val_loss: 0.035955	recall: 0.502800 precision: 0.876953
epoch-1 step 92600/3451022 - loss: 0.035769 val_loss: 0.036690	recall: 0.489474 precision: 0.875706
epoch-1 step 92700/3451022 - loss: 0.036500 val_loss: 0.036363	recall: 0.535039 precision: 0.907547
epoch-1 step 92800/3451022 - loss: 0.037348 val_loss: 0.040134	recall: 0.530892 precision: 0.900971
epoch-1 step 92900/3451022 - loss: 0.034866 val_loss: 0.037231	recall: 0.485169 precision: 0.894531
epoch-1 step 93000/3451022 - loss: 0.034718 val_loss: 0.037341	recall: 0.508696 precision: 0.906977

checkpoint saved

epoch-1 step 93100/3451022 - loss: 0.034797 val_loss: 0.036517	recall: 0.510315 precision: 0.903846
epoch-1 step 93200/3451022 - loss: 0.040920 val_loss: 0.037109	recall: 0.503226 precision: 0.898273
epoch-1 step 93300/3451022 - loss: 0.035209 val_loss: 0.035932	recall: 0.522484 precision: 0.912150
epoch-1 step 93400/3451022 - loss: 0.034281 val_loss: 0.042668	recall: 0.523497 precision: 0.898687
epoch-1 step 93500/3451022 - loss: 0.035767 val_loss: 0.035193	recall: 0.500000 precision: 0.905588
epoch-1 step 93600/3451022 - loss: 0.038398 val_loss: 0.035272	recall: 0.483766 precision: 0.883399
epoch-1 step 93700/3451022 - loss: 0.035359 val_loss: 0.035038	recall: 0.514640 precision: 0.875479
epoch-1 step 93800/3451022 - loss: 0.034546 val_loss: 0.034771	recall: 0.523148 precision: 0.891519
epoch-1 step 93900/3451022 - loss: 0.038065 val_loss: 0.038763	recall: 0.518559 precision: 0.903042
epoch-1 step 94000/3451022 - loss: 0.035367 val_loss: 0.034778	recall: 0.509476 precision: 0.908549

checkpoint saved

epoch-1 step 94100/3451022 - loss: 0.035420 val_loss: 0.034788	recall: 0.516977 precision: 0.893939

model exported!

epoch-1 step 94200/3451022 - loss: 0.035041 val_loss: 0.035851	recall: 0.517672 precision: 0.907104
epoch-1 step 94300/3451022 - loss: 0.035561 val_loss: 0.036242	recall: 0.549661 precision: 0.936538
epoch-1 step 94400/3451022 - loss: 0.048795 val_loss: 0.034184	recall: 0.532131 precision: 0.897338
epoch-1 step 94500/3451022 - loss: 0.036617 val_loss: 0.034599	recall: 0.497732 precision: 0.879760
epoch-1 step 94600/3451022 - loss: 0.034716 val_loss: 0.034216	recall: 0.514595 precision: 0.933333
epoch-1 step 94700/3451022 - loss: 0.037741 val_loss: 0.039354	recall: 0.499449 precision: 0.893491
epoch-1 step 94800/3451022 - loss: 0.034176 val_loss: 0.038469	recall: 0.474453 precision: 0.881783
epoch-1 step 94900/3451022 - loss: 0.034833 val_loss: 0.044021	recall: 0.521452 precision: 0.904580
epoch-1 step 95000/3451022 - loss: 0.039108 val_loss: 0.035901	recall: 0.510474 precision: 0.920477

checkpoint saved

epoch-1 step 95100/3451022 - loss: 0.033951 val_loss: 0.039605	recall: 0.506787 precision: 0.876712
epoch-1 step 95200/3451022 - loss: 0.034795 val_loss: 0.040736	recall: 0.484558 precision: 0.860113
epoch-1 step 95300/3451022 - loss: 0.037949 val_loss: 0.034374	recall: 0.514563 precision: 0.910305
epoch-1 step 95400/3451022 - loss: 0.035966 val_loss: 0.034675	recall: 0.473520 precision: 0.894118
epoch-1 step 95500/3451022 - loss: 0.034847 val_loss: 0.035469	recall: 0.489818 precision: 0.912176
epoch-1 step 95600/3451022 - loss: 0.033616 val_loss: 0.044552	recall: 0.502750 precision: 0.887379
epoch-1 step 95700/3451022 - loss: 0.034399 val_loss: 0.034799	recall: 0.503834 precision: 0.905512
epoch-1 step 95800/3451022 - loss: 0.035557 val_loss: 0.037600	recall: 0.494835 precision: 0.888683
epoch-1 step 95900/3451022 - loss: 0.050228 val_loss: 0.041488	recall: 0.475155 precision: 0.887814
epoch-1 step 96000/3451022 - loss: 0.040150 val_loss: 0.037618	recall: 0.527233 precision: 0.918406

checkpoint saved

epoch-1 step 96100/3451022 - loss: 0.034382 val_loss: 0.036366	recall: 0.501057 precision: 0.920388

model exported!

epoch-1 step 96200/3451022 - loss: 0.038145 val_loss: 0.035588	recall: 0.505423 precision: 0.904854
epoch-1 step 96300/3451022 - loss: 0.036511 val_loss: 0.039516	recall: 0.517817 precision: 0.904669
epoch-1 step 96400/3451022 - loss: 0.034790 val_loss: 0.036052	recall: 0.505908 precision: 0.921722
epoch-1 step 96500/3451022 - loss: 0.038063 val_loss: 0.036964	recall: 0.547085 precision: 0.920755
epoch-1 step 96600/3451022 - loss: 0.034878 val_loss: 0.036472	recall: 0.515017 precision: 0.900778
epoch-1 step 96700/3451022 - loss: 0.036740 val_loss: 0.034575	recall: 0.514377 precision: 0.916509
epoch-1 step 96800/3451022 - loss: 0.036439 val_loss: 0.036295	recall: 0.525918 precision: 0.917137
epoch-1 step 96900/3451022 - loss: 0.044732 val_loss: 0.034751	recall: 0.508380 precision: 0.892157
epoch-1 step 97000/3451022 - loss: 0.034379 val_loss: 0.035091	recall: 0.503834 precision: 0.912698

checkpoint saved

epoch-1 step 97100/3451022 - loss: 0.035854 val_loss: 0.034922	recall: 0.486200 precision: 0.879079
epoch-1 step 97200/3451022 - loss: 0.035341 val_loss: 0.037770	recall: 0.494565 precision: 0.902778
epoch-1 step 97300/3451022 - loss: 0.034647 val_loss: 0.041843	recall: 0.506967 precision: 0.922027
epoch-1 step 97400/3451022 - loss: 0.036095 val_loss: 0.040443	recall: 0.490281 precision: 0.893701
epoch-1 step 97500/3451022 - loss: 0.038333 val_loss: 0.034647	recall: 0.519337 precision: 0.914397
epoch-1 step 97600/3451022 - loss: 0.037315 val_loss: 0.035886	recall: 0.511706 precision: 0.910714
epoch-1 step 97700/3451022 - loss: 0.035504 val_loss: 0.034598	recall: 0.497338 precision: 0.905039
epoch-1 step 97800/3451022 - loss: 0.035546 val_loss: 0.034554	recall: 0.506834 precision: 0.900810
epoch-1 step 97900/3451022 - loss: 0.039119 val_loss: 0.055980	recall: 0.520690 precision: 0.897030
epoch-1 step 98000/3451022 - loss: 0.034892 val_loss: 0.035053	recall: 0.527902 precision: 0.906130

checkpoint saved

epoch-1 step 98100/3451022 - loss: 0.035351 val_loss: 0.038214	recall: 0.504972 precision: 0.889105

model exported!

epoch-1 step 98200/3451022 - loss: 0.035225 val_loss: 0.042781	recall: 0.492147 precision: 0.907336
epoch-1 step 98300/3451022 - loss: 0.040499 val_loss: 0.041090	recall: 0.512432 precision: 0.890977
epoch-1 step 98400/3451022 - loss: 0.036202 val_loss: 0.042265	recall: 0.482759 precision: 0.880157
epoch-1 step 98500/3451022 - loss: 0.037545 val_loss: 0.037426	recall: 0.477941 precision: 0.897436
epoch-1 step 98600/3451022 - loss: 0.038455 val_loss: 0.044459	recall: 0.519423 precision: 0.915851
epoch-1 step 98700/3451022 - loss: 0.035731 val_loss: 0.037692	recall: 0.525967 precision: 0.881481
epoch-1 step 98800/3451022 - loss: 0.035258 val_loss: 0.038079	recall: 0.552846 precision: 0.926070
epoch-1 step 98900/3451022 - loss: 0.039188 val_loss: 0.040014	recall: 0.551044 precision: 0.916988
epoch-1 step 99000/3451022 - loss: 0.039264 val_loss: 0.035824	recall: 0.525670 precision: 0.912791

checkpoint saved

epoch-1 step 99100/3451022 - loss: 0.034550 val_loss: 0.036017	recall: 0.508380 precision: 0.885214
epoch-1 step 99200/3451022 - loss: 0.037934 val_loss: 0.037265	recall: 0.535354 precision: 0.917308
epoch-1 step 99300/3451022 - loss: 0.035094 val_loss: 0.038677	recall: 0.505073 precision: 0.892430
epoch-1 step 99400/3451022 - loss: 0.034637 val_loss: 0.034696	recall: 0.529345 precision: 0.908915
epoch-1 step 99500/3451022 - loss: 0.033921 val_loss: 0.035711	recall: 0.489407 precision: 0.897087
epoch-1 step 99600/3451022 - loss: 0.034491 val_loss: 0.035456	recall: 0.516903 precision: 0.913295
epoch-1 step 99700/3451022 - loss: 0.040377 val_loss: 0.036694	recall: 0.547977 precision: 0.913295
epoch-1 step 99800/3451022 - loss: 0.041614 val_loss: 0.035970	recall: 0.526201 precision: 0.930502
epoch-1 step 99900/3451022 - loss: 0.034883 val_loss: 0.034690	recall: 0.500551 precision: 0.891945
epoch-1 step 100000/3451022 - loss: 0.034488 val_loss: 0.034752	recall: 0.519318 precision: 0.919517

checkpoint saved

epoch-1 step 100100/3451022 - loss: 0.036843 val_loss: 0.036589	recall: 0.512249 precision: 0.901961

model exported!

epoch-1 step 100200/3451022 - loss: 0.039608 val_loss: 0.036561	recall: 0.521111 precision: 0.928713
epoch-1 step 100300/3451022 - loss: 0.038980 val_loss: 0.038686	recall: 0.504505 precision: 0.875000
epoch-1 step 100400/3451022 - loss: 0.040854 val_loss: 0.034848	recall: 0.529954 precision: 0.914513
epoch-1 step 100500/3451022 - loss: 0.039286 val_loss: 0.035569	recall: 0.514029 precision: 0.880769
epoch-1 step 100600/3451022 - loss: 0.035685 val_loss: 0.045593	recall: 0.504255 precision: 0.894340
epoch-1 step 100700/3451022 - loss: 0.035448 val_loss: 0.034907	recall: 0.497849 precision: 0.873585
epoch-1 step 100800/3451022 - loss: 0.036902 val_loss: 0.038647	recall: 0.546787 precision: 0.909944
epoch-1 step 100900/3451022 - loss: 0.036629 val_loss: 0.043211	recall: 0.504823 precision: 0.893738
epoch-1 step 101000/3451022 - loss: 0.037810 val_loss: 0.035062	recall: 0.489904 precision: 0.902153

checkpoint saved

epoch-1 step 101100/3451022 - loss: 0.040528 val_loss: 0.039838	recall: 0.509518 precision: 0.895669
epoch-1 step 101200/3451022 - loss: 0.036526 val_loss: 0.035032	recall: 0.522210 precision: 0.919847
epoch-1 step 101300/3451022 - loss: 0.036269 val_loss: 0.036474	recall: 0.493711 precision: 0.900574
epoch-1 step 101400/3451022 - loss: 0.034962 val_loss: 0.037788	recall: 0.501096 precision: 0.910359
epoch-1 step 101500/3451022 - loss: 0.036280 val_loss: 0.045798	recall: 0.484624 precision: 0.894325
epoch-1 step 101600/3451022 - loss: 0.035138 val_loss: 0.035566	recall: 0.492457 precision: 0.901381
epoch-1 step 101700/3451022 - loss: 0.035201 val_loss: 0.036290	recall: 0.474747 precision: 0.891841
epoch-1 step 101800/3451022 - loss: 0.043007 val_loss: 0.037700	recall: 0.508547 precision: 0.920696
epoch-1 step 101900/3451022 - loss: 0.045958 val_loss: 0.035056	recall: 0.553473 precision: 0.933086
epoch-1 step 102000/3451022 - loss: 0.036600 val_loss: 0.036087	recall: 0.496875 precision: 0.931641

checkpoint saved

epoch-1 step 102100/3451022 - loss: 0.035780 val_loss: 0.035142	recall: 0.505085 precision: 0.894000

model exported!

epoch-1 step 102200/3451022 - loss: 0.037107 val_loss: 0.040661	recall: 0.512931 precision: 0.918919
epoch-1 step 102300/3451022 - loss: 0.034404 val_loss: 0.034708	recall: 0.543093 precision: 0.909091
epoch-1 step 102400/3451022 - loss: 0.034497 val_loss: 0.034679	recall: 0.516556 precision: 0.901734
epoch-1 step 102500/3451022 - loss: 0.037004 val_loss: 0.034813	recall: 0.506424 precision: 0.880819
epoch-1 step 102600/3451022 - loss: 0.034684 val_loss: 0.035363	recall: 0.528153 precision: 0.908915
epoch-1 step 102700/3451022 - loss: 0.034376 val_loss: 0.034584	recall: 0.481865 precision: 0.885714
epoch-1 step 102800/3451022 - loss: 0.037053 val_loss: 0.038651	recall: 0.534169 precision: 0.912451
epoch-1 step 102900/3451022 - loss: 0.035826 val_loss: 0.040017	recall: 0.500522 precision: 0.912381
epoch-1 step 103000/3451022 - loss: 0.036159 val_loss: 0.038937	recall: 0.510707 precision: 0.905123

checkpoint saved

epoch-1 step 103100/3451022 - loss: 0.035830 val_loss: 0.042973	recall: 0.500000 precision: 0.909266
epoch-1 step 103200/3451022 - loss: 0.035449 val_loss: 0.036678	recall: 0.522321 precision: 0.898273
epoch-1 step 103300/3451022 - loss: 0.044571 val_loss: 0.042013	recall: 0.494067 precision: 0.875717
epoch-1 step 103400/3451022 - loss: 0.035963 val_loss: 0.036963	recall: 0.497244 precision: 0.900200
epoch-1 step 103500/3451022 - loss: 0.036597 val_loss: 0.036912	recall: 0.515847 precision: 0.895636
epoch-1 step 103600/3451022 - loss: 0.041222 val_loss: 0.034827	recall: 0.508403 precision: 0.899628
epoch-1 step 103700/3451022 - loss: 0.038495 val_loss: 0.040429	recall: 0.498455 precision: 0.925430
epoch-1 step 103800/3451022 - loss: 0.036437 val_loss: 0.038469	recall: 0.506792 precision: 0.903166
epoch-1 step 103900/3451022 - loss: 0.036763 val_loss: 0.034604	recall: 0.508247 precision: 0.916357
epoch-1 step 104000/3451022 - loss: 0.040582 val_loss: 0.035546	recall: 0.502137 precision: 0.905588

checkpoint saved

epoch-1 step 104100/3451022 - loss: 0.036206 val_loss: 0.035734	recall: 0.516447 precision: 0.911025

model exported!

epoch-1 step 104200/3451022 - loss: 0.035381 val_loss: 0.034672	recall: 0.511628 precision: 0.900585
epoch-1 step 104300/3451022 - loss: 0.034512 val_loss: 0.038090	recall: 0.501109 precision: 0.877670
epoch-1 step 104400/3451022 - loss: 0.034673 val_loss: 0.036052	recall: 0.518987 precision: 0.940727
epoch-1 step 104500/3451022 - loss: 0.034912 val_loss: 0.035740	recall: 0.497817 precision: 0.878613
epoch-1 step 104600/3451022 - loss: 0.037296 val_loss: 0.038390	recall: 0.529345 precision: 0.901923
epoch-1 step 104700/3451022 - loss: 0.036355 val_loss: 0.038725	recall: 0.545872 precision: 0.910134
epoch-1 step 104800/3451022 - loss: 0.042203 val_loss: 0.035041	recall: 0.549488 precision: 0.921756
epoch-1 step 104900/3451022 - loss: 0.038653 val_loss: 0.041640	recall: 0.520089 precision: 0.894434
epoch-1 step 105000/3451022 - loss: 0.034638 val_loss: 0.037632	recall: 0.490323 precision: 0.887160

checkpoint saved

epoch-1 step 105100/3451022 - loss: 0.034241 val_loss: 0.035093	recall: 0.519523 precision: 0.897004
epoch-1 step 105200/3451022 - loss: 0.035115 val_loss: 0.037502	recall: 0.472596 precision: 0.899606
epoch-1 step 105300/3451022 - loss: 0.037407 val_loss: 0.056815	recall: 0.504854 precision: 0.874766
epoch-1 step 105400/3451022 - loss: 0.035212 val_loss: 0.037026	recall: 0.490405 precision: 0.888031
epoch-1 step 105500/3451022 - loss: 0.036382 val_loss: 0.036441	recall: 0.510870 precision: 0.896947
epoch-1 step 105600/3451022 - loss: 0.045641 val_loss: 0.035015	recall: 0.505039 precision: 0.896620
epoch-1 step 105700/3451022 - loss: 0.037479 val_loss: 0.036361	recall: 0.517837 precision: 0.907258
epoch-1 step 105800/3451022 - loss: 0.044167 val_loss: 0.035518	recall: 0.476042 precision: 0.914000
epoch-1 step 105900/3451022 - loss: 0.035801 val_loss: 0.043125	recall: 0.489186 precision: 0.868373
epoch-1 step 106000/3451022 - loss: 0.040792 val_loss: 0.036612	recall: 0.508772 precision: 0.906250

checkpoint saved

epoch-1 step 106100/3451022 - loss: 0.040505 val_loss: 0.042354	recall: 0.505308 precision: 0.918919

model exported!

epoch-1 step 106200/3451022 - loss: 0.035775 val_loss: 0.040071	recall: 0.503627 precision: 0.906716
epoch-1 step 106300/3451022 - loss: 0.036644 val_loss: 0.035712	recall: 0.507463 precision: 0.904943
epoch-1 step 106400/3451022 - loss: 0.045738 val_loss: 0.037596	recall: 0.456564 precision: 0.885768
epoch-1 step 106500/3451022 - loss: 0.034482 val_loss: 0.037825	recall: 0.475327 precision: 0.911197
epoch-1 step 106600/3451022 - loss: 0.039255 val_loss: 0.036951	recall: 0.529083 precision: 0.890772
epoch-1 step 106700/3451022 - loss: 0.035772 val_loss: 0.034427	recall: 0.533792 precision: 0.906615
epoch-1 step 106800/3451022 - loss: 0.036531 val_loss: 0.037251	recall: 0.526427 precision: 0.920518
epoch-1 step 106900/3451022 - loss: 0.038007 val_loss: 0.034843	recall: 0.552863 precision: 0.931354
epoch-1 step 107000/3451022 - loss: 0.034768 val_loss: 0.045848	recall: 0.477742 precision: 0.887097

checkpoint saved

epoch-1 step 107100/3451022 - loss: 0.042871 val_loss: 0.037472	recall: 0.493976 precision: 0.872340
epoch-1 step 107200/3451022 - loss: 0.036170 val_loss: 0.047269	recall: 0.517582 precision: 0.902299
epoch-1 step 107300/3451022 - loss: 0.033709 val_loss: 0.034382	recall: 0.497377 precision: 0.911538
epoch-1 step 107400/3451022 - loss: 0.036641 val_loss: 0.040925	recall: 0.530269 precision: 0.920233
epoch-1 step 107500/3451022 - loss: 0.036345 val_loss: 0.038158	recall: 0.512195 precision: 0.936047
epoch-1 step 107600/3451022 - loss: 0.036359 val_loss: 0.036106	recall: 0.493333 precision: 0.876138
epoch-1 step 107700/3451022 - loss: 0.036771 val_loss: 0.035724	recall: 0.532058 precision: 0.909615
epoch-1 step 107800/3451022 - loss: 0.047199 val_loss: 0.040031	recall: 0.479839 precision: 0.888060
epoch-1 step 107900/3451022 - loss: 0.035371 val_loss: 0.041193	recall: 0.508811 precision: 0.916667
epoch-1 step 108000/3451022 - loss: 0.035321 val_loss: 0.037504	recall: 0.496802 precision: 0.910156

checkpoint saved

epoch-1 step 108100/3451022 - loss: 0.039011 val_loss: 0.037240	recall: 0.476239 precision: 0.909266

model exported!

epoch-1 step 108200/3451022 - loss: 0.038678 val_loss: 0.036532	recall: 0.492662 precision: 0.891841
epoch-1 step 108300/3451022 - loss: 0.041750 val_loss: 0.037927	recall: 0.496842 precision: 0.900763
epoch-1 step 108400/3451022 - loss: 0.035020 val_loss: 0.034136	recall: 0.516685 precision: 0.902256
epoch-1 step 108500/3451022 - loss: 0.045696 val_loss: 0.035539	recall: 0.473251 precision: 0.879541
epoch-1 step 108600/3451022 - loss: 0.039589 val_loss: 0.038937	recall: 0.496358 precision: 0.919075
epoch-1 step 108700/3451022 - loss: 0.035298 val_loss: 0.036725	recall: 0.485804 precision: 0.904110
epoch-1 step 108800/3451022 - loss: 0.036455 val_loss: 0.035676	recall: 0.492114 precision: 0.903475
epoch-1 step 108900/3451022 - loss: 0.036283 val_loss: 0.038471	recall: 0.490281 precision: 0.884990
epoch-1 step 109000/3451022 - loss: 0.035337 val_loss: 0.036205	recall: 0.515084 precision: 0.895146

checkpoint saved

epoch-1 step 109100/3451022 - loss: 0.037531 val_loss: 0.036327	recall: 0.499471 precision: 0.899048
epoch-1 step 109200/3451022 - loss: 0.035365 val_loss: 0.033994	recall: 0.519685 precision: 0.902344
epoch-1 step 109300/3451022 - loss: 0.035150 val_loss: 0.035087	recall: 0.497326 precision: 0.913556
epoch-1 step 109400/3451022 - loss: 0.035942 val_loss: 0.035837	recall: 0.501053 precision: 0.911877
epoch-1 step 109500/3451022 - loss: 0.034862 val_loss: 0.043389	recall: 0.487856 precision: 0.904110
epoch-1 step 109600/3451022 - loss: 0.045257 val_loss: 0.035632	recall: 0.480129 precision: 0.901210
epoch-1 step 109700/3451022 - loss: 0.036017 val_loss: 0.036729	recall: 0.500530 precision: 0.895636
epoch-1 step 109800/3451022 - loss: 0.035297 val_loss: 0.037068	recall: 0.515351 precision: 0.914397
epoch-1 step 109900/3451022 - loss: 0.038765 val_loss: 0.036724	recall: 0.516842 precision: 0.900917
epoch-1 step 110000/3451022 - loss: 0.043786 val_loss: 0.039288	recall: 0.529742 precision: 0.890566

checkpoint saved

epoch-1 step 110100/3451022 - loss: 0.038018 val_loss: 0.035860	recall: 0.506937 precision: 0.915222

model exported!

epoch-1 step 110200/3451022 - loss: 0.038043 val_loss: 0.036080	recall: 0.524807 precision: 0.910134
epoch-1 step 110300/3451022 - loss: 0.038796 val_loss: 0.039343	recall: 0.526256 precision: 0.914683
epoch-1 step 110400/3451022 - loss: 0.034319 val_loss: 0.037978	recall: 0.509269 precision: 0.913894
epoch-1 step 110500/3451022 - loss: 0.034712 val_loss: 0.048263	recall: 0.469303 precision: 0.911111
epoch-1 step 110600/3451022 - loss: 0.033792 val_loss: 0.036732	recall: 0.509554 precision: 0.893855
epoch-1 step 110700/3451022 - loss: 0.036462 val_loss: 0.042543	recall: 0.480588 precision: 0.925253
epoch-1 step 110800/3451022 - loss: 0.046303 val_loss: 0.036891	recall: 0.510799 precision: 0.909615
epoch-1 step 110900/3451022 - loss: 0.041050 val_loss: 0.036126	recall: 0.492647 precision: 0.908915
epoch-1 step 111000/3451022 - loss: 0.037503 val_loss: 0.038467	recall: 0.514884 precision: 0.917485

checkpoint saved

epoch-1 step 111100/3451022 - loss: 0.036208 val_loss: 0.035409	recall: 0.495187 precision: 0.886973
epoch-1 step 111200/3451022 - loss: 0.034394 val_loss: 0.039547	recall: 0.491903 precision: 0.918715
epoch-1 step 111300/3451022 - loss: 0.036566 val_loss: 0.048208	recall: 0.513966 precision: 0.874525
epoch-1 step 111400/3451022 - loss: 0.043635 val_loss: 0.036115	recall: 0.508215 precision: 0.883810
epoch-1 step 111500/3451022 - loss: 0.037007 val_loss: 0.034987	recall: 0.506937 precision: 0.920543
epoch-1 step 111600/3451022 - loss: 0.036385 val_loss: 0.034374	recall: 0.513661 precision: 0.880150
epoch-1 step 111700/3451022 - loss: 0.033454 val_loss: 0.035833	recall: 0.518319 precision: 0.921456
epoch-1 step 111800/3451022 - loss: 0.034869 val_loss: 0.035206	recall: 0.489685 precision: 0.879142
epoch-1 step 111900/3451022 - loss: 0.036333 val_loss: 0.034222	recall: 0.527840 precision: 0.904580
epoch-1 step 112000/3451022 - loss: 0.035241 val_loss: 0.038253	recall: 0.497320 precision: 0.890595

checkpoint saved

epoch-1 step 112100/3451022 - loss: 0.035703 val_loss: 0.036319	recall: 0.490066 precision: 0.882704

model exported!

epoch-1 step 112200/3451022 - loss: 0.035781 val_loss: 0.038894	recall: 0.470226 precision: 0.903353
epoch-1 step 112300/3451022 - loss: 0.034746 val_loss: 0.041803	recall: 0.538198 precision: 0.925490
epoch-1 step 112400/3451022 - loss: 0.039367 val_loss: 0.034815	recall: 0.501672 precision: 0.896414
epoch-1 step 112500/3451022 - loss: 0.035327 val_loss: 0.034503	recall: 0.508565 precision: 0.908222
epoch-1 step 112600/3451022 - loss: 0.037582 val_loss: 0.035916	recall: 0.501574 precision: 0.903592
epoch-1 step 112700/3451022 - loss: 0.035472 val_loss: 0.041220	recall: 0.497908 precision: 0.903226
epoch-1 step 112800/3451022 - loss: 0.035140 val_loss: 0.035707	recall: 0.476440 precision: 0.893910
epoch-1 step 112900/3451022 - loss: 0.042668 val_loss: 0.037067	recall: 0.500000 precision: 0.885659
epoch-1 step 113000/3451022 - loss: 0.040236 val_loss: 0.036818	recall: 0.487500 precision: 0.906977

checkpoint saved

epoch-1 step 113100/3451022 - loss: 0.035602 val_loss: 0.036698	recall: 0.516264 precision: 0.912801
epoch-1 step 113200/3451022 - loss: 0.036881 val_loss: 0.040223	recall: 0.519016 precision: 0.922465
epoch-1 step 113300/3451022 - loss: 0.035716 val_loss: 0.042597	recall: 0.494748 precision: 0.914563
epoch-1 step 113400/3451022 - loss: 0.034976 val_loss: 0.040955	recall: 0.508772 precision: 0.900971
epoch-1 step 113500/3451022 - loss: 0.038834 val_loss: 0.037234	recall: 0.485774 precision: 0.909270
epoch-1 step 113600/3451022 - loss: 0.034762 val_loss: 0.034806	recall: 0.523179 precision: 0.909789
epoch-1 step 113700/3451022 - loss: 0.036230 val_loss: 0.037044	recall: 0.530983 precision: 0.922078
epoch-1 step 113800/3451022 - loss: 0.036531 val_loss: 0.034957	recall: 0.479249 precision: 0.904851
epoch-1 step 113900/3451022 - loss: 0.035634 val_loss: 0.033628	recall: 0.525901 precision: 0.922925
epoch-1 step 114000/3451022 - loss: 0.035929 val_loss: 0.034735	recall: 0.524336 precision: 0.920388

checkpoint saved

epoch-1 step 114100/3451022 - loss: 0.034963 val_loss: 0.034762	recall: 0.515812 precision: 0.914894

model exported!

epoch-1 step 114200/3451022 - loss: 0.047887 val_loss: 0.034120	recall: 0.523977 precision: 0.888889
epoch-1 step 114300/3451022 - loss: 0.043862 val_loss: 0.038476	recall: 0.551326 precision: 0.935421
epoch-1 step 114400/3451022 - loss: 0.038302 val_loss: 0.035431	recall: 0.511387 precision: 0.923364
epoch-1 step 114500/3451022 - loss: 0.037260 val_loss: 0.040321	recall: 0.498426 precision: 0.933202
epoch-1 step 114600/3451022 - loss: 0.036538 val_loss: 0.035213	recall: 0.511905 precision: 0.904398
epoch-1 step 114700/3451022 - loss: 0.040281 val_loss: 0.034537	recall: 0.496208 precision: 0.887597
epoch-1 step 114800/3451022 - loss: 0.037596 val_loss: 0.042051	recall: 0.500538 precision: 0.897683
epoch-1 step 114900/3451022 - loss: 0.037327 val_loss: 0.034755	recall: 0.533776 precision: 0.939571
epoch-1 step 115000/3451022 - loss: 0.036135 val_loss: 0.037094	recall: 0.500543 precision: 0.912871

checkpoint saved

epoch-1 step 115100/3451022 - loss: 0.037494 val_loss: 0.055250	recall: 0.536071 precision: 0.906191
epoch-1 step 115200/3451022 - loss: 0.035763 val_loss: 0.033974	recall: 0.496746 precision: 0.912351
epoch-1 step 115300/3451022 - loss: 0.036990 val_loss: 0.035733	recall: 0.480810 precision: 0.863985
epoch-1 step 115400/3451022 - loss: 0.041621 val_loss: 0.039258	recall: 0.505062 precision: 0.899800
epoch-1 step 115500/3451022 - loss: 0.036219 val_loss: 0.037175	recall: 0.497194 precision: 0.882470
epoch-1 step 115600/3451022 - loss: 0.034823 val_loss: 0.048141	recall: 0.538991 precision: 0.902111
epoch-1 step 115700/3451022 - loss: 0.038395 val_loss: 0.041643	recall: 0.498423 precision: 0.922179
epoch-1 step 115800/3451022 - loss: 0.034653 val_loss: 0.047731	recall: 0.512735 precision: 0.883588
epoch-1 step 115900/3451022 - loss: 0.037545 val_loss: 0.039606	recall: 0.508004 precision: 0.911877
epoch-1 step 116000/3451022 - loss: 0.037180 val_loss: 0.035777	recall: 0.506937 precision: 0.903042

checkpoint saved

epoch-1 step 116100/3451022 - loss: 0.037580 val_loss: 0.036081	recall: 0.519084 precision: 0.917148

model exported!

epoch-1 step 116200/3451022 - loss: 0.034104 val_loss: 0.038845	recall: 0.499451 precision: 0.906375
epoch-1 step 116300/3451022 - loss: 0.046994 val_loss: 0.035584	recall: 0.501080 precision: 0.906250
epoch-1 step 116400/3451022 - loss: 0.034703 val_loss: 0.035585	recall: 0.515385 precision: 0.900192
epoch-1 step 116500/3451022 - loss: 0.035125 val_loss: 0.038769	recall: 0.516201 precision: 0.895349
epoch-1 step 116600/3451022 - loss: 0.035785 val_loss: 0.035743	recall: 0.512541 precision: 0.930693
epoch-1 step 116700/3451022 - loss: 0.045577 val_loss: 0.050142	recall: 0.517993 precision: 0.904762
epoch-1 step 116800/3451022 - loss: 0.039468 val_loss: 0.036692	recall: 0.477320 precision: 0.900778
epoch-1 step 116900/3451022 - loss: 0.036509 val_loss: 0.042283	recall: 0.534778 precision: 0.910680
epoch-1 step 117000/3451022 - loss: 0.039487 val_loss: 0.034674	recall: 0.509761 precision: 0.900383

checkpoint saved

epoch-1 step 117100/3451022 - loss: 0.039756 val_loss: 0.039732	recall: 0.504310 precision: 0.914062
epoch-1 step 117200/3451022 - loss: 0.036365 val_loss: 0.035538	recall: 0.508772 precision: 0.924303
epoch-1 step 117300/3451022 - loss: 0.036763 val_loss: 0.039174	recall: 0.497320 precision: 0.902724
epoch-1 step 117400/3451022 - loss: 0.038878 val_loss: 0.037050	recall: 0.513966 precision: 0.907298
epoch-1 step 117500/3451022 - loss: 0.038999 val_loss: 0.036212	recall: 0.484222 precision: 0.895372
epoch-1 step 117600/3451022 - loss: 0.037665 val_loss: 0.046388	recall: 0.520742 precision: 0.913793
epoch-1 step 117700/3451022 - loss: 0.039914 val_loss: 0.043132	recall: 0.517915 precision: 0.926214
epoch-1 step 117800/3451022 - loss: 0.037066 val_loss: 0.034974	recall: 0.536117 precision: 0.903042
epoch-1 step 117900/3451022 - loss: 0.034677 val_loss: 0.040110	recall: 0.483770 precision: 0.907662
epoch-1 step 118000/3451022 - loss: 0.035309 val_loss: 0.035088	recall: 0.509392 precision: 0.900391

checkpoint saved

epoch-1 step 118100/3451022 - loss: 0.035403 val_loss: 0.036905	recall: 0.505319 precision: 0.909962

model exported!

epoch-1 step 118200/3451022 - loss: 0.038098 val_loss: 0.035694	recall: 0.477103 precision: 0.887129
epoch-1 step 118300/3451022 - loss: 0.037190 val_loss: 0.036507	recall: 0.530134 precision: 0.896226
epoch-1 step 118400/3451022 - loss: 0.034561 val_loss: 0.041292	recall: 0.491785 precision: 0.892644
epoch-1 step 118500/3451022 - loss: 0.036819 val_loss: 0.034785	recall: 0.526201 precision: 0.911153
epoch-1 step 118600/3451022 - loss: 0.039657 val_loss: 0.036786	recall: 0.517978 precision: 0.895146
epoch-1 step 118700/3451022 - loss: 0.036399 val_loss: 0.035263	recall: 0.483633 precision: 0.898039
epoch-1 step 118800/3451022 - loss: 0.035300 val_loss: 0.035942	recall: 0.517204 precision: 0.923225
epoch-1 step 118900/3451022 - loss: 0.037184 val_loss: 0.042442	recall: 0.545861 precision: 0.929524
epoch-1 step 119000/3451022 - loss: 0.036626 val_loss: 0.036593	recall: 0.511425 precision: 0.910853

checkpoint saved

epoch-1 step 119100/3451022 - loss: 0.035749 val_loss: 0.040191	recall: 0.531042 precision: 0.919386
epoch-1 step 119200/3451022 - loss: 0.036070 val_loss: 0.035065	recall: 0.525164 precision: 0.930233
epoch-1 step 119300/3451022 - loss: 0.036083 val_loss: 0.038370	recall: 0.474645 precision: 0.889734
epoch-1 step 119400/3451022 - loss: 0.056029 val_loss: 0.034651	recall: 0.523656 precision: 0.924099
epoch-1 step 119500/3451022 - loss: 0.039791 val_loss: 0.037169	recall: 0.467413 precision: 0.884393
epoch-1 step 119600/3451022 - loss: 0.038678 val_loss: 0.036311	recall: 0.504274 precision: 0.897338
epoch-1 step 119700/3451022 - loss: 0.034832 val_loss: 0.046906	recall: 0.528217 precision: 0.917647
epoch-1 step 119800/3451022 - loss: 0.050752 val_loss: 0.035233	recall: 0.500000 precision: 0.906883
epoch-1 step 119900/3451022 - loss: 0.047256 val_loss: 0.039637	recall: 0.497286 precision: 0.892788
epoch-1 step 120000/3451022 - loss: 0.042979 val_loss: 0.035114	recall: 0.516093 precision: 0.894231

checkpoint saved

epoch-1 step 120100/3451022 - loss: 0.042405 val_loss: 0.041418	recall: 0.495468 precision: 0.906077

model exported!

epoch-1 step 120200/3451022 - loss: 0.042149 val_loss: 0.034293	recall: 0.520591 precision: 0.906250
epoch-1 step 120300/3451022 - loss: 0.036317 val_loss: 0.033925	recall: 0.518644 precision: 0.887814
epoch-1 step 120400/3451022 - loss: 0.037594 val_loss: 0.034650	recall: 0.546189 precision: 0.899240
epoch-1 step 120500/3451022 - loss: 0.035452 val_loss: 0.037208	recall: 0.515351 precision: 0.909091
epoch-1 step 120600/3451022 - loss: 0.035915 val_loss: 0.036421	recall: 0.501608 precision: 0.905222
epoch-1 step 120700/3451022 - loss: 0.035158 val_loss: 0.034783	recall: 0.524239 precision: 0.889101
epoch-1 step 120800/3451022 - loss: 0.034760 val_loss: 0.034969	recall: 0.520548 precision: 0.906561
epoch-1 step 120900/3451022 - loss: 0.040244 val_loss: 0.047830	recall: 0.536000 precision: 0.905405
epoch-1 step 121000/3451022 - loss: 0.045034 val_loss: 0.040189	recall: 0.500554 precision: 0.889764

checkpoint saved

epoch-1 step 121100/3451022 - loss: 0.034688 val_loss: 0.035610	recall: 0.530752 precision: 0.904854
epoch-1 step 121200/3451022 - loss: 0.038135 val_loss: 0.034750	recall: 0.539352 precision: 0.899614
epoch-1 step 121300/3451022 - loss: 0.035474 val_loss: 0.038478	recall: 0.525832 precision: 0.892788
epoch-1 step 121400/3451022 - loss: 0.041327 val_loss: 0.040415	recall: 0.530425 precision: 0.895349
epoch-1 step 121500/3451022 - loss: 0.037435 val_loss: 0.035721	recall: 0.528193 precision: 0.901768
epoch-1 step 121600/3451022 - loss: 0.041264 val_loss: 0.045258	recall: 0.548423 precision: 0.901852
epoch-1 step 121700/3451022 - loss: 0.036030 val_loss: 0.040011	recall: 0.510204 precision: 0.889328
epoch-1 step 121800/3451022 - loss: 0.039829 val_loss: 0.036190	recall: 0.467222 precision: 0.865125
epoch-1 step 121900/3451022 - loss: 0.035975 val_loss: 0.036211	recall: 0.507883 precision: 0.875728
epoch-1 step 122000/3451022 - loss: 0.037736 val_loss: 0.036018	recall: 0.516022 precision: 0.935872

checkpoint saved

epoch-1 step 122100/3451022 - loss: 0.037254 val_loss: 0.035012	recall: 0.537683 precision: 0.893458

model exported!

epoch-1 step 122200/3451022 - loss: 0.037723 val_loss: 0.039877	recall: 0.480465 precision: 0.885214
epoch-1 step 122300/3451022 - loss: 0.034947 val_loss: 0.034745	recall: 0.510753 precision: 0.899621
epoch-1 step 122400/3451022 - loss: 0.036480 val_loss: 0.038830	recall: 0.510482 precision: 0.924099
epoch-1 step 122500/3451022 - loss: 0.040409 val_loss: 0.035613	recall: 0.501121 precision: 0.894000
epoch-1 step 122600/3451022 - loss: 0.053545 val_loss: 0.033963	recall: 0.528634 precision: 0.921305
epoch-1 step 122700/3451022 - loss: 0.036069 val_loss: 0.037108	recall: 0.525084 precision: 0.892045
epoch-1 step 122800/3451022 - loss: 0.034692 val_loss: 0.036313	recall: 0.486966 precision: 0.905039
epoch-1 step 122900/3451022 - loss: 0.038971 val_loss: 0.036157	recall: 0.508565 precision: 0.892857
epoch-1 step 123000/3451022 - loss: 0.038000 val_loss: 0.036309	recall: 0.509989 precision: 0.901487

checkpoint saved

epoch-1 step 123100/3451022 - loss: 0.035890 val_loss: 0.038111	recall: 0.535513 precision: 0.894539
epoch-1 step 123200/3451022 - loss: 0.035804 val_loss: 0.045615	recall: 0.522503 precision: 0.891386
epoch-1 step 123300/3451022 - loss: 0.034660 val_loss: 0.037453	recall: 0.487404 precision: 0.862403
epoch-1 step 123400/3451022 - loss: 0.037058 val_loss: 0.044000	recall: 0.506329 precision: 0.921305
epoch-1 step 123500/3451022 - loss: 0.034635 val_loss: 0.037094	recall: 0.511182 precision: 0.917782
epoch-1 step 123600/3451022 - loss: 0.035319 val_loss: 0.038429	recall: 0.514286 precision: 0.914062
epoch-1 step 123700/3451022 - loss: 0.038559 val_loss: 0.036153	recall: 0.551370 precision: 0.904494
epoch-1 step 123800/3451022 - loss: 0.034516 val_loss: 0.036443	recall: 0.477387 precision: 0.904762
epoch-1 step 123900/3451022 - loss: 0.036058 val_loss: 0.049693	recall: 0.475127 precision: 0.894837
epoch-1 step 124000/3451022 - loss: 0.036140 val_loss: 0.036160	recall: 0.512878 precision: 0.916000

checkpoint saved

epoch-1 step 124100/3451022 - loss: 0.038796 val_loss: 0.034694	recall: 0.531659 precision: 0.922348

model exported!

epoch-1 step 124200/3451022 - loss: 0.037818 val_loss: 0.035402	recall: 0.511579 precision: 0.932821
epoch-1 step 124300/3451022 - loss: 0.039162 val_loss: 0.034109	recall: 0.507937 precision: 0.905660
epoch-1 step 124400/3451022 - loss: 0.034607 val_loss: 0.036960	recall: 0.540193 precision: 0.914701
epoch-1 step 124500/3451022 - loss: 0.036893 val_loss: 0.036877	recall: 0.469697 precision: 0.882114
epoch-1 step 124600/3451022 - loss: 0.038200 val_loss: 0.035535	recall: 0.518438 precision: 0.900188
epoch-1 step 124700/3451022 - loss: 0.036552 val_loss: 0.041817	recall: 0.504386 precision: 0.907298
epoch-1 step 124800/3451022 - loss: 0.038870 val_loss: 0.038035	recall: 0.517127 precision: 0.893130
epoch-1 step 124900/3451022 - loss: 0.037314 val_loss: 0.041583	recall: 0.478307 precision: 0.896825
epoch-1 step 125000/3451022 - loss: 0.035173 val_loss: 0.038526	recall: 0.513761 precision: 0.880157

checkpoint saved

epoch-1 step 125100/3451022 - loss: 0.037359 val_loss: 0.036768	recall: 0.492323 precision: 0.892393
epoch-1 step 125200/3451022 - loss: 0.041081 val_loss: 0.039193	recall: 0.477398 precision: 0.885481
epoch-1 step 125300/3451022 - loss: 0.043345 val_loss: 0.037955	recall: 0.494143 precision: 0.882129
epoch-1 step 125400/3451022 - loss: 0.036641 val_loss: 0.037911	recall: 0.519274 precision: 0.899804
epoch-1 step 125500/3451022 - loss: 0.037932 val_loss: 0.040523	recall: 0.499469 precision: 0.934394
epoch-1 step 125600/3451022 - loss: 0.036303 val_loss: 0.035722	recall: 0.535556 precision: 0.923372
epoch-1 step 125700/3451022 - loss: 0.036592 val_loss: 0.035290	recall: 0.505808 precision: 0.926499
epoch-1 step 125800/3451022 - loss: 0.036967 val_loss: 0.034682	recall: 0.489293 precision: 0.894325
epoch-1 step 125900/3451022 - loss: 0.034404 val_loss: 0.033749	recall: 0.520442 precision: 0.927165
epoch-1 step 126000/3451022 - loss: 0.036358 val_loss: 0.051558	recall: 0.503219 precision: 0.903661

checkpoint saved

epoch-1 step 126100/3451022 - loss: 0.040787 val_loss: 0.039792	recall: 0.513043 precision: 0.911197

model exported!

epoch-1 step 126200/3451022 - loss: 0.034900 val_loss: 0.034325	recall: 0.533181 precision: 0.920949
epoch-1 step 126300/3451022 - loss: 0.035021 val_loss: 0.040200	recall: 0.529477 precision: 0.915385
epoch-1 step 126400/3451022 - loss: 0.041609 val_loss: 0.036869	recall: 0.510117 precision: 0.921154
epoch-1 step 126500/3451022 - loss: 0.034868 val_loss: 0.042759	recall: 0.497821 precision: 0.904950
epoch-1 step 126600/3451022 - loss: 0.036327 val_loss: 0.035191	recall: 0.532805 precision: 0.900574
epoch-1 step 126700/3451022 - loss: 0.038372 val_loss: 0.037818	recall: 0.491713 precision: 0.882937
epoch-1 step 126800/3451022 - loss: 0.036495 val_loss: 0.036209	recall: 0.545558 precision: 0.917625
epoch-1 step 126900/3451022 - loss: 0.039932 val_loss: 0.040572	recall: 0.494092 precision: 0.900196
epoch-1 step 127000/3451022 - loss: 0.038499 val_loss: 0.035847	recall: 0.503212 precision: 0.898662

checkpoint saved

epoch-1 step 127100/3451022 - loss: 0.034524 val_loss: 0.037092	recall: 0.509895 precision: 0.869048
epoch-1 step 127200/3451022 - loss: 0.037199 val_loss: 0.046112	recall: 0.496158 precision: 0.884540
epoch-1 step 127300/3451022 - loss: 0.035794 val_loss: 0.035556	recall: 0.514917 precision: 0.917323
epoch-1 step 127400/3451022 - loss: 0.035263 val_loss: 0.036572	recall: 0.502146 precision: 0.898273
epoch-1 step 127500/3451022 - loss: 0.039953 val_loss: 0.042289	recall: 0.499474 precision: 0.897921
epoch-1 step 127600/3451022 - loss: 0.034895 val_loss: 0.034376	recall: 0.512764 precision: 0.907662
epoch-1 step 127700/3451022 - loss: 0.041036 val_loss: 0.039482	recall: 0.503080 precision: 0.914179
epoch-1 step 127800/3451022 - loss: 0.035416 val_loss: 0.043871	recall: 0.548458 precision: 0.934334
epoch-1 step 127900/3451022 - loss: 0.037957 val_loss: 0.035120	recall: 0.498945 precision: 0.925636
epoch-1 step 128000/3451022 - loss: 0.037884 val_loss: 0.036934	recall: 0.481865 precision: 0.904669

checkpoint saved

epoch-1 step 128100/3451022 - loss: 0.034843 val_loss: 0.035500	recall: 0.517423 precision: 0.929791

model exported!

epoch-1 step 128200/3451022 - loss: 0.033995 val_loss: 0.043287	recall: 0.528761 precision: 0.898496
epoch-1 step 128300/3451022 - loss: 0.039221 val_loss: 0.035665	recall: 0.505845 precision: 0.926070
epoch-1 step 128400/3451022 - loss: 0.036251 val_loss: 0.038433	recall: 0.495807 precision: 0.902672
epoch-1 step 128500/3451022 - loss: 0.034884 val_loss: 0.039440	recall: 0.523702 precision: 0.888889
epoch-1 step 128600/3451022 - loss: 0.035753 val_loss: 0.035261	recall: 0.506466 precision: 0.893536
epoch-1 step 128700/3451022 - loss: 0.034079 val_loss: 0.035108	recall: 0.546875 precision: 0.915888
epoch-1 step 128800/3451022 - loss: 0.035202 val_loss: 0.035172	recall: 0.517838 precision: 0.903774
epoch-1 step 128900/3451022 - loss: 0.038296 val_loss: 0.047742	recall: 0.506466 precision: 0.898662
epoch-1 step 129000/3451022 - loss: 0.063692 val_loss: 0.034365	recall: 0.518272 precision: 0.915851

checkpoint saved

epoch-1 step 129100/3451022 - loss: 0.035071 val_loss: 0.035482	recall: 0.505342 precision: 0.900952
epoch-1 step 129200/3451022 - loss: 0.036582 val_loss: 0.035565	recall: 0.516304 precision: 0.896226
epoch-1 step 129300/3451022 - loss: 0.035313 val_loss: 0.036446	recall: 0.534463 precision: 0.907869
epoch-1 step 129400/3451022 - loss: 0.035506 val_loss: 0.035006	recall: 0.523482 precision: 0.896078
epoch-1 step 129500/3451022 - loss: 0.035794 val_loss: 0.036484	recall: 0.509033 precision: 0.919386
epoch-1 step 129600/3451022 - loss: 0.044593 val_loss: 0.039517	recall: 0.501089 precision: 0.893204
epoch-1 step 129700/3451022 - loss: 0.036036 val_loss: 0.036179	recall: 0.508696 precision: 0.906977
epoch-1 step 129800/3451022 - loss: 0.039201 val_loss: 0.038462	recall: 0.539735 precision: 0.917448
epoch-1 step 129900/3451022 - loss: 0.040522 val_loss: 0.034640	recall: 0.496888 precision: 0.910646
epoch-1 step 130000/3451022 - loss: 0.041447 val_loss: 0.036501	recall: 0.511475 precision: 0.905222

checkpoint saved

epoch-1 step 130100/3451022 - loss: 0.035745 val_loss: 0.034677	recall: 0.507675 precision: 0.907843

model exported!

epoch-1 step 130200/3451022 - loss: 0.035939 val_loss: 0.035217	recall: 0.523294 precision: 0.896104
epoch-1 step 130300/3451022 - loss: 0.043168 val_loss: 0.045937	recall: 0.500538 precision: 0.897683
epoch-1 step 130400/3451022 - loss: 0.039230 val_loss: 0.038532	recall: 0.512931 precision: 0.896422
epoch-1 step 130500/3451022 - loss: 0.039980 val_loss: 0.037843	recall: 0.539936 precision: 0.937153
epoch-1 step 130600/3451022 - loss: 0.038120 val_loss: 0.035378	recall: 0.516779 precision: 0.902344
epoch-1 step 130700/3451022 - loss: 0.035248 val_loss: 0.035154	recall: 0.502662 precision: 0.911197
epoch-1 step 130800/3451022 - loss: 0.033973 val_loss: 0.036506	recall: 0.470588 precision: 0.881764
epoch-1 step 130900/3451022 - loss: 0.034876 val_loss: 0.036355	recall: 0.489774 precision: 0.899209
epoch-1 step 131000/3451022 - loss: 0.035286 val_loss: 0.034683	recall: 0.509677 precision: 0.915058

checkpoint saved

epoch-1 step 131100/3451022 - loss: 0.038653 val_loss: 0.037239	recall: 0.488445 precision: 0.922619
epoch-1 step 131200/3451022 - loss: 0.034349 val_loss: 0.035528	recall: 0.540571 precision: 0.913127
epoch-1 step 131300/3451022 - loss: 0.037776 val_loss: 0.037271	recall: 0.483528 precision: 0.885214
epoch-1 step 131400/3451022 - loss: 0.035280 val_loss: 0.036404	recall: 0.504772 precision: 0.911877
epoch-1 step 131500/3451022 - loss: 0.042262 val_loss: 0.034507	recall: 0.489754 precision: 0.900188
epoch-1 step 131600/3451022 - loss: 0.035639 val_loss: 0.034310	recall: 0.505605 precision: 0.896620
epoch-1 step 131700/3451022 - loss: 0.033776 val_loss: 0.034710	recall: 0.522552 precision: 0.906489
epoch-1 step 131800/3451022 - loss: 0.037865 val_loss: 0.036315	recall: 0.479959 precision: 0.876173
epoch-1 step 131900/3451022 - loss: 0.038157 val_loss: 0.033950	recall: 0.515279 precision: 0.931429
epoch-1 step 132000/3451022 - loss: 0.039683 val_loss: 0.035256	recall: 0.533557 precision: 0.910305

checkpoint saved

epoch-1 step 132100/3451022 - loss: 0.040637 val_loss: 0.034325	recall: 0.524554 precision: 0.881801

model exported!

epoch-1 step 132200/3451022 - loss: 0.040016 val_loss: 0.046173	recall: 0.558167 precision: 0.891182
epoch-1 step 132300/3451022 - loss: 0.035615 val_loss: 0.039141	recall: 0.533958 precision: 0.899408
epoch-1 step 132400/3451022 - loss: 0.042661 val_loss: 0.039598	recall: 0.503893 precision: 0.897030
epoch-1 step 132500/3451022 - loss: 0.038950 val_loss: 0.039808	recall: 0.504844 precision: 0.895038
epoch-1 step 132600/3451022 - loss: 0.037508 val_loss: 0.035755	recall: 0.481243 precision: 0.892644
epoch-1 step 132700/3451022 - loss: 0.036594 val_loss: 0.037616	recall: 0.512141 precision: 0.897485
epoch-1 step 132800/3451022 - loss: 0.034945 val_loss: 0.036206	recall: 0.509033 precision: 0.907197
epoch-1 step 132900/3451022 - loss: 0.038036 val_loss: 0.040210	recall: 0.489549 precision: 0.902637
epoch-1 step 133000/3451022 - loss: 0.036779 val_loss: 0.038412	recall: 0.508161 precision: 0.896353

checkpoint saved

epoch-1 step 133100/3451022 - loss: 0.038326 val_loss: 0.035915	recall: 0.489097 precision: 0.867403
epoch-1 step 133200/3451022 - loss: 0.038797 val_loss: 0.038453	recall: 0.503226 precision: 0.898273
epoch-1 step 133300/3451022 - loss: 0.035719 val_loss: 0.036615	recall: 0.482328 precision: 0.904483
epoch-1 step 133400/3451022 - loss: 0.035192 val_loss: 0.044124	recall: 0.513284 precision: 0.902804
epoch-1 step 133500/3451022 - loss: 0.044205 val_loss: 0.036814	recall: 0.519774 precision: 0.882917
epoch-1 step 133600/3451022 - loss: 0.035691 val_loss: 0.035135	recall: 0.490302 precision: 0.890411
epoch-1 step 133700/3451022 - loss: 0.035814 val_loss: 0.035016	recall: 0.501104 precision: 0.891945
epoch-1 step 133800/3451022 - loss: 0.037473 val_loss: 0.036978	recall: 0.495708 precision: 0.893617
epoch-1 step 133900/3451022 - loss: 0.035450 val_loss: 0.041345	recall: 0.510096 precision: 0.916031
epoch-1 step 134000/3451022 - loss: 0.035647 val_loss: 0.035176	recall: 0.508869 precision: 0.918000

checkpoint saved

epoch-1 step 134100/3451022 - loss: 0.035456 val_loss: 0.033509	recall: 0.496249 precision: 0.918651

model exported!

epoch-1 step 134200/3451022 - loss: 0.036790 val_loss: 0.034197	recall: 0.508380 precision: 0.900990
epoch-1 step 134300/3451022 - loss: 0.034764 val_loss: 0.036798	recall: 0.491667 precision: 0.885553
epoch-1 step 134400/3451022 - loss: 0.035638 val_loss: 0.043121	recall: 0.526374 precision: 0.921154
epoch-1 step 134500/3451022 - loss: 0.034459 val_loss: 0.036626	recall: 0.514673 precision: 0.887160
epoch-1 step 134600/3451022 - loss: 0.036197 val_loss: 0.033917	recall: 0.519144 precision: 0.888247
epoch-1 step 134700/3451022 - loss: 0.035661 val_loss: 0.035257	recall: 0.496795 precision: 0.904669
epoch-1 step 134800/3451022 - loss: 0.039671 val_loss: 0.035619	recall: 0.520474 precision: 0.901119
epoch-1 step 134900/3451022 - loss: 0.048301 val_loss: 0.035096	recall: 0.510870 precision: 0.940000
epoch-1 step 135000/3451022 - loss: 0.035230 val_loss: 0.041318	recall: 0.522472 precision: 0.897683

checkpoint saved

epoch-1 step 135100/3451022 - loss: 0.037272 val_loss: 0.041996	recall: 0.484244 precision: 0.909270
epoch-1 step 135200/3451022 - loss: 0.041689 val_loss: 0.034689	recall: 0.491614 precision: 0.903661
epoch-1 step 135300/3451022 - loss: 0.041949 val_loss: 0.038170	recall: 0.525028 precision: 0.929134
epoch-1 step 135400/3451022 - loss: 0.036630 val_loss: 0.035762	recall: 0.508696 precision: 0.901734
epoch-1 step 135500/3451022 - loss: 0.037132 val_loss: 0.034944	recall: 0.511206 precision: 0.914122
epoch-1 step 135600/3451022 - loss: 0.034467 val_loss: 0.042443	recall: 0.500556 precision: 0.884086
epoch-1 step 135700/3451022 - loss: 0.035491 val_loss: 0.035599	recall: 0.504320 precision: 0.919291
epoch-1 step 135800/3451022 - loss: 0.036452 val_loss: 0.036224	recall: 0.512332 precision: 0.904950
epoch-1 step 135900/3451022 - loss: 0.035934 val_loss: 0.036583	recall: 0.515945 precision: 0.906000
epoch-1 step 136000/3451022 - loss: 0.035772 val_loss: 0.034623	recall: 0.519058 precision: 0.922311

checkpoint saved

epoch-1 step 136100/3451022 - loss: 0.036071 val_loss: 0.035841	recall: 0.541810 precision: 0.918447

model exported!

epoch-1 step 136200/3451022 - loss: 0.035228 val_loss: 0.035585	recall: 0.516058 precision: 0.910156
epoch-1 step 136300/3451022 - loss: 0.045302 val_loss: 0.037642	recall: 0.528409 precision: 0.918972
epoch-1 step 136400/3451022 - loss: 0.035424 val_loss: 0.039703	recall: 0.522503 precision: 0.904943
epoch-1 step 136500/3451022 - loss: 0.038798 val_loss: 0.038781	recall: 0.511236 precision: 0.895669
epoch-1 step 136600/3451022 - loss: 0.038705 val_loss: 0.036126	recall: 0.526077 precision: 0.902724
epoch-1 step 136700/3451022 - loss: 0.037339 val_loss: 0.035294	recall: 0.497309 precision: 0.893617
epoch-1 step 136800/3451022 - loss: 0.037258 val_loss: 0.035394	recall: 0.517932 precision: 0.912639
epoch-1 step 136900/3451022 - loss: 0.035716 val_loss: 0.036263	recall: 0.490000 precision: 0.896341
epoch-1 step 137000/3451022 - loss: 0.037031 val_loss: 0.035228	recall: 0.484232 precision: 0.896422

checkpoint saved

epoch-1 step 137100/3451022 - loss: 0.034436 val_loss: 0.035451	recall: 0.490011 precision: 0.885932
epoch-1 step 137200/3451022 - loss: 0.035693 val_loss: 0.035574	recall: 0.509414 precision: 0.906890
epoch-1 step 137300/3451022 - loss: 0.035368 val_loss: 0.036411	recall: 0.478678 precision: 0.868472
epoch-1 step 137400/3451022 - loss: 0.035493 val_loss: 0.034955	recall: 0.489685 precision: 0.898406
epoch-1 step 137500/3451022 - loss: 0.040986 val_loss: 0.036794	recall: 0.533408 precision: 0.915870
epoch-1 step 137600/3451022 - loss: 0.040892 val_loss: 0.035446	recall: 0.510112 precision: 0.900794
epoch-1 step 137700/3451022 - loss: 0.036541 val_loss: 0.039126	recall: 0.527687 precision: 0.908411
epoch-1 step 137800/3451022 - loss: 0.034157 val_loss: 0.036882	recall: 0.512277 precision: 0.910714
epoch-1 step 137900/3451022 - loss: 0.035616 val_loss: 0.037085	recall: 0.495910 precision: 0.925573
epoch-1 step 138000/3451022 - loss: 0.041039 val_loss: 0.037538	recall: 0.487983 precision: 0.913894

checkpoint saved

epoch-1 step 138100/3451022 - loss: 0.036561 val_loss: 0.034746	recall: 0.487500 precision: 0.910506

model exported!

epoch-1 step 138200/3451022 - loss: 0.035163 val_loss: 0.034904	recall: 0.460417 precision: 0.882236
epoch-1 step 138300/3451022 - loss: 0.034845 val_loss: 0.035687	recall: 0.487368 precision: 0.893822
epoch-1 step 138400/3451022 - loss: 0.039114 val_loss: 0.036548	recall: 0.488172 precision: 0.899010
epoch-1 step 138500/3451022 - loss: 0.033778 val_loss: 0.036142	recall: 0.517454 precision: 0.929889
epoch-1 step 138600/3451022 - loss: 0.044125 val_loss: 0.035566	recall: 0.489407 precision: 0.909449
epoch-1 step 138700/3451022 - loss: 0.036930 val_loss: 0.034271	recall: 0.523549 precision: 0.935421
epoch-1 step 138800/3451022 - loss: 0.036581 val_loss: 0.039880	recall: 0.515882 precision: 0.882022
epoch-1 step 138900/3451022 - loss: 0.039749 val_loss: 0.050062	recall: 0.493724 precision: 0.900763
epoch-1 step 139000/3451022 - loss: 0.036170 val_loss: 0.035175	recall: 0.501625 precision: 0.913215

checkpoint saved

epoch-1 step 139100/3451022 - loss: 0.041543 val_loss: 0.036255	recall: 0.529344 precision: 0.894942
epoch-1 step 139200/3451022 - loss: 0.041495 val_loss: 0.034566	recall: 0.523649 precision: 0.904669
epoch-1 step 139300/3451022 - loss: 0.042753 val_loss: 0.043529	recall: 0.526030 precision: 0.920304
epoch-1 step 139400/3451022 - loss: 0.039529 val_loss: 0.036589	recall: 0.496304 precision: 0.903846
epoch-1 step 139500/3451022 - loss: 0.045008 val_loss: 0.036282	recall: 0.486631 precision: 0.908184
epoch-1 step 139600/3451022 - loss: 0.035598 val_loss: 0.044654	recall: 0.509865 precision: 0.922932
epoch-1 step 139700/3451022 - loss: 0.035134 val_loss: 0.035379	recall: 0.531686 precision: 0.932203
epoch-1 step 139800/3451022 - loss: 0.035660 val_loss: 0.038132	recall: 0.476780 precision: 0.886756
epoch-1 step 139900/3451022 - loss: 0.035411 val_loss: 0.038671	recall: 0.497758 precision: 0.891566
epoch-1 step 140000/3451022 - loss: 0.040160 val_loss: 0.037782	recall: 0.529018 precision: 0.896030

checkpoint saved

epoch-1 step 140100/3451022 - loss: 0.035806 val_loss: 0.037902	recall: 0.480851 precision: 0.886275

model exported!

epoch-1 step 140200/3451022 - loss: 0.035104 val_loss: 0.036051	recall: 0.512360 precision: 0.917505
epoch-1 step 140300/3451022 - loss: 0.035403 val_loss: 0.037916	recall: 0.505330 precision: 0.911538
epoch-1 step 140400/3451022 - loss: 0.039514 val_loss: 0.041022	recall: 0.494518 precision: 0.911111
epoch-1 step 140500/3451022 - loss: 0.039851 val_loss: 0.037085	recall: 0.498971 precision: 0.908240
epoch-1 step 140600/3451022 - loss: 0.035009 val_loss: 0.039879	recall: 0.522222 precision: 0.895238
epoch-1 step 140700/3451022 - loss: 0.037079 val_loss: 0.036123	recall: 0.496233 precision: 0.902153
epoch-1 step 140800/3451022 - loss: 0.036124 val_loss: 0.035301	recall: 0.511111 precision: 0.920000
epoch-1 step 140900/3451022 - loss: 0.035819 val_loss: 0.036172	recall: 0.505263 precision: 0.916031
epoch-1 step 141000/3451022 - loss: 0.036871 val_loss: 0.034170	recall: 0.483539 precision: 0.900383

checkpoint saved

epoch-1 step 141100/3451022 - loss: 0.039905 val_loss: 0.038371	recall: 0.519084 precision: 0.918919
epoch-1 step 141200/3451022 - loss: 0.037124 val_loss: 0.034797	recall: 0.526596 precision: 0.928705
epoch-1 step 141300/3451022 - loss: 0.035382 val_loss: 0.038382	recall: 0.540632 precision: 0.922929
epoch-1 step 141400/3451022 - loss: 0.035835 val_loss: 0.035026	recall: 0.482830 precision: 0.902724
epoch-1 step 141500/3451022 - loss: 0.036213 val_loss: 0.037172	recall: 0.541850 precision: 0.917910
epoch-1 step 141600/3451022 - loss: 0.035088 val_loss: 0.036555	recall: 0.512486 precision: 0.912959
epoch-1 step 141700/3451022 - loss: 0.040442 val_loss: 0.038827	recall: 0.514690 precision: 0.920233
epoch-1 step 141800/3451022 - loss: 0.040899 val_loss: 0.040403	recall: 0.514737 precision: 0.902214
epoch-1 step 141900/3451022 - loss: 0.040820 val_loss: 0.039019	recall: 0.481142 precision: 0.911197
epoch-1 step 142000/3451022 - loss: 0.040349 val_loss: 0.049199	recall: 0.507761 precision: 0.894531

checkpoint saved

epoch-1 step 142100/3451022 - loss: 0.038162 val_loss: 0.035927	recall: 0.518600 precision: 0.944223

model exported!

epoch-1 step 142200/3451022 - loss: 0.042321 val_loss: 0.043293	recall: 0.506849 precision: 0.900749
epoch-1 step 142300/3451022 - loss: 0.037449 val_loss: 0.036197	recall: 0.522702 precision: 0.914729
epoch-1 step 142400/3451022 - loss: 0.035044 val_loss: 0.034747	recall: 0.493304 precision: 0.884000
epoch-1 step 142500/3451022 - loss: 0.036442 val_loss: 0.033811	recall: 0.490256 precision: 0.913958
epoch-1 step 142600/3451022 - loss: 0.047138 val_loss: 0.040213	recall: 0.501078 precision: 0.901163
epoch-1 step 142700/3451022 - loss: 0.036976 val_loss: 0.051518	recall: 0.491785 precision: 0.898000
epoch-1 step 142800/3451022 - loss: 0.036588 val_loss: 0.043024	recall: 0.510917 precision: 0.914062
epoch-1 step 142900/3451022 - loss: 0.035891 val_loss: 0.039293	recall: 0.527088 precision: 0.899807
epoch-1 step 143000/3451022 - loss: 0.038246 val_loss: 0.036798	recall: 0.540113 precision: 0.900188

checkpoint saved

epoch-1 step 143100/3451022 - loss: 0.034625 val_loss: 0.037192	recall: 0.506944 precision: 0.886640
epoch-1 step 143200/3451022 - loss: 0.046671 val_loss: 0.040442	recall: 0.531773 precision: 0.891589
epoch-1 step 143300/3451022 - loss: 0.034034 val_loss: 0.035117	recall: 0.505342 precision: 0.892453
epoch-1 step 143400/3451022 - loss: 0.036018 val_loss: 0.035804	recall: 0.540204 precision: 0.908571
epoch-1 step 143500/3451022 - loss: 0.036171 val_loss: 0.033654	recall: 0.520788 precision: 0.894737
epoch-1 step 143600/3451022 - loss: 0.035511 val_loss: 0.034477	recall: 0.519585 precision: 0.894841
epoch-1 step 143700/3451022 - loss: 0.034636 val_loss: 0.040064	recall: 0.533627 precision: 0.906367
epoch-1 step 143800/3451022 - loss: 0.034951 val_loss: 0.038369	recall: 0.524920 precision: 0.920074
epoch-1 step 143900/3451022 - loss: 0.034733 val_loss: 0.040585	recall: 0.534054 precision: 0.928571
epoch-1 step 144000/3451022 - loss: 0.034657 val_loss: 0.034963	recall: 0.468041 precision: 0.888454

checkpoint saved

epoch-1 step 144100/3451022 - loss: 0.041042 val_loss: 0.035019	recall: 0.497360 precision: 0.904031

model exported!

epoch-1 step 144200/3451022 - loss: 0.036645 val_loss: 0.036129	recall: 0.501092 precision: 0.901768
epoch-1 step 144300/3451022 - loss: 0.035219 val_loss: 0.034681	recall: 0.498350 precision: 0.874517
epoch-1 step 144400/3451022 - loss: 0.041460 val_loss: 0.034785	recall: 0.555046 precision: 0.908068
epoch-1 step 144500/3451022 - loss: 0.035411 val_loss: 0.034669	recall: 0.527233 precision: 0.911488
epoch-1 step 144600/3451022 - loss: 0.036333 val_loss: 0.034768	recall: 0.519187 precision: 0.900196
epoch-1 step 144700/3451022 - loss: 0.035106 val_loss: 0.043815	recall: 0.537541 precision: 0.925094
epoch-1 step 144800/3451022 - loss: 0.035692 val_loss: 0.034877	recall: 0.517582 precision: 0.893738
epoch-1 step 144900/3451022 - loss: 0.038940 val_loss: 0.035704	recall: 0.507795 precision: 0.875240
epoch-1 step 145000/3451022 - loss: 0.035260 val_loss: 0.035342	recall: 0.483731 precision: 0.872798

checkpoint saved

epoch-1 step 145100/3451022 - loss: 0.043374 val_loss: 0.037321	recall: 0.488936 precision: 0.897485
epoch-1 step 145200/3451022 - loss: 0.036424 val_loss: 0.036830	recall: 0.499470 precision: 0.907514
epoch-1 step 145300/3451022 - loss: 0.035524 val_loss: 0.043823	recall: 0.496809 precision: 0.884470
epoch-1 step 145400/3451022 - loss: 0.041115 val_loss: 0.034792	recall: 0.525330 precision: 0.919075
epoch-1 step 145500/3451022 - loss: 0.042036 val_loss: 0.035093	recall: 0.504823 precision: 0.890359
epoch-1 step 145600/3451022 - loss: 0.035686 val_loss: 0.036523	recall: 0.551876 precision: 0.936330
epoch-1 step 145700/3451022 - loss: 0.036313 val_loss: 0.035211	recall: 0.520087 precision: 0.919386
epoch-1 step 145800/3451022 - loss: 0.035088 val_loss: 0.037226	recall: 0.515118 precision: 0.909091
epoch-1 step 145900/3451022 - loss: 0.039731 val_loss: 0.035379	recall: 0.488147 precision: 0.879612
epoch-1 step 146000/3451022 - loss: 0.046506 val_loss: 0.039225	recall: 0.507088 precision: 0.892514

checkpoint saved

epoch-1 step 146100/3451022 - loss: 0.042183 val_loss: 0.050909	recall: 0.493763 precision: 0.901328

model exported!

epoch-1 step 146200/3451022 - loss: 0.034377 val_loss: 0.041252	recall: 0.499443 precision: 0.869903
epoch-1 step 146300/3451022 - loss: 0.038243 val_loss: 0.041499	recall: 0.543195 precision: 0.903543
epoch-1 step 146400/3451022 - loss: 0.036428 val_loss: 0.036116	recall: 0.517954 precision: 0.901515
epoch-1 step 146500/3451022 - loss: 0.036916 val_loss: 0.036945	recall: 0.503226 precision: 0.903475
epoch-1 step 146600/3451022 - loss: 0.041398 val_loss: 0.036924	recall: 0.531042 precision: 0.903774
epoch-1 step 146700/3451022 - loss: 0.047946 val_loss: 0.035333	recall: 0.535912 precision: 0.908240
epoch-1 step 146800/3451022 - loss: 0.035470 val_loss: 0.046879	recall: 0.491398 precision: 0.885659
epoch-1 step 146900/3451022 - loss: 0.035356 val_loss: 0.040952	recall: 0.532634 precision: 0.919517
epoch-1 step 147000/3451022 - loss: 0.039037 val_loss: 0.035739	recall: 0.510482 precision: 0.925856

checkpoint saved

epoch-1 step 147100/3451022 - loss: 0.040238 val_loss: 0.036864	recall: 0.522676 precision: 0.902153
epoch-1 step 147200/3451022 - loss: 0.037481 val_loss: 0.034437	recall: 0.506452 precision: 0.888679
epoch-1 step 147300/3451022 - loss: 0.036804 val_loss: 0.034967	recall: 0.506952 precision: 0.889306
epoch-1 step 147400/3451022 - loss: 0.038913 val_loss: 0.034996	recall: 0.509761 precision: 0.914397
epoch-1 step 147500/3451022 - loss: 0.041395 val_loss: 0.036367	recall: 0.497773 precision: 0.885149
epoch-1 step 147600/3451022 - loss: 0.045244 val_loss: 0.042448	recall: 0.522388 precision: 0.924528
epoch-1 step 147700/3451022 - loss: 0.036230 val_loss: 0.039988	recall: 0.517514 precision: 0.901575
epoch-1 step 147800/3451022 - loss: 0.033976 val_loss: 0.035409	recall: 0.520174 precision: 0.908571
epoch-1 step 147900/3451022 - loss: 0.038744 val_loss: 0.035515	recall: 0.507675 precision: 0.900778
epoch-1 step 148000/3451022 - loss: 0.042088 val_loss: 0.034645	recall: 0.482201 precision: 0.874755

checkpoint saved

epoch-1 step 148100/3451022 - loss: 0.037784 val_loss: 0.034171	recall: 0.524590 precision: 0.905660

model exported!

epoch-1 step 148200/3451022 - loss: 0.038636 val_loss: 0.034861	recall: 0.528825 precision: 0.920849
epoch-1 step 148300/3451022 - loss: 0.044490 val_loss: 0.035970	recall: 0.525843 precision: 0.928571
epoch-1 step 148400/3451022 - loss: 0.040502 val_loss: 0.037259	recall: 0.505723 precision: 0.911820
epoch-1 step 148500/3451022 - loss: 0.038583 val_loss: 0.034817	recall: 0.497807 precision: 0.884990
epoch-1 step 148600/3451022 - loss: 0.043844 val_loss: 0.039525	recall: 0.504329 precision: 0.892720
epoch-1 step 148700/3451022 - loss: 0.048873 val_loss: 0.037214	recall: 0.499458 precision: 0.889961
epoch-1 step 148800/3451022 - loss: 0.034455 val_loss: 0.035759	recall: 0.493222 precision: 0.922027
epoch-1 step 148900/3451022 - loss: 0.037994 val_loss: 0.034626	recall: 0.488649 precision: 0.865900
epoch-1 step 149000/3451022 - loss: 0.039683 val_loss: 0.037164	recall: 0.522624 precision: 0.900585

checkpoint saved

epoch-1 step 149100/3451022 - loss: 0.041068 val_loss: 0.036943	recall: 0.525386 precision: 0.893058
epoch-1 step 149200/3451022 - loss: 0.034624 val_loss: 0.034946	recall: 0.523915 precision: 0.911025
epoch-1 step 149300/3451022 - loss: 0.036095 val_loss: 0.035555	recall: 0.523454 precision: 0.899267
epoch-1 step 149400/3451022 - loss: 0.035283 val_loss: 0.036458	recall: 0.487179 precision: 0.882012
epoch-1 step 149500/3451022 - loss: 0.034678 val_loss: 0.036894	recall: 0.529478 precision: 0.921105
epoch-1 step 149600/3451022 - loss: 0.040646 val_loss: 0.037337	recall: 0.488936 precision: 0.924303
epoch-1 step 149700/3451022 - loss: 0.035295 val_loss: 0.034858	recall: 0.519252 precision: 0.899048
epoch-1 step 149800/3451022 - loss: 0.037354 val_loss: 0.037940	recall: 0.501618 precision: 0.922619
epoch-1 step 149900/3451022 - loss: 0.035857 val_loss: 0.034412	recall: 0.518313 precision: 0.891221
epoch-1 step 150000/3451022 - loss: 0.034296 val_loss: 0.035632	recall: 0.501068 precision: 0.895038

checkpoint saved

epoch-1 step 150100/3451022 - loss: 0.035240 val_loss: 0.037276	recall: 0.471204 precision: 0.909091

model exported!

epoch-1 step 150200/3451022 - loss: 0.039344 val_loss: 0.035582	recall: 0.488397 precision: 0.883588
epoch-1 step 150300/3451022 - loss: 0.036196 val_loss: 0.037762	recall: 0.490586 precision: 0.889943
epoch-1 step 150400/3451022 - loss: 0.036502 val_loss: 0.036808	recall: 0.505376 precision: 0.890152
epoch-1 step 150500/3451022 - loss: 0.039331 val_loss: 0.041640	recall: 0.493333 precision: 0.867188
epoch-1 step 150600/3451022 - loss: 0.035476 val_loss: 0.038227	recall: 0.483315 precision: 0.889109
epoch-1 step 150700/3451022 - loss: 0.035716 val_loss: 0.037832	recall: 0.474468 precision: 0.872798
epoch-1 step 150800/3451022 - loss: 0.036831 val_loss: 0.034665	recall: 0.519337 precision: 0.912621
epoch-1 step 150900/3451022 - loss: 0.038004 val_loss: 0.039379	recall: 0.503800 precision: 0.888889
epoch-1 step 151000/3451022 - loss: 0.035366 val_loss: 0.040015	recall: 0.490216 precision: 0.927875

checkpoint saved

epoch-1 step 151100/3451022 - loss: 0.036676 val_loss: 0.044571	recall: 0.466391 precision: 0.884314
epoch-1 step 151200/3451022 - loss: 0.035247 val_loss: 0.035769	recall: 0.516340 precision: 0.906310
epoch-1 step 151300/3451022 - loss: 0.042218 val_loss: 0.037738	recall: 0.522976 precision: 0.907021
epoch-1 step 151400/3451022 - loss: 0.040021 val_loss: 0.035545	recall: 0.476089 precision: 0.876712
epoch-1 step 151500/3451022 - loss: 0.035593 val_loss: 0.034771	recall: 0.486602 precision: 0.891945
epoch-1 step 151600/3451022 - loss: 0.034652 val_loss: 0.037055	recall: 0.524838 precision: 0.927481
epoch-1 step 151700/3451022 - loss: 0.035473 val_loss: 0.036281	recall: 0.510032 precision: 0.911321
epoch-1 step 151800/3451022 - loss: 0.036587 val_loss: 0.039140	recall: 0.554374 precision: 0.916016
epoch-1 step 151900/3451022 - loss: 0.040512 val_loss: 0.046071	recall: 0.494703 precision: 0.892925
epoch-1 step 152000/3451022 - loss: 0.044114 val_loss: 0.042884	recall: 0.508179 precision: 0.904854

checkpoint saved

epoch-1 step 152100/3451022 - loss: 0.034453 val_loss: 0.035028	recall: 0.504175 precision: 0.916509

model exported!

epoch-1 step 152200/3451022 - loss: 0.034867 val_loss: 0.043786	recall: 0.535948 precision: 0.931818
epoch-1 step 152300/3451022 - loss: 0.037075 val_loss: 0.034991	recall: 0.553613 precision: 0.911708
epoch-1 step 152400/3451022 - loss: 0.039515 val_loss: 0.036903	recall: 0.531180 precision: 0.919075
epoch-1 step 152500/3451022 - loss: 0.035292 val_loss: 0.034694	recall: 0.549425 precision: 0.910476
epoch-1 step 152600/3451022 - loss: 0.040538 val_loss: 0.036241	recall: 0.478858 precision: 0.897030
epoch-1 step 152700/3451022 - loss: 0.038887 val_loss: 0.034592	recall: 0.527473 precision: 0.924855
epoch-1 step 152800/3451022 - loss: 0.037325 val_loss: 0.034257	recall: 0.534884 precision: 0.909091
epoch-1 step 152900/3451022 - loss: 0.039380 val_loss: 0.035073	recall: 0.556689 precision: 0.924670
epoch-1 step 153000/3451022 - loss: 0.039709 val_loss: 0.035493	recall: 0.490670 precision: 0.908537

checkpoint saved

epoch-1 step 153100/3451022 - loss: 0.036689 val_loss: 0.036646	recall: 0.513782 precision: 0.899614
epoch-1 step 153200/3451022 - loss: 0.042895 val_loss: 0.036300	recall: 0.514739 precision: 0.895464
epoch-1 step 153300/3451022 - loss: 0.037861 val_loss: 0.039538	recall: 0.503817 precision: 0.909449
epoch-1 step 153400/3451022 - loss: 0.034833 val_loss: 0.040036	recall: 0.508493 precision: 0.903774
epoch-1 step 153500/3451022 - loss: 0.040026 val_loss: 0.037569	recall: 0.510823 precision: 0.929134
epoch-1 step 153600/3451022 - loss: 0.036253 val_loss: 0.039343	recall: 0.512632 precision: 0.893578
epoch-1 step 153700/3451022 - loss: 0.042851 val_loss: 0.039221	recall: 0.515385 precision: 0.910680
epoch-1 step 153800/3451022 - loss: 0.035214 val_loss: 0.035882	recall: 0.490760 precision: 0.913958
epoch-1 step 153900/3451022 - loss: 0.034380 val_loss: 0.035502	recall: 0.507353 precision: 0.891144
epoch-1 step 154000/3451022 - loss: 0.035607 val_loss: 0.034425	recall: 0.519231 precision: 0.920455

checkpoint saved

epoch-1 step 154100/3451022 - loss: 0.037976 val_loss: 0.045785	recall: 0.479913 precision: 0.871795

model exported!

epoch-1 step 154200/3451022 - loss: 0.036481 val_loss: 0.036917	recall: 0.500524 precision: 0.913958
epoch-1 step 154300/3451022 - loss: 0.035685 val_loss: 0.035972	recall: 0.496166 precision: 0.904192
epoch-1 step 154400/3451022 - loss: 0.036918 val_loss: 0.038226	recall: 0.506652 precision: 0.901381
epoch-1 step 154500/3451022 - loss: 0.034836 val_loss: 0.034930	recall: 0.518973 precision: 0.917160
epoch-1 step 154600/3451022 - loss: 0.035283 val_loss: 0.035868	recall: 0.509636 precision: 0.917148
epoch-1 step 154700/3451022 - loss: 0.037698 val_loss: 0.034866	recall: 0.493063 precision: 0.907662
epoch-1 step 154800/3451022 - loss: 0.036982 val_loss: 0.043897	recall: 0.503205 precision: 0.912791
epoch-1 step 154900/3451022 - loss: 0.035182 val_loss: 0.037796	recall: 0.478173 precision: 0.919922
epoch-1 step 155000/3451022 - loss: 0.038736 val_loss: 0.035131	recall: 0.471000 precision: 0.909266

checkpoint saved

epoch-1 step 155100/3451022 - loss: 0.034346 val_loss: 0.036163	recall: 0.509072 precision: 0.891589
epoch-1 step 155200/3451022 - loss: 0.034270 val_loss: 0.035845	recall: 0.523915 precision: 0.921722
epoch-1 step 155300/3451022 - loss: 0.037315 val_loss: 0.040868	recall: 0.494670 precision: 0.920635
epoch-1 step 155400/3451022 - loss: 0.034834 val_loss: 0.035554	recall: 0.490486 precision: 0.900971
epoch-1 step 155500/3451022 - loss: 0.039245 val_loss: 0.039233	recall: 0.489904 precision: 0.903922
epoch-1 step 155600/3451022 - loss: 0.043243 val_loss: 0.037333	recall: 0.489518 precision: 0.903288
epoch-1 step 155700/3451022 - loss: 0.036069 val_loss: 0.035513	recall: 0.494143 precision: 0.892308
epoch-1 step 155800/3451022 - loss: 0.037576 val_loss: 0.038220	recall: 0.524537 precision: 0.928571
epoch-1 step 155900/3451022 - loss: 0.034324 val_loss: 0.034781	recall: 0.519774 precision: 0.916335
epoch-1 step 156000/3451022 - loss: 0.034761 val_loss: 0.034351	recall: 0.522581 precision: 0.908411

checkpoint saved

epoch-1 step 156100/3451022 - loss: 0.033865 val_loss: 0.034448	recall: 0.525242 precision: 0.924386

model exported!

epoch-1 step 156200/3451022 - loss: 0.034570 val_loss: 0.034745	recall: 0.504844 precision: 0.934263
epoch-1 step 156300/3451022 - loss: 0.036811 val_loss: 0.037385	recall: 0.524138 precision: 0.904762
epoch-1 step 156400/3451022 - loss: 0.038835 val_loss: 0.034642	recall: 0.505342 precision: 0.914894
epoch-1 step 156500/3451022 - loss: 0.042329 val_loss: 0.037607	recall: 0.519231 precision: 0.903543
epoch-1 step 156600/3451022 - loss: 0.039804 val_loss: 0.036136	recall: 0.500554 precision: 0.907631
epoch-1 step 156700/3451022 - loss: 0.037755 val_loss: 0.037931	recall: 0.531915 precision: 0.905433
epoch-1 step 156800/3451022 - loss: 0.038787 val_loss: 0.036322	recall: 0.518878 precision: 0.910985
epoch-1 step 156900/3451022 - loss: 0.042830 val_loss: 0.035130	recall: 0.489707 precision: 0.913131
epoch-1 step 157000/3451022 - loss: 0.041930 val_loss: 0.034822	recall: 0.529478 precision: 0.898077

checkpoint saved

epoch-1 step 157100/3451022 - loss: 0.034816 val_loss: 0.040070	recall: 0.498382 precision: 0.904110
epoch-1 step 157200/3451022 - loss: 0.038983 val_loss: 0.037358	recall: 0.519914 precision: 0.920000
epoch-1 step 157300/3451022 - loss: 0.035508 val_loss: 0.035687	recall: 0.496249 precision: 0.909627
epoch-1 step 157400/3451022 - loss: 0.046698 val_loss: 0.035455	recall: 0.490486 precision: 0.906250
epoch-1 step 157500/3451022 - loss: 0.034588 val_loss: 0.040105	recall: 0.533258 precision: 0.913127
epoch-1 step 157600/3451022 - loss: 0.033813 val_loss: 0.036380	recall: 0.494054 precision: 0.875479
epoch-1 step 157700/3451022 - loss: 0.038026 val_loss: 0.034937	recall: 0.497845 precision: 0.891892
epoch-1 step 157800/3451022 - loss: 0.035640 val_loss: 0.036014	recall: 0.496829 precision: 0.925197
epoch-1 step 157900/3451022 - loss: 0.038422 val_loss: 0.035024	recall: 0.528962 precision: 0.908068
epoch-1 step 158000/3451022 - loss: 0.034662 val_loss: 0.041292	recall: 0.477111 precision: 0.914230

checkpoint saved

epoch-1 step 158100/3451022 - loss: 0.035762 val_loss: 0.035630	recall: 0.499483 precision: 0.913043

model exported!

epoch-1 step 158200/3451022 - loss: 0.035576 val_loss: 0.039131	recall: 0.499446 precision: 0.916667
epoch-1 step 158300/3451022 - loss: 0.036806 val_loss: 0.040543	recall: 0.502183 precision: 0.909091
epoch-1 step 158400/3451022 - loss: 0.049135 val_loss: 0.037265	recall: 0.523810 precision: 0.911488
epoch-1 step 158500/3451022 - loss: 0.037885 val_loss: 0.035558	recall: 0.536071 precision: 0.920000
epoch-1 step 158600/3451022 - loss: 0.040732 val_loss: 0.038512	recall: 0.513129 precision: 0.903661
epoch-1 step 158700/3451022 - loss: 0.035020 val_loss: 0.036340	recall: 0.483871 precision: 0.901163
epoch-1 step 158800/3451022 - loss: 0.041720 val_loss: 0.034647	recall: 0.521047 precision: 0.901575
epoch-1 step 158900/3451022 - loss: 0.034538 val_loss: 0.035551	recall: 0.483422 precision: 0.882812
epoch-1 step 159000/3451022 - loss: 0.036242 val_loss: 0.033894	recall: 0.516854 precision: 0.881226

checkpoint saved

epoch-1 step 159100/3451022 - loss: 0.036260 val_loss: 0.035034	recall: 0.524892 precision: 0.927342
epoch-1 step 159200/3451022 - loss: 0.037186 val_loss: 0.036343	recall: 0.515152 precision: 0.924272
epoch-1 step 159300/3451022 - loss: 0.035025 val_loss: 0.039965	recall: 0.522854 precision: 0.907157
epoch-1 step 159400/3451022 - loss: 0.037984 val_loss: 0.041983	recall: 0.531042 precision: 0.907197
epoch-1 step 159500/3451022 - loss: 0.038419 val_loss: 0.037081	recall: 0.505735 precision: 0.901487
epoch-1 step 159600/3451022 - loss: 0.035446 val_loss: 0.035836	recall: 0.516892 precision: 0.916168
epoch-1 step 159700/3451022 - loss: 0.039224 val_loss: 0.036126	recall: 0.526316 precision: 0.905660
epoch-1 step 159800/3451022 - loss: 0.035688 val_loss: 0.036994	recall: 0.529148 precision: 0.893939
epoch-1 step 159900/3451022 - loss: 0.035389 val_loss: 0.041711	recall: 0.537228 precision: 0.916016
epoch-1 step 160000/3451022 - loss: 0.035896 val_loss: 0.037529	recall: 0.525366 precision: 0.913725

checkpoint saved

epoch-1 step 160100/3451022 - loss: 0.035638 val_loss: 0.036114	recall: 0.537228 precision: 0.895038

model exported!

epoch-1 step 160200/3451022 - loss: 0.036322 val_loss: 0.037013	recall: 0.496288 precision: 0.878049
epoch-1 step 160300/3451022 - loss: 0.037732 val_loss: 0.036148	recall: 0.495754 precision: 0.889524
epoch-1 step 160400/3451022 - loss: 0.034852 val_loss: 0.040589	recall: 0.472163 precision: 0.887324
epoch-1 step 160500/3451022 - loss: 0.042800 val_loss: 0.034237	recall: 0.508584 precision: 0.913295
epoch-1 step 160600/3451022 - loss: 0.035917 val_loss: 0.036390	recall: 0.511236 precision: 0.873321
epoch-1 step 160700/3451022 - loss: 0.035610 val_loss: 0.043793	recall: 0.524763 precision: 0.917127
epoch-1 step 160800/3451022 - loss: 0.037586 val_loss: 0.036503	recall: 0.479538 precision: 0.878846
epoch-1 step 160900/3451022 - loss: 0.038496 val_loss: 0.036460	recall: 0.504292 precision: 0.903846
epoch-1 step 161000/3451022 - loss: 0.038104 val_loss: 0.035463	recall: 0.495082 precision: 0.904192

checkpoint saved

epoch-1 step 161100/3451022 - loss: 0.041824 val_loss: 0.035736	recall: 0.500000 precision: 0.866426
epoch-1 step 161200/3451022 - loss: 0.041221 val_loss: 0.038929	recall: 0.516842 precision: 0.909259
epoch-1 step 161300/3451022 - loss: 0.039142 val_loss: 0.036372	recall: 0.502141 precision: 0.857404
epoch-1 step 161400/3451022 - loss: 0.038490 val_loss: 0.043482	recall: 0.506952 precision: 0.882682
epoch-1 step 161500/3451022 - loss: 0.036762 val_loss: 0.036451	recall: 0.521047 precision: 0.880769
epoch-1 step 161600/3451022 - loss: 0.050855 val_loss: 0.038940	recall: 0.535320 precision: 0.903166
epoch-1 step 161700/3451022 - loss: 0.035122 val_loss: 0.036764	recall: 0.499444 precision: 0.898000
epoch-1 step 161800/3451022 - loss: 0.039148 val_loss: 0.036024	recall: 0.532887 precision: 0.886827
epoch-1 step 161900/3451022 - loss: 0.034960 val_loss: 0.036575	recall: 0.499454 precision: 0.896078
epoch-1 step 162000/3451022 - loss: 0.035896 val_loss: 0.045062	recall: 0.548387 precision: 0.918919

checkpoint saved

epoch-1 step 162100/3451022 - loss: 0.034408 val_loss: 0.040347	recall: 0.518889 precision: 0.915686

model exported!

epoch-1 step 162200/3451022 - loss: 0.046507 val_loss: 0.041927	recall: 0.539863 precision: 0.908046
epoch-1 step 162300/3451022 - loss: 0.034468 val_loss: 0.036877	recall: 0.530079 precision: 0.913894
epoch-1 step 162400/3451022 - loss: 0.034858 val_loss: 0.038731	recall: 0.483368 precision: 0.874060
epoch-1 step 162500/3451022 - loss: 0.034270 val_loss: 0.037828	recall: 0.548023 precision: 0.916824
epoch-1 step 162600/3451022 - loss: 0.035829 val_loss: 0.043653	recall: 0.486966 precision: 0.901544
epoch-1 step 162700/3451022 - loss: 0.034927 val_loss: 0.034880	recall: 0.521191 precision: 0.895669
epoch-1 step 162800/3451022 - loss: 0.035245 val_loss: 0.035653	recall: 0.491453 precision: 0.900196
epoch-1 step 162900/3451022 - loss: 0.038577 val_loss: 0.047279	recall: 0.504961 precision: 0.908730
epoch-1 step 163000/3451022 - loss: 0.034620 val_loss: 0.036570	recall: 0.497256 precision: 0.881323

checkpoint saved

epoch-1 step 163100/3451022 - loss: 0.041991 val_loss: 0.035304	recall: 0.494589 precision: 0.899606
epoch-1 step 163200/3451022 - loss: 0.035817 val_loss: 0.039183	recall: 0.516854 precision: 0.894942
epoch-1 step 163300/3451022 - loss: 0.038162 val_loss: 0.035824	recall: 0.519565 precision: 0.915709
epoch-1 step 163400/3451022 - loss: 0.034478 val_loss: 0.040034	recall: 0.516793 precision: 0.931641
epoch-1 step 163500/3451022 - loss: 0.035085 val_loss: 0.034950	recall: 0.520652 precision: 0.905482
epoch-1 step 163600/3451022 - loss: 0.036383 val_loss: 0.037699	recall: 0.501096 precision: 0.889105
epoch-1 step 163700/3451022 - loss: 0.035095 val_loss: 0.038438	recall: 0.509072 precision: 0.913793
epoch-1 step 163800/3451022 - loss: 0.035782 val_loss: 0.034550	recall: 0.500552 precision: 0.884766
epoch-1 step 163900/3451022 - loss: 0.035173 val_loss: 0.044497	recall: 0.502252 precision: 0.913934
epoch-1 step 164000/3451022 - loss: 0.036594 val_loss: 0.036298	recall: 0.512379 precision: 0.903226

checkpoint saved

epoch-1 step 164100/3451022 - loss: 0.034624 val_loss: 0.040902	recall: 0.501046 precision: 0.903774

model exported!

epoch-1 step 164200/3451022 - loss: 0.037732 val_loss: 0.036505	recall: 0.523915 precision: 0.905769
epoch-1 step 164300/3451022 - loss: 0.039160 val_loss: 0.045331	recall: 0.514673 precision: 0.908367
epoch-1 step 164400/3451022 - loss: 0.038238 val_loss: 0.040100	recall: 0.522652 precision: 0.897533
epoch-1 step 164500/3451022 - loss: 0.034813 val_loss: 0.034680	recall: 0.524460 precision: 0.891683
epoch-1 step 164600/3451022 - loss: 0.043385 val_loss: 0.037519	recall: 0.510270 precision: 0.907692
epoch-1 step 164700/3451022 - loss: 0.037425 val_loss: 0.037278	recall: 0.513948 precision: 0.926499
epoch-1 step 164800/3451022 - loss: 0.036324 val_loss: 0.037034	recall: 0.493333 precision: 0.911704
epoch-1 step 164900/3451022 - loss: 0.038767 val_loss: 0.037782	recall: 0.501676 precision: 0.880392
epoch-1 step 165000/3451022 - loss: 0.034830 val_loss: 0.035114	recall: 0.523965 precision: 0.923225

checkpoint saved

epoch-1 step 165100/3451022 - loss: 0.035668 val_loss: 0.035885	recall: 0.519868 precision: 0.918129
epoch-1 step 165200/3451022 - loss: 0.038459 val_loss: 0.036331	recall: 0.518644 precision: 0.896484
epoch-1 step 165300/3451022 - loss: 0.039428 val_loss: 0.034790	recall: 0.518059 precision: 0.910714
epoch-1 step 165400/3451022 - loss: 0.036736 val_loss: 0.034418	recall: 0.514477 precision: 0.911243
epoch-1 step 165500/3451022 - loss: 0.039528 val_loss: 0.036933	recall: 0.498963 precision: 0.909263
epoch-1 step 165600/3451022 - loss: 0.033612 val_loss: 0.037948	recall: 0.510045 precision: 0.889105
epoch-1 step 165700/3451022 - loss: 0.041701 val_loss: 0.035771	recall: 0.522652 precision: 0.899240
epoch-1 step 165800/3451022 - loss: 0.036134 val_loss: 0.050679	recall: 0.517761 precision: 0.890741
epoch-1 step 165900/3451022 - loss: 0.036058 val_loss: 0.034484	recall: 0.516269 precision: 0.931507
epoch-1 step 166000/3451022 - loss: 0.035949 val_loss: 0.037382	recall: 0.546145 precision: 0.924632

checkpoint saved

epoch-1 step 166100/3451022 - loss: 0.036683 val_loss: 0.037356	recall: 0.543224 precision: 0.897683

model exported!

epoch-1 step 166200/3451022 - loss: 0.042292 val_loss: 0.035747	recall: 0.523333 precision: 0.893738
epoch-1 step 166300/3451022 - loss: 0.038905 val_loss: 0.040166	recall: 0.492553 precision: 0.895551
epoch-1 step 166400/3451022 - loss: 0.043902 val_loss: 0.036881	recall: 0.508511 precision: 0.915709
epoch-1 step 166500/3451022 - loss: 0.036346 val_loss: 0.034884	recall: 0.491820 precision: 0.897388
epoch-1 step 166600/3451022 - loss: 0.035142 val_loss: 0.042832	recall: 0.496233 precision: 0.888247
epoch-1 step 166700/3451022 - loss: 0.037413 val_loss: 0.036279	recall: 0.518033 precision: 0.902857
epoch-1 step 166800/3451022 - loss: 0.034554 val_loss: 0.037300	recall: 0.492521 precision: 0.876426
epoch-1 step 166900/3451022 - loss: 0.035273 val_loss: 0.036466	recall: 0.517052 precision: 0.905588
epoch-1 step 167000/3451022 - loss: 0.035404 val_loss: 0.047060	recall: 0.539593 precision: 0.908571

checkpoint saved

epoch-1 step 167100/3451022 - loss: 0.040211 val_loss: 0.035727	recall: 0.513572 precision: 0.907869
epoch-1 step 167200/3451022 - loss: 0.035408 val_loss: 0.034778	recall: 0.532333 precision: 0.900391
epoch-1 step 167300/3451022 - loss: 0.038146 val_loss: 0.038004	recall: 0.509956 precision: 0.900391
epoch-1 step 167400/3451022 - loss: 0.042631 val_loss: 0.034051	recall: 0.519294 precision: 0.914563
epoch-1 step 167500/3451022 - loss: 0.034468 val_loss: 0.034999	recall: 0.545147 precision: 0.913043
epoch-1 step 167600/3451022 - loss: 0.038748 val_loss: 0.041006	recall: 0.525571 precision: 0.907895
epoch-1 step 167700/3451022 - loss: 0.037950 val_loss: 0.035987	recall: 0.513966 precision: 0.900196
epoch-1 step 167800/3451022 - loss: 0.035382 val_loss: 0.035891	recall: 0.508126 precision: 0.895038
epoch-1 step 167900/3451022 - loss: 0.038528 val_loss: 0.035096	recall: 0.496241 precision: 0.880000
epoch-1 step 168000/3451022 - loss: 0.034578 val_loss: 0.036923	recall: 0.505771 precision: 0.902622

checkpoint saved

epoch-1 step 168100/3451022 - loss: 0.037943 val_loss: 0.038717	recall: 0.527027 precision: 0.884688

model exported!

epoch-1 step 168200/3451022 - loss: 0.039545 val_loss: 0.034577	recall: 0.490831 precision: 0.890411
epoch-1 step 168300/3451022 - loss: 0.039854 val_loss: 0.046881	recall: 0.505330 precision: 0.906310
epoch-1 step 168400/3451022 - loss: 0.035810 val_loss: 0.039668	recall: 0.503767 precision: 0.905222
epoch-1 step 168500/3451022 - loss: 0.037625 val_loss: 0.035069	recall: 0.508143 precision: 0.900000
epoch-1 step 168600/3451022 - loss: 0.034964 val_loss: 0.037813	recall: 0.528825 precision: 0.908571
epoch-1 step 168700/3451022 - loss: 0.039051 val_loss: 0.036071	recall: 0.518960 precision: 0.912381
epoch-1 step 168800/3451022 - loss: 0.035509 val_loss: 0.038090	recall: 0.519956 precision: 0.889943
epoch-1 step 168900/3451022 - loss: 0.035243 val_loss: 0.037412	recall: 0.501591 precision: 0.897533
epoch-1 step 169000/3451022 - loss: 0.035669 val_loss: 0.034980	recall: 0.522075 precision: 0.918447

checkpoint saved

epoch-1 step 169100/3451022 - loss: 0.035841 val_loss: 0.035468	recall: 0.534778 precision: 0.891635
epoch-1 step 169200/3451022 - loss: 0.038305 val_loss: 0.034834	recall: 0.498353 precision: 0.886719
epoch-1 step 169300/3451022 - loss: 0.040237 val_loss: 0.035417	recall: 0.501101 precision: 0.900990
epoch-1 step 169400/3451022 - loss: 0.039505 val_loss: 0.035398	recall: 0.498371 precision: 0.889535
epoch-1 step 169500/3451022 - loss: 0.036999 val_loss: 0.036456	recall: 0.484783 precision: 0.895582
epoch-1 step 169600/3451022 - loss: 0.034340 val_loss: 0.040058	recall: 0.501087 precision: 0.902153
epoch-1 step 169700/3451022 - loss: 0.038277 val_loss: 0.036863	recall: 0.545984 precision: 0.907157
epoch-1 step 169800/3451022 - loss: 0.036018 val_loss: 0.035742	recall: 0.530055 precision: 0.920304
epoch-1 step 169900/3451022 - loss: 0.034053 val_loss: 0.040995	recall: 0.520595 precision: 0.904573
epoch-1 step 170000/3451022 - loss: 0.036218 val_loss: 0.034687	recall: 0.513514 precision: 0.904762

checkpoint saved

epoch-1 step 170100/3451022 - loss: 0.033795 val_loss: 0.038598	recall: 0.505388 precision: 0.878277

model exported!

epoch-1 step 170200/3451022 - loss: 0.037973 val_loss: 0.036167	recall: 0.493377 precision: 0.895792
epoch-1 step 170300/3451022 - loss: 0.039019 val_loss: 0.042810	recall: 0.502137 precision: 0.905588
epoch-1 step 170400/3451022 - loss: 0.037046 val_loss: 0.035642	recall: 0.528634 precision: 0.921305
epoch-1 step 170500/3451022 - loss: 0.036942 val_loss: 0.035890	recall: 0.516630 precision: 0.906615
epoch-1 step 170600/3451022 - loss: 0.036988 val_loss: 0.034840	recall: 0.532823 precision: 0.905204
epoch-1 step 170700/3451022 - loss: 0.038633 val_loss: 0.035436	recall: 0.491857 precision: 0.891732
epoch-1 step 170800/3451022 - loss: 0.040307 val_loss: 0.035496	recall: 0.519912 precision: 0.902111
epoch-1 step 170900/3451022 - loss: 0.034546 val_loss: 0.037593	recall: 0.545767 precision: 0.913793
epoch-1 step 171000/3451022 - loss: 0.036776 val_loss: 0.043910	recall: 0.515660 precision: 0.884837

checkpoint saved

epoch-1 step 171100/3451022 - loss: 0.037789 val_loss: 0.038956	recall: 0.513363 precision: 0.896887
epoch-1 step 171200/3451022 - loss: 0.041113 val_loss: 0.036206	recall: 0.497783 precision: 0.878669
epoch-1 step 171300/3451022 - loss: 0.042029 val_loss: 0.034108	recall: 0.483422 precision: 0.900398
epoch-1 step 171400/3451022 - loss: 0.036393 val_loss: 0.034649	recall: 0.509514 precision: 0.926923
epoch-1 step 171500/3451022 - loss: 0.035067 val_loss: 0.037422	recall: 0.504292 precision: 0.893536
epoch-1 step 171600/3451022 - loss: 0.035315 val_loss: 0.039050	recall: 0.498901 precision: 0.895464
epoch-1 step 171700/3451022 - loss: 0.034481 val_loss: 0.035709	recall: 0.477468 precision: 0.869141
epoch-1 step 171800/3451022 - loss: 0.043809 val_loss: 0.035585	recall: 0.520670 precision: 0.899614
epoch-1 step 171900/3451022 - loss: 0.036250 val_loss: 0.034856	recall: 0.485201 precision: 0.905325
epoch-1 step 172000/3451022 - loss: 0.040970 val_loss: 0.069455	recall: 0.493048 precision: 0.879771

checkpoint saved

epoch-1 step 172100/3451022 - loss: 0.037321 val_loss: 0.039754	recall: 0.508287 precision: 0.914513

model exported!

epoch-1 step 172200/3451022 - loss: 0.036368 val_loss: 0.035202	recall: 0.515442 precision: 0.921905
epoch-1 step 172300/3451022 - loss: 0.038267 val_loss: 0.038232	recall: 0.513691 precision: 0.901923
epoch-1 step 172400/3451022 - loss: 0.036111 val_loss: 0.035570	recall: 0.500000 precision: 0.928429
epoch-1 step 172500/3451022 - loss: 0.040514 val_loss: 0.037108	recall: 0.536249 precision: 0.917323
epoch-1 step 172600/3451022 - loss: 0.037679 val_loss: 0.041755	recall: 0.529083 precision: 0.914894
epoch-1 step 172700/3451022 - loss: 0.034616 val_loss: 0.035793	recall: 0.516447 precision: 0.898855
epoch-1 step 172800/3451022 - loss: 0.035972 val_loss: 0.035563	recall: 0.510710 precision: 0.888235
epoch-1 step 172900/3451022 - loss: 0.035418 val_loss: 0.042173	recall: 0.537528 precision: 0.915414
epoch-1 step 173000/3451022 - loss: 0.036291 val_loss: 0.039423	recall: 0.516459 precision: 0.908184

checkpoint saved

epoch-1 step 173100/3451022 - loss: 0.035086 val_loss: 0.049109	recall: 0.513631 precision: 0.877095
epoch-1 step 173200/3451022 - loss: 0.047104 val_loss: 0.034978	recall: 0.487882 precision: 0.892100
epoch-1 step 173300/3451022 - loss: 0.037894 val_loss: 0.036609	recall: 0.543401 precision: 0.899606
epoch-1 step 173400/3451022 - loss: 0.036487 val_loss: 0.035667	recall: 0.546404 precision: 0.897143
epoch-1 step 173500/3451022 - loss: 0.038730 val_loss: 0.034809	recall: 0.539843 precision: 0.910985
epoch-1 step 173600/3451022 - loss: 0.041850 val_loss: 0.045394	recall: 0.504444 precision: 0.897233
epoch-1 step 173700/3451022 - loss: 0.035294 val_loss: 0.034563	recall: 0.512878 precision: 0.905138
epoch-1 step 173800/3451022 - loss: 0.037057 val_loss: 0.042044	recall: 0.539933 precision: 0.907372
epoch-1 step 173900/3451022 - loss: 0.037799 val_loss: 0.035866	recall: 0.564460 precision: 0.929254
epoch-1 step 174000/3451022 - loss: 0.040176 val_loss: 0.037612	recall: 0.529876 precision: 0.917969

checkpoint saved

epoch-1 step 174100/3451022 - loss: 0.034326 val_loss: 0.040191	recall: 0.508791 precision: 0.875236

model exported!

epoch-1 step 174200/3451022 - loss: 0.035754 val_loss: 0.035718	recall: 0.539701 precision: 0.905405
epoch-1 step 174300/3451022 - loss: 0.041682 val_loss: 0.035820	recall: 0.522321 precision: 0.906977
epoch-1 step 174400/3451022 - loss: 0.039455 val_loss: 0.038383	recall: 0.498335 precision: 0.882122
epoch-1 step 174500/3451022 - loss: 0.040114 val_loss: 0.038549	recall: 0.537143 precision: 0.925197
epoch-1 step 174600/3451022 - loss: 0.034555 val_loss: 0.047744	recall: 0.557647 precision: 0.899431
epoch-1 step 174700/3451022 - loss: 0.037389 val_loss: 0.034347	recall: 0.515789 precision: 0.901840
epoch-1 step 174800/3451022 - loss: 0.037952 val_loss: 0.063510	recall: 0.512009 precision: 0.886578
epoch-1 step 174900/3451022 - loss: 0.034600 val_loss: 0.034415	recall: 0.509434 precision: 0.916168
epoch-1 step 175000/3451022 - loss: 0.034857 val_loss: 0.036834	recall: 0.487404 precision: 0.888224

checkpoint saved

epoch-1 step 175100/3451022 - loss: 0.035581 val_loss: 0.039728	recall: 0.522321 precision: 0.910506
epoch-1 step 175200/3451022 - loss: 0.043019 val_loss: 0.040010	recall: 0.514477 precision: 0.890173
epoch-1 step 175300/3451022 - loss: 0.036266 val_loss: 0.034860	recall: 0.500537 precision: 0.904854
epoch-1 step 175400/3451022 - loss: 0.036166 val_loss: 0.040534	recall: 0.520624 precision: 0.898077
epoch-1 step 175500/3451022 - loss: 0.034394 val_loss: 0.035166	recall: 0.542565 precision: 0.910476
epoch-1 step 175600/3451022 - loss: 0.035036 val_loss: 0.034074	recall: 0.541619 precision: 0.911708
epoch-1 step 175700/3451022 - loss: 0.036623 val_loss: 0.034790	recall: 0.536782 precision: 0.886148
epoch-1 step 175800/3451022 - loss: 0.035823 val_loss: 0.034607	recall: 0.526490 precision: 0.901701
epoch-1 step 175900/3451022 - loss: 0.043552 val_loss: 0.034512	recall: 0.538106 precision: 0.906615
epoch-1 step 176000/3451022 - loss: 0.036263 val_loss: 0.035251	recall: 0.519016 precision: 0.900971

checkpoint saved

epoch-1 step 176100/3451022 - loss: 0.034106 val_loss: 0.035835	recall: 0.547258 precision: 0.893333

model exported!

epoch-1 step 176200/3451022 - loss: 0.035052 val_loss: 0.034898	recall: 0.508324 precision: 0.874046
epoch-1 step 176300/3451022 - loss: 0.034994 val_loss: 0.037400	recall: 0.522173 precision: 0.923529
epoch-1 step 176400/3451022 - loss: 0.037364 val_loss: 0.040167	recall: 0.504435 precision: 0.910000
epoch-1 step 176500/3451022 - loss: 0.036962 val_loss: 0.034613	recall: 0.517738 precision: 0.908560
epoch-1 step 176600/3451022 - loss: 0.035893 val_loss: 0.033936	recall: 0.513935 precision: 0.911067
epoch-1 step 176700/3451022 - loss: 0.039322 val_loss: 0.039883	recall: 0.498920 precision: 0.909449
epoch-1 step 176800/3451022 - loss: 0.048942 val_loss: 0.040982	recall: 0.528953 precision: 0.913462
epoch-1 step 176900/3451022 - loss: 0.038500 val_loss: 0.038061	recall: 0.537209 precision: 0.911243
epoch-1 step 177000/3451022 - loss: 0.034689 val_loss: 0.040847	recall: 0.490670 precision: 0.888668

checkpoint saved

epoch-1 step 177100/3451022 - loss: 0.035556 val_loss: 0.036322	recall: 0.528217 precision: 0.915851
epoch-1 step 177200/3451022 - loss: 0.036298 val_loss: 0.037658	recall: 0.520397 precision: 0.895636
epoch-1 step 177300/3451022 - loss: 0.038078 val_loss: 0.035532	recall: 0.514532 precision: 0.913958
epoch-1 step 177400/3451022 - loss: 0.037523 val_loss: 0.036016	recall: 0.497250 precision: 0.914980
epoch-1 step 177500/3451022 - loss: 0.034281 val_loss: 0.035179	recall: 0.481256 precision: 0.896226
epoch-1 step 177600/3451022 - loss: 0.037764 val_loss: 0.038923	recall: 0.557191 precision: 0.937143
epoch-1 step 177700/3451022 - loss: 0.040346 val_loss: 0.034601	recall: 0.485067 precision: 0.898855
epoch-1 step 177800/3451022 - loss: 0.040735 val_loss: 0.035192	recall: 0.546804 precision: 0.903774
epoch-1 step 177900/3451022 - loss: 0.036265 val_loss: 0.039439	recall: 0.478931 precision: 0.896154
epoch-1 step 178000/3451022 - loss: 0.036385 val_loss: 0.035125	recall: 0.506159 precision: 0.893281

checkpoint saved

epoch-1 step 178100/3451022 - loss: 0.035723 val_loss: 0.046732	recall: 0.513575 precision: 0.906188

model exported!

epoch-1 step 178200/3451022 - loss: 0.037106 val_loss: 0.036920	recall: 0.523596 precision: 0.897881
epoch-1 step 178300/3451022 - loss: 0.036886 val_loss: 0.033763	recall: 0.506536 precision: 0.894231
epoch-1 step 178400/3451022 - loss: 0.035335 val_loss: 0.045529	recall: 0.519909 precision: 0.872137
epoch-1 step 178500/3451022 - loss: 0.035940 val_loss: 0.037246	recall: 0.518313 precision: 0.912109
epoch-1 step 178600/3451022 - loss: 0.035120 val_loss: 0.035430	recall: 0.525910 precision: 0.893258
epoch-1 step 178700/3451022 - loss: 0.038980 val_loss: 0.038001	recall: 0.503341 precision: 0.900398
epoch-1 step 178800/3451022 - loss: 0.040565 val_loss: 0.039110	recall: 0.480908 precision: 0.899614
epoch-1 step 178900/3451022 - loss: 0.036228 val_loss: 0.036379	recall: 0.511551 precision: 0.894231
epoch-1 step 179000/3451022 - loss: 0.042413 val_loss: 0.044540	recall: 0.517699 precision: 0.923077

checkpoint saved

epoch-1 step 179100/3451022 - loss: 0.036168 val_loss: 0.037651	recall: 0.532276 precision: 0.890152
epoch-1 step 179200/3451022 - loss: 0.034692 val_loss: 0.036023	recall: 0.516613 precision: 0.914611
epoch-1 step 179300/3451022 - loss: 0.038477 val_loss: 0.034854	recall: 0.537939 precision: 0.897921
epoch-1 step 179400/3451022 - loss: 0.036080 val_loss: 0.035239	recall: 0.505882 precision: 0.882463
epoch-1 step 179500/3451022 - loss: 0.036205 val_loss: 0.038895	recall: 0.485437 precision: 0.891089
epoch-1 step 179600/3451022 - loss: 0.039557 val_loss: 0.036586	recall: 0.522727 precision: 0.934236
epoch-1 step 179700/3451022 - loss: 0.035922 val_loss: 0.033965	recall: 0.525219 precision: 0.935547
epoch-1 step 179800/3451022 - loss: 0.035890 val_loss: 0.042856	recall: 0.503247 precision: 0.913556
epoch-1 step 179900/3451022 - loss: 0.035977 val_loss: 0.036131	recall: 0.558548 precision: 0.913793
epoch-1 step 180000/3451022 - loss: 0.034803 val_loss: 0.036628	recall: 0.496689 precision: 0.884086

checkpoint saved

epoch-1 step 180100/3451022 - loss: 0.037304 val_loss: 0.038577	recall: 0.489297 precision: 0.898876

model exported!

epoch-1 step 180200/3451022 - loss: 0.037044 val_loss: 0.035267	recall: 0.527273 precision: 0.899225
epoch-1 step 180300/3451022 - loss: 0.035382 val_loss: 0.036827	recall: 0.495763 precision: 0.884688
epoch-1 step 180400/3451022 - loss: 0.036560 val_loss: 0.037127	recall: 0.493750 precision: 0.890977
epoch-1 step 180500/3451022 - loss: 0.036972 val_loss: 0.035743	recall: 0.512270 precision: 0.915905
epoch-1 step 180600/3451022 - loss: 0.034907 val_loss: 0.035534	recall: 0.525959 precision: 0.913725
epoch-1 step 180700/3451022 - loss: 0.037805 val_loss: 0.036203	recall: 0.522307 precision: 0.919540
epoch-1 step 180800/3451022 - loss: 0.038396 val_loss: 0.034888	recall: 0.496335 precision: 0.906310
epoch-1 step 180900/3451022 - loss: 0.034124 val_loss: 0.035664	recall: 0.506977 precision: 0.884381
epoch-1 step 181000/3451022 - loss: 0.036250 val_loss: 0.043038	recall: 0.508269 precision: 0.912871

checkpoint saved

epoch-1 step 181100/3451022 - loss: 0.034300 val_loss: 0.035510	recall: 0.510526 precision: 0.923810
epoch-1 step 181200/3451022 - loss: 0.036280 val_loss: 0.035142	recall: 0.527497 precision: 0.921569
epoch-1 step 181300/3451022 - loss: 0.033911 val_loss: 0.035159	recall: 0.540782 precision: 0.916667
epoch-1 step 181400/3451022 - loss: 0.037510 val_loss: 0.043518	recall: 0.514754 precision: 0.912791
epoch-1 step 181500/3451022 - loss: 0.034884 val_loss: 0.036323	recall: 0.513978 precision: 0.915709
epoch-1 step 181600/3451022 - loss: 0.034411 val_loss: 0.037049	recall: 0.495772 precision: 0.888258
epoch-1 step 181700/3451022 - loss: 0.035417 val_loss: 0.035003	recall: 0.516058 precision: 0.922772
epoch-1 step 181800/3451022 - loss: 0.034960 val_loss: 0.034845	recall: 0.529345 precision: 0.910680
epoch-1 step 181900/3451022 - loss: 0.037861 val_loss: 0.039200	recall: 0.514069 precision: 0.918762
epoch-1 step 182000/3451022 - loss: 0.034519 val_loss: 0.035758	recall: 0.513015 precision: 0.914894

checkpoint saved

epoch-1 step 182100/3451022 - loss: 0.036161 val_loss: 0.040886	recall: 0.524336 precision: 0.897727

model exported!

epoch-1 step 182200/3451022 - loss: 0.034945 val_loss: 0.037332	recall: 0.510730 precision: 0.903226
epoch-1 step 182300/3451022 - loss: 0.038761 val_loss: 0.039734	recall: 0.506410 precision: 0.887640
epoch-1 step 182400/3451022 - loss: 0.036174 val_loss: 0.042173	recall: 0.525219 precision: 0.903774
epoch-1 step 182500/3451022 - loss: 0.035611 val_loss: 0.048131	recall: 0.482906 precision: 0.869231
epoch-1 step 182600/3451022 - loss: 0.036992 val_loss: 0.036998	recall: 0.514256 precision: 0.929389
epoch-1 step 182700/3451022 - loss: 0.035703 val_loss: 0.037812	recall: 0.528953 precision: 0.909962
epoch-1 step 182800/3451022 - loss: 0.038195 val_loss: 0.034637	recall: 0.505796 precision: 0.914286
epoch-1 step 182900/3451022 - loss: 0.034577 val_loss: 0.039047	recall: 0.484472 precision: 0.900000
epoch-1 step 183000/3451022 - loss: 0.035627 val_loss: 0.035092	recall: 0.549153 precision: 0.922201

checkpoint saved

epoch-1 step 183100/3451022 - loss: 0.036349 val_loss: 0.036993	recall: 0.499452 precision: 0.883721
epoch-1 step 183200/3451022 - loss: 0.036358 val_loss: 0.035178	recall: 0.489989 precision: 0.887405
epoch-1 step 183300/3451022 - loss: 0.036814 val_loss: 0.035836	recall: 0.518722 precision: 0.912791
epoch-1 step 183400/3451022 - loss: 0.034964 val_loss: 0.040051	recall: 0.494472 precision: 0.907749
epoch-1 step 183500/3451022 - loss: 0.035729 val_loss: 0.036701	recall: 0.495228 precision: 0.912109
epoch-1 step 183600/3451022 - loss: 0.036087 val_loss: 0.038720	recall: 0.511351 precision: 0.913127
epoch-1 step 183700/3451022 - loss: 0.048250 val_loss: 0.035250	recall: 0.489297 precision: 0.914286
epoch-1 step 183800/3451022 - loss: 0.034746 val_loss: 0.036555	recall: 0.525901 precision: 0.912109
epoch-1 step 183900/3451022 - loss: 0.034996 val_loss: 0.037856	recall: 0.491770 precision: 0.898496
epoch-1 step 184000/3451022 - loss: 0.034365 val_loss: 0.049882	recall: 0.522453 precision: 0.924419

checkpoint saved

epoch-1 step 184100/3451022 - loss: 0.035343 val_loss: 0.038238	recall: 0.525140 precision: 0.928854

model exported!

epoch-1 step 184200/3451022 - loss: 0.044343 val_loss: 0.036942	recall: 0.501554 precision: 0.911488
epoch-1 step 184300/3451022 - loss: 0.037219 val_loss: 0.035222	recall: 0.523438 precision: 0.901923
epoch-1 step 184400/3451022 - loss: 0.034954 val_loss: 0.042898	recall: 0.512931 precision: 0.918919
epoch-1 step 184500/3451022 - loss: 0.035402 val_loss: 0.041888	recall: 0.470460 precision: 0.865191
epoch-1 step 184600/3451022 - loss: 0.049680 val_loss: 0.038948	recall: 0.486373 precision: 0.911591
epoch-1 step 184700/3451022 - loss: 0.034736 val_loss: 0.045901	recall: 0.518280 precision: 0.912879
epoch-1 step 184800/3451022 - loss: 0.035863 val_loss: 0.034745	recall: 0.528153 precision: 0.905405
epoch-1 step 184900/3451022 - loss: 0.034279 val_loss: 0.036168	recall: 0.517058 precision: 0.911654
epoch-1 step 185000/3451022 - loss: 0.034452 val_loss: 0.035980	recall: 0.479873 precision: 0.898810

checkpoint saved

epoch-1 step 185100/3451022 - loss: 0.038160 val_loss: 0.036221	recall: 0.533485 precision: 0.898662
epoch-1 step 185200/3451022 - loss: 0.036514 val_loss: 0.035079	recall: 0.511803 precision: 0.883333
epoch-1 step 185300/3451022 - loss: 0.034944 val_loss: 0.038164	recall: 0.513800 precision: 0.928983
epoch-1 step 185400/3451022 - loss: 0.044463 val_loss: 0.034633	recall: 0.501046 precision: 0.903774
epoch-1 step 185500/3451022 - loss: 0.037626 val_loss: 0.043558	recall: 0.477707 precision: 0.892857
epoch-1 step 185600/3451022 - loss: 0.046258 val_loss: 0.034808	recall: 0.486010 precision: 0.888258
epoch-1 step 185700/3451022 - loss: 0.038862 val_loss: 0.035658	recall: 0.522307 precision: 0.905660
epoch-1 step 185800/3451022 - loss: 0.041190 val_loss: 0.034808	recall: 0.489384 precision: 0.883142
epoch-1 step 185900/3451022 - loss: 0.034675 val_loss: 0.035688	recall: 0.485075 precision: 0.886940
epoch-1 step 186000/3451022 - loss: 0.054002 val_loss: 0.042334	recall: 0.515508 precision: 0.914611

checkpoint saved

epoch-1 step 186100/3451022 - loss: 0.035776 val_loss: 0.036075	recall: 0.494143 precision: 0.911591

model exported!

epoch-1 step 186200/3451022 - loss: 0.034685 val_loss: 0.037884	recall: 0.511475 precision: 0.889734
epoch-1 step 186300/3451022 - loss: 0.035376 val_loss: 0.039573	recall: 0.485374 precision: 0.897796
epoch-1 step 186400/3451022 - loss: 0.035752 val_loss: 0.042914	recall: 0.528889 precision: 0.901515
epoch-1 step 186500/3451022 - loss: 0.034934 val_loss: 0.036559	recall: 0.509249 precision: 0.906977
epoch-1 step 186600/3451022 - loss: 0.036077 val_loss: 0.036258	recall: 0.504301 precision: 0.905405
epoch-1 step 186700/3451022 - loss: 0.035935 val_loss: 0.036085	recall: 0.540023 precision: 0.903774
epoch-1 step 186800/3451022 - loss: 0.037935 val_loss: 0.036864	recall: 0.497332 precision: 0.897881
epoch-1 step 186900/3451022 - loss: 0.035204 val_loss: 0.036266	recall: 0.499474 precision: 0.915222
epoch-1 step 187000/3451022 - loss: 0.041960 val_loss: 0.035501	recall: 0.528492 precision: 0.936634

checkpoint saved

epoch-1 step 187100/3451022 - loss: 0.034451 val_loss: 0.040048	recall: 0.496774 precision: 0.888462
epoch-1 step 187200/3451022 - loss: 0.037035 val_loss: 0.037662	recall: 0.504929 precision: 0.902153
epoch-1 step 187300/3451022 - loss: 0.035302 val_loss: 0.035269	recall: 0.501584 precision: 0.911708
epoch-1 step 187400/3451022 - loss: 0.035008 val_loss: 0.036757	recall: 0.526894 precision: 0.905660
epoch-1 step 187500/3451022 - loss: 0.034144 val_loss: 0.035045	recall: 0.546180 precision: 0.908918
epoch-1 step 187600/3451022 - loss: 0.042101 val_loss: 0.041599	recall: 0.519058 precision: 0.862197
epoch-1 step 187700/3451022 - loss: 0.036537 val_loss: 0.035817	recall: 0.518141 precision: 0.904950
epoch-1 step 187800/3451022 - loss: 0.035393 val_loss: 0.034272	recall: 0.506736 precision: 0.920904
epoch-1 step 187900/3451022 - loss: 0.036238 val_loss: 0.035920	recall: 0.510832 precision: 0.903226
epoch-1 step 188000/3451022 - loss: 0.035775 val_loss: 0.038380	recall: 0.500556 precision: 0.877193

checkpoint saved

epoch-1 step 188100/3451022 - loss: 0.040414 val_loss: 0.038772	recall: 0.515017 precision: 0.881905

model exported!

epoch-1 step 188200/3451022 - loss: 0.033922 val_loss: 0.041340	recall: 0.512685 precision: 0.913371
epoch-1 step 188300/3451022 - loss: 0.034191 val_loss: 0.034220	recall: 0.538547 precision: 0.907721
epoch-1 step 188400/3451022 - loss: 0.034250 val_loss: 0.034383	recall: 0.514884 precision: 0.892925
epoch-1 step 188500/3451022 - loss: 0.034410 val_loss: 0.036502	recall: 0.515778 precision: 0.913295
epoch-1 step 188600/3451022 - loss: 0.038328 val_loss: 0.035106	recall: 0.515909 precision: 0.891945
epoch-1 step 188700/3451022 - loss: 0.035274 val_loss: 0.038167	recall: 0.507012 precision: 0.890152
epoch-1 step 188800/3451022 - loss: 0.039869 val_loss: 0.036802	recall: 0.525597 precision: 0.918489
epoch-1 step 188900/3451022 - loss: 0.036719 val_loss: 0.034917	recall: 0.497908 precision: 0.913628
epoch-1 step 189000/3451022 - loss: 0.036396 val_loss: 0.041871	recall: 0.510661 precision: 0.930097

checkpoint saved

epoch-1 step 189100/3451022 - loss: 0.039063 val_loss: 0.035771	recall: 0.538636 precision: 0.906310
epoch-1 step 189200/3451022 - loss: 0.038544 val_loss: 0.034714	recall: 0.501726 precision: 0.879032
epoch-1 step 189300/3451022 - loss: 0.045370 val_loss: 0.036313	recall: 0.514100 precision: 0.899431
epoch-1 step 189400/3451022 - loss: 0.041713 val_loss: 0.040168	recall: 0.515952 precision: 0.907157
epoch-1 step 189500/3451022 - loss: 0.045703 val_loss: 0.043462	recall: 0.512088 precision: 0.911937
epoch-1 step 189600/3451022 - loss: 0.036470 val_loss: 0.036032	recall: 0.493658 precision: 0.898077
epoch-1 step 189700/3451022 - loss: 0.036253 val_loss: 0.035009	recall: 0.522173 precision: 0.923529
epoch-1 step 189800/3451022 - loss: 0.043862 val_loss: 0.036939	recall: 0.523965 precision: 0.905838
epoch-1 step 189900/3451022 - loss: 0.036316 val_loss: 0.036351	recall: 0.518973 precision: 0.920792
epoch-1 step 190000/3451022 - loss: 0.035595 val_loss: 0.039751	recall: 0.500000 precision: 0.880859

checkpoint saved

epoch-1 step 190100/3451022 - loss: 0.037171 val_loss: 0.047745	recall: 0.518837 precision: 0.914611

model exported!

epoch-1 step 190200/3451022 - loss: 0.036655 val_loss: 0.043958	recall: 0.531866 precision: 0.905325
epoch-1 step 190300/3451022 - loss: 0.036006 val_loss: 0.036250	recall: 0.504320 precision: 0.896353
epoch-1 step 190400/3451022 - loss: 0.038841 val_loss: 0.036064	recall: 0.553241 precision: 0.900188
epoch-1 step 190500/3451022 - loss: 0.035164 val_loss: 0.034695	recall: 0.534325 precision: 0.912109
epoch-1 step 190600/3451022 - loss: 0.040216 val_loss: 0.035126	recall: 0.536585 precision: 0.886756
epoch-1 step 190700/3451022 - loss: 0.038902 val_loss: 0.035354	recall: 0.550758 precision: 0.907692
epoch-1 step 190800/3451022 - loss: 0.037973 val_loss: 0.036521	recall: 0.541906 precision: 0.909441
epoch-1 step 190900/3451022 - loss: 0.039476 val_loss: 0.035165	recall: 0.551326 precision: 0.900188
epoch-1 step 191000/3451022 - loss: 0.038668 val_loss: 0.038037	recall: 0.524684 precision: 0.906746

checkpoint saved

epoch-1 step 191100/3451022 - loss: 0.035410 val_loss: 0.037388	recall: 0.549714 precision: 0.933981
epoch-1 step 191200/3451022 - loss: 0.038898 val_loss: 0.035149	recall: 0.510158 precision: 0.902196
epoch-1 step 191300/3451022 - loss: 0.038298 val_loss: 0.039266	recall: 0.498920 precision: 0.900585
epoch-1 step 191400/3451022 - loss: 0.035284 val_loss: 0.035549	recall: 0.503205 precision: 0.909266
epoch-1 step 191500/3451022 - loss: 0.035308 val_loss: 0.035205	recall: 0.506637 precision: 0.869070
epoch-1 step 191600/3451022 - loss: 0.035289 val_loss: 0.036543	recall: 0.502714 precision: 0.897287
epoch-1 step 191700/3451022 - loss: 0.041198 val_loss: 0.039166	recall: 0.524684 precision: 0.897839
epoch-1 step 191800/3451022 - loss: 0.041995 val_loss: 0.034753	recall: 0.531323 precision: 0.879079
epoch-1 step 191900/3451022 - loss: 0.036966 val_loss: 0.034755	recall: 0.502222 precision: 0.889764
epoch-1 step 192000/3451022 - loss: 0.044146 val_loss: 0.044506	recall: 0.541667 precision: 0.928571

checkpoint saved

epoch-1 step 192100/3451022 - loss: 0.035297 val_loss: 0.038276	recall: 0.512443 precision: 0.876209

model exported!

epoch-1 step 192200/3451022 - loss: 0.035115 val_loss: 0.037408	recall: 0.536199 precision: 0.899431
epoch-1 step 192300/3451022 - loss: 0.038404 val_loss: 0.036535	recall: 0.474174 precision: 0.907115
epoch-1 step 192400/3451022 - loss: 0.034976 val_loss: 0.035018	recall: 0.535414 precision: 0.917695
epoch-1 step 192500/3451022 - loss: 0.038294 val_loss: 0.034676	recall: 0.557062 precision: 0.919776
epoch-1 step 192600/3451022 - loss: 0.037434 val_loss: 0.040175	recall: 0.519523 precision: 0.941061
epoch-1 step 192700/3451022 - loss: 0.037161 val_loss: 0.034275	recall: 0.511628 precision: 0.904110
epoch-1 step 192800/3451022 - loss: 0.036528 val_loss: 0.042399	recall: 0.528908 precision: 0.919926
epoch-1 step 192900/3451022 - loss: 0.034971 val_loss: 0.037660	recall: 0.503219 precision: 0.901923
epoch-1 step 193000/3451022 - loss: 0.034790 val_loss: 0.034646	recall: 0.533485 precision: 0.880150

checkpoint saved

epoch-1 step 193100/3451022 - loss: 0.039201 val_loss: 0.035410	recall: 0.524831 precision: 0.890805
epoch-1 step 193200/3451022 - loss: 0.035883 val_loss: 0.035814	recall: 0.483264 precision: 0.886756
epoch-1 step 193300/3451022 - loss: 0.036691 val_loss: 0.041381	recall: 0.500000 precision: 0.897485
epoch-1 step 193400/3451022 - loss: 0.034642 val_loss: 0.039849	recall: 0.512088 precision: 0.879245
epoch-1 step 193500/3451022 - loss: 0.037820 val_loss: 0.035832	recall: 0.529851 precision: 0.910256
epoch-1 step 193600/3451022 - loss: 0.038952 val_loss: 0.036316	recall: 0.505308 precision: 0.903226
epoch-1 step 193700/3451022 - loss: 0.036039 val_loss: 0.036994	recall: 0.513873 precision: 0.904297
epoch-1 step 193800/3451022 - loss: 0.036385 val_loss: 0.035670	recall: 0.509413 precision: 0.918164
epoch-1 step 193900/3451022 - loss: 0.034272 val_loss: 0.037004	recall: 0.486574 precision: 0.897030
epoch-1 step 194000/3451022 - loss: 0.042915 val_loss: 0.036275	recall: 0.519864 precision: 0.910537

checkpoint saved

epoch-1 step 194100/3451022 - loss: 0.039686 val_loss: 0.036699	recall: 0.538117 precision: 0.939335

model exported!

epoch-1 step 194200/3451022 - loss: 0.038334 val_loss: 0.036365	recall: 0.537683 precision: 0.931774
epoch-1 step 194300/3451022 - loss: 0.035522 val_loss: 0.037176	recall: 0.532887 precision: 0.890130
epoch-1 step 194400/3451022 - loss: 0.035849 val_loss: 0.036908	recall: 0.502288 precision: 0.876248
epoch-1 step 194500/3451022 - loss: 0.036383 val_loss: 0.036525	recall: 0.537634 precision: 0.907258
epoch-1 step 194600/3451022 - loss: 0.034877 val_loss: 0.045855	recall: 0.521396 precision: 0.895551
epoch-1 step 194700/3451022 - loss: 0.034642 val_loss: 0.034811	recall: 0.510710 precision: 0.904192
epoch-1 step 194800/3451022 - loss: 0.033651 val_loss: 0.037249	recall: 0.535098 precision: 0.922619
epoch-1 step 194900/3451022 - loss: 0.034170 val_loss: 0.035564	recall: 0.517435 precision: 0.905512
epoch-1 step 195000/3451022 - loss: 0.042344 val_loss: 0.034470	recall: 0.521693 precision: 0.924953

checkpoint saved

epoch-1 step 195100/3451022 - loss: 0.034933 val_loss: 0.036177	recall: 0.518814 precision: 0.910000
epoch-1 step 195200/3451022 - loss: 0.041044 val_loss: 0.035308	recall: 0.542955 precision: 0.913295
epoch-1 step 195300/3451022 - loss: 0.040698 val_loss: 0.036079	recall: 0.522956 precision: 0.908560
epoch-1 step 195400/3451022 - loss: 0.034166 val_loss: 0.038745	recall: 0.523454 precision: 0.917757
epoch-1 step 195500/3451022 - loss: 0.036102 val_loss: 0.047566	recall: 0.522235 precision: 0.896282
epoch-1 step 195600/3451022 - loss: 0.041759 val_loss: 0.043081	recall: 0.510686 precision: 0.904382
epoch-1 step 195700/3451022 - loss: 0.043191 val_loss: 0.036246	recall: 0.477505 precision: 0.887833
epoch-1 step 195800/3451022 - loss: 0.036079 val_loss: 0.034405	recall: 0.474012 precision: 0.894118
epoch-1 step 195900/3451022 - loss: 0.035060 val_loss: 0.036388	recall: 0.497840 precision: 0.923848
epoch-1 step 196000/3451022 - loss: 0.035106 val_loss: 0.035308	recall: 0.526919 precision: 0.896686

checkpoint saved

epoch-1 step 196100/3451022 - loss: 0.036772 val_loss: 0.038733	recall: 0.513228 precision: 0.913371

model exported!

epoch-1 step 196200/3451022 - loss: 0.036353 val_loss: 0.037352	recall: 0.477074 precision: 0.865347
epoch-1 step 196300/3451022 - loss: 0.035044 val_loss: 0.038637	recall: 0.502119 precision: 0.902857
epoch-1 step 196400/3451022 - loss: 0.036665 val_loss: 0.034443	recall: 0.530963 precision: 0.911417
epoch-1 step 196500/3451022 - loss: 0.035831 val_loss: 0.039503	recall: 0.513771 precision: 0.923810
epoch-1 step 196600/3451022 - loss: 0.033955 val_loss: 0.039792	recall: 0.522905 precision: 0.906977
epoch-1 step 196700/3451022 - loss: 0.041383 val_loss: 0.047737	recall: 0.528634 precision: 0.923077
epoch-1 step 196800/3451022 - loss: 0.037850 val_loss: 0.043022	recall: 0.539140 precision: 0.926136
epoch-1 step 196900/3451022 - loss: 0.042198 val_loss: 0.037805	recall: 0.500525 precision: 0.915547
epoch-1 step 197000/3451022 - loss: 0.034765 val_loss: 0.036396	recall: 0.532453 precision: 0.911488

checkpoint saved

epoch-1 step 197100/3451022 - loss: 0.037833 val_loss: 0.034563	recall: 0.515351 precision: 0.907336
epoch-1 step 197200/3451022 - loss: 0.038041 val_loss: 0.035783	recall: 0.512360 precision: 0.895874
epoch-1 step 197300/3451022 - loss: 0.035879 val_loss: 0.035138	recall: 0.491435 precision: 0.894737
epoch-1 step 197400/3451022 - loss: 0.037911 val_loss: 0.036536	recall: 0.490302 precision: 0.897436
epoch-1 step 197500/3451022 - loss: 0.040558 val_loss: 0.035529	recall: 0.528944 precision: 0.897881
epoch-1 step 197600/3451022 - loss: 0.034600 val_loss: 0.041531	recall: 0.481442 precision: 0.899010
epoch-1 step 197700/3451022 - loss: 0.037997 val_loss: 0.046423	recall: 0.492662 precision: 0.903846
epoch-1 step 197800/3451022 - loss: 0.038746 val_loss: 0.034304	recall: 0.527233 precision: 0.918406
epoch-1 step 197900/3451022 - loss: 0.043346 val_loss: 0.037967	recall: 0.514722 precision: 0.920078
epoch-1 step 198000/3451022 - loss: 0.041155 val_loss: 0.035419	recall: 0.493644 precision: 0.904854

checkpoint saved

epoch-1 step 198100/3451022 - loss: 0.037425 val_loss: 0.034502	recall: 0.507511 precision: 0.900952

model exported!

epoch-1 step 198200/3451022 - loss: 0.034583 val_loss: 0.037755	recall: 0.487315 precision: 0.902153
epoch-1 step 198300/3451022 - loss: 0.040156 val_loss: 0.034855	recall: 0.516129 precision: 0.885609
epoch-1 step 198400/3451022 - loss: 0.036499 val_loss: 0.034201	recall: 0.498913 precision: 0.907115
epoch-1 step 198500/3451022 - loss: 0.040838 val_loss: 0.035175	recall: 0.521358 precision: 0.906667
epoch-1 step 198600/3451022 - loss: 0.040778 val_loss: 0.034469	recall: 0.491282 precision: 0.905482
epoch-1 step 198700/3451022 - loss: 0.037145 val_loss: 0.052223	recall: 0.500000 precision: 0.906433
epoch-1 step 198800/3451022 - loss: 0.037244 val_loss: 0.035336	recall: 0.514607 precision: 0.910537
epoch-1 step 198900/3451022 - loss: 0.037481 val_loss: 0.037427	recall: 0.495166 precision: 0.898635
epoch-1 step 199000/3451022 - loss: 0.037789 val_loss: 0.037469	recall: 0.496781 precision: 0.881905

checkpoint saved

epoch-1 step 199100/3451022 - loss: 0.044616 val_loss: 0.034295	recall: 0.490114 precision: 0.898855
epoch-1 step 199200/3451022 - loss: 0.034113 val_loss: 0.033938	recall: 0.504274 precision: 0.909441
epoch-1 step 199300/3451022 - loss: 0.034302 val_loss: 0.036187	recall: 0.516741 precision: 0.900778
epoch-1 step 199400/3451022 - loss: 0.034859 val_loss: 0.063161	recall: 0.517131 precision: 0.914773
epoch-1 step 199500/3451022 - loss: 0.039874 val_loss: 0.037832	recall: 0.515508 precision: 0.904315
epoch-1 step 199600/3451022 - loss: 0.035182 val_loss: 0.037390	recall: 0.492600 precision: 0.899614
epoch-1 step 199700/3451022 - loss: 0.035467 val_loss: 0.036288	recall: 0.503212 precision: 0.888469
epoch-1 step 199800/3451022 - loss: 0.036880 val_loss: 0.035289	recall: 0.493506 precision: 0.880309
epoch-1 step 199900/3451022 - loss: 0.037469 val_loss: 0.036203	recall: 0.522897 precision: 0.924670
epoch-1 step 200000/3451022 - loss: 0.045637 val_loss: 0.035987	recall: 0.532741 precision: 0.912548

checkpoint saved

epoch-1 step 200100/3451022 - loss: 0.038398 val_loss: 0.039549	recall: 0.518319 precision: 0.895717

model exported!

epoch-1 step 200200/3451022 - loss: 0.035689 val_loss: 0.038153	recall: 0.528090 precision: 0.912621
epoch-1 step 200300/3451022 - loss: 0.041671 val_loss: 0.035530	recall: 0.509948 precision: 0.924099
epoch-1 step 200400/3451022 - loss: 0.035409 val_loss: 0.035150	recall: 0.485714 precision: 0.882692
epoch-1 step 200500/3451022 - loss: 0.035693 val_loss: 0.038393	recall: 0.524554 precision: 0.934394
epoch-1 step 200600/3451022 - loss: 0.035160 val_loss: 0.056136	recall: 0.525967 precision: 0.918919
epoch-1 step 200700/3451022 - loss: 0.038178 val_loss: 0.038795	recall: 0.495288 precision: 0.889098
epoch-1 step 200800/3451022 - loss: 0.041756 val_loss: 0.041273	recall: 0.533643 precision: 0.881226
epoch-1 step 200900/3451022 - loss: 0.035767 val_loss: 0.034853	recall: 0.523322 precision: 0.910891
epoch-1 step 201000/3451022 - loss: 0.036029 val_loss: 0.037457	recall: 0.545657 precision: 0.910781

checkpoint saved

epoch-1 step 201100/3451022 - loss: 0.034142 val_loss: 0.035921	recall: 0.486287 precision: 0.916501
epoch-1 step 201200/3451022 - loss: 0.036564 val_loss: 0.035482	recall: 0.493671 precision: 0.894837
epoch-1 step 201300/3451022 - loss: 0.036186 val_loss: 0.036256	recall: 0.506369 precision: 0.894934
epoch-1 step 201400/3451022 - loss: 0.039097 val_loss: 0.037501	recall: 0.512195 precision: 0.884615
epoch-1 step 201500/3451022 - loss: 0.034084 val_loss: 0.035563	recall: 0.513144 precision: 0.908752
epoch-1 step 201600/3451022 - loss: 0.038037 val_loss: 0.035002	recall: 0.514351 precision: 0.908722
epoch-1 step 201700/3451022 - loss: 0.037448 val_loss: 0.039829	recall: 0.483801 precision: 0.894212
epoch-1 step 201800/3451022 - loss: 0.037326 val_loss: 0.034759	recall: 0.530055 precision: 0.916824
epoch-1 step 201900/3451022 - loss: 0.042518 val_loss: 0.035652	recall: 0.527293 precision: 0.899441
epoch-1 step 202000/3451022 - loss: 0.042965 val_loss: 0.036406	recall: 0.500000 precision: 0.891429

checkpoint saved

epoch-1 step 202100/3451022 - loss: 0.035441 val_loss: 0.036702	recall: 0.488938 precision: 0.902041

model exported!

epoch-1 step 202200/3451022 - loss: 0.036351 val_loss: 0.034544	recall: 0.500000 precision: 0.916509
epoch-1 step 202300/3451022 - loss: 0.040039 val_loss: 0.035790	recall: 0.504292 precision: 0.928854
epoch-1 step 202400/3451022 - loss: 0.038764 val_loss: 0.037305	recall: 0.468303 precision: 0.905138
epoch-1 step 202500/3451022 - loss: 0.039111 val_loss: 0.035595	recall: 0.481013 precision: 0.878613
epoch-1 step 202600/3451022 - loss: 0.034528 val_loss: 0.034909	recall: 0.492114 precision: 0.915851
epoch-1 step 202700/3451022 - loss: 0.036780 val_loss: 0.035435	recall: 0.484392 precision: 0.901804
epoch-1 step 202800/3451022 - loss: 0.039148 val_loss: 0.035819	recall: 0.518519 precision: 0.925852
epoch-1 step 202900/3451022 - loss: 0.035370 val_loss: 0.045748	recall: 0.506508 precision: 0.899807
epoch-1 step 203000/3451022 - loss: 0.037183 val_loss: 0.035834	recall: 0.540000 precision: 0.898239

checkpoint saved

epoch-1 step 203100/3451022 - loss: 0.035251 val_loss: 0.039155	recall: 0.523333 precision: 0.909266
epoch-1 step 203200/3451022 - loss: 0.035664 val_loss: 0.040479	recall: 0.562573 precision: 0.916190
epoch-1 step 203300/3451022 - loss: 0.037494 val_loss: 0.037599	recall: 0.512061 precision: 0.905039
epoch-1 step 203400/3451022 - loss: 0.034927 val_loss: 0.042300	recall: 0.503776 precision: 0.886148
epoch-1 step 203500/3451022 - loss: 0.036536 val_loss: 0.034833	recall: 0.532909 precision: 0.934823
epoch-1 step 203600/3451022 - loss: 0.035167 val_loss: 0.042558	recall: 0.492585 precision: 0.887405
epoch-1 step 203700/3451022 - loss: 0.034273 val_loss: 0.037054	recall: 0.488818 precision: 0.891262
epoch-1 step 203800/3451022 - loss: 0.035081 val_loss: 0.041772	recall: 0.508830 precision: 0.900391
epoch-1 step 203900/3451022 - loss: 0.036150 val_loss: 0.039891	recall: 0.508995 precision: 0.926782
epoch-1 step 204000/3451022 - loss: 0.038787 val_loss: 0.034588	recall: 0.504972 precision: 0.908549

checkpoint saved

epoch-1 step 204100/3451022 - loss: 0.035152 val_loss: 0.039456	recall: 0.492678 precision: 0.911025

model exported!

epoch-1 step 204200/3451022 - loss: 0.037132 val_loss: 0.038189	recall: 0.521499 precision: 0.911368
epoch-1 step 204300/3451022 - loss: 0.034762 val_loss: 0.034597	recall: 0.501078 precision: 0.902913
epoch-1 step 204400/3451022 - loss: 0.035496 val_loss: 0.038690	recall: 0.518847 precision: 0.896552
epoch-1 step 204500/3451022 - loss: 0.035116 val_loss: 0.035054	recall: 0.546460 precision: 0.919926
epoch-1 step 204600/3451022 - loss: 0.035983 val_loss: 0.044950	recall: 0.546620 precision: 0.898467
epoch-1 step 204700/3451022 - loss: 0.038192 val_loss: 0.038031	recall: 0.542045 precision: 0.894934
epoch-1 step 204800/3451022 - loss: 0.034249 val_loss: 0.034784	recall: 0.545872 precision: 0.920696
epoch-1 step 204900/3451022 - loss: 0.035004 val_loss: 0.036665	recall: 0.525499 precision: 0.892655
epoch-1 step 205000/3451022 - loss: 0.034847 val_loss: 0.034679	recall: 0.495585 precision: 0.894422

checkpoint saved

epoch-1 step 205100/3451022 - loss: 0.034173 val_loss: 0.040277	recall: 0.491189 precision: 0.888446
epoch-1 step 205200/3451022 - loss: 0.039125 val_loss: 0.043074	recall: 0.575515 precision: 0.940187
epoch-1 step 205300/3451022 - loss: 0.035885 val_loss: 0.041866	recall: 0.546980 precision: 0.933206
epoch-1 step 205400/3451022 - loss: 0.035771 val_loss: 0.035974	recall: 0.480382 precision: 0.893491
epoch-1 step 205500/3451022 - loss: 0.038223 val_loss: 0.035175	recall: 0.554147 precision: 0.912713
epoch-1 step 205600/3451022 - loss: 0.037883 val_loss: 0.034597	recall: 0.500537 precision: 0.899614
epoch-1 step 205700/3451022 - loss: 0.035900 val_loss: 0.039138	recall: 0.508547 precision: 0.926070
epoch-1 step 205800/3451022 - loss: 0.039495 val_loss: 0.037438	recall: 0.521127 precision: 0.907547
epoch-1 step 205900/3451022 - loss: 0.044643 val_loss: 0.035971	recall: 0.513284 precision: 0.904494
epoch-1 step 206000/3451022 - loss: 0.036403 val_loss: 0.035967	recall: 0.527991 precision: 0.900749

checkpoint saved

epoch-1 step 206100/3451022 - loss: 0.034415 val_loss: 0.037182	recall: 0.500000 precision: 0.902913

model exported!

epoch-1 step 206200/3451022 - loss: 0.034525 val_loss: 0.035585	recall: 0.489572 precision: 0.895582
epoch-1 step 206300/3451022 - loss: 0.041852 val_loss: 0.034702	recall: 0.530023 precision: 0.886100
epoch-1 step 206400/3451022 - loss: 0.034829 val_loss: 0.043651	recall: 0.511062 precision: 0.895349
epoch-1 step 206500/3451022 - loss: 0.035455 val_loss: 0.035560	recall: 0.539313 precision: 0.936538
epoch-1 step 206600/3451022 - loss: 0.036635 val_loss: 0.035537	recall: 0.522581 precision: 0.918715
epoch-1 step 206700/3451022 - loss: 0.034953 val_loss: 0.038836	recall: 0.500561 precision: 0.899194
epoch-1 step 206800/3451022 - loss: 0.036843 val_loss: 0.037992	recall: 0.506997 precision: 0.909266
epoch-1 step 206900/3451022 - loss: 0.038803 val_loss: 0.038309	recall: 0.508772 precision: 0.895753
epoch-1 step 207000/3451022 - loss: 0.042802 val_loss: 0.042988	recall: 0.502160 precision: 0.904669

checkpoint saved

epoch-1 step 207100/3451022 - loss: 0.038355 val_loss: 0.041423	recall: 0.465839 precision: 0.882353
epoch-1 step 207200/3451022 - loss: 0.035225 val_loss: 0.034686	recall: 0.534308 precision: 0.925926
epoch-1 step 207300/3451022 - loss: 0.039246 val_loss: 0.035456	recall: 0.500546 precision: 0.891051
epoch-1 step 207400/3451022 - loss: 0.035547 val_loss: 0.035996	recall: 0.506997 precision: 0.907514
epoch-1 step 207500/3451022 - loss: 0.035780 val_loss: 0.035483	recall: 0.518192 precision: 0.927022
epoch-1 step 207600/3451022 - loss: 0.035908 val_loss: 0.035145	recall: 0.496746 precision: 0.892788
epoch-1 step 207700/3451022 - loss: 0.034369 val_loss: 0.034886	recall: 0.529670 precision: 0.902622
epoch-1 step 207800/3451022 - loss: 0.068734 val_loss: 0.035367	recall: 0.517544 precision: 0.888889
epoch-1 step 207900/3451022 - loss: 0.033926 val_loss: 0.036025	recall: 0.532037 precision: 0.922619
epoch-1 step 208000/3451022 - loss: 0.040759 val_loss: 0.037944	recall: 0.513256 precision: 0.901304

checkpoint saved

epoch-1 step 208100/3451022 - loss: 0.035615 val_loss: 0.034414	recall: 0.534857 precision: 0.912281

model exported!

epoch-1 step 208200/3451022 - loss: 0.037099 val_loss: 0.036148	recall: 0.530822 precision: 0.915354
epoch-1 step 208300/3451022 - loss: 0.034923 val_loss: 0.035904	recall: 0.484076 precision: 0.895874
epoch-1 step 208400/3451022 - loss: 0.035651 val_loss: 0.035283	recall: 0.540749 precision: 0.933460
epoch-1 step 208500/3451022 - loss: 0.034779 val_loss: 0.035051	recall: 0.508475 precision: 0.877193
epoch-1 step 208600/3451022 - loss: 0.034105 val_loss: 0.036896	recall: 0.525000 precision: 0.913043
epoch-1 step 208700/3451022 - loss: 0.034158 val_loss: 0.033778	recall: 0.534386 precision: 0.884328
epoch-1 step 208800/3451022 - loss: 0.037736 val_loss: 0.035014	recall: 0.511811 precision: 0.878378
epoch-1 step 208900/3451022 - loss: 0.038028 val_loss: 0.045004	recall: 0.520089 precision: 0.892720
epoch-1 step 209000/3451022 - loss: 0.041804 val_loss: 0.038612	recall: 0.500556 precision: 0.889328

checkpoint saved

epoch-1 step 209100/3451022 - loss: 0.044003 val_loss: 0.041739	recall: 0.526786 precision: 0.907692
epoch-1 step 209200/3451022 - loss: 0.034286 val_loss: 0.040867	recall: 0.522727 precision: 0.898438
epoch-1 step 209300/3451022 - loss: 0.035430 val_loss: 0.036260	recall: 0.507135 precision: 0.909449
epoch-1 step 209400/3451022 - loss: 0.036696 val_loss: 0.034396	recall: 0.510567 precision: 0.874286
epoch-1 step 209500/3451022 - loss: 0.040667 val_loss: 0.035086	recall: 0.511905 precision: 0.918447
epoch-1 step 209600/3451022 - loss: 0.034900 val_loss: 0.034446	recall: 0.532880 precision: 0.905588
epoch-1 step 209700/3451022 - loss: 0.034193 val_loss: 0.037178	recall: 0.525683 precision: 0.884191
epoch-1 step 209800/3451022 - loss: 0.035486 val_loss: 0.034669	recall: 0.488398 precision: 0.894737
epoch-1 step 209900/3451022 - loss: 0.035893 val_loss: 0.039611	recall: 0.527621 precision: 0.906977
epoch-1 step 210000/3451022 - loss: 0.037594 val_loss: 0.036117	recall: 0.521839 precision: 0.874759

checkpoint saved

epoch-1 step 210100/3451022 - loss: 0.036960 val_loss: 0.038009	recall: 0.502726 precision: 0.905697

model exported!

epoch-1 step 210200/3451022 - loss: 0.034765 val_loss: 0.038628	recall: 0.496224 precision: 0.889749
epoch-1 step 210300/3451022 - loss: 0.036718 val_loss: 0.036262	recall: 0.492212 precision: 0.890977
epoch-1 step 210400/3451022 - loss: 0.034847 val_loss: 0.035960	recall: 0.488277 precision: 0.924710
epoch-1 step 210500/3451022 - loss: 0.036574 val_loss: 0.035057	recall: 0.520430 precision: 0.916667
epoch-1 step 210600/3451022 - loss: 0.034372 val_loss: 0.034761	recall: 0.498876 precision: 0.889780
epoch-1 step 210700/3451022 - loss: 0.034883 val_loss: 0.034743	recall: 0.532407 precision: 0.910891
epoch-1 step 210800/3451022 - loss: 0.041317 val_loss: 0.053566	recall: 0.486039 precision: 0.881801
epoch-1 step 210900/3451022 - loss: 0.038847 val_loss: 0.034483	recall: 0.527897 precision: 0.921348
epoch-1 step 211000/3451022 - loss: 0.041308 val_loss: 0.038257	recall: 0.522371 precision: 0.922925

checkpoint saved

epoch-1 step 211100/3451022 - loss: 0.036058 val_loss: 0.035706	recall: 0.468915 precision: 0.870841
epoch-1 step 211200/3451022 - loss: 0.038421 val_loss: 0.034973	recall: 0.500000 precision: 0.903162
epoch-1 step 211300/3451022 - loss: 0.036616 val_loss: 0.035658	recall: 0.526092 precision: 0.919926
epoch-1 step 211400/3451022 - loss: 0.037095 val_loss: 0.036752	recall: 0.521368 precision: 0.920755
epoch-1 step 211500/3451022 - loss: 0.038679 val_loss: 0.038783	recall: 0.531590 precision: 0.913858
epoch-1 step 211600/3451022 - loss: 0.036419 val_loss: 0.044570	recall: 0.514317 precision: 0.896353
epoch-1 step 211700/3451022 - loss: 0.038751 val_loss: 0.040084	recall: 0.505319 precision: 0.884544
epoch-1 step 211800/3451022 - loss: 0.037612 val_loss: 0.034366	recall: 0.516854 precision: 0.916335
epoch-1 step 211900/3451022 - loss: 0.036961 val_loss: 0.037205	recall: 0.541667 precision: 0.903475
epoch-1 step 212000/3451022 - loss: 0.035921 val_loss: 0.035125	recall: 0.504237 precision: 0.918919

checkpoint saved

epoch-1 step 212100/3451022 - loss: 0.035544 val_loss: 0.039697	recall: 0.514009 precision: 0.926214

model exported!

epoch-1 step 212200/3451022 - loss: 0.035825 val_loss: 0.035096	recall: 0.498963 precision: 0.930368
epoch-1 step 212300/3451022 - loss: 0.037130 val_loss: 0.041713	recall: 0.506077 precision: 0.908730
epoch-1 step 212400/3451022 - loss: 0.038513 val_loss: 0.035077	recall: 0.514989 precision: 0.933981
epoch-1 step 212500/3451022 - loss: 0.034550 val_loss: 0.035397	recall: 0.541712 precision: 0.938086
epoch-1 step 212600/3451022 - loss: 0.034741 val_loss: 0.037913	recall: 0.502806 precision: 0.885375
epoch-1 step 212700/3451022 - loss: 0.037928 val_loss: 0.034819	recall: 0.520742 precision: 0.928016
epoch-1 step 212800/3451022 - loss: 0.034406 val_loss: 0.037026	recall: 0.532887 precision: 0.935421
epoch-1 step 212900/3451022 - loss: 0.036462 val_loss: 0.035929	recall: 0.533490 precision: 0.899010
epoch-1 step 213000/3451022 - loss: 0.040915 val_loss: 0.035487	recall: 0.513782 precision: 0.897881

checkpoint saved

epoch-1 step 213100/3451022 - loss: 0.033996 val_loss: 0.039417	recall: 0.490791 precision: 0.895257
epoch-1 step 213200/3451022 - loss: 0.034411 val_loss: 0.040144	recall: 0.526316 precision: 0.916335
epoch-1 step 213300/3451022 - loss: 0.038190 val_loss: 0.035558	recall: 0.516866 precision: 0.878004
epoch-1 step 213400/3451022 - loss: 0.034557 val_loss: 0.036200	recall: 0.511983 precision: 0.917969
epoch-1 step 213500/3451022 - loss: 0.037977 val_loss: 0.036884	recall: 0.512702 precision: 0.896970
epoch-1 step 213600/3451022 - loss: 0.034990 val_loss: 0.037830	recall: 0.504940 precision: 0.894942
epoch-1 step 213700/3451022 - loss: 0.044560 val_loss: 0.040826	recall: 0.524807 precision: 0.904943
epoch-1 step 213800/3451022 - loss: 0.037431 val_loss: 0.044841	recall: 0.489730 precision: 0.874517
epoch-1 step 213900/3451022 - loss: 0.037616 val_loss: 0.039917	recall: 0.526144 precision: 0.906191
epoch-1 step 214000/3451022 - loss: 0.041277 val_loss: 0.042470	recall: 0.520857 precision: 0.891892

checkpoint saved

epoch-1 step 214100/3451022 - loss: 0.046803 val_loss: 0.038588	recall: 0.514574 precision: 0.910714

model exported!

epoch-1 step 214200/3451022 - loss: 0.034691 val_loss: 0.037462	recall: 0.501101 precision: 0.886940
epoch-1 step 214300/3451022 - loss: 0.035776 val_loss: 0.035086	recall: 0.514444 precision: 0.890385
epoch-1 step 214400/3451022 - loss: 0.034982 val_loss: 0.040610	recall: 0.512764 precision: 0.900585
epoch-1 step 214500/3451022 - loss: 0.034730 val_loss: 0.049757	recall: 0.511654 precision: 0.911067
epoch-1 step 214600/3451022 - loss: 0.035050 val_loss: 0.036518	recall: 0.527586 precision: 0.907115
epoch-1 step 214700/3451022 - loss: 0.036397 val_loss: 0.045843	recall: 0.503719 precision: 0.897727
epoch-1 step 214800/3451022 - loss: 0.039972 val_loss: 0.044558	recall: 0.483974 precision: 0.897030
epoch-1 step 214900/3451022 - loss: 0.035169 val_loss: 0.037891	recall: 0.502141 precision: 0.919608
epoch-1 step 215000/3451022 - loss: 0.035729 val_loss: 0.037161	recall: 0.527497 precision: 0.907336

checkpoint saved

epoch-1 step 215100/3451022 - loss: 0.035418 val_loss: 0.035402	recall: 0.502110 precision: 0.903226
epoch-1 step 215200/3451022 - loss: 0.034756 val_loss: 0.035101	recall: 0.558140 precision: 0.923077
epoch-1 step 215300/3451022 - loss: 0.035170 val_loss: 0.037163	recall: 0.513200 precision: 0.927481
epoch-1 step 215400/3451022 - loss: 0.034717 val_loss: 0.035780	recall: 0.537313 precision: 0.919450
epoch-1 step 215500/3451022 - loss: 0.035242 val_loss: 0.039500	recall: 0.517165 precision: 0.910331
epoch-1 step 215600/3451022 - loss: 0.034035 val_loss: 0.039667	recall: 0.513393 precision: 0.903733
epoch-1 step 215700/3451022 - loss: 0.039192 val_loss: 0.035718	recall: 0.516940 precision: 0.904398
epoch-1 step 215800/3451022 - loss: 0.041501 val_loss: 0.040731	recall: 0.487621 precision: 0.909639
epoch-1 step 215900/3451022 - loss: 0.038689 val_loss: 0.039198	recall: 0.497262 precision: 0.881553
epoch-1 step 216000/3451022 - loss: 0.036960 val_loss: 0.037212	recall: 0.511230 precision: 0.910476

checkpoint saved

epoch-1 step 216100/3451022 - loss: 0.035819 val_loss: 0.038427	recall: 0.513514 precision: 0.883721

model exported!

epoch-1 step 216200/3451022 - loss: 0.037066 val_loss: 0.037747	recall: 0.501094 precision: 0.894531
epoch-1 step 216300/3451022 - loss: 0.034426 val_loss: 0.038901	recall: 0.510615 precision: 0.897839
epoch-1 step 216400/3451022 - loss: 0.036530 val_loss: 0.033928	recall: 0.500557 precision: 0.898000
epoch-1 step 216500/3451022 - loss: 0.044720 val_loss: 0.035774	recall: 0.478745 precision: 0.890772
epoch-1 step 216600/3451022 - loss: 0.038720 val_loss: 0.036799	recall: 0.485991 precision: 0.898406
epoch-1 step 216700/3451022 - loss: 0.034744 val_loss: 0.038649	recall: 0.529279 precision: 0.909091
epoch-1 step 216800/3451022 - loss: 0.036575 val_loss: 0.042371	recall: 0.520607 precision: 0.892193
epoch-1 step 216900/3451022 - loss: 0.036035 val_loss: 0.039522	recall: 0.522936 precision: 0.917505
epoch-1 step 217000/3451022 - loss: 0.041614 val_loss: 0.035106	recall: 0.533762 precision: 0.923933

checkpoint saved

epoch-1 step 217100/3451022 - loss: 0.039066 val_loss: 0.035773	recall: 0.526087 precision: 0.911488
epoch-1 step 217200/3451022 - loss: 0.035029 val_loss: 0.036299	recall: 0.529217 precision: 0.909091
epoch-1 step 217300/3451022 - loss: 0.035717 val_loss: 0.036565	recall: 0.516704 precision: 0.902724
epoch-1 step 217400/3451022 - loss: 0.038993 val_loss: 0.035108	recall: 0.504219 precision: 0.907021
epoch-1 step 217500/3451022 - loss: 0.042464 val_loss: 0.033989	recall: 0.509737 precision: 0.879447
epoch-1 step 217600/3451022 - loss: 0.034893 val_loss: 0.043126	recall: 0.518359 precision: 0.900563
epoch-1 step 217700/3451022 - loss: 0.035621 val_loss: 0.036197	recall: 0.497371 precision: 0.909615
epoch-1 step 217800/3451022 - loss: 0.037361 val_loss: 0.036086	recall: 0.524892 precision: 0.920304
epoch-1 step 217900/3451022 - loss: 0.037038 val_loss: 0.036164	recall: 0.523707 precision: 0.936416
epoch-1 step 218000/3451022 - loss: 0.038868 val_loss: 0.035872	recall: 0.511983 precision: 0.927022

checkpoint saved

epoch-1 step 218100/3451022 - loss: 0.036012 val_loss: 0.037425	recall: 0.483701 precision: 0.925553

model exported!

epoch-1 step 218200/3451022 - loss: 0.036304 val_loss: 0.035706	recall: 0.498378 precision: 0.902153
epoch-1 step 218300/3451022 - loss: 0.037256 val_loss: 0.041956	recall: 0.533482 precision: 0.912214
epoch-1 step 218400/3451022 - loss: 0.035353 val_loss: 0.038767	recall: 0.518681 precision: 0.905950
epoch-1 step 218500/3451022 - loss: 0.040220 val_loss: 0.035984	recall: 0.497881 precision: 0.900383
epoch-1 step 218600/3451022 - loss: 0.034824 val_loss: 0.035855	recall: 0.528944 precision: 0.892720
epoch-1 step 218700/3451022 - loss: 0.036333 val_loss: 0.035558	recall: 0.492114 precision: 0.912281
epoch-1 step 218800/3451022 - loss: 0.038171 val_loss: 0.043037	recall: 0.526726 precision: 0.889098
epoch-1 step 218900/3451022 - loss: 0.036915 val_loss: 0.033886	recall: 0.515778 precision: 0.901141
epoch-1 step 219000/3451022 - loss: 0.035779 val_loss: 0.035220	recall: 0.526718 precision: 0.916509

checkpoint saved

epoch-1 step 219100/3451022 - loss: 0.034729 val_loss: 0.035770	recall: 0.523596 precision: 0.897881
epoch-1 step 219200/3451022 - loss: 0.036469 val_loss: 0.037677	recall: 0.515521 precision: 0.904669
epoch-1 step 219300/3451022 - loss: 0.041022 val_loss: 0.038260	recall: 0.513605 precision: 0.883041
epoch-1 step 219400/3451022 - loss: 0.039466 val_loss: 0.038073	recall: 0.532511 precision: 0.899621
epoch-1 step 219500/3451022 - loss: 0.041546 val_loss: 0.037161	recall: 0.506522 precision: 0.904854
epoch-1 step 219600/3451022 - loss: 0.034606 val_loss: 0.037795	recall: 0.497835 precision: 0.905512
epoch-1 step 219700/3451022 - loss: 0.034886 val_loss: 0.038504	recall: 0.547148 precision: 0.903846
epoch-1 step 219800/3451022 - loss: 0.036526 val_loss: 0.035272	recall: 0.506726 precision: 0.886275
epoch-1 step 219900/3451022 - loss: 0.039536 val_loss: 0.038382	recall: 0.535288 precision: 0.931947
epoch-1 step 220000/3451022 - loss: 0.034696 val_loss: 0.034322	recall: 0.545455 precision: 0.902256

checkpoint saved

epoch-1 step 220100/3451022 - loss: 0.038586 val_loss: 0.034155	recall: 0.545244 precision: 0.903846

model exported!

epoch-1 step 220200/3451022 - loss: 0.042410 val_loss: 0.038247	recall: 0.517131 precision: 0.918251
epoch-1 step 220300/3451022 - loss: 0.036881 val_loss: 0.037270	recall: 0.508179 precision: 0.885932
epoch-1 step 220400/3451022 - loss: 0.037921 val_loss: 0.034925	recall: 0.526316 precision: 0.898204
epoch-1 step 220500/3451022 - loss: 0.034397 val_loss: 0.035572	recall: 0.516055 precision: 0.905433
epoch-1 step 220600/3451022 - loss: 0.040037 val_loss: 0.035021	recall: 0.522826 precision: 0.884191
epoch-1 step 220700/3451022 - loss: 0.040914 val_loss: 0.034421	recall: 0.510965 precision: 0.911937
epoch-1 step 220800/3451022 - loss: 0.035485 val_loss: 0.037989	recall: 0.534676 precision: 0.917466
epoch-1 step 220900/3451022 - loss: 0.039132 val_loss: 0.042423	recall: 0.528345 precision: 0.903101
epoch-1 step 221000/3451022 - loss: 0.067035 val_loss: 0.035866	recall: 0.529906 precision: 0.914855

checkpoint saved

epoch-1 step 221100/3451022 - loss: 0.035426 val_loss: 0.036165	recall: 0.505108 precision: 0.870841
epoch-1 step 221200/3451022 - loss: 0.035491 val_loss: 0.036569	recall: 0.484324 precision: 0.880157
epoch-1 step 221300/3451022 - loss: 0.035513 val_loss: 0.034087	recall: 0.538895 precision: 0.905303
epoch-1 step 221400/3451022 - loss: 0.038042 val_loss: 0.038078	recall: 0.500000 precision: 0.896422
epoch-1 step 221500/3451022 - loss: 0.036941 val_loss: 0.036925	recall: 0.494241 precision: 0.916505
epoch-1 step 221600/3451022 - loss: 0.037472 val_loss: 0.035293	recall: 0.477903 precision: 0.869159
epoch-1 step 221700/3451022 - loss: 0.034511 val_loss: 0.035141	recall: 0.538808 precision: 0.919386
epoch-1 step 221800/3451022 - loss: 0.035418 val_loss: 0.035977	recall: 0.526549 precision: 0.901515
epoch-1 step 221900/3451022 - loss: 0.040006 val_loss: 0.037345	recall: 0.524184 precision: 0.874296
epoch-1 step 222000/3451022 - loss: 0.040235 val_loss: 0.036654	recall: 0.518900 precision: 0.904192

checkpoint saved

epoch-1 step 222100/3451022 - loss: 0.035658 val_loss: 0.035537	recall: 0.521231 precision: 0.922932

model exported!

epoch-1 step 222200/3451022 - loss: 0.036539 val_loss: 0.038157	recall: 0.507182 precision: 0.884393
epoch-1 step 222300/3451022 - loss: 0.035003 val_loss: 0.034888	recall: 0.517391 precision: 0.904943
epoch-1 step 222400/3451022 - loss: 0.040236 val_loss: 0.035700	recall: 0.501654 precision: 0.893910
epoch-1 step 222500/3451022 - loss: 0.044827 val_loss: 0.035660	recall: 0.515676 precision: 0.901701
epoch-1 step 222600/3451022 - loss: 0.040372 val_loss: 0.035386	recall: 0.533851 precision: 0.904135
epoch-1 step 222700/3451022 - loss: 0.040741 val_loss: 0.035909	recall: 0.518686 precision: 0.887597
epoch-1 step 222800/3451022 - loss: 0.041217 val_loss: 0.036828	recall: 0.517954 precision: 0.896422
epoch-1 step 222900/3451022 - loss: 0.035058 val_loss: 0.041359	recall: 0.566975 precision: 0.928166
epoch-1 step 223000/3451022 - loss: 0.043351 val_loss: 0.036786	recall: 0.509740 precision: 0.897143

checkpoint saved

epoch-1 step 223100/3451022 - loss: 0.038027 val_loss: 0.034145	recall: 0.516165 precision: 0.907843
epoch-1 step 223200/3451022 - loss: 0.035520 val_loss: 0.033268	recall: 0.520624 precision: 0.881132
epoch-1 step 223300/3451022 - loss: 0.036111 val_loss: 0.036638	recall: 0.500000 precision: 0.889320
epoch-1 step 223400/3451022 - loss: 0.043748 val_loss: 0.041117	recall: 0.477083 precision: 0.903353
epoch-1 step 223500/3451022 - loss: 0.036802 val_loss: 0.037808	recall: 0.527233 precision: 0.902985
epoch-1 step 223600/3451022 - loss: 0.038892 val_loss: 0.034517	recall: 0.519274 precision: 0.917836
epoch-1 step 223700/3451022 - loss: 0.035102 val_loss: 0.038158	recall: 0.506550 precision: 0.906250
epoch-1 step 223800/3451022 - loss: 0.035244 val_loss: 0.035964	recall: 0.487020 precision: 0.898467
epoch-1 step 223900/3451022 - loss: 0.035225 val_loss: 0.038517	recall: 0.522484 precision: 0.915572
epoch-1 step 224000/3451022 - loss: 0.035225 val_loss: 0.035877	recall: 0.531250 precision: 0.920696

checkpoint saved

epoch-1 step 224100/3451022 - loss: 0.044473 val_loss: 0.033973	recall: 0.500000 precision: 0.913127

model exported!

epoch-1 step 224200/3451022 - loss: 0.034788 val_loss: 0.035375	recall: 0.502132 precision: 0.897143
epoch-1 step 224300/3451022 - loss: 0.036230 val_loss: 0.036277	recall: 0.495060 precision: 0.879142
epoch-1 step 224400/3451022 - loss: 0.035609 val_loss: 0.040890	recall: 0.494647 precision: 0.883365
epoch-1 step 224500/3451022 - loss: 0.043713 val_loss: 0.036067	recall: 0.512735 precision: 0.893822
epoch-1 step 224600/3451022 - loss: 0.036096 val_loss: 0.038024	recall: 0.528064 precision: 0.907480
epoch-1 step 224700/3451022 - loss: 0.036196 val_loss: 0.035647	recall: 0.500552 precision: 0.893491
epoch-1 step 224800/3451022 - loss: 0.037275 val_loss: 0.037213	recall: 0.534025 precision: 0.920477
epoch-1 step 224900/3451022 - loss: 0.037600 val_loss: 0.035405	recall: 0.522854 precision: 0.912451
epoch-1 step 225000/3451022 - loss: 0.034928 val_loss: 0.036880	recall: 0.511501 precision: 0.912109

checkpoint saved

epoch-1 step 225100/3451022 - loss: 0.034828 val_loss: 0.036476	recall: 0.523962 precision: 0.917910
epoch-1 step 225200/3451022 - loss: 0.038938 val_loss: 0.041813	recall: 0.519956 precision: 0.901923
epoch-1 step 225300/3451022 - loss: 0.035356 val_loss: 0.039497	recall: 0.503219 precision: 0.908915
epoch-1 step 225400/3451022 - loss: 0.034622 val_loss: 0.035847	recall: 0.533480 precision: 0.900000
epoch-1 step 225500/3451022 - loss: 0.036490 val_loss: 0.041009	recall: 0.520316 precision: 0.902153
epoch-1 step 225600/3451022 - loss: 0.035552 val_loss: 0.036147	recall: 0.498881 precision: 0.877953
epoch-1 step 225700/3451022 - loss: 0.039598 val_loss: 0.036366	recall: 0.510497 precision: 0.905882
epoch-1 step 225800/3451022 - loss: 0.038856 val_loss: 0.044546	recall: 0.537931 precision: 0.912281
epoch-1 step 225900/3451022 - loss: 0.035330 val_loss: 0.035223	recall: 0.521311 precision: 0.912046
epoch-1 step 226000/3451022 - loss: 0.036148 val_loss: 0.034121	recall: 0.529809 precision: 0.907514

checkpoint saved

epoch-1 step 226100/3451022 - loss: 0.035636 val_loss: 0.036812	recall: 0.538376 precision: 0.918406

model exported!

epoch-1 step 226200/3451022 - loss: 0.042421 val_loss: 0.042422	recall: 0.511785 precision: 0.897638
epoch-1 step 226300/3451022 - loss: 0.044002 val_loss: 0.035613	recall: 0.526258 precision: 0.926782
epoch-1 step 226400/3451022 - loss: 0.041164 val_loss: 0.037111	recall: 0.502193 precision: 0.879079
epoch-1 step 226500/3451022 - loss: 0.037169 val_loss: 0.036596	recall: 0.521127 precision: 0.912713
epoch-1 step 226600/3451022 - loss: 0.035945 val_loss: 0.034642	recall: 0.506893 precision: 0.907021
epoch-1 step 226700/3451022 - loss: 0.035665 val_loss: 0.041254	recall: 0.509636 precision: 0.883117
epoch-1 step 226800/3451022 - loss: 0.035591 val_loss: 0.036065	recall: 0.513751 precision: 0.908560
epoch-1 step 226900/3451022 - loss: 0.037824 val_loss: 0.036362	recall: 0.511879 precision: 0.915058
epoch-1 step 227000/3451022 - loss: 0.037819 val_loss: 0.037616	recall: 0.527027 precision: 0.893130

checkpoint saved

epoch-1 step 227100/3451022 - loss: 0.036058 val_loss: 0.035895	recall: 0.531603 precision: 0.907514
epoch-1 step 227200/3451022 - loss: 0.040717 val_loss: 0.038087	recall: 0.515119 precision: 0.896617
epoch-1 step 227300/3451022 - loss: 0.034568 val_loss: 0.035252	recall: 0.484656 precision: 0.898039
epoch-1 step 227400/3451022 - loss: 0.035283 val_loss: 0.035108	recall: 0.521645 precision: 0.912879
epoch-1 step 227500/3451022 - loss: 0.036101 val_loss: 0.035313	recall: 0.516854 precision: 0.898438
epoch-1 step 227600/3451022 - loss: 0.035537 val_loss: 0.034995	recall: 0.511811 precision: 0.892157
epoch-1 step 227700/3451022 - loss: 0.038248 val_loss: 0.034520	recall: 0.489978 precision: 0.897959
epoch-1 step 227800/3451022 - loss: 0.040651 val_loss: 0.034510	recall: 0.553531 precision: 0.929254
epoch-1 step 227900/3451022 - loss: 0.038012 val_loss: 0.035462	recall: 0.549708 precision: 0.905588
epoch-1 step 228000/3451022 - loss: 0.035209 val_loss: 0.038062	recall: 0.538737 precision: 0.907631

checkpoint saved

epoch-1 step 228100/3451022 - loss: 0.040757 val_loss: 0.036717	recall: 0.544118 precision: 0.914449

model exported!

epoch-1 step 228200/3451022 - loss: 0.039285 val_loss: 0.035424	recall: 0.538976 precision: 0.916667
epoch-1 step 228300/3451022 - loss: 0.036050 val_loss: 0.037152	recall: 0.521542 precision: 0.909091
epoch-1 step 228400/3451022 - loss: 0.039717 val_loss: 0.036808	recall: 0.537747 precision: 0.915020
epoch-1 step 228500/3451022 - loss: 0.036239 val_loss: 0.037716	recall: 0.539823 precision: 0.912150
epoch-1 step 228600/3451022 - loss: 0.035961 val_loss: 0.036925	recall: 0.495082 precision: 0.879612
epoch-1 step 228700/3451022 - loss: 0.035460 val_loss: 0.034710	recall: 0.504918 precision: 0.902344
epoch-1 step 228800/3451022 - loss: 0.048127 val_loss: 0.037959	recall: 0.527088 precision: 0.886148
epoch-1 step 228900/3451022 - loss: 0.036316 val_loss: 0.034002	recall: 0.543900 precision: 0.915547
epoch-1 step 229000/3451022 - loss: 0.034444 val_loss: 0.034335	recall: 0.538190 precision: 0.916000

checkpoint saved

epoch-1 step 229100/3451022 - loss: 0.036128 val_loss: 0.034491	recall: 0.523230 precision: 0.927451
epoch-1 step 229200/3451022 - loss: 0.039056 val_loss: 0.037282	recall: 0.532796 precision: 0.895551
epoch-1 step 229300/3451022 - loss: 0.035767 val_loss: 0.034416	recall: 0.548578 precision: 0.909627
epoch-1 step 229400/3451022 - loss: 0.043977 val_loss: 0.036892	recall: 0.501571 precision: 0.907197
epoch-1 step 229500/3451022 - loss: 0.034782 val_loss: 0.033617	recall: 0.520999 precision: 0.901768
epoch-1 step 229600/3451022 - loss: 0.035079 val_loss: 0.035653	recall: 0.512249 precision: 0.901961
epoch-1 step 229700/3451022 - loss: 0.036271 val_loss: 0.034649	recall: 0.503219 precision: 0.908915
epoch-1 step 229800/3451022 - loss: 0.037665 val_loss: 0.035929	recall: 0.510022 precision: 0.905138
epoch-1 step 229900/3451022 - loss: 0.040469 val_loss: 0.044786	recall: 0.549065 precision: 0.893536
epoch-1 step 230000/3451022 - loss: 0.042022 val_loss: 0.034628	recall: 0.535513 precision: 0.913462

checkpoint saved

epoch-1 step 230100/3451022 - loss: 0.035021 val_loss: 0.039270	recall: 0.466391 precision: 0.912955

model exported!

epoch-1 step 230200/3451022 - loss: 0.040431 val_loss: 0.036481	recall: 0.527412 precision: 0.897388
epoch-1 step 230300/3451022 - loss: 0.041613 val_loss: 0.039835	recall: 0.523060 precision: 0.897683
epoch-1 step 230400/3451022 - loss: 0.041090 val_loss: 0.034631	recall: 0.503233 precision: 0.899807
epoch-1 step 230500/3451022 - loss: 0.036799 val_loss: 0.044505	recall: 0.517897 precision: 0.888676
epoch-1 step 230600/3451022 - loss: 0.042512 val_loss: 0.038093	recall: 0.521839 precision: 0.883268
epoch-1 step 230700/3451022 - loss: 0.037991 val_loss: 0.040274	recall: 0.532438 precision: 0.917148
epoch-1 step 230800/3451022 - loss: 0.036187 val_loss: 0.040005	recall: 0.533040 precision: 0.939806
epoch-1 step 230900/3451022 - loss: 0.034678 val_loss: 0.039515	recall: 0.502744 precision: 0.898039
epoch-1 step 231000/3451022 - loss: 0.044753 val_loss: 0.035820	recall: 0.521739 precision: 0.888889

checkpoint saved

epoch-1 step 231100/3451022 - loss: 0.039627 val_loss: 0.035477	recall: 0.552693 precision: 0.907692
epoch-1 step 231200/3451022 - loss: 0.042806 val_loss: 0.039127	recall: 0.491024 precision: 0.882353
epoch-1 step 231300/3451022 - loss: 0.037166 val_loss: 0.042979	recall: 0.537330 precision: 0.918762
epoch-1 step 231400/3451022 - loss: 0.035538 val_loss: 0.039649	recall: 0.513904 precision: 0.893617
epoch-1 step 231500/3451022 - loss: 0.036965 val_loss: 0.040640	recall: 0.527842 precision: 0.885214
epoch-1 step 231600/3451022 - loss: 0.034525 val_loss: 0.037423	recall: 0.498382 precision: 0.876660
epoch-1 step 231700/3451022 - loss: 0.042497 val_loss: 0.042367	recall: 0.499464 precision: 0.896154
epoch-1 step 231800/3451022 - loss: 0.039867 val_loss: 0.045792	recall: 0.510428 precision: 0.920792
epoch-1 step 231900/3451022 - loss: 0.036248 val_loss: 0.044433	recall: 0.522876 precision: 0.903955
epoch-1 step 232000/3451022 - loss: 0.035373 val_loss: 0.048869	recall: 0.536928 precision: 0.882466

checkpoint saved

epoch-1 step 232100/3451022 - loss: 0.043121 val_loss: 0.036854	recall: 0.516093 precision: 0.928144

model exported!

epoch-1 step 232200/3451022 - loss: 0.037264 val_loss: 0.042023	recall: 0.546563 precision: 0.918063
epoch-1 step 232300/3451022 - loss: 0.036760 val_loss: 0.038100	recall: 0.547258 precision: 0.891635
epoch-1 step 232400/3451022 - loss: 0.037432 val_loss: 0.034362	recall: 0.512568 precision: 0.898467
epoch-1 step 232500/3451022 - loss: 0.040950 val_loss: 0.034847	recall: 0.535836 precision: 0.916342
epoch-1 step 232600/3451022 - loss: 0.040261 val_loss: 0.041745	recall: 0.513699 precision: 0.920245
epoch-1 step 232700/3451022 - loss: 0.036609 val_loss: 0.037347	recall: 0.518973 precision: 0.904669
epoch-1 step 232800/3451022 - loss: 0.034035 val_loss: 0.035358	recall: 0.530067 precision: 0.889720
epoch-1 step 232900/3451022 - loss: 0.036241 val_loss: 0.035618	recall: 0.539891 precision: 0.921642
epoch-1 step 233000/3451022 - loss: 0.035686 val_loss: 0.042393	recall: 0.523969 precision: 0.914397

checkpoint saved

epoch-1 step 233100/3451022 - loss: 0.037914 val_loss: 0.035750	recall: 0.482948 precision: 0.876248
epoch-1 step 233200/3451022 - loss: 0.042853 val_loss: 0.034579	recall: 0.534155 precision: 0.910305
epoch-1 step 233300/3451022 - loss: 0.034940 val_loss: 0.037958	recall: 0.537844 precision: 0.917808
epoch-1 step 233400/3451022 - loss: 0.036738 val_loss: 0.038734	recall: 0.504587 precision: 0.901639
epoch-1 step 233500/3451022 - loss: 0.035379 val_loss: 0.034708	recall: 0.487991 precision: 0.862934
epoch-1 step 233600/3451022 - loss: 0.034200 val_loss: 0.039681	recall: 0.505908 precision: 0.897143
epoch-1 step 233700/3451022 - loss: 0.037526 val_loss: 0.037139	recall: 0.525084 precision: 0.905769
epoch-1 step 233800/3451022 - loss: 0.033692 val_loss: 0.039847	recall: 0.500550 precision: 0.885214
epoch-1 step 233900/3451022 - loss: 0.034928 val_loss: 0.034974	recall: 0.510989 precision: 0.901163
epoch-1 step 234000/3451022 - loss: 0.036280 val_loss: 0.034864	recall: 0.534541 precision: 0.914729

checkpoint saved

epoch-1 step 234100/3451022 - loss: 0.034347 val_loss: 0.034664	recall: 0.483770 precision: 0.888462

model exported!

epoch-1 step 234200/3451022 - loss: 0.035133 val_loss: 0.035151	recall: 0.516093 precision: 0.924453
epoch-1 step 234300/3451022 - loss: 0.034469 val_loss: 0.038865	recall: 0.522779 precision: 0.918000
epoch-1 step 234400/3451022 - loss: 0.042295 val_loss: 0.035149	recall: 0.492647 precision: 0.914230
epoch-1 step 234500/3451022 - loss: 0.033932 val_loss: 0.037361	recall: 0.521405 precision: 0.929550
epoch-1 step 234600/3451022 - loss: 0.037074 val_loss: 0.035132	recall: 0.548122 precision: 0.905039
epoch-1 step 234700/3451022 - loss: 0.038259 val_loss: 0.044901	recall: 0.531429 precision: 0.895954
epoch-1 step 234800/3451022 - loss: 0.036942 val_loss: 0.034353	recall: 0.509561 precision: 0.886497
epoch-1 step 234900/3451022 - loss: 0.037320 val_loss: 0.038504	recall: 0.503704 precision: 0.896422
epoch-1 step 235000/3451022 - loss: 0.039952 val_loss: 0.034831	recall: 0.491803 precision: 0.882353

checkpoint saved

epoch-1 step 235100/3451022 - loss: 0.035389 val_loss: 0.036043	recall: 0.533408 precision: 0.915870
epoch-1 step 235200/3451022 - loss: 0.042255 val_loss: 0.036187	recall: 0.525499 precision: 0.906310
epoch-1 step 235300/3451022 - loss: 0.035635 val_loss: 0.041422	recall: 0.559676 precision: 0.921756
epoch-1 step 235400/3451022 - loss: 0.036972 val_loss: 0.039486	recall: 0.516060 precision: 0.923372
epoch-1 step 235500/3451022 - loss: 0.036174 val_loss: 0.034518	recall: 0.514532 precision: 0.912214
epoch-1 step 235600/3451022 - loss: 0.035643 val_loss: 0.040311	recall: 0.519438 precision: 0.919694
epoch-1 step 235700/3451022 - loss: 0.042024 val_loss: 0.034378	recall: 0.531868 precision: 0.908068
epoch-1 step 235800/3451022 - loss: 0.036500 val_loss: 0.035396	recall: 0.506494 precision: 0.908738
epoch-1 step 235900/3451022 - loss: 0.035498 val_loss: 0.035455	recall: 0.533408 precision: 0.921154
epoch-1 step 236000/3451022 - loss: 0.035945 val_loss: 0.036310	recall: 0.506565 precision: 0.911417

checkpoint saved

epoch-1 step 236100/3451022 - loss: 0.038154 val_loss: 0.036037	recall: 0.530522 precision: 0.910476

model exported!

epoch-1 step 236200/3451022 - loss: 0.036492 val_loss: 0.037795	recall: 0.511161 precision: 0.910537
epoch-1 step 236300/3451022 - loss: 0.034996 val_loss: 0.038721	recall: 0.510000 precision: 0.908911
epoch-1 step 236400/3451022 - loss: 0.036061 val_loss: 0.035037	recall: 0.508197 precision: 0.877358
epoch-1 step 236500/3451022 - loss: 0.035021 val_loss: 0.042712	recall: 0.515882 precision: 0.900574
epoch-1 step 236600/3451022 - loss: 0.041663 val_loss: 0.037667	recall: 0.525739 precision: 0.916031
epoch-1 step 236700/3451022 - loss: 0.036262 val_loss: 0.053616	recall: 0.488818 precision: 0.887814
epoch-1 step 236800/3451022 - loss: 0.043012 val_loss: 0.037607	recall: 0.519868 precision: 0.895437
epoch-1 step 236900/3451022 - loss: 0.034523 val_loss: 0.041535	recall: 0.515184 precision: 0.909962
epoch-1 step 237000/3451022 - loss: 0.034604 val_loss: 0.036365	recall: 0.474216 precision: 0.905405

checkpoint saved

epoch-1 step 237100/3451022 - loss: 0.034214 val_loss: 0.035190	recall: 0.502146 precision: 0.912281
epoch-1 step 237200/3451022 - loss: 0.039595 val_loss: 0.043136	recall: 0.484070 precision: 0.905769
epoch-1 step 237300/3451022 - loss: 0.034626 val_loss: 0.035677	recall: 0.498922 precision: 0.900778
epoch-1 step 237400/3451022 - loss: 0.036587 val_loss: 0.040669	recall: 0.510360 precision: 0.908738
epoch-1 step 237500/3451022 - loss: 0.034271 val_loss: 0.037241	recall: 0.508565 precision: 0.908222
epoch-1 step 237600/3451022 - loss: 0.040306 val_loss: 0.039765	recall: 0.544406 precision: 0.880597
epoch-1 step 237700/3451022 - loss: 0.034913 val_loss: 0.035959	recall: 0.511706 precision: 0.907115
epoch-1 step 237800/3451022 - loss: 0.042237 val_loss: 0.035150	recall: 0.522905 precision: 0.874766
epoch-1 step 237900/3451022 - loss: 0.034393 val_loss: 0.034735	recall: 0.540632 precision: 0.903774
epoch-1 step 238000/3451022 - loss: 0.035106 val_loss: 0.036355	recall: 0.495726 precision: 0.899225

checkpoint saved

epoch-1 step 238100/3451022 - loss: 0.037139 val_loss: 0.036850	recall: 0.523243 precision: 0.930769

model exported!

epoch-1 step 238200/3451022 - loss: 0.035270 val_loss: 0.035436	recall: 0.527991 precision: 0.889094
epoch-1 step 238300/3451022 - loss: 0.035451 val_loss: 0.040675	recall: 0.478903 precision: 0.888454
epoch-1 step 238400/3451022 - loss: 0.042216 val_loss: 0.035526	recall: 0.538713 precision: 0.921642
epoch-1 step 238500/3451022 - loss: 0.035598 val_loss: 0.043547	recall: 0.510783 precision: 0.882353
epoch-1 step 238600/3451022 - loss: 0.041492 val_loss: 0.036018	recall: 0.551804 precision: 0.918605
epoch-1 step 238700/3451022 - loss: 0.038796 val_loss: 0.038714	recall: 0.505519 precision: 0.889320
epoch-1 step 238800/3451022 - loss: 0.037766 val_loss: 0.038481	recall: 0.486911 precision: 0.895954
epoch-1 step 238900/3451022 - loss: 0.034669 val_loss: 0.035330	recall: 0.534128 precision: 0.888288
epoch-1 step 239000/3451022 - loss: 0.040085 val_loss: 0.041568	recall: 0.503859 precision: 0.901381

checkpoint saved

epoch-1 step 239100/3451022 - loss: 0.038377 val_loss: 0.036844	recall: 0.516903 precision: 0.915058
epoch-1 step 239200/3451022 - loss: 0.041930 val_loss: 0.035134	recall: 0.502203 precision: 0.894118
epoch-1 step 239300/3451022 - loss: 0.038254 val_loss: 0.035986	recall: 0.526726 precision: 0.909615
epoch-1 step 239400/3451022 - loss: 0.035615 val_loss: 0.037794	recall: 0.529480 precision: 0.891051
epoch-1 step 239500/3451022 - loss: 0.034207 val_loss: 0.040428	recall: 0.515778 precision: 0.899431
epoch-1 step 239600/3451022 - loss: 0.036643 val_loss: 0.035266	recall: 0.509934 precision: 0.895349
epoch-1 step 239700/3451022 - loss: 0.035749 val_loss: 0.036886	recall: 0.505519 precision: 0.884170
epoch-1 step 239800/3451022 - loss: 0.037684 val_loss: 0.038708	recall: 0.523230 precision: 0.916667
epoch-1 step 239900/3451022 - loss: 0.037941 val_loss: 0.038850	recall: 0.515952 precision: 0.893333
epoch-1 step 240000/3451022 - loss: 0.035738 val_loss: 0.034924	recall: 0.513843 precision: 0.887189

checkpoint saved

epoch-1 step 240100/3451022 - loss: 0.038933 val_loss: 0.034513	recall: 0.507042 precision: 0.915851

model exported!

epoch-1 step 240200/3451022 - loss: 0.034758 val_loss: 0.037952	recall: 0.522956 precision: 0.899807
epoch-1 step 240300/3451022 - loss: 0.035011 val_loss: 0.038918	recall: 0.535755 precision: 0.902486
epoch-1 step 240400/3451022 - loss: 0.037790 val_loss: 0.038986	recall: 0.505365 precision: 0.888679
epoch-1 step 240500/3451022 - loss: 0.038800 val_loss: 0.037391	recall: 0.495633 precision: 0.924644
epoch-1 step 240600/3451022 - loss: 0.039132 val_loss: 0.040217	recall: 0.461774 precision: 0.907816
epoch-1 step 240700/3451022 - loss: 0.035604 val_loss: 0.036279	recall: 0.472596 precision: 0.903162
epoch-1 step 240800/3451022 - loss: 0.036481 val_loss: 0.036800	recall: 0.529543 precision: 0.933202
epoch-1 step 240900/3451022 - loss: 0.035630 val_loss: 0.035498	recall: 0.517167 precision: 0.935922
epoch-1 step 241000/3451022 - loss: 0.038025 val_loss: 0.037882	recall: 0.512907 precision: 0.908549

checkpoint saved

epoch-1 step 241100/3451022 - loss: 0.036749 val_loss: 0.035144	recall: 0.502123 precision: 0.900952
epoch-1 step 241200/3451022 - loss: 0.038249 val_loss: 0.034803	recall: 0.508386 precision: 0.932692
epoch-1 step 241300/3451022 - loss: 0.036579 val_loss: 0.042520	recall: 0.519608 precision: 0.915547
epoch-1 step 241400/3451022 - loss: 0.039070 val_loss: 0.034919	recall: 0.517660 precision: 0.891635
epoch-1 step 241500/3451022 - loss: 0.035342 val_loss: 0.034950	recall: 0.503859 precision: 0.903162
epoch-1 step 241600/3451022 - loss: 0.040026 val_loss: 0.035656	recall: 0.515254 precision: 0.880309
epoch-1 step 241700/3451022 - loss: 0.034766 val_loss: 0.036076	recall: 0.549592 precision: 0.909266
epoch-1 step 241800/3451022 - loss: 0.038020 val_loss: 0.034808	recall: 0.543153 precision: 0.905950
epoch-1 step 241900/3451022 - loss: 0.035796 val_loss: 0.044482	recall: 0.538286 precision: 0.897143
epoch-1 step 242000/3451022 - loss: 0.036454 val_loss: 0.034425	recall: 0.525057 precision: 0.902153

checkpoint saved

epoch-1 step 242100/3451022 - loss: 0.038858 val_loss: 0.035696	recall: 0.519868 precision: 0.909266

model exported!

epoch-1 step 242200/3451022 - loss: 0.041034 val_loss: 0.044920	recall: 0.523256 precision: 0.880626
epoch-1 step 242300/3451022 - loss: 0.037049 val_loss: 0.034094	recall: 0.531915 precision: 0.922330
epoch-1 step 242400/3451022 - loss: 0.040283 val_loss: 0.034229	recall: 0.546091 precision: 0.884688
epoch-1 step 242500/3451022 - loss: 0.040236 val_loss: 0.037350	recall: 0.516779 precision: 0.891892
epoch-1 step 242600/3451022 - loss: 0.036491 val_loss: 0.037254	recall: 0.535017 precision: 0.882576
epoch-1 step 242700/3451022 - loss: 0.042283 val_loss: 0.034754	recall: 0.559361 precision: 0.914179
epoch-1 step 242800/3451022 - loss: 0.034230 val_loss: 0.035685	recall: 0.507659 precision: 0.882129
epoch-1 step 242900/3451022 - loss: 0.037552 val_loss: 0.036787	recall: 0.528749 precision: 0.910680
epoch-1 step 243000/3451022 - loss: 0.034668 val_loss: 0.037711	recall: 0.516913 precision: 0.914019

checkpoint saved

epoch-1 step 243100/3451022 - loss: 0.036553 val_loss: 0.034644	recall: 0.515823 precision: 0.907236
epoch-1 step 243200/3451022 - loss: 0.036120 val_loss: 0.039544	recall: 0.531773 precision: 0.900000
epoch-1 step 243300/3451022 - loss: 0.035839 val_loss: 0.034425	recall: 0.485043 precision: 0.895464
epoch-1 step 243400/3451022 - loss: 0.042715 val_loss: 0.036406	recall: 0.512541 precision: 0.902111
epoch-1 step 243500/3451022 - loss: 0.037099 val_loss: 0.036533	recall: 0.532571 precision: 0.887619
epoch-1 step 243600/3451022 - loss: 0.035976 val_loss: 0.037079	recall: 0.537264 precision: 0.920000
epoch-1 step 243700/3451022 - loss: 0.037673 val_loss: 0.040572	recall: 0.542955 precision: 0.908046
epoch-1 step 243800/3451022 - loss: 0.035165 val_loss: 0.036598	recall: 0.533991 precision: 0.924099
epoch-1 step 243900/3451022 - loss: 0.035137 val_loss: 0.035381	recall: 0.524239 precision: 0.908203
epoch-1 step 244000/3451022 - loss: 0.038007 val_loss: 0.033768	recall: 0.530201 precision: 0.918605

checkpoint saved

epoch-1 step 244100/3451022 - loss: 0.034405 val_loss: 0.037670	recall: 0.532058 precision: 0.911368

model exported!

epoch-1 step 244200/3451022 - loss: 0.035088 val_loss: 0.034562	recall: 0.544931 precision: 0.890772
epoch-1 step 244300/3451022 - loss: 0.036378 val_loss: 0.043250	recall: 0.541317 precision: 0.886275
epoch-1 step 244400/3451022 - loss: 0.036806 val_loss: 0.034852	recall: 0.518478 precision: 0.915547
epoch-1 step 244500/3451022 - loss: 0.034700 val_loss: 0.037582	recall: 0.532131 precision: 0.900763
epoch-1 step 244600/3451022 - loss: 0.035431 val_loss: 0.044822	recall: 0.524116 precision: 0.905556
epoch-1 step 244700/3451022 - loss: 0.034516 val_loss: 0.039200	recall: 0.513083 precision: 0.889546
epoch-1 step 244800/3451022 - loss: 0.037703 val_loss: 0.037460	recall: 0.541040 precision: 0.923077
epoch-1 step 244900/3451022 - loss: 0.035533 val_loss: 0.039772	recall: 0.512443 precision: 0.928279
epoch-1 step 245000/3451022 - loss: 0.038075 val_loss: 0.034760	recall: 0.528389 precision: 0.899408

checkpoint saved

epoch-1 step 245100/3451022 - loss: 0.038577 val_loss: 0.036694	recall: 0.514902 precision: 0.926063
epoch-1 step 245200/3451022 - loss: 0.034165 val_loss: 0.036371	recall: 0.517127 precision: 0.905222
epoch-1 step 245300/3451022 - loss: 0.034966 val_loss: 0.036690	recall: 0.524013 precision: 0.928166
epoch-1 step 245400/3451022 - loss: 0.033680 val_loss: 0.034910	recall: 0.503185 precision: 0.916828
epoch-1 step 245500/3451022 - loss: 0.038285 val_loss: 0.048842	recall: 0.490605 precision: 0.885122
epoch-1 step 245600/3451022 - loss: 0.038307 val_loss: 0.033825	recall: 0.519168 precision: 0.902857
epoch-1 step 245700/3451022 - loss: 0.035671 val_loss: 0.035590	recall: 0.490446 precision: 0.895349
epoch-1 step 245800/3451022 - loss: 0.039713 val_loss: 0.034688	recall: 0.501094 precision: 0.898039
epoch-1 step 245900/3451022 - loss: 0.037639 val_loss: 0.035472	recall: 0.489293 precision: 0.883946
epoch-1 step 246000/3451022 - loss: 0.039647 val_loss: 0.041582	recall: 0.540571 precision: 0.916667

checkpoint saved

epoch-1 step 246100/3451022 - loss: 0.039081 val_loss: 0.038062	recall: 0.529347 precision: 0.903592

model exported!

epoch-1 step 246200/3451022 - loss: 0.035283 val_loss: 0.036318	recall: 0.520857 precision: 0.876660
epoch-1 step 246300/3451022 - loss: 0.035159 val_loss: 0.036932	recall: 0.539339 precision: 0.909615
epoch-1 step 246400/3451022 - loss: 0.034792 val_loss: 0.038209	recall: 0.505631 precision: 0.868472
epoch-1 step 246500/3451022 - loss: 0.041525 val_loss: 0.039748	recall: 0.553288 precision: 0.910448
epoch-1 step 246600/3451022 - loss: 0.037421 val_loss: 0.036772	recall: 0.522075 precision: 0.914894
epoch-1 step 246700/3451022 - loss: 0.040207 val_loss: 0.035159	recall: 0.523864 precision: 0.914683
epoch-1 step 246800/3451022 - loss: 0.035928 val_loss: 0.037601	recall: 0.517738 precision: 0.906796
epoch-1 step 246900/3451022 - loss: 0.036548 val_loss: 0.034999	recall: 0.522371 precision: 0.884470
epoch-1 step 247000/3451022 - loss: 0.038909 val_loss: 0.035725	recall: 0.513024 precision: 0.881323

checkpoint saved

epoch-1 step 247100/3451022 - loss: 0.037277 val_loss: 0.034818	recall: 0.536557 precision: 0.885214
epoch-1 step 247200/3451022 - loss: 0.042783 val_loss: 0.034792	recall: 0.531178 precision: 0.894942
epoch-1 step 247300/3451022 - loss: 0.040620 val_loss: 0.034012	recall: 0.554259 precision: 0.901328
epoch-1 step 247400/3451022 - loss: 0.036498 val_loss: 0.035100	recall: 0.517324 precision: 0.883673
epoch-1 step 247500/3451022 - loss: 0.036191 val_loss: 0.035037	recall: 0.526374 precision: 0.914122
epoch-1 step 247600/3451022 - loss: 0.035582 val_loss: 0.046141	recall: 0.526132 precision: 0.881323
epoch-1 step 247700/3451022 - loss: 0.034573 val_loss: 0.040188	recall: 0.503767 precision: 0.894837
epoch-1 step 247800/3451022 - loss: 0.035676 val_loss: 0.038910	recall: 0.506711 precision: 0.881323
epoch-1 step 247900/3451022 - loss: 0.034525 val_loss: 0.034140	recall: 0.513667 precision: 0.877432
epoch-1 step 248000/3451022 - loss: 0.040957 val_loss: 0.035894	recall: 0.516092 precision: 0.907071

checkpoint saved

epoch-1 step 248100/3451022 - loss: 0.048079 val_loss: 0.034184	recall: 0.514408 precision: 0.897579

model exported!

epoch-1 step 248200/3451022 - loss: 0.034875 val_loss: 0.033841	recall: 0.510808 precision: 0.883858
epoch-1 step 248300/3451022 - loss: 0.037295 val_loss: 0.038738	recall: 0.486258 precision: 0.896686
epoch-1 step 248400/3451022 - loss: 0.037879 val_loss: 0.036392	recall: 0.493521 precision: 0.899606
epoch-1 step 248500/3451022 - loss: 0.037888 val_loss: 0.035020	recall: 0.540449 precision: 0.917939
epoch-1 step 248600/3451022 - loss: 0.037285 val_loss: 0.039724	recall: 0.492521 precision: 0.898635
epoch-1 step 248700/3451022 - loss: 0.043423 val_loss: 0.039740	recall: 0.513200 precision: 0.922201
epoch-1 step 248800/3451022 - loss: 0.036001 val_loss: 0.040369	recall: 0.520263 precision: 0.906489
epoch-1 step 248900/3451022 - loss: 0.034348 val_loss: 0.035042	recall: 0.529944 precision: 0.905405
epoch-1 step 249000/3451022 - loss: 0.034839 val_loss: 0.040961	recall: 0.535513 precision: 0.901328

checkpoint saved

epoch-1 step 249100/3451022 - loss: 0.036488 val_loss: 0.040162	recall: 0.517014 precision: 0.898855
epoch-1 step 249200/3451022 - loss: 0.034833 val_loss: 0.042007	recall: 0.529412 precision: 0.893258
epoch-1 step 249300/3451022 - loss: 0.033896 val_loss: 0.042736	recall: 0.502183 precision: 0.889749
epoch-1 step 249400/3451022 - loss: 0.035447 val_loss: 0.035088	recall: 0.534368 precision: 0.934109
epoch-1 step 249500/3451022 - loss: 0.034224 val_loss: 0.040118	recall: 0.507230 precision: 0.908367
epoch-1 step 249600/3451022 - loss: 0.040305 val_loss: 0.042376	recall: 0.489752 precision: 0.913481
epoch-1 step 249700/3451022 - loss: 0.035379 val_loss: 0.039610	recall: 0.501071 precision: 0.896552
epoch-1 step 249800/3451022 - loss: 0.035205 val_loss: 0.036593	recall: 0.518059 precision: 0.886100
epoch-1 step 249900/3451022 - loss: 0.037983 val_loss: 0.035123	recall: 0.510799 precision: 0.914894
epoch-1 step 250000/3451022 - loss: 0.039029 val_loss: 0.036510	recall: 0.514188 precision: 0.889980

checkpoint saved

epoch-1 step 250100/3451022 - loss: 0.034497 val_loss: 0.037894	recall: 0.521240 precision: 0.871401

model exported!

epoch-1 step 250200/3451022 - loss: 0.037969 val_loss: 0.034434	recall: 0.502634 precision: 0.915547
epoch-1 step 250300/3451022 - loss: 0.034485 val_loss: 0.036872	recall: 0.533257 precision: 0.906433
epoch-1 step 250400/3451022 - loss: 0.034905 val_loss: 0.035926	recall: 0.512568 precision: 0.917808
epoch-1 step 250500/3451022 - loss: 0.035254 val_loss: 0.035736	recall: 0.516968 precision: 0.875479
epoch-1 step 250600/3451022 - loss: 0.034104 val_loss: 0.035223	recall: 0.514124 precision: 0.906375
epoch-1 step 250700/3451022 - loss: 0.035491 val_loss: 0.036873	recall: 0.519676 precision: 0.896208
epoch-1 step 250800/3451022 - loss: 0.038600 val_loss: 0.039955	recall: 0.491471 precision: 0.903922
epoch-1 step 250900/3451022 - loss: 0.035646 val_loss: 0.037403	recall: 0.483458 precision: 0.895257
epoch-1 step 251000/3451022 - loss: 0.035974 val_loss: 0.037884	recall: 0.537500 precision: 0.906130

checkpoint saved

epoch-1 step 251100/3451022 - loss: 0.034081 val_loss: 0.036937	recall: 0.534961 precision: 0.945098
epoch-1 step 251200/3451022 - loss: 0.035450 val_loss: 0.033998	recall: 0.535308 precision: 0.934394
epoch-1 step 251300/3451022 - loss: 0.051597 val_loss: 0.035219	recall: 0.539978 precision: 0.919776
epoch-1 step 251400/3451022 - loss: 0.035912 val_loss: 0.034098	recall: 0.534183 precision: 0.909270
epoch-1 step 251500/3451022 - loss: 0.039016 val_loss: 0.051176	recall: 0.520045 precision: 0.922925
epoch-1 step 251600/3451022 - loss: 0.034687 val_loss: 0.034014	recall: 0.532258 precision: 0.888462
epoch-1 step 251700/3451022 - loss: 0.047260 val_loss: 0.036523	recall: 0.529101 precision: 0.922509
epoch-1 step 251800/3451022 - loss: 0.037167 val_loss: 0.034688	recall: 0.487568 precision: 0.884314
epoch-1 step 251900/3451022 - loss: 0.037336 val_loss: 0.035622	recall: 0.511603 precision: 0.904851
epoch-1 step 252000/3451022 - loss: 0.035481 val_loss: 0.043902	recall: 0.547977 precision: 0.906310

checkpoint saved

epoch-1 step 252100/3451022 - loss: 0.036010 val_loss: 0.036573	recall: 0.509392 precision: 0.895146

model exported!

epoch-1 step 252200/3451022 - loss: 0.039367 val_loss: 0.034588	recall: 0.525057 precision: 0.896887
epoch-1 step 252300/3451022 - loss: 0.036649 val_loss: 0.034694	recall: 0.509476 precision: 0.883946
epoch-1 step 252400/3451022 - loss: 0.038912 val_loss: 0.040764	recall: 0.538037 precision: 0.924242
epoch-1 step 252500/3451022 - loss: 0.035040 val_loss: 0.036816	recall: 0.528825 precision: 0.917308
epoch-1 step 252600/3451022 - loss: 0.034533 val_loss: 0.037028	recall: 0.518395 precision: 0.890805
epoch-1 step 252700/3451022 - loss: 0.044009 val_loss: 0.035637	recall: 0.544612 precision: 0.903846
epoch-1 step 252800/3451022 - loss: 0.040479 val_loss: 0.034929	recall: 0.487459 precision: 0.879921
epoch-1 step 252900/3451022 - loss: 0.040385 val_loss: 0.035763	recall: 0.495135 precision: 0.912351
epoch-1 step 253000/3451022 - loss: 0.037311 val_loss: 0.035362	recall: 0.527357 precision: 0.913306

checkpoint saved

epoch-1 step 253100/3451022 - loss: 0.036235 val_loss: 0.037862	recall: 0.513793 precision: 0.895792
epoch-1 step 253200/3451022 - loss: 0.034179 val_loss: 0.035503	recall: 0.515419 precision: 0.921260
epoch-1 step 253300/3451022 - loss: 0.037730 val_loss: 0.034754	recall: 0.502198 precision: 0.906746
epoch-1 step 253400/3451022 - loss: 0.034274 val_loss: 0.038039	recall: 0.506479 precision: 0.888258
epoch-1 step 253500/3451022 - loss: 0.048732 val_loss: 0.037604	recall: 0.508380 precision: 0.908184
epoch-1 step 253600/3451022 - loss: 0.035118 val_loss: 0.036725	recall: 0.543307 precision: 0.925287
epoch-1 step 253700/3451022 - loss: 0.036976 val_loss: 0.041432	recall: 0.492358 precision: 0.891304
epoch-1 step 253800/3451022 - loss: 0.036974 val_loss: 0.034880	recall: 0.536131 precision: 0.896686
epoch-1 step 253900/3451022 - loss: 0.034597 val_loss: 0.036492	recall: 0.501618 precision: 0.906433
epoch-1 step 254000/3451022 - loss: 0.035323 val_loss: 0.042113	recall: 0.512764 precision: 0.895349

checkpoint saved

epoch-1 step 254100/3451022 - loss: 0.036683 val_loss: 0.036562	recall: 0.517280 precision: 0.892308

model exported!

epoch-1 step 254200/3451022 - loss: 0.039028 val_loss: 0.035289	recall: 0.511526 precision: 0.899614
epoch-1 step 254300/3451022 - loss: 0.035613 val_loss: 0.037833	recall: 0.536935 precision: 0.920605
epoch-1 step 254400/3451022 - loss: 0.037956 val_loss: 0.039666	recall: 0.526857 precision: 0.898635
epoch-1 step 254500/3451022 - loss: 0.036110 val_loss: 0.034692	recall: 0.513873 precision: 0.868668
epoch-1 step 254600/3451022 - loss: 0.035104 val_loss: 0.038307	recall: 0.524807 precision: 0.922481
epoch-1 step 254700/3451022 - loss: 0.050178 val_loss: 0.040225	recall: 0.485098 precision: 0.888889
epoch-1 step 254800/3451022 - loss: 0.035322 val_loss: 0.038692	recall: 0.550827 precision: 0.904854
epoch-1 step 254900/3451022 - loss: 0.036485 val_loss: 0.039827	recall: 0.502193 precision: 0.917836
epoch-1 step 255000/3451022 - loss: 0.041052 val_loss: 0.037690	recall: 0.521311 precision: 0.906844

checkpoint saved

epoch-1 step 255100/3451022 - loss: 0.037345 val_loss: 0.041998	recall: 0.481013 precision: 0.892368
epoch-1 step 255200/3451022 - loss: 0.037407 val_loss: 0.034678	recall: 0.508161 precision: 0.912109
epoch-1 step 255300/3451022 - loss: 0.039708 val_loss: 0.036092	recall: 0.508361 precision: 0.904762
epoch-1 step 255400/3451022 - loss: 0.034991 val_loss: 0.040769	recall: 0.509278 precision: 0.926829
epoch-1 step 255500/3451022 - loss: 0.038998 val_loss: 0.040042	recall: 0.501073 precision: 0.917485
epoch-1 step 255600/3451022 - loss: 0.038713 val_loss: 0.036008	recall: 0.504202 precision: 0.912548
epoch-1 step 255700/3451022 - loss: 0.035595 val_loss: 0.037597	recall: 0.517167 precision: 0.899254
epoch-1 step 255800/3451022 - loss: 0.044202 val_loss: 0.035348	recall: 0.493208 precision: 0.925490
epoch-1 step 255900/3451022 - loss: 0.035480 val_loss: 0.037112	recall: 0.508529 precision: 0.893258
epoch-1 step 256000/3451022 - loss: 0.036576 val_loss: 0.042695	recall: 0.504301 precision: 0.907157

checkpoint saved

epoch-1 step 256100/3451022 - loss: 0.034720 val_loss: 0.037185	recall: 0.522453 precision: 0.912046

model exported!

epoch-1 step 256200/3451022 - loss: 0.035652 val_loss: 0.035126	recall: 0.522602 precision: 0.920388
epoch-1 step 256300/3451022 - loss: 0.035345 val_loss: 0.037192	recall: 0.512352 precision: 0.917308
epoch-1 step 256400/3451022 - loss: 0.034940 val_loss: 0.037836	recall: 0.524752 precision: 0.898305
epoch-1 step 256500/3451022 - loss: 0.035799 val_loss: 0.039679	recall: 0.513782 precision: 0.894434
epoch-1 step 256600/3451022 - loss: 0.034597 val_loss: 0.035356	recall: 0.531603 precision: 0.892045
epoch-1 step 256700/3451022 - loss: 0.041330 val_loss: 0.036114	recall: 0.525405 precision: 0.936416
epoch-1 step 256800/3451022 - loss: 0.046159 val_loss: 0.034642	recall: 0.524972 precision: 0.913127
epoch-1 step 256900/3451022 - loss: 0.041309 val_loss: 0.040064	recall: 0.500531 precision: 0.909266
epoch-1 step 257000/3451022 - loss: 0.036965 val_loss: 0.034484	recall: 0.530120 precision: 0.911488

checkpoint saved

epoch-1 step 257100/3451022 - loss: 0.037731 val_loss: 0.036093	recall: 0.533860 precision: 0.904398
epoch-1 step 257200/3451022 - loss: 0.035711 val_loss: 0.038319	recall: 0.533708 precision: 0.887850
epoch-1 step 257300/3451022 - loss: 0.037534 val_loss: 0.044056	recall: 0.523756 precision: 0.909627
epoch-1 step 257400/3451022 - loss: 0.035521 val_loss: 0.037001	recall: 0.525843 precision: 0.914062
epoch-1 step 257500/3451022 - loss: 0.035436 val_loss: 0.037516	recall: 0.515152 precision: 0.903226
epoch-1 step 257600/3451022 - loss: 0.037065 val_loss: 0.041099	recall: 0.538291 precision: 0.923810
epoch-1 step 257700/3451022 - loss: 0.034882 val_loss: 0.035731	recall: 0.538018 precision: 0.912109
epoch-1 step 257800/3451022 - loss: 0.034399 val_loss: 0.036038	recall: 0.534014 precision: 0.902299
epoch-1 step 257900/3451022 - loss: 0.040849 val_loss: 0.038178	recall: 0.502208 precision: 0.885214
epoch-1 step 258000/3451022 - loss: 0.037985 val_loss: 0.036434	recall: 0.494915 precision: 0.893878

checkpoint saved

epoch-1 step 258100/3451022 - loss: 0.036777 val_loss: 0.034857	recall: 0.529742 precision: 0.904215

model exported!

epoch-1 step 258200/3451022 - loss: 0.037273 val_loss: 0.037388	recall: 0.546911 precision: 0.917466
epoch-1 step 258300/3451022 - loss: 0.034977 val_loss: 0.038771	recall: 0.513605 precision: 0.888235
epoch-1 step 258400/3451022 - loss: 0.035298 val_loss: 0.036322	recall: 0.483158 precision: 0.912525
epoch-1 step 258500/3451022 - loss: 0.034971 val_loss: 0.036107	recall: 0.517915 precision: 0.905123
epoch-1 step 258600/3451022 - loss: 0.035815 val_loss: 0.035970	recall: 0.520856 precision: 0.908582
epoch-1 step 258700/3451022 - loss: 0.035340 val_loss: 0.036023	recall: 0.506849 precision: 0.884462
epoch-1 step 258800/3451022 - loss: 0.038132 val_loss: 0.034590	recall: 0.528281 precision: 0.913894
epoch-1 step 258900/3451022 - loss: 0.034814 val_loss: 0.034707	recall: 0.510315 precision: 0.912621
epoch-1 step 259000/3451022 - loss: 0.037462 val_loss: 0.038111	recall: 0.512486 precision: 0.921875

checkpoint saved

epoch-1 step 259100/3451022 - loss: 0.039518 val_loss: 0.036007	recall: 0.513274 precision: 0.878788
epoch-1 step 259200/3451022 - loss: 0.036114 val_loss: 0.038534	recall: 0.552661 precision: 0.908752
epoch-1 step 259300/3451022 - loss: 0.034839 val_loss: 0.034855	recall: 0.518797 precision: 0.920000
epoch-1 step 259400/3451022 - loss: 0.037491 val_loss: 0.042769	recall: 0.538551 precision: 0.900391
epoch-1 step 259500/3451022 - loss: 0.035876 val_loss: 0.040171	recall: 0.525499 precision: 0.908046
epoch-1 step 259600/3451022 - loss: 0.036710 val_loss: 0.034378	recall: 0.521036 precision: 0.923518
epoch-1 step 259700/3451022 - loss: 0.036162 val_loss: 0.034383	recall: 0.518354 precision: 0.904854
epoch-1 step 259800/3451022 - loss: 0.036638 val_loss: 0.037305	recall: 0.502123 precision: 0.913127
epoch-1 step 259900/3451022 - loss: 0.041202 val_loss: 0.044974	recall: 0.497908 precision: 0.886406
epoch-1 step 260000/3451022 - loss: 0.036693 val_loss: 0.034019	recall: 0.507012 precision: 0.912621

checkpoint saved

epoch-1 step 260100/3451022 - loss: 0.034783 val_loss: 0.037288	recall: 0.513859 precision: 0.909434

model exported!

epoch-1 step 260200/3451022 - loss: 0.041171 val_loss: 0.042423	recall: 0.501050 precision: 0.903409
epoch-1 step 260300/3451022 - loss: 0.037335 val_loss: 0.034612	recall: 0.564424 precision: 0.913284
epoch-1 step 260400/3451022 - loss: 0.034793 val_loss: 0.034650	recall: 0.513859 precision: 0.928709
epoch-1 step 260500/3451022 - loss: 0.038621 val_loss: 0.037639	recall: 0.513158 precision: 0.903475
epoch-1 step 260600/3451022 - loss: 0.035456 val_loss: 0.041883	recall: 0.532328 precision: 0.899818
epoch-1 step 260700/3451022 - loss: 0.038625 val_loss: 0.034951	recall: 0.492358 precision: 0.884314
epoch-1 step 260800/3451022 - loss: 0.034962 val_loss: 0.036624	recall: 0.530612 precision: 0.925094
epoch-1 step 260900/3451022 - loss: 0.039101 val_loss: 0.037040	recall: 0.502762 precision: 0.892157
epoch-1 step 261000/3451022 - loss: 0.034456 val_loss: 0.036300	recall: 0.488421 precision: 0.888889

checkpoint saved

epoch-1 step 261100/3451022 - loss: 0.039856 val_loss: 0.038752	recall: 0.504742 precision: 0.897004
epoch-1 step 261200/3451022 - loss: 0.037206 val_loss: 0.034522	recall: 0.524831 precision: 0.913556
epoch-1 step 261300/3451022 - loss: 0.036831 val_loss: 0.036744	recall: 0.501657 precision: 0.909820
epoch-1 step 261400/3451022 - loss: 0.038750 val_loss: 0.035411	recall: 0.508696 precision: 0.900000
epoch-1 step 261500/3451022 - loss: 0.034921 val_loss: 0.039639	recall: 0.525057 precision: 0.909270
epoch-1 step 261600/3451022 - loss: 0.037151 val_loss: 0.046125	recall: 0.561485 precision: 0.928983
epoch-1 step 261700/3451022 - loss: 0.035683 val_loss: 0.037923	recall: 0.503817 precision: 0.918489
epoch-1 step 261800/3451022 - loss: 0.037139 val_loss: 0.037060	recall: 0.508989 precision: 0.898810
epoch-1 step 261900/3451022 - loss: 0.034507 val_loss: 0.035531	recall: 0.540717 precision: 0.918819
epoch-1 step 262000/3451022 - loss: 0.040138 val_loss: 0.042793	recall: 0.520607 precision: 0.909091

checkpoint saved

epoch-1 step 262100/3451022 - loss: 0.036122 val_loss: 0.035215	recall: 0.534676 precision: 0.921002

model exported!

epoch-1 step 262200/3451022 - loss: 0.033957 val_loss: 0.036186	recall: 0.473415 precision: 0.883588
epoch-1 step 262300/3451022 - loss: 0.036168 val_loss: 0.034823	recall: 0.490446 precision: 0.865169
epoch-1 step 262400/3451022 - loss: 0.037271 val_loss: 0.035123	recall: 0.521097 precision: 0.911439
epoch-1 step 262500/3451022 - loss: 0.034823 val_loss: 0.039580	recall: 0.506145 precision: 0.913306
epoch-1 step 262600/3451022 - loss: 0.035387 val_loss: 0.035413	recall: 0.490831 precision: 0.897436
epoch-1 step 262700/3451022 - loss: 0.039704 val_loss: 0.036520	recall: 0.514412 precision: 0.906250
epoch-1 step 262800/3451022 - loss: 0.041559 val_loss: 0.034716	recall: 0.524116 precision: 0.926136
epoch-1 step 262900/3451022 - loss: 0.042028 val_loss: 0.044428	recall: 0.520925 precision: 0.907869
epoch-1 step 263000/3451022 - loss: 0.037788 val_loss: 0.036735	recall: 0.514196 precision: 0.920904

checkpoint saved

epoch-1 step 263100/3451022 - loss: 0.040820 val_loss: 0.035379	recall: 0.502146 precision: 0.906977
epoch-1 step 263200/3451022 - loss: 0.034780 val_loss: 0.040760	recall: 0.512249 precision: 0.901961
epoch-1 step 263300/3451022 - loss: 0.035146 val_loss: 0.037298	recall: 0.510520 precision: 0.905697
epoch-1 step 263400/3451022 - loss: 0.035413 val_loss: 0.035582	recall: 0.525981 precision: 0.932331
epoch-1 step 263500/3451022 - loss: 0.037144 val_loss: 0.035657	recall: 0.518398 precision: 0.907197
epoch-1 step 263600/3451022 - loss: 0.034610 val_loss: 0.035218	recall: 0.496725 precision: 0.895669
epoch-1 step 263700/3451022 - loss: 0.060644 val_loss: 0.037607	recall: 0.517280 precision: 0.894027
epoch-1 step 263800/3451022 - loss: 0.034769 val_loss: 0.034450	recall: 0.498403 precision: 0.896552
epoch-1 step 263900/3451022 - loss: 0.037060 val_loss: 0.035142	recall: 0.507592 precision: 0.910506
epoch-1 step 264000/3451022 - loss: 0.036687 val_loss: 0.035023	recall: 0.535597 precision: 0.914019

checkpoint saved

epoch-1 step 264100/3451022 - loss: 0.037006 val_loss: 0.035058	recall: 0.516340 precision: 0.916828

model exported!

epoch-1 step 264200/3451022 - loss: 0.038580 val_loss: 0.035060	recall: 0.529010 precision: 0.908203
epoch-1 step 264300/3451022 - loss: 0.033931 val_loss: 0.037079	recall: 0.519523 precision: 0.910646
epoch-1 step 264400/3451022 - loss: 0.034421 val_loss: 0.064656	recall: 0.507279 precision: 0.884766
epoch-1 step 264500/3451022 - loss: 0.034569 val_loss: 0.034626	recall: 0.477848 precision: 0.893491
epoch-1 step 264600/3451022 - loss: 0.036027 val_loss: 0.053553	recall: 0.515118 precision: 0.909091
epoch-1 step 264700/3451022 - loss: 0.038137 val_loss: 0.042027	recall: 0.505388 precision: 0.898467
epoch-1 step 264800/3451022 - loss: 0.037322 val_loss: 0.038519	recall: 0.512528 precision: 0.880626
epoch-1 step 264900/3451022 - loss: 0.035485 val_loss: 0.036582	recall: 0.517796 precision: 0.916667
epoch-1 step 265000/3451022 - loss: 0.035349 val_loss: 0.034370	recall: 0.524176 precision: 0.896617

checkpoint saved

epoch-1 step 265100/3451022 - loss: 0.035813 val_loss: 0.037930	recall: 0.517621 precision: 0.896947
epoch-1 step 265200/3451022 - loss: 0.035179 val_loss: 0.035742	recall: 0.522388 precision: 0.899209
epoch-1 step 265300/3451022 - loss: 0.035652 val_loss: 0.036547	recall: 0.473016 precision: 0.862934
epoch-1 step 265400/3451022 - loss: 0.035532 val_loss: 0.034770	recall: 0.507659 precision: 0.887189
epoch-1 step 265500/3451022 - loss: 0.036596 val_loss: 0.037753	recall: 0.523977 precision: 0.875000
epoch-1 step 265600/3451022 - loss: 0.035152 val_loss: 0.041856	recall: 0.501053 precision: 0.908397
epoch-1 step 265700/3451022 - loss: 0.058029 val_loss: 0.038271	recall: 0.510474 precision: 0.911417
epoch-1 step 265800/3451022 - loss: 0.033889 val_loss: 0.036092	recall: 0.535274 precision: 0.886827
epoch-1 step 265900/3451022 - loss: 0.044380 val_loss: 0.039603	recall: 0.526614 precision: 0.911765
epoch-1 step 266000/3451022 - loss: 0.034340 val_loss: 0.033905	recall: 0.545984 precision: 0.914230

checkpoint saved

epoch-1 step 266100/3451022 - loss: 0.033780 val_loss: 0.038905	recall: 0.522573 precision: 0.895551

model exported!

epoch-1 step 266200/3451022 - loss: 0.041096 val_loss: 0.034917	recall: 0.501111 precision: 0.880859
epoch-1 step 266300/3451022 - loss: 0.034746 val_loss: 0.035730	recall: 0.564679 precision: 0.941839
epoch-1 step 266400/3451022 - loss: 0.040681 val_loss: 0.042025	recall: 0.530120 precision: 0.908068
epoch-1 step 266500/3451022 - loss: 0.035210 val_loss: 0.035102	recall: 0.536748 precision: 0.918095
epoch-1 step 266600/3451022 - loss: 0.035848 val_loss: 0.034779	recall: 0.488147 precision: 0.889980
epoch-1 step 266700/3451022 - loss: 0.038285 val_loss: 0.036876	recall: 0.522573 precision: 0.892100
epoch-1 step 266800/3451022 - loss: 0.036903 val_loss: 0.036045	recall: 0.512352 precision: 0.917308
epoch-1 step 266900/3451022 - loss: 0.035299 val_loss: 0.034360	recall: 0.522222 precision: 0.919765
epoch-1 step 267000/3451022 - loss: 0.040862 val_loss: 0.041019	recall: 0.513458 precision: 0.915129

checkpoint saved

epoch-1 step 267100/3451022 - loss: 0.036883 val_loss: 0.034860	recall: 0.491043 precision: 0.896154
epoch-1 step 267200/3451022 - loss: 0.035003 val_loss: 0.037586	recall: 0.521445 precision: 0.902344
epoch-1 step 267300/3451022 - loss: 0.034873 val_loss: 0.037169	recall: 0.525806 precision: 0.920904
epoch-1 step 267400/3451022 - loss: 0.036202 val_loss: 0.033889	recall: 0.533408 precision: 0.915870
epoch-1 step 267500/3451022 - loss: 0.042256 val_loss: 0.034725	recall: 0.531674 precision: 0.917969
epoch-1 step 267600/3451022 - loss: 0.050671 val_loss: 0.035060	recall: 0.531773 precision: 0.919075
epoch-1 step 267700/3451022 - loss: 0.038775 val_loss: 0.034779	recall: 0.508671 precision: 0.909091
epoch-1 step 267800/3451022 - loss: 0.037710 val_loss: 0.036554	recall: 0.498343 precision: 0.896620
epoch-1 step 267900/3451022 - loss: 0.037956 val_loss: 0.038059	recall: 0.527352 precision: 0.928709
epoch-1 step 268000/3451022 - loss: 0.036721 val_loss: 0.034680	recall: 0.536996 precision: 0.908918

checkpoint saved

epoch-1 step 268100/3451022 - loss: 0.042011 val_loss: 0.037119	recall: 0.504348 precision: 0.908023

model exported!

epoch-1 step 268200/3451022 - loss: 0.035809 val_loss: 0.033385	recall: 0.508380 precision: 0.895669
epoch-1 step 268300/3451022 - loss: 0.035721 val_loss: 0.034432	recall: 0.504348 precision: 0.897485
epoch-1 step 268400/3451022 - loss: 0.034416 val_loss: 0.041587	recall: 0.509847 precision: 0.892720
epoch-1 step 268500/3451022 - loss: 0.035501 val_loss: 0.035474	recall: 0.498335 precision: 0.905242
epoch-1 step 268600/3451022 - loss: 0.037295 val_loss: 0.037829	recall: 0.508233 precision: 0.890385
epoch-1 step 268700/3451022 - loss: 0.035813 val_loss: 0.034403	recall: 0.514840 precision: 0.914807
epoch-1 step 268800/3451022 - loss: 0.039841 val_loss: 0.039512	recall: 0.527149 precision: 0.920949
epoch-1 step 268900/3451022 - loss: 0.035558 val_loss: 0.035162	recall: 0.495736 precision: 0.887405
epoch-1 step 269000/3451022 - loss: 0.039692 val_loss: 0.034806	recall: 0.491632 precision: 0.902111

checkpoint saved

epoch-1 step 269100/3451022 - loss: 0.046693 val_loss: 0.035171	recall: 0.529605 precision: 0.930636
epoch-1 step 269200/3451022 - loss: 0.034596 val_loss: 0.037502	recall: 0.513800 precision: 0.947162
epoch-1 step 269300/3451022 - loss: 0.035211 val_loss: 0.034868	recall: 0.523600 precision: 0.901701
epoch-1 step 269400/3451022 - loss: 0.035019 val_loss: 0.034494	recall: 0.519423 precision: 0.919450
epoch-1 step 269500/3451022 - loss: 0.037551 val_loss: 0.035295	recall: 0.540138 precision: 0.883677
epoch-1 step 269600/3451022 - loss: 0.037405 val_loss: 0.033739	recall: 0.517915 precision: 0.929825
epoch-1 step 269700/3451022 - loss: 0.036238 val_loss: 0.033336	recall: 0.514444 precision: 0.902534
epoch-1 step 269800/3451022 - loss: 0.034618 val_loss: 0.036488	recall: 0.498378 precision: 0.895146
epoch-1 step 269900/3451022 - loss: 0.038096 val_loss: 0.036557	recall: 0.519956 precision: 0.907157
epoch-1 step 270000/3451022 - loss: 0.044372 val_loss: 0.040331	recall: 0.557562 precision: 0.926829

checkpoint saved

epoch-1 step 270100/3451022 - loss: 0.039083 val_loss: 0.034517	recall: 0.495050 precision: 0.860421

model exported!

epoch-1 step 270200/3451022 - loss: 0.035067 val_loss: 0.043737	recall: 0.520925 precision: 0.923828
epoch-1 step 270300/3451022 - loss: 0.035920 val_loss: 0.037123	recall: 0.561916 precision: 0.897388
epoch-1 step 270400/3451022 - loss: 0.041800 val_loss: 0.035345	recall: 0.509169 precision: 0.916505
epoch-1 step 270500/3451022 - loss: 0.043864 val_loss: 0.035134	recall: 0.536165 precision: 0.906796
epoch-1 step 270600/3451022 - loss: 0.035665 val_loss: 0.038186	recall: 0.510846 precision: 0.914563
epoch-1 step 270700/3451022 - loss: 0.034345 val_loss: 0.035670	recall: 0.529002 precision: 0.912000
epoch-1 step 270800/3451022 - loss: 0.042237 val_loss: 0.035724	recall: 0.495595 precision: 0.907258
epoch-1 step 270900/3451022 - loss: 0.035200 val_loss: 0.036740	recall: 0.542601 precision: 0.913208
epoch-1 step 271000/3451022 - loss: 0.049946 val_loss: 0.038741	recall: 0.537296 precision: 0.895146

checkpoint saved

epoch-1 step 271100/3451022 - loss: 0.034584 val_loss: 0.040292	recall: 0.541231 precision: 0.884250
epoch-1 step 271200/3451022 - loss: 0.034302 val_loss: 0.037465	recall: 0.525901 precision: 0.910331
epoch-1 step 271300/3451022 - loss: 0.037598 val_loss: 0.035343	recall: 0.526667 precision: 0.918605
epoch-1 step 271400/3451022 - loss: 0.046976 val_loss: 0.038302	recall: 0.521219 precision: 0.910646
epoch-1 step 271500/3451022 - loss: 0.039550 val_loss: 0.036771	recall: 0.494824 precision: 0.915709
epoch-1 step 271600/3451022 - loss: 0.035014 val_loss: 0.039582	recall: 0.516704 precision: 0.909804
epoch-1 step 271700/3451022 - loss: 0.037612 val_loss: 0.038335	recall: 0.526807 precision: 0.891519
epoch-1 step 271800/3451022 - loss: 0.042652 val_loss: 0.042469	recall: 0.517202 precision: 0.893069
epoch-1 step 271900/3451022 - loss: 0.040252 val_loss: 0.037942	recall: 0.521253 precision: 0.906615
epoch-1 step 272000/3451022 - loss: 0.036794 val_loss: 0.037390	recall: 0.530093 precision: 0.899804

checkpoint saved

epoch-1 step 272100/3451022 - loss: 0.035760 val_loss: 0.034438	recall: 0.528162 precision: 0.927239

model exported!

epoch-1 step 272200/3451022 - loss: 0.035585 val_loss: 0.042102	recall: 0.508197 precision: 0.894231
epoch-1 step 272300/3451022 - loss: 0.034560 val_loss: 0.035738	recall: 0.499443 precision: 0.890656
epoch-1 step 272400/3451022 - loss: 0.037881 val_loss: 0.033994	recall: 0.484649 precision: 0.880478
epoch-1 step 272500/3451022 - loss: 0.038048 val_loss: 0.034367	recall: 0.520179 precision: 0.913386
epoch-1 step 272600/3451022 - loss: 0.035211 val_loss: 0.040642	recall: 0.535098 precision: 0.894231
epoch-1 step 272700/3451022 - loss: 0.035792 val_loss: 0.035423	recall: 0.497868 precision: 0.910331
epoch-1 step 272800/3451022 - loss: 0.035133 val_loss: 0.041111	recall: 0.552339 precision: 0.916821
epoch-1 step 272900/3451022 - loss: 0.037301 val_loss: 0.037107	recall: 0.509698 precision: 0.894140
epoch-1 step 273000/3451022 - loss: 0.036860 val_loss: 0.035126	recall: 0.527027 precision: 0.906977

checkpoint saved

epoch-1 step 273100/3451022 - loss: 0.034521 val_loss: 0.035185	recall: 0.511261 precision: 0.881553
epoch-1 step 273200/3451022 - loss: 0.034867 val_loss: 0.034966	recall: 0.520742 precision: 0.928016
epoch-1 step 273300/3451022 - loss: 0.036526 val_loss: 0.035079	recall: 0.535068 precision: 0.892453
epoch-1 step 273400/3451022 - loss: 0.034753 val_loss: 0.034077	recall: 0.523429 precision: 0.892788
epoch-1 step 273500/3451022 - loss: 0.036752 val_loss: 0.036177	recall: 0.519909 precision: 0.894325
epoch-1 step 273600/3451022 - loss: 0.036523 val_loss: 0.036444	recall: 0.538547 precision: 0.928709
epoch-1 step 273700/3451022 - loss: 0.034763 val_loss: 0.040477	recall: 0.526906 precision: 0.930693
epoch-1 step 273800/3451022 - loss: 0.040853 val_loss: 0.040516	recall: 0.515730 precision: 0.889535
epoch-1 step 273900/3451022 - loss: 0.034919 val_loss: 0.037073	recall: 0.527714 precision: 0.859023
epoch-1 step 274000/3451022 - loss: 0.046968 val_loss: 0.036243	recall: 0.554398 precision: 0.914122

checkpoint saved

epoch-1 step 274100/3451022 - loss: 0.034500 val_loss: 0.035521	recall: 0.530822 precision: 0.897683

model exported!

epoch-1 step 274200/3451022 - loss: 0.034857 val_loss: 0.035457	recall: 0.510369 precision: 0.891348
epoch-1 step 274300/3451022 - loss: 0.043480 val_loss: 0.036375	recall: 0.520307 precision: 0.899431
epoch-1 step 274400/3451022 - loss: 0.035162 val_loss: 0.035430	recall: 0.537923 precision: 0.895146
epoch-1 step 274500/3451022 - loss: 0.037532 val_loss: 0.041755	recall: 0.510497 precision: 0.907662
epoch-1 step 274600/3451022 - loss: 0.035549 val_loss: 0.034332	recall: 0.550588 precision: 0.928571
epoch-1 step 274700/3451022 - loss: 0.035174 val_loss: 0.039811	recall: 0.504464 precision: 0.879377
epoch-1 step 274800/3451022 - loss: 0.041038 val_loss: 0.033876	recall: 0.513043 precision: 0.883895
epoch-1 step 274900/3451022 - loss: 0.037728 val_loss: 0.042042	recall: 0.567474 precision: 0.906077
epoch-1 step 275000/3451022 - loss: 0.035633 val_loss: 0.038576	recall: 0.532080 precision: 0.917939

checkpoint saved

epoch-1 step 275100/3451022 - loss: 0.037025 val_loss: 0.034357	recall: 0.499475 precision: 0.903226
epoch-1 step 275200/3451022 - loss: 0.036613 val_loss: 0.037406	recall: 0.506623 precision: 0.910714
epoch-1 step 275300/3451022 - loss: 0.035625 val_loss: 0.034612	recall: 0.520533 precision: 0.907157
epoch-1 step 275400/3451022 - loss: 0.043900 val_loss: 0.034553	recall: 0.516940 precision: 0.885768
epoch-1 step 275500/3451022 - loss: 0.035869 val_loss: 0.034770	recall: 0.527072 precision: 0.908571
epoch-1 step 275600/3451022 - loss: 0.035902 val_loss: 0.035981	recall: 0.492408 precision: 0.893701
epoch-1 step 275700/3451022 - loss: 0.039313 val_loss: 0.038169	recall: 0.514130 precision: 0.887430
epoch-1 step 275800/3451022 - loss: 0.038806 val_loss: 0.034959	recall: 0.519318 precision: 0.901381
epoch-1 step 275900/3451022 - loss: 0.037349 val_loss: 0.033965	recall: 0.513514 precision: 0.913828
epoch-1 step 276000/3451022 - loss: 0.045071 val_loss: 0.038841	recall: 0.510000 precision: 0.886100

checkpoint saved

epoch-1 step 276100/3451022 - loss: 0.042066 val_loss: 0.034889	recall: 0.516779 precision: 0.886756

model exported!

epoch-1 step 276200/3451022 - loss: 0.035552 val_loss: 0.037368	recall: 0.535794 precision: 0.902072
epoch-1 step 276300/3451022 - loss: 0.036049 val_loss: 0.035650	recall: 0.498324 precision: 0.874510
epoch-1 step 276400/3451022 - loss: 0.035546 val_loss: 0.036009	recall: 0.520170 precision: 0.889292
epoch-1 step 276500/3451022 - loss: 0.036835 val_loss: 0.042576	recall: 0.504929 precision: 0.889961
epoch-1 step 276600/3451022 - loss: 0.034944 val_loss: 0.036294	recall: 0.511803 precision: 0.913793
epoch-1 step 276700/3451022 - loss: 0.037194 val_loss: 0.036140	recall: 0.560046 precision: 0.915094
epoch-1 step 276800/3451022 - loss: 0.034642 val_loss: 0.035726	recall: 0.508753 precision: 0.897683
epoch-1 step 276900/3451022 - loss: 0.036404 val_loss: 0.038439	recall: 0.517915 precision: 0.903409
epoch-1 step 277000/3451022 - loss: 0.033876 val_loss: 0.035713	recall: 0.524229 precision: 0.894737

checkpoint saved

epoch-1 step 277100/3451022 - loss: 0.039579 val_loss: 0.036779	recall: 0.515453 precision: 0.915686
epoch-1 step 277200/3451022 - loss: 0.036043 val_loss: 0.048711	recall: 0.536199 precision: 0.899431
epoch-1 step 277300/3451022 - loss: 0.037349 val_loss: 0.034902	recall: 0.524752 precision: 0.908571
epoch-1 step 277400/3451022 - loss: 0.035823 val_loss: 0.034901	recall: 0.508969 precision: 0.895464
epoch-1 step 277500/3451022 - loss: 0.038925 val_loss: 0.035081	recall: 0.525727 precision: 0.893536
epoch-1 step 277600/3451022 - loss: 0.035808 val_loss: 0.037000	recall: 0.505747 precision: 0.908068
epoch-1 step 277700/3451022 - loss: 0.035591 val_loss: 0.035219	recall: 0.521643 precision: 0.888469
epoch-1 step 277800/3451022 - loss: 0.037083 val_loss: 0.035574	recall: 0.540965 precision: 0.930502
epoch-1 step 277900/3451022 - loss: 0.036229 val_loss: 0.035978	recall: 0.516484 precision: 0.891841
epoch-1 step 278000/3451022 - loss: 0.038066 val_loss: 0.048286	recall: 0.473361 precision: 0.890173

checkpoint saved

epoch-1 step 278100/3451022 - loss: 0.041365 val_loss: 0.036275	recall: 0.495135 precision: 0.901575

model exported!

epoch-1 step 278200/3451022 - loss: 0.035544 val_loss: 0.035713	recall: 0.502674 precision: 0.900383
epoch-1 step 278300/3451022 - loss: 0.037708 val_loss: 0.035928	recall: 0.526846 precision: 0.919922
epoch-1 step 278400/3451022 - loss: 0.042983 val_loss: 0.053342	recall: 0.495146 precision: 0.891262
epoch-1 step 278500/3451022 - loss: 0.034513 val_loss: 0.038065	recall: 0.525656 precision: 0.909270
epoch-1 step 278600/3451022 - loss: 0.034648 val_loss: 0.035264	recall: 0.528322 precision: 0.934489
epoch-1 step 278700/3451022 - loss: 0.034272 val_loss: 0.038403	recall: 0.517594 precision: 0.901186
epoch-1 step 278800/3451022 - loss: 0.036352 val_loss: 0.035638	recall: 0.519694 precision: 0.916988
epoch-1 step 278900/3451022 - loss: 0.036826 val_loss: 0.037718	recall: 0.540094 precision: 0.906931
epoch-1 step 279000/3451022 - loss: 0.038714 val_loss: 0.035998	recall: 0.492896 precision: 0.884314

checkpoint saved

epoch-1 step 279100/3451022 - loss: 0.034144 val_loss: 0.038208	recall: 0.498409 precision: 0.912621
epoch-1 step 279200/3451022 - loss: 0.034560 val_loss: 0.040366	recall: 0.502146 precision: 0.914062
epoch-1 step 279300/3451022 - loss: 0.041188 val_loss: 0.035584	recall: 0.519027 precision: 0.924670
epoch-1 step 279400/3451022 - loss: 0.036970 val_loss: 0.036768	recall: 0.540416 precision: 0.888046
epoch-1 step 279500/3451022 - loss: 0.035974 val_loss: 0.036008	recall: 0.501062 precision: 0.925490
epoch-1 step 279600/3451022 - loss: 0.035612 val_loss: 0.036877	recall: 0.513043 precision: 0.895636
epoch-1 step 279700/3451022 - loss: 0.036043 val_loss: 0.037660	recall: 0.527374 precision: 0.893939
epoch-1 step 279800/3451022 - loss: 0.041937 val_loss: 0.035456	recall: 0.569444 precision: 0.931818
epoch-1 step 279900/3451022 - loss: 0.036667 val_loss: 0.038398	recall: 0.497817 precision: 0.888889
epoch-1 step 280000/3451022 - loss: 0.041735 val_loss: 0.035269	recall: 0.518931 precision: 0.922772

checkpoint saved

epoch-1 step 280100/3451022 - loss: 0.035420 val_loss: 0.034741	recall: 0.549020 precision: 0.922481

model exported!

epoch-1 step 280200/3451022 - loss: 0.043138 val_loss: 0.035576	recall: 0.529213 precision: 0.919922
epoch-1 step 280300/3451022 - loss: 0.042801 val_loss: 0.034489	recall: 0.487674 precision: 0.863378
epoch-1 step 280400/3451022 - loss: 0.038544 val_loss: 0.036432	recall: 0.524719 precision: 0.898077
epoch-1 step 280500/3451022 - loss: 0.034580 val_loss: 0.035819	recall: 0.533258 precision: 0.902672
epoch-1 step 280600/3451022 - loss: 0.035153 val_loss: 0.038761	recall: 0.550169 precision: 0.913858
epoch-1 step 280700/3451022 - loss: 0.036832 val_loss: 0.035606	recall: 0.538117 precision: 0.914286
epoch-1 step 280800/3451022 - loss: 0.034660 val_loss: 0.041561	recall: 0.483707 precision: 0.892857
epoch-1 step 280900/3451022 - loss: 0.041908 val_loss: 0.037030	recall: 0.530963 precision: 0.895551
epoch-1 step 281000/3451022 - loss: 0.039485 val_loss: 0.034890	recall: 0.521978 precision: 0.894539

checkpoint saved

epoch-1 step 281100/3451022 - loss: 0.035778 val_loss: 0.038231	recall: 0.500000 precision: 0.880626
epoch-1 step 281200/3451022 - loss: 0.041244 val_loss: 0.038119	recall: 0.525739 precision: 0.912548
epoch-1 step 281300/3451022 - loss: 0.035958 val_loss: 0.039736	recall: 0.540380 precision: 0.888672
epoch-1 step 281400/3451022 - loss: 0.035211 val_loss: 0.036045	recall: 0.533186 precision: 0.916350
epoch-1 step 281500/3451022 - loss: 0.034027 val_loss: 0.035033	recall: 0.511654 precision: 0.905697
epoch-1 step 281600/3451022 - loss: 0.035288 val_loss: 0.036710	recall: 0.524123 precision: 0.915709
epoch-1 step 281700/3451022 - loss: 0.038612 val_loss: 0.036835	recall: 0.491062 precision: 0.887833
epoch-1 step 281800/3451022 - loss: 0.036838 val_loss: 0.039341	recall: 0.554787 precision: 0.917939
epoch-1 step 281900/3451022 - loss: 0.035440 val_loss: 0.035208	recall: 0.558824 precision: 0.930320
epoch-1 step 282000/3451022 - loss: 0.036492 val_loss: 0.034201	recall: 0.525556 precision: 0.911368

checkpoint saved

epoch-1 step 282100/3451022 - loss: 0.042605 val_loss: 0.040186	recall: 0.519231 precision: 0.916168

model exported!

epoch-1 step 282200/3451022 - loss: 0.037463 val_loss: 0.035019	recall: 0.537037 precision: 0.904483
epoch-1 step 282300/3451022 - loss: 0.034426 val_loss: 0.038583	recall: 0.545353 precision: 0.903525
epoch-1 step 282400/3451022 - loss: 0.035572 val_loss: 0.035800	recall: 0.561611 precision: 0.929412
epoch-1 step 282500/3451022 - loss: 0.036749 val_loss: 0.038461	recall: 0.507743 precision: 0.900000
epoch-1 step 282600/3451022 - loss: 0.056589 val_loss: 0.036454	recall: 0.500535 precision: 0.915851
epoch-1 step 282700/3451022 - loss: 0.035547 val_loss: 0.037563	recall: 0.555180 precision: 0.909594
epoch-1 step 282800/3451022 - loss: 0.037498 val_loss: 0.034314	recall: 0.511838 precision: 0.900794
epoch-1 step 282900/3451022 - loss: 0.035262 val_loss: 0.036706	recall: 0.513782 precision: 0.904854
epoch-1 step 283000/3451022 - loss: 0.036642 val_loss: 0.034396	recall: 0.500517 precision: 0.909774

checkpoint saved

epoch-1 step 283100/3451022 - loss: 0.041299 val_loss: 0.038575	recall: 0.513904 precision: 0.904110
epoch-1 step 283200/3451022 - loss: 0.034562 val_loss: 0.038784	recall: 0.527253 precision: 0.902857
epoch-1 step 283300/3451022 - loss: 0.037819 val_loss: 0.035009	recall: 0.479339 precision: 0.878788
epoch-1 step 283400/3451022 - loss: 0.034288 val_loss: 0.035008	recall: 0.501092 precision: 0.912525
epoch-1 step 283500/3451022 - loss: 0.036171 val_loss: 0.034926	recall: 0.517876 precision: 0.901887
epoch-1 step 283600/3451022 - loss: 0.035112 val_loss: 0.034032	recall: 0.573141 precision: 0.915709
epoch-1 step 283700/3451022 - loss: 0.035661 val_loss: 0.034621	recall: 0.520624 precision: 0.915686
epoch-1 step 283800/3451022 - loss: 0.034623 val_loss: 0.037001	recall: 0.505435 precision: 0.894231
epoch-1 step 283900/3451022 - loss: 0.035651 val_loss: 0.035820	recall: 0.553613 precision: 0.920543
epoch-1 step 284000/3451022 - loss: 0.038897 val_loss: 0.036454	recall: 0.522371 precision: 0.910331

checkpoint saved

epoch-1 step 284100/3451022 - loss: 0.034886 val_loss: 0.038540	recall: 0.527460 precision: 0.888247

model exported!

epoch-1 step 284200/3451022 - loss: 0.037731 val_loss: 0.036488	recall: 0.528953 precision: 0.904762
epoch-1 step 284300/3451022 - loss: 0.035910 val_loss: 0.035170	recall: 0.526087 precision: 0.909774
epoch-1 step 284400/3451022 - loss: 0.041316 val_loss: 0.034943	recall: 0.516459 precision: 0.899209
epoch-1 step 284500/3451022 - loss: 0.036976 val_loss: 0.036089	recall: 0.523282 precision: 0.895636
epoch-1 step 284600/3451022 - loss: 0.041497 val_loss: 0.038202	recall: 0.496703 precision: 0.896825
epoch-1 step 284700/3451022 - loss: 0.034172 val_loss: 0.035045	recall: 0.502775 precision: 0.889980
epoch-1 step 284800/3451022 - loss: 0.036405 val_loss: 0.035979	recall: 0.505274 precision: 0.900376
epoch-1 step 284900/3451022 - loss: 0.041172 val_loss: 0.038086	recall: 0.490506 precision: 0.904669
epoch-1 step 285000/3451022 - loss: 0.034708 val_loss: 0.038320	recall: 0.505051 precision: 0.882353

checkpoint saved

epoch-1 step 285100/3451022 - loss: 0.034338 val_loss: 0.044938	recall: 0.511211 precision: 0.919355
epoch-1 step 285200/3451022 - loss: 0.034359 val_loss: 0.036301	recall: 0.522222 precision: 0.917969
epoch-1 step 285300/3451022 - loss: 0.035647 val_loss: 0.034576	recall: 0.516093 precision: 0.902913
epoch-1 step 285400/3451022 - loss: 0.034439 val_loss: 0.039364	recall: 0.498925 precision: 0.894027
epoch-1 step 285500/3451022 - loss: 0.035486 val_loss: 0.034605	recall: 0.514286 precision: 0.905222
epoch-1 step 285600/3451022 - loss: 0.035678 val_loss: 0.039955	recall: 0.492616 precision: 0.903288
epoch-1 step 285700/3451022 - loss: 0.038248 val_loss: 0.035855	recall: 0.519824 precision: 0.920078
epoch-1 step 285800/3451022 - loss: 0.037483 val_loss: 0.036608	recall: 0.493534 precision: 0.901575
epoch-1 step 285900/3451022 - loss: 0.040458 val_loss: 0.036513	recall: 0.526018 precision: 0.908203
epoch-1 step 286000/3451022 - loss: 0.038462 val_loss: 0.035301	recall: 0.497262 precision: 0.876448

checkpoint saved

epoch-1 step 286100/3451022 - loss: 0.041284 val_loss: 0.036493	recall: 0.523143 precision: 0.932821

model exported!

epoch-1 step 286200/3451022 - loss: 0.035939 val_loss: 0.035677	recall: 0.545554 precision: 0.916974
epoch-1 step 286300/3451022 - loss: 0.036727 val_loss: 0.036695	recall: 0.542294 precision: 0.914062
epoch-1 step 286400/3451022 - loss: 0.054474 val_loss: 0.037402	recall: 0.495177 precision: 0.900585
epoch-1 step 286500/3451022 - loss: 0.048309 val_loss: 0.035549	recall: 0.523864 precision: 0.912871
epoch-1 step 286600/3451022 - loss: 0.041849 val_loss: 0.040313	recall: 0.509413 precision: 0.894942
epoch-1 step 286700/3451022 - loss: 0.034183 val_loss: 0.035746	recall: 0.526786 precision: 0.911197
epoch-1 step 286800/3451022 - loss: 0.034443 val_loss: 0.042407	recall: 0.491786 precision: 0.926499
epoch-1 step 286900/3451022 - loss: 0.034516 val_loss: 0.040680	recall: 0.493671 precision: 0.914062
epoch-1 step 287000/3451022 - loss: 0.034737 val_loss: 0.035115	recall: 0.492507 precision: 0.921495

checkpoint saved

epoch-1 step 287100/3451022 - loss: 0.033460 val_loss: 0.036888	recall: 0.526257 precision: 0.897143
epoch-1 step 287200/3451022 - loss: 0.038341 val_loss: 0.033797	recall: 0.508039 precision: 0.915058
epoch-1 step 287300/3451022 - loss: 0.040770 val_loss: 0.035796	recall: 0.512459 precision: 0.907869
epoch-1 step 287400/3451022 - loss: 0.035476 val_loss: 0.038579	recall: 0.481888 precision: 0.874502
epoch-1 step 287500/3451022 - loss: 0.038528 val_loss: 0.036615	recall: 0.483871 precision: 0.880682
epoch-1 step 287600/3451022 - loss: 0.040575 val_loss: 0.034439	recall: 0.494229 precision: 0.907514
epoch-1 step 287700/3451022 - loss: 0.036008 val_loss: 0.039010	recall: 0.496224 precision: 0.896686
epoch-1 step 287800/3451022 - loss: 0.037738 val_loss: 0.036196	recall: 0.464995 precision: 0.891784
epoch-1 step 287900/3451022 - loss: 0.035380 val_loss: 0.036384	recall: 0.512221 precision: 0.911153
epoch-1 step 288000/3451022 - loss: 0.038231 val_loss: 0.039682	recall: 0.499469 precision: 0.891841

checkpoint saved

epoch-1 step 288100/3451022 - loss: 0.037276 val_loss: 0.041058	recall: 0.507027 precision: 0.905405

model exported!

epoch-1 step 288200/3451022 - loss: 0.037484 val_loss: 0.035121	recall: 0.513274 precision: 0.908023
epoch-1 step 288300/3451022 - loss: 0.035544 val_loss: 0.039311	recall: 0.551609 precision: 0.922078
epoch-1 step 288400/3451022 - loss: 0.035004 val_loss: 0.035614	recall: 0.523179 precision: 0.885981
epoch-1 step 288500/3451022 - loss: 0.035652 val_loss: 0.035636	recall: 0.522371 precision: 0.910331
epoch-1 step 288600/3451022 - loss: 0.035939 val_loss: 0.035446	recall: 0.503842 precision: 0.903543
epoch-1 step 288700/3451022 - loss: 0.041094 val_loss: 0.036185	recall: 0.546416 precision: 0.906433
epoch-1 step 288800/3451022 - loss: 0.035149 val_loss: 0.039677	recall: 0.481481 precision: 0.904573
epoch-1 step 288900/3451022 - loss: 0.040607 val_loss: 0.040087	recall: 0.522573 precision: 0.918651
epoch-1 step 289000/3451022 - loss: 0.041158 val_loss: 0.037939	recall: 0.533632 precision: 0.888060

checkpoint saved

epoch-1 step 289100/3451022 - loss: 0.041740 val_loss: 0.037078	recall: 0.494726 precision: 0.930556
epoch-1 step 289200/3451022 - loss: 0.035795 val_loss: 0.036868	recall: 0.513304 precision: 0.902534
epoch-1 step 289300/3451022 - loss: 0.053856 val_loss: 0.036140	recall: 0.508715 precision: 0.908560
epoch-1 step 289400/3451022 - loss: 0.036784 val_loss: 0.035019	recall: 0.565928 precision: 0.929119
epoch-1 step 289500/3451022 - loss: 0.043158 val_loss: 0.034714	recall: 0.493562 precision: 0.905512
epoch-1 step 289600/3451022 - loss: 0.035918 val_loss: 0.034988	recall: 0.518232 precision: 0.895038
epoch-1 step 289700/3451022 - loss: 0.036202 val_loss: 0.034674	recall: 0.526498 precision: 0.914000
epoch-1 step 289800/3451022 - loss: 0.036756 val_loss: 0.037161	recall: 0.515837 precision: 0.904762
epoch-1 step 289900/3451022 - loss: 0.036560 val_loss: 0.035159	recall: 0.531144 precision: 0.910680
epoch-1 step 290000/3451022 - loss: 0.034981 val_loss: 0.034581	recall: 0.506750 precision: 0.919021

checkpoint saved

epoch-1 step 290100/3451022 - loss: 0.040461 val_loss: 0.034959	recall: 0.533333 precision: 0.905660

model exported!

epoch-1 step 290200/3451022 - loss: 0.039389 val_loss: 0.034025	recall: 0.477497 precision: 0.878788
epoch-1 step 290300/3451022 - loss: 0.034860 val_loss: 0.035397	recall: 0.538288 precision: 0.912214
epoch-1 step 290400/3451022 - loss: 0.035510 val_loss: 0.040084	recall: 0.542431 precision: 0.920233
epoch-1 step 290500/3451022 - loss: 0.036910 val_loss: 0.035337	recall: 0.499455 precision: 0.914172
epoch-1 step 290600/3451022 - loss: 0.035469 val_loss: 0.035555	recall: 0.519058 precision: 0.909627
epoch-1 step 290700/3451022 - loss: 0.035017 val_loss: 0.036924	recall: 0.539130 precision: 0.911765
epoch-1 step 290800/3451022 - loss: 0.041101 val_loss: 0.034869	recall: 0.534699 precision: 0.917969
epoch-1 step 290900/3451022 - loss: 0.034426 val_loss: 0.041714	recall: 0.501594 precision: 0.892250
epoch-1 step 291000/3451022 - loss: 0.039381 val_loss: 0.035067	recall: 0.519912 precision: 0.893536

checkpoint saved

epoch-1 step 291100/3451022 - loss: 0.034954 val_loss: 0.040472	recall: 0.502769 precision: 0.886719
epoch-1 step 291200/3451022 - loss: 0.037342 val_loss: 0.035957	recall: 0.525366 precision: 0.920949
epoch-1 step 291300/3451022 - loss: 0.041598 val_loss: 0.035136	recall: 0.512459 precision: 0.911368
epoch-1 step 291400/3451022 - loss: 0.035593 val_loss: 0.037131	recall: 0.551412 precision: 0.910448
epoch-1 step 291500/3451022 - loss: 0.037402 val_loss: 0.035087	recall: 0.535593 precision: 0.913295
epoch-1 step 291600/3451022 - loss: 0.037026 val_loss: 0.037225	recall: 0.510846 precision: 0.900574
epoch-1 step 291700/3451022 - loss: 0.035872 val_loss: 0.037515	recall: 0.533408 precision: 0.926499
epoch-1 step 291800/3451022 - loss: 0.035416 val_loss: 0.035241	recall: 0.511390 precision: 0.890873
epoch-1 step 291900/3451022 - loss: 0.034643 val_loss: 0.035051	recall: 0.541913 precision: 0.905325
epoch-1 step 292000/3451022 - loss: 0.035522 val_loss: 0.040836	recall: 0.492457 precision: 0.897839

checkpoint saved

epoch-1 step 292100/3451022 - loss: 0.035325 val_loss: 0.038351	recall: 0.511957 precision: 0.864220

model exported!

epoch-1 step 292200/3451022 - loss: 0.036434 val_loss: 0.036904	recall: 0.519101 precision: 0.913043
epoch-1 step 292300/3451022 - loss: 0.035132 val_loss: 0.042567	recall: 0.533557 precision: 0.920849
epoch-1 step 292400/3451022 - loss: 0.036811 val_loss: 0.034263	recall: 0.511654 precision: 0.891683
epoch-1 step 292500/3451022 - loss: 0.044742 val_loss: 0.037020	recall: 0.522803 precision: 0.895238
epoch-1 step 292600/3451022 - loss: 0.038513 val_loss: 0.035926	recall: 0.519864 precision: 0.877395
epoch-1 step 292700/3451022 - loss: 0.035861 val_loss: 0.038217	recall: 0.520231 precision: 0.877193
epoch-1 step 292800/3451022 - loss: 0.033746 val_loss: 0.038183	recall: 0.535077 precision: 0.900000
epoch-1 step 292900/3451022 - loss: 0.041647 val_loss: 0.041178	recall: 0.530134 precision: 0.911708
epoch-1 step 293000/3451022 - loss: 0.043439 val_loss: 0.034601	recall: 0.501104 precision: 0.902584

checkpoint saved

epoch-1 step 293100/3451022 - loss: 0.036115 val_loss: 0.035484	recall: 0.497309 precision: 0.898833
epoch-1 step 293200/3451022 - loss: 0.035560 val_loss: 0.036390	recall: 0.519694 precision: 0.942460
epoch-1 step 293300/3451022 - loss: 0.036779 val_loss: 0.035376	recall: 0.491507 precision: 0.876894
epoch-1 step 293400/3451022 - loss: 0.037456 val_loss: 0.037335	recall: 0.517544 precision: 0.905950
epoch-1 step 293500/3451022 - loss: 0.035565 val_loss: 0.043066	recall: 0.514989 precision: 0.921456
epoch-1 step 293600/3451022 - loss: 0.047134 val_loss: 0.039229	recall: 0.506682 precision: 0.908184
epoch-1 step 293700/3451022 - loss: 0.035070 val_loss: 0.035643	recall: 0.481243 precision: 0.894422
epoch-1 step 293800/3451022 - loss: 0.034267 val_loss: 0.037226	recall: 0.517241 precision: 0.930451
epoch-1 step 293900/3451022 - loss: 0.038891 val_loss: 0.035017	recall: 0.515358 precision: 0.881323
epoch-1 step 294000/3451022 - loss: 0.039099 val_loss: 0.040228	recall: 0.518519 precision: 0.899811

checkpoint saved

epoch-1 step 294100/3451022 - loss: 0.037267 val_loss: 0.037426	recall: 0.524831 precision: 0.899420

model exported!

epoch-1 step 294200/3451022 - loss: 0.038876 val_loss: 0.034768	recall: 0.538462 precision: 0.906667
epoch-1 step 294300/3451022 - loss: 0.035440 val_loss: 0.042961	recall: 0.492163 precision: 0.914563
epoch-1 step 294400/3451022 - loss: 0.036049 val_loss: 0.034743	recall: 0.506397 precision: 0.899621
epoch-1 step 294500/3451022 - loss: 0.034579 val_loss: 0.036096	recall: 0.492616 precision: 0.891221
epoch-1 step 294600/3451022 - loss: 0.038849 val_loss: 0.040013	recall: 0.528571 precision: 0.923225
epoch-1 step 294700/3451022 - loss: 0.036342 val_loss: 0.034637	recall: 0.544760 precision: 0.925788
epoch-1 step 294800/3451022 - loss: 0.036017 val_loss: 0.034646	recall: 0.498954 precision: 0.906844
epoch-1 step 294900/3451022 - loss: 0.041943 val_loss: 0.038374	recall: 0.530822 precision: 0.917160
epoch-1 step 295000/3451022 - loss: 0.035719 val_loss: 0.035641	recall: 0.508949 precision: 0.890411

checkpoint saved

epoch-1 step 295100/3451022 - loss: 0.034400 val_loss: 0.034187	recall: 0.507743 precision: 0.891262
epoch-1 step 295200/3451022 - loss: 0.034480 val_loss: 0.036706	recall: 0.506494 precision: 0.901734
epoch-1 step 295300/3451022 - loss: 0.036486 val_loss: 0.037700	recall: 0.496257 precision: 0.900971
epoch-1 step 295400/3451022 - loss: 0.040678 val_loss: 0.034554	recall: 0.535308 precision: 0.909091
epoch-1 step 295500/3451022 - loss: 0.039606 val_loss: 0.037426	recall: 0.507479 precision: 0.899621
epoch-1 step 295600/3451022 - loss: 0.037241 val_loss: 0.034811	recall: 0.526201 precision: 0.946955
epoch-1 step 295700/3451022 - loss: 0.039122 val_loss: 0.035914	recall: 0.550282 precision: 0.936538
epoch-1 step 295800/3451022 - loss: 0.038133 val_loss: 0.042648	recall: 0.532584 precision: 0.915058
epoch-1 step 295900/3451022 - loss: 0.035571 val_loss: 0.035730	recall: 0.502750 precision: 0.899606
epoch-1 step 296000/3451022 - loss: 0.040388 val_loss: 0.036333	recall: 0.504792 precision: 0.894340

checkpoint saved

epoch-1 step 296100/3451022 - loss: 0.038363 val_loss: 0.042515	recall: 0.515556 precision: 0.890595

model exported!

epoch-1 step 296200/3451022 - loss: 0.036257 val_loss: 0.035586	recall: 0.490506 precision: 0.906433
epoch-1 step 296300/3451022 - loss: 0.035255 val_loss: 0.035330	recall: 0.531111 precision: 0.928155
epoch-1 step 296400/3451022 - loss: 0.035601 val_loss: 0.034017	recall: 0.542529 precision: 0.920078
epoch-1 step 296500/3451022 - loss: 0.038614 val_loss: 0.034874	recall: 0.530543 precision: 0.883239
epoch-1 step 296600/3451022 - loss: 0.042707 val_loss: 0.035999	recall: 0.546875 precision: 0.890411
epoch-1 step 296700/3451022 - loss: 0.039222 val_loss: 0.037606	recall: 0.517582 precision: 0.907514
epoch-1 step 296800/3451022 - loss: 0.035018 val_loss: 0.035673	recall: 0.556206 precision: 0.916988
epoch-1 step 296900/3451022 - loss: 0.042100 val_loss: 0.039417	recall: 0.533408 precision: 0.919386
epoch-1 step 297000/3451022 - loss: 0.035553 val_loss: 0.036163	recall: 0.547977 precision: 0.916828

checkpoint saved

epoch-1 step 297100/3451022 - loss: 0.037778 val_loss: 0.040206	recall: 0.527559 precision: 0.917808
epoch-1 step 297200/3451022 - loss: 0.034922 val_loss: 0.034809	recall: 0.506037 precision: 0.900391
epoch-1 step 297300/3451022 - loss: 0.035227 val_loss: 0.037122	recall: 0.517203 precision: 0.892720
epoch-1 step 297400/3451022 - loss: 0.042551 val_loss: 0.040289	recall: 0.533409 precision: 0.890359
epoch-1 step 297500/3451022 - loss: 0.034936 val_loss: 0.034895	recall: 0.513113 precision: 0.884086
epoch-1 step 297600/3451022 - loss: 0.041589 val_loss: 0.034247	recall: 0.516704 precision: 0.900971
epoch-1 step 297700/3451022 - loss: 0.038367 val_loss: 0.036374	recall: 0.529602 precision: 0.901099
epoch-1 step 297800/3451022 - loss: 0.036662 val_loss: 0.034536	recall: 0.515695 precision: 0.900196
epoch-1 step 297900/3451022 - loss: 0.037911 val_loss: 0.039200	recall: 0.502697 precision: 0.899614
epoch-1 step 298000/3451022 - loss: 0.041242 val_loss: 0.038679	recall: 0.532571 precision: 0.896154

checkpoint saved

epoch-1 step 298100/3451022 - loss: 0.039350 val_loss: 0.037662	recall: 0.512931 precision: 0.891386

model exported!

epoch-1 step 298200/3451022 - loss: 0.035145 val_loss: 0.035087	recall: 0.488818 precision: 0.869318
epoch-1 step 298300/3451022 - loss: 0.036271 val_loss: 0.034925	recall: 0.482255 precision: 0.905882
epoch-1 step 298400/3451022 - loss: 0.044210 val_loss: 0.034473	recall: 0.523013 precision: 0.929368
epoch-1 step 298500/3451022 - loss: 0.034404 val_loss: 0.036251	recall: 0.497366 precision: 0.890566
epoch-1 step 298600/3451022 - loss: 0.041146 val_loss: 0.037846	recall: 0.534911 precision: 0.884540
epoch-1 step 298700/3451022 - loss: 0.034076 val_loss: 0.037548	recall: 0.511312 precision: 0.886275
epoch-1 step 298800/3451022 - loss: 0.036739 val_loss: 0.033360	recall: 0.548200 precision: 0.916505
epoch-1 step 298900/3451022 - loss: 0.037545 val_loss: 0.036674	recall: 0.513514 precision: 0.888889
epoch-1 step 299000/3451022 - loss: 0.039513 val_loss: 0.034311	recall: 0.527293 precision: 0.887868

checkpoint saved

epoch-1 step 299100/3451022 - loss: 0.036553 val_loss: 0.043134	recall: 0.511206 precision: 0.902072
epoch-1 step 299200/3451022 - loss: 0.036215 val_loss: 0.038878	recall: 0.503817 precision: 0.914851
epoch-1 step 299300/3451022 - loss: 0.033887 val_loss: 0.034053	recall: 0.528634 precision: 0.917782
epoch-1 step 299400/3451022 - loss: 0.034292 val_loss: 0.043494	recall: 0.513200 precision: 0.895028
epoch-1 step 299500/3451022 - loss: 0.036355 val_loss: 0.039628	recall: 0.524644 precision: 0.915870
epoch-1 step 299600/3451022 - loss: 0.033475 val_loss: 0.035706	recall: 0.497835 precision: 0.888031
epoch-1 step 299700/3451022 - loss: 0.042579 val_loss: 0.035078	recall: 0.524377 precision: 0.901304
epoch-1 step 299800/3451022 - loss: 0.042766 val_loss: 0.044729	recall: 0.493976 precision: 0.877432
epoch-1 step 299900/3451022 - loss: 0.043425 val_loss: 0.039490	recall: 0.511551 precision: 0.885714
epoch-1 step 300000/3451022 - loss: 0.036034 val_loss: 0.034155	recall: 0.525442 precision: 0.916988

checkpoint saved

epoch-1 step 300100/3451022 - loss: 0.042294 val_loss: 0.034120	recall: 0.533776 precision: 0.906015

model exported!

epoch-1 step 300200/3451022 - loss: 0.036128 val_loss: 0.035425	recall: 0.551339 precision: 0.935606
epoch-1 step 300300/3451022 - loss: 0.037190 val_loss: 0.035500	recall: 0.509033 precision: 0.908918
epoch-1 step 300400/3451022 - loss: 0.034277 val_loss: 0.037597	recall: 0.545029 precision: 0.904854
epoch-1 step 300500/3451022 - loss: 0.040209 val_loss: 0.036667	recall: 0.504425 precision: 0.906561
epoch-1 step 300600/3451022 - loss: 0.036065 val_loss: 0.035795	recall: 0.519641 precision: 0.906067
epoch-1 step 300700/3451022 - loss: 0.035266 val_loss: 0.036672	recall: 0.521595 precision: 0.918129
epoch-1 step 300800/3451022 - loss: 0.035488 val_loss: 0.034980	recall: 0.516704 precision: 0.906250
epoch-1 step 300900/3451022 - loss: 0.039576 val_loss: 0.043324	recall: 0.515801 precision: 0.914000
epoch-1 step 301000/3451022 - loss: 0.034836 val_loss: 0.036598	recall: 0.509574 precision: 0.908918

checkpoint saved

epoch-1 step 301100/3451022 - loss: 0.034628 val_loss: 0.034973	recall: 0.522013 precision: 0.934334
epoch-1 step 301200/3451022 - loss: 0.038804 val_loss: 0.034059	recall: 0.528474 precision: 0.920635
epoch-1 step 301300/3451022 - loss: 0.041333 val_loss: 0.042775	recall: 0.536036 precision: 0.879852
epoch-1 step 301400/3451022 - loss: 0.035265 val_loss: 0.036405	recall: 0.502151 precision: 0.899807
epoch-1 step 301500/3451022 - loss: 0.038993 val_loss: 0.038554	recall: 0.518112 precision: 0.905950
epoch-1 step 301600/3451022 - loss: 0.037469 val_loss: 0.034102	recall: 0.508850 precision: 0.882917
epoch-1 step 301700/3451022 - loss: 0.034743 val_loss: 0.040117	recall: 0.495039 precision: 0.901606
epoch-1 step 301800/3451022 - loss: 0.034613 val_loss: 0.034869	recall: 0.527192 precision: 0.931373
epoch-1 step 301900/3451022 - loss: 0.036474 val_loss: 0.040399	recall: 0.512764 precision: 0.905882
epoch-1 step 302000/3451022 - loss: 0.034437 val_loss: 0.038139	recall: 0.532658 precision: 0.907869

checkpoint saved

epoch-1 step 302100/3451022 - loss: 0.035570 val_loss: 0.036662	recall: 0.526796 precision: 0.897087

model exported!

epoch-1 step 302200/3451022 - loss: 0.036014 val_loss: 0.037464	recall: 0.520263 precision: 0.916988
epoch-1 step 302300/3451022 - loss: 0.037434 val_loss: 0.034396	recall: 0.528345 precision: 0.911937
epoch-1 step 302400/3451022 - loss: 0.039803 val_loss: 0.038147	recall: 0.521935 precision: 0.899225
epoch-1 step 302500/3451022 - loss: 0.035957 val_loss: 0.035069	recall: 0.542373 precision: 0.902256
epoch-1 step 302600/3451022 - loss: 0.034911 val_loss: 0.034509	recall: 0.503191 precision: 0.879182
epoch-1 step 302700/3451022 - loss: 0.038890 val_loss: 0.037245	recall: 0.542952 precision: 0.907919
epoch-1 step 302800/3451022 - loss: 0.039044 val_loss: 0.036291	recall: 0.530217 precision: 0.906433
epoch-1 step 302900/3451022 - loss: 0.036180 val_loss: 0.041252	recall: 0.507920 precision: 0.902439
epoch-1 step 303000/3451022 - loss: 0.035653 val_loss: 0.036635	recall: 0.553364 precision: 0.919075

checkpoint saved

epoch-1 step 303100/3451022 - loss: 0.035471 val_loss: 0.043980	recall: 0.523385 precision: 0.916179
epoch-1 step 303200/3451022 - loss: 0.040292 val_loss: 0.040243	recall: 0.508584 precision: 0.923977
epoch-1 step 303300/3451022 - loss: 0.039324 val_loss: 0.034190	recall: 0.500539 precision: 0.900971
epoch-1 step 303400/3451022 - loss: 0.037694 val_loss: 0.043612	recall: 0.545866 precision: 0.926923
epoch-1 step 303500/3451022 - loss: 0.035971 val_loss: 0.049908	recall: 0.486010 precision: 0.900192
epoch-1 step 303600/3451022 - loss: 0.036067 val_loss: 0.034875	recall: 0.485592 precision: 0.895669
epoch-1 step 303700/3451022 - loss: 0.035039 val_loss: 0.035421	recall: 0.505028 precision: 0.918699
epoch-1 step 303800/3451022 - loss: 0.034504 val_loss: 0.034155	recall: 0.533258 precision: 0.897533
epoch-1 step 303900/3451022 - loss: 0.035385 val_loss: 0.038022	recall: 0.500000 precision: 0.910359
epoch-1 step 304000/3451022 - loss: 0.034440 val_loss: 0.036317	recall: 0.514786 precision: 0.903846

checkpoint saved

epoch-1 step 304100/3451022 - loss: 0.036370 val_loss: 0.038355	recall: 0.501068 precision: 0.917808

model exported!

epoch-1 step 304200/3451022 - loss: 0.037080 val_loss: 0.040573	recall: 0.487342 precision: 0.914851
epoch-1 step 304300/3451022 - loss: 0.035893 val_loss: 0.038024	recall: 0.512432 precision: 0.902857
epoch-1 step 304400/3451022 - loss: 0.036762 val_loss: 0.035178	recall: 0.480789 precision: 0.890385
epoch-1 step 304500/3451022 - loss: 0.036746 val_loss: 0.035246	recall: 0.517572 precision: 0.915254
epoch-1 step 304600/3451022 - loss: 0.035674 val_loss: 0.040746	recall: 0.484946 precision: 0.882583
epoch-1 step 304700/3451022 - loss: 0.035708 val_loss: 0.037623	recall: 0.497967 precision: 0.915888
epoch-1 step 304800/3451022 - loss: 0.039771 val_loss: 0.045078	recall: 0.523438 precision: 0.900192
epoch-1 step 304900/3451022 - loss: 0.044661 val_loss: 0.036002	recall: 0.498392 precision: 0.911765
epoch-1 step 305000/3451022 - loss: 0.034647 val_loss: 0.035697	recall: 0.506908 precision: 0.938976

checkpoint saved

epoch-1 step 305100/3451022 - loss: 0.039483 val_loss: 0.037575	recall: 0.562156 precision: 0.941068
epoch-1 step 305200/3451022 - loss: 0.043816 val_loss: 0.036864	recall: 0.493631 precision: 0.895954
epoch-1 step 305300/3451022 - loss: 0.035857 val_loss: 0.037262	recall: 0.508565 precision: 0.889513
epoch-1 step 305400/3451022 - loss: 0.039333 val_loss: 0.041426	recall: 0.530405 precision: 0.921722
epoch-1 step 305500/3451022 - loss: 0.036250 val_loss: 0.039143	recall: 0.532131 precision: 0.902486
epoch-1 step 305600/3451022 - loss: 0.035342 val_loss: 0.034679	recall: 0.535832 precision: 0.920455
epoch-1 step 305700/3451022 - loss: 0.037428 val_loss: 0.036972	recall: 0.501597 precision: 0.883677
epoch-1 step 305800/3451022 - loss: 0.041753 val_loss: 0.037288	recall: 0.529543 precision: 0.906489
epoch-1 step 305900/3451022 - loss: 0.036994 val_loss: 0.035285	recall: 0.512557 precision: 0.905242
epoch-1 step 306000/3451022 - loss: 0.036684 val_loss: 0.034904	recall: 0.536036 precision: 0.917148

checkpoint saved

epoch-1 step 306100/3451022 - loss: 0.037777 val_loss: 0.038472	recall: 0.484783 precision: 0.901010

model exported!

epoch-1 step 306200/3451022 - loss: 0.036485 val_loss: 0.034835	recall: 0.540636 precision: 0.903543
epoch-1 step 306300/3451022 - loss: 0.044477 val_loss: 0.036692	recall: 0.505808 precision: 0.897004
epoch-1 step 306400/3451022 - loss: 0.036778 val_loss: 0.035399	recall: 0.504246 precision: 0.916988
epoch-1 step 306500/3451022 - loss: 0.036762 val_loss: 0.034978	recall: 0.523060 precision: 0.915354
epoch-1 step 306600/3451022 - loss: 0.034648 val_loss: 0.036372	recall: 0.532453 precision: 0.927203
epoch-1 step 306700/3451022 - loss: 0.038185 val_loss: 0.035493	recall: 0.516930 precision: 0.891051
epoch-1 step 306800/3451022 - loss: 0.035972 val_loss: 0.036191	recall: 0.525832 precision: 0.917836
epoch-1 step 306900/3451022 - loss: 0.034841 val_loss: 0.036498	recall: 0.544509 precision: 0.907514
epoch-1 step 307000/3451022 - loss: 0.037660 val_loss: 0.034447	recall: 0.494080 precision: 0.905325

checkpoint saved

epoch-1 step 307100/3451022 - loss: 0.033977 val_loss: 0.041891	recall: 0.520518 precision: 0.899254
epoch-1 step 307200/3451022 - loss: 0.037658 val_loss: 0.035914	recall: 0.482684 precision: 0.871094
epoch-1 step 307300/3451022 - loss: 0.038033 val_loss: 0.042253	recall: 0.521158 precision: 0.912281
epoch-1 step 307400/3451022 - loss: 0.036464 val_loss: 0.035503	recall: 0.514439 precision: 0.933981
epoch-1 step 307500/3451022 - loss: 0.045104 val_loss: 0.038956	recall: 0.492239 precision: 0.877470
epoch-1 step 307600/3451022 - loss: 0.034829 val_loss: 0.035103	recall: 0.543700 precision: 0.915870
epoch-1 step 307700/3451022 - loss: 0.037925 val_loss: 0.036239	recall: 0.532328 precision: 0.928571
epoch-1 step 307800/3451022 - loss: 0.034763 val_loss: 0.035515	recall: 0.545024 precision: 0.918164
epoch-1 step 307900/3451022 - loss: 0.035312 val_loss: 0.036000	recall: 0.531073 precision: 0.898662
epoch-1 step 308000/3451022 - loss: 0.035056 val_loss: 0.039808	recall: 0.517127 precision: 0.889734

checkpoint saved

epoch-1 step 308100/3451022 - loss: 0.036475 val_loss: 0.033635	recall: 0.529210 precision: 0.898833

model exported!

epoch-1 step 308200/3451022 - loss: 0.034531 val_loss: 0.035666	recall: 0.528962 precision: 0.932563
epoch-1 step 308300/3451022 - loss: 0.036042 val_loss: 0.037514	recall: 0.474346 precision: 0.883041
epoch-1 step 308400/3451022 - loss: 0.039288 val_loss: 0.035790	recall: 0.498339 precision: 0.894632
epoch-1 step 308500/3451022 - loss: 0.035335 val_loss: 0.035077	recall: 0.511654 precision: 0.909270
epoch-1 step 308600/3451022 - loss: 0.037482 val_loss: 0.039586	recall: 0.494565 precision: 0.900990
epoch-1 step 308700/3451022 - loss: 0.050441 val_loss: 0.034695	recall: 0.556322 precision: 0.934363
epoch-1 step 308800/3451022 - loss: 0.040542 val_loss: 0.035942	recall: 0.524083 precision: 0.899606
epoch-1 step 308900/3451022 - loss: 0.038462 val_loss: 0.036584	recall: 0.485900 precision: 0.888889
epoch-1 step 309000/3451022 - loss: 0.038099 val_loss: 0.035115	recall: 0.525952 precision: 0.912000

checkpoint saved

epoch-1 step 309100/3451022 - loss: 0.040630 val_loss: 0.041792	recall: 0.514412 precision: 0.916996
epoch-1 step 309200/3451022 - loss: 0.033489 val_loss: 0.036459	recall: 0.499472 precision: 0.902672
epoch-1 step 309300/3451022 - loss: 0.040767 val_loss: 0.034251	recall: 0.517167 precision: 0.916350
epoch-1 step 309400/3451022 - loss: 0.035171 val_loss: 0.034952	recall: 0.502155 precision: 0.874296
epoch-1 step 309500/3451022 - loss: 0.034122 val_loss: 0.041530	recall: 0.533186 precision: 0.925144
epoch-1 step 309600/3451022 - loss: 0.035527 val_loss: 0.047858	recall: 0.512379 precision: 0.927875
epoch-1 step 309700/3451022 - loss: 0.040052 val_loss: 0.035941	recall: 0.510226 precision: 0.894340
epoch-1 step 309800/3451022 - loss: 0.036001 val_loss: 0.038173	recall: 0.552663 precision: 0.910331
epoch-1 step 309900/3451022 - loss: 0.039495 val_loss: 0.036470	recall: 0.503247 precision: 0.926295
epoch-1 step 310000/3451022 - loss: 0.051854 val_loss: 0.033802	recall: 0.533333 precision: 0.916031

checkpoint saved

epoch-1 step 310100/3451022 - loss: 0.041489 val_loss: 0.043745	recall: 0.531792 precision: 0.914513

model exported!

epoch-1 step 310200/3451022 - loss: 0.035706 val_loss: 0.035852	recall: 0.511111 precision: 0.905512
epoch-1 step 310300/3451022 - loss: 0.035865 val_loss: 0.038422	recall: 0.527778 precision: 0.894539
epoch-1 step 310400/3451022 - loss: 0.036444 val_loss: 0.034809	recall: 0.527293 precision: 0.918251
epoch-1 step 310500/3451022 - loss: 0.035812 val_loss: 0.039224	recall: 0.505643 precision: 0.878431
epoch-1 step 310600/3451022 - loss: 0.038917 val_loss: 0.034688	recall: 0.540541 precision: 0.914513
epoch-1 step 310700/3451022 - loss: 0.037113 val_loss: 0.040399	recall: 0.502680 precision: 0.888258
epoch-1 step 310800/3451022 - loss: 0.039876 val_loss: 0.036434	recall: 0.517564 precision: 0.882236
epoch-1 step 310900/3451022 - loss: 0.034789 val_loss: 0.035502	recall: 0.519318 precision: 0.885659
epoch-1 step 311000/3451022 - loss: 0.047543 val_loss: 0.034665	recall: 0.507104 precision: 0.887189

checkpoint saved

epoch-1 step 311100/3451022 - loss: 0.037246 val_loss: 0.038994	recall: 0.478587 precision: 0.867961
epoch-1 step 311200/3451022 - loss: 0.035198 val_loss: 0.035367	recall: 0.502188 precision: 0.887814
epoch-1 step 311300/3451022 - loss: 0.038780 val_loss: 0.036127	recall: 0.547479 precision: 0.898077
epoch-1 step 311400/3451022 - loss: 0.042716 val_loss: 0.034791	recall: 0.544715 precision: 0.923228
epoch-1 step 311500/3451022 - loss: 0.038430 val_loss: 0.036494	recall: 0.506637 precision: 0.889320
epoch-1 step 311600/3451022 - loss: 0.035601 val_loss: 0.042241	recall: 0.521645 precision: 0.914611
epoch-1 step 311700/3451022 - loss: 0.035518 val_loss: 0.035045	recall: 0.514574 precision: 0.905325
epoch-1 step 311800/3451022 - loss: 0.043699 val_loss: 0.040528	recall: 0.509783 precision: 0.905405
epoch-1 step 311900/3451022 - loss: 0.039377 val_loss: 0.036064	recall: 0.506952 precision: 0.911538
epoch-1 step 312000/3451022 - loss: 0.037478 val_loss: 0.034903	recall: 0.488865 precision: 0.886538

checkpoint saved

epoch-1 step 312100/3451022 - loss: 0.035047 val_loss: 0.035813	recall: 0.511086 precision: 0.893411

model exported!

epoch-1 step 312200/3451022 - loss: 0.034666 val_loss: 0.037434	recall: 0.509740 precision: 0.885338
epoch-1 step 312300/3451022 - loss: 0.039293 val_loss: 0.037520	recall: 0.545767 precision: 0.913793
epoch-1 step 312400/3451022 - loss: 0.038466 val_loss: 0.036394	recall: 0.517316 precision: 0.915709
epoch-1 step 312500/3451022 - loss: 0.034335 val_loss: 0.034573	recall: 0.513015 precision: 0.887430
epoch-1 step 312600/3451022 - loss: 0.043526 val_loss: 0.037253	recall: 0.488770 precision: 0.919517
epoch-1 step 312700/3451022 - loss: 0.035209 val_loss: 0.042921	recall: 0.524499 precision: 0.900574
epoch-1 step 312800/3451022 - loss: 0.040130 val_loss: 0.037452	recall: 0.502155 precision: 0.894434
epoch-1 step 312900/3451022 - loss: 0.033923 val_loss: 0.038554	recall: 0.497872 precision: 0.908738
epoch-1 step 313000/3451022 - loss: 0.036118 val_loss: 0.035784	recall: 0.503696 precision: 0.908571

checkpoint saved

epoch-1 step 313100/3451022 - loss: 0.035098 val_loss: 0.036939	recall: 0.518059 precision: 0.891262
epoch-1 step 313200/3451022 - loss: 0.035028 val_loss: 0.035326	recall: 0.543359 precision: 0.928705
epoch-1 step 313300/3451022 - loss: 0.035937 val_loss: 0.035733	recall: 0.521493 precision: 0.896887
epoch-1 step 313400/3451022 - loss: 0.036628 val_loss: 0.039837	recall: 0.516129 precision: 0.908722
epoch-1 step 313500/3451022 - loss: 0.035881 val_loss: 0.039206	recall: 0.511551 precision: 0.901163
epoch-1 step 313600/3451022 - loss: 0.039603 val_loss: 0.035267	recall: 0.526726 precision: 0.929273
epoch-1 step 313700/3451022 - loss: 0.035241 val_loss: 0.035569	recall: 0.520763 precision: 0.888889
epoch-1 step 313800/3451022 - loss: 0.037556 val_loss: 0.034356	recall: 0.523861 precision: 0.921756
epoch-1 step 313900/3451022 - loss: 0.037444 val_loss: 0.035239	recall: 0.477812 precision: 0.878558
epoch-1 step 314000/3451022 - loss: 0.034962 val_loss: 0.036487	recall: 0.495789 precision: 0.897143

checkpoint saved

epoch-1 step 314100/3451022 - loss: 0.035122 val_loss: 0.035384	recall: 0.535513 precision: 0.909962

model exported!

epoch-1 step 314200/3451022 - loss: 0.036804 val_loss: 0.036905	recall: 0.539071 precision: 0.927875
epoch-1 step 314300/3451022 - loss: 0.038819 val_loss: 0.036085	recall: 0.540509 precision: 0.899807
epoch-1 step 314400/3451022 - loss: 0.038926 val_loss: 0.036992	recall: 0.512679 precision: 0.889101
epoch-1 step 314500/3451022 - loss: 0.037683 val_loss: 0.035579	recall: 0.532009 precision: 0.911153
epoch-1 step 314600/3451022 - loss: 0.040735 val_loss: 0.035318	recall: 0.507675 precision: 0.895551
epoch-1 step 314700/3451022 - loss: 0.035301 val_loss: 0.036713	recall: 0.488613 precision: 0.902486
epoch-1 step 314800/3451022 - loss: 0.038249 val_loss: 0.043361	recall: 0.530675 precision: 0.907343
epoch-1 step 314900/3451022 - loss: 0.037298 val_loss: 0.034892	recall: 0.511752 precision: 0.921154
epoch-1 step 315000/3451022 - loss: 0.034596 val_loss: 0.039783	recall: 0.507026 precision: 0.876518

checkpoint saved

epoch-1 step 315100/3451022 - loss: 0.037932 val_loss: 0.036121	recall: 0.540946 precision: 0.891635
epoch-1 step 315200/3451022 - loss: 0.035564 val_loss: 0.035278	recall: 0.515086 precision: 0.900188
epoch-1 step 315300/3451022 - loss: 0.035945 val_loss: 0.035871	recall: 0.545354 precision: 0.914657
epoch-1 step 315400/3451022 - loss: 0.042677 val_loss: 0.038087	recall: 0.526257 precision: 0.897143
epoch-1 step 315500/3451022 - loss: 0.034197 val_loss: 0.035213	recall: 0.526906 precision: 0.886792
epoch-1 step 315600/3451022 - loss: 0.035280 val_loss: 0.034729	recall: 0.520879 precision: 0.911538
epoch-1 step 315700/3451022 - loss: 0.036043 val_loss: 0.046830	recall: 0.490217 precision: 0.874031
epoch-1 step 315800/3451022 - loss: 0.039790 val_loss: 0.036105	recall: 0.490052 precision: 0.888046
epoch-1 step 315900/3451022 - loss: 0.035141 val_loss: 0.040826	recall: 0.495356 precision: 0.912548
epoch-1 step 316000/3451022 - loss: 0.039823 val_loss: 0.037817	recall: 0.486200 precision: 0.903353

checkpoint saved

epoch-1 step 316100/3451022 - loss: 0.037895 val_loss: 0.034128	recall: 0.489339 precision: 0.886100

model exported!

epoch-1 step 316200/3451022 - loss: 0.034719 val_loss: 0.038593	recall: 0.521173 precision: 0.903955
epoch-1 step 316300/3451022 - loss: 0.037350 val_loss: 0.045152	recall: 0.486660 precision: 0.892368
epoch-1 step 316400/3451022 - loss: 0.038155 val_loss: 0.035060	recall: 0.521396 precision: 0.909627
epoch-1 step 316500/3451022 - loss: 0.040487 val_loss: 0.040989	recall: 0.495585 precision: 0.883858
epoch-1 step 316600/3451022 - loss: 0.037871 val_loss: 0.036578	recall: 0.486258 precision: 0.888031
epoch-1 step 316700/3451022 - loss: 0.039401 val_loss: 0.034845	recall: 0.515086 precision: 0.919231
epoch-1 step 316800/3451022 - loss: 0.039840 val_loss: 0.037091	recall: 0.543017 precision: 0.915254
epoch-1 step 316900/3451022 - loss: 0.037286 val_loss: 0.041519	recall: 0.519423 precision: 0.917647
epoch-1 step 317000/3451022 - loss: 0.036604 val_loss: 0.035116	recall: 0.488494 precision: 0.919291

checkpoint saved

epoch-1 step 317100/3451022 - loss: 0.039825 val_loss: 0.038843	recall: 0.519380 precision: 0.912451
epoch-1 step 317200/3451022 - loss: 0.038669 val_loss: 0.037216	recall: 0.526953 precision: 0.924710
epoch-1 step 317300/3451022 - loss: 0.039925 val_loss: 0.041449	recall: 0.525612 precision: 0.905950
epoch-1 step 317400/3451022 - loss: 0.036974 val_loss: 0.042308	recall: 0.474820 precision: 0.909449
epoch-1 step 317500/3451022 - loss: 0.035225 val_loss: 0.037840	recall: 0.488959 precision: 0.895954
epoch-1 step 317600/3451022 - loss: 0.036339 val_loss: 0.038312	recall: 0.521930 precision: 0.917148
epoch-1 step 317700/3451022 - loss: 0.035634 val_loss: 0.042720	recall: 0.498925 precision: 0.913386
epoch-1 step 317800/3451022 - loss: 0.035440 val_loss: 0.035677	recall: 0.542529 precision: 0.914729
epoch-1 step 317900/3451022 - loss: 0.035287 val_loss: 0.035425	recall: 0.501615 precision: 0.917323
epoch-1 step 318000/3451022 - loss: 0.035749 val_loss: 0.034505	recall: 0.523649 precision: 0.913556

checkpoint saved

epoch-1 step 318100/3451022 - loss: 0.035130 val_loss: 0.035483	recall: 0.513483 precision: 0.906746

model exported!

epoch-1 step 318200/3451022 - loss: 0.036880 val_loss: 0.044726	recall: 0.528953 precision: 0.897921
epoch-1 step 318300/3451022 - loss: 0.035847 val_loss: 0.039212	recall: 0.540445 precision: 0.895146
epoch-1 step 318400/3451022 - loss: 0.040811 val_loss: 0.037215	recall: 0.545665 precision: 0.911197
epoch-1 step 318500/3451022 - loss: 0.034891 val_loss: 0.034929	recall: 0.532438 precision: 0.906667
epoch-1 step 318600/3451022 - loss: 0.034240 val_loss: 0.034549	recall: 0.500543 precision: 0.898635
epoch-1 step 318700/3451022 - loss: 0.038363 val_loss: 0.037465	recall: 0.540816 precision: 0.912046
epoch-1 step 318800/3451022 - loss: 0.035157 val_loss: 0.034684	recall: 0.496788 precision: 0.909804
epoch-1 step 318900/3451022 - loss: 0.034934 val_loss: 0.040884	recall: 0.571596 precision: 0.922348
epoch-1 step 319000/3451022 - loss: 0.040273 val_loss: 0.037757	recall: 0.558789 precision: 0.919540

checkpoint saved

epoch-1 step 319100/3451022 - loss: 0.036229 val_loss: 0.035032	recall: 0.526018 precision: 0.897683
epoch-1 step 319200/3451022 - loss: 0.036386 val_loss: 0.036962	recall: 0.496760 precision: 0.889749
epoch-1 step 319300/3451022 - loss: 0.035987 val_loss: 0.035860	recall: 0.501622 precision: 0.904483
epoch-1 step 319400/3451022 - loss: 0.038389 val_loss: 0.034489	recall: 0.506118 precision: 0.866667
epoch-1 step 319500/3451022 - loss: 0.037319 val_loss: 0.037303	recall: 0.511401 precision: 0.865809
epoch-1 step 319600/3451022 - loss: 0.034555 val_loss: 0.037966	recall: 0.551522 precision: 0.911025
epoch-1 step 319700/3451022 - loss: 0.038080 val_loss: 0.037147	recall: 0.516509 precision: 0.869048
epoch-1 step 319800/3451022 - loss: 0.041525 val_loss: 0.034935	recall: 0.512792 precision: 0.876426
epoch-1 step 319900/3451022 - loss: 0.035062 val_loss: 0.034863	recall: 0.546838 precision: 0.921105
epoch-1 step 320000/3451022 - loss: 0.036376 val_loss: 0.038058	recall: 0.547674 precision: 0.900574

checkpoint saved

epoch-1 step 320100/3451022 - loss: 0.034487 val_loss: 0.034355	recall: 0.524294 precision: 0.902724

model exported!

epoch-1 step 320200/3451022 - loss: 0.035293 val_loss: 0.036452	recall: 0.563927 precision: 0.926829
epoch-1 step 320300/3451022 - loss: 0.035531 val_loss: 0.040648	recall: 0.557471 precision: 0.898148
epoch-1 step 320400/3451022 - loss: 0.039494 val_loss: 0.036325	recall: 0.545350 precision: 0.903042
epoch-1 step 320500/3451022 - loss: 0.036526 val_loss: 0.035953	recall: 0.540323 precision: 0.900192
epoch-1 step 320600/3451022 - loss: 0.042748 val_loss: 0.036313	recall: 0.539062 precision: 0.911321
epoch-1 step 320700/3451022 - loss: 0.036652 val_loss: 0.037268	recall: 0.497812 precision: 0.885214
epoch-1 step 320800/3451022 - loss: 0.042955 val_loss: 0.036490	recall: 0.517594 precision: 0.876923
epoch-1 step 320900/3451022 - loss: 0.034357 val_loss: 0.035405	recall: 0.523705 precision: 0.894539
epoch-1 step 321000/3451022 - loss: 0.035232 val_loss: 0.034673	recall: 0.516878 precision: 0.922787

checkpoint saved

epoch-1 step 321100/3451022 - loss: 0.035083 val_loss: 0.039925	recall: 0.530148 precision: 0.917323
epoch-1 step 321200/3451022 - loss: 0.042538 val_loss: 0.035004	recall: 0.510383 precision: 0.917485
epoch-1 step 321300/3451022 - loss: 0.038084 val_loss: 0.037099	recall: 0.514950 precision: 0.897683
epoch-1 step 321400/3451022 - loss: 0.038263 val_loss: 0.038697	recall: 0.475891 precision: 0.886719
epoch-1 step 321500/3451022 - loss: 0.035516 val_loss: 0.036691	recall: 0.524022 precision: 0.919608
epoch-1 step 321600/3451022 - loss: 0.035402 val_loss: 0.044092	recall: 0.507726 precision: 0.903733
epoch-1 step 321700/3451022 - loss: 0.035352 val_loss: 0.040479	recall: 0.503902 precision: 0.891519
epoch-1 step 321800/3451022 - loss: 0.044843 val_loss: 0.035981	recall: 0.529153 precision: 0.916190
epoch-1 step 321900/3451022 - loss: 0.033839 val_loss: 0.037752	recall: 0.535714 precision: 0.909091
epoch-1 step 322000/3451022 - loss: 0.035927 val_loss: 0.039693	recall: 0.490236 precision: 0.912046

checkpoint saved

epoch-1 step 322100/3451022 - loss: 0.035036 val_loss: 0.036925	recall: 0.508850 precision: 0.893204

model exported!

epoch-1 step 322200/3451022 - loss: 0.037949 val_loss: 0.034991	recall: 0.516129 precision: 0.915187
epoch-1 step 322300/3451022 - loss: 0.037575 val_loss: 0.034345	recall: 0.537199 precision: 0.931689
epoch-1 step 322400/3451022 - loss: 0.037623 val_loss: 0.042268	recall: 0.491024 precision: 0.917160
epoch-1 step 322500/3451022 - loss: 0.046293 val_loss: 0.035220	recall: 0.515351 precision: 0.905588
epoch-1 step 322600/3451022 - loss: 0.035342 val_loss: 0.033901	recall: 0.525516 precision: 0.914934
epoch-1 step 322700/3451022 - loss: 0.038085 val_loss: 0.035199	recall: 0.489177 precision: 0.898608
epoch-1 step 322800/3451022 - loss: 0.037824 val_loss: 0.042747	recall: 0.516022 precision: 0.882798
epoch-1 step 322900/3451022 - loss: 0.048919 val_loss: 0.036433	recall: 0.526376 precision: 0.898239
epoch-1 step 323000/3451022 - loss: 0.034523 val_loss: 0.036145	recall: 0.515642 precision: 0.896811

checkpoint saved

epoch-1 step 323100/3451022 - loss: 0.045744 val_loss: 0.037692	recall: 0.533480 precision: 0.916981
epoch-1 step 323200/3451022 - loss: 0.036792 val_loss: 0.035353	recall: 0.514754 precision: 0.918129
epoch-1 step 323300/3451022 - loss: 0.051370 val_loss: 0.037722	recall: 0.514532 precision: 0.907021
epoch-1 step 323400/3451022 - loss: 0.035592 val_loss: 0.040459	recall: 0.526082 precision: 0.909789
epoch-1 step 323500/3451022 - loss: 0.037918 val_loss: 0.040294	recall: 0.522293 precision: 0.921348
epoch-1 step 323600/3451022 - loss: 0.035376 val_loss: 0.035957	recall: 0.502662 precision: 0.909441
epoch-1 step 323700/3451022 - loss: 0.035018 val_loss: 0.035717	recall: 0.471875 precision: 0.883041
epoch-1 step 323800/3451022 - loss: 0.036508 val_loss: 0.035541	recall: 0.509310 precision: 0.913556
epoch-1 step 323900/3451022 - loss: 0.035751 val_loss: 0.035188	recall: 0.522034 precision: 0.922156
epoch-1 step 324000/3451022 - loss: 0.039525 val_loss: 0.041147	recall: 0.511945 precision: 0.896414

checkpoint saved

epoch-1 step 324100/3451022 - loss: 0.034852 val_loss: 0.037071	recall: 0.519438 precision: 0.917939

model exported!

epoch-1 step 324200/3451022 - loss: 0.034615 val_loss: 0.035975	recall: 0.483051 precision: 0.883721
epoch-1 step 324300/3451022 - loss: 0.035153 val_loss: 0.036319	recall: 0.505108 precision: 0.897177
epoch-1 step 324400/3451022 - loss: 0.035914 val_loss: 0.034097	recall: 0.500000 precision: 0.891519
epoch-1 step 324500/3451022 - loss: 0.033717 val_loss: 0.035073	recall: 0.511261 precision: 0.902584
epoch-1 step 324600/3451022 - loss: 0.037320 val_loss: 0.037558	recall: 0.526894 precision: 0.910816
epoch-1 step 324700/3451022 - loss: 0.039681 val_loss: 0.036507	recall: 0.525164 precision: 0.910816
epoch-1 step 324800/3451022 - loss: 0.039181 val_loss: 0.034890	recall: 0.495690 precision: 0.894942
epoch-1 step 324900/3451022 - loss: 0.036858 val_loss: 0.035325	recall: 0.513450 precision: 0.862475
epoch-1 step 325000/3451022 - loss: 0.047976 val_loss: 0.038508	recall: 0.508734 precision: 0.885932

checkpoint saved

epoch-1 step 325100/3451022 - loss: 0.034441 val_loss: 0.035822	recall: 0.501087 precision: 0.911067
epoch-1 step 325200/3451022 - loss: 0.040526 val_loss: 0.050042	recall: 0.535469 precision: 0.915851
epoch-1 step 325300/3451022 - loss: 0.038080 val_loss: 0.036660	recall: 0.503371 precision: 0.881890
epoch-1 step 325400/3451022 - loss: 0.036387 val_loss: 0.038844	recall: 0.508696 precision: 0.900000
epoch-1 step 325500/3451022 - loss: 0.042172 val_loss: 0.035981	recall: 0.493450 precision: 0.874275
epoch-1 step 325600/3451022 - loss: 0.041297 val_loss: 0.037262	recall: 0.502580 precision: 0.920605
epoch-1 step 325700/3451022 - loss: 0.037080 val_loss: 0.035580	recall: 0.513484 precision: 0.896422
epoch-1 step 325800/3451022 - loss: 0.035726 val_loss: 0.034691	recall: 0.520925 precision: 0.906130
epoch-1 step 325900/3451022 - loss: 0.034544 val_loss: 0.034871	recall: 0.514477 precision: 0.900585
epoch-1 step 326000/3451022 - loss: 0.046295 val_loss: 0.049809	recall: 0.528217 precision: 0.881356

checkpoint saved

epoch-1 step 326100/3451022 - loss: 0.041867 val_loss: 0.042723	recall: 0.507527 precision: 0.905950

model exported!

epoch-1 step 326200/3451022 - loss: 0.036800 val_loss: 0.036971	recall: 0.513699 precision: 0.903614
epoch-1 step 326300/3451022 - loss: 0.037721 val_loss: 0.034218	recall: 0.534829 precision: 0.864504
epoch-1 step 326400/3451022 - loss: 0.034219 val_loss: 0.035198	recall: 0.531891 precision: 0.919291
epoch-1 step 326500/3451022 - loss: 0.052811 val_loss: 0.037045	recall: 0.498908 precision: 0.885659
epoch-1 step 326600/3451022 - loss: 0.035770 val_loss: 0.034854	recall: 0.495807 precision: 0.911368
epoch-1 step 326700/3451022 - loss: 0.035915 val_loss: 0.034036	recall: 0.511577 precision: 0.920635
epoch-1 step 326800/3451022 - loss: 0.036283 val_loss: 0.039565	recall: 0.536453 precision: 0.916357
epoch-1 step 326900/3451022 - loss: 0.035248 val_loss: 0.035466	recall: 0.539843 precision: 0.925000
epoch-1 step 327000/3451022 - loss: 0.039826 val_loss: 0.039738	recall: 0.524807 precision: 0.894737

checkpoint saved

epoch-1 step 327100/3451022 - loss: 0.034881 val_loss: 0.036567	recall: 0.508143 precision: 0.878049
epoch-1 step 327200/3451022 - loss: 0.036175 val_loss: 0.038409	recall: 0.516685 precision: 0.903955
epoch-1 step 327300/3451022 - loss: 0.039057 val_loss: 0.041058	recall: 0.504484 precision: 0.892857
epoch-1 step 327400/3451022 - loss: 0.038984 val_loss: 0.036362	recall: 0.544170 precision: 0.905882
epoch-1 step 327500/3451022 - loss: 0.035211 val_loss: 0.036247	recall: 0.540541 precision: 0.898438
epoch-1 step 327600/3451022 - loss: 0.037427 val_loss: 0.034066	recall: 0.487939 precision: 0.890000
epoch-1 step 327700/3451022 - loss: 0.034192 val_loss: 0.036704	recall: 0.504505 precision: 0.896000
epoch-1 step 327800/3451022 - loss: 0.034615 val_loss: 0.037673	recall: 0.541714 precision: 0.915058
epoch-1 step 327900/3451022 - loss: 0.036666 val_loss: 0.035521	recall: 0.528555 precision: 0.920078
epoch-1 step 328000/3451022 - loss: 0.035564 val_loss: 0.036719	recall: 0.524404 precision: 0.897087

checkpoint saved

epoch-1 step 328100/3451022 - loss: 0.035188 val_loss: 0.034281	recall: 0.561176 precision: 0.898305

model exported!

epoch-1 step 328200/3451022 - loss: 0.041792 val_loss: 0.034809	recall: 0.516571 precision: 0.914980
epoch-1 step 328300/3451022 - loss: 0.042142 val_loss: 0.036544	recall: 0.533851 precision: 0.921456
epoch-1 step 328400/3451022 - loss: 0.036911 val_loss: 0.039599	recall: 0.498894 precision: 0.887795
epoch-1 step 328500/3451022 - loss: 0.038903 val_loss: 0.035154	recall: 0.540393 precision: 0.921788
epoch-1 step 328600/3451022 - loss: 0.041338 val_loss: 0.034789	recall: 0.534521 precision: 0.914286
epoch-1 step 328700/3451022 - loss: 0.040833 val_loss: 0.041683	recall: 0.520299 precision: 0.922348
epoch-1 step 328800/3451022 - loss: 0.035238 val_loss: 0.034697	recall: 0.518944 precision: 0.895050
epoch-1 step 328900/3451022 - loss: 0.038844 val_loss: 0.035220	recall: 0.524887 precision: 0.880455
epoch-1 step 329000/3451022 - loss: 0.035287 val_loss: 0.039126	recall: 0.504865 precision: 0.908560

checkpoint saved

epoch-1 step 329100/3451022 - loss: 0.039646 val_loss: 0.034835	recall: 0.498419 precision: 0.906130
epoch-1 step 329200/3451022 - loss: 0.038092 val_loss: 0.035323	recall: 0.510520 precision: 0.911067
epoch-1 step 329300/3451022 - loss: 0.035307 val_loss: 0.035536	recall: 0.522404 precision: 0.908745
epoch-1 step 329400/3451022 - loss: 0.034570 val_loss: 0.036854	recall: 0.505895 precision: 0.918288
epoch-1 step 329500/3451022 - loss: 0.036237 val_loss: 0.035203	recall: 0.508830 precision: 0.907480
epoch-1 step 329600/3451022 - loss: 0.035517 val_loss: 0.035406	recall: 0.505096 precision: 0.895582
epoch-1 step 329700/3451022 - loss: 0.034948 val_loss: 0.036143	recall: 0.512876 precision: 0.913958
epoch-1 step 329800/3451022 - loss: 0.036402 val_loss: 0.035777	recall: 0.505208 precision: 0.929119
epoch-1 step 329900/3451022 - loss: 0.035104 val_loss: 0.038641	recall: 0.520000 precision: 0.906977
epoch-1 step 330000/3451022 - loss: 0.035709 val_loss: 0.038436	recall: 0.489861 precision: 0.901768

checkpoint saved

epoch-1 step 330100/3451022 - loss: 0.037491 val_loss: 0.035981	recall: 0.525109 precision: 0.904135

model exported!

epoch-1 step 330200/3451022 - loss: 0.042645 val_loss: 0.044420	recall: 0.498353 precision: 0.890196
epoch-1 step 330300/3451022 - loss: 0.036270 val_loss: 0.036949	recall: 0.525901 precision: 0.910331
epoch-1 step 330400/3451022 - loss: 0.034135 val_loss: 0.037922	recall: 0.485744 precision: 0.900196
epoch-1 step 330500/3451022 - loss: 0.034315 val_loss: 0.035720	recall: 0.520856 precision: 0.917137
epoch-1 step 330600/3451022 - loss: 0.034969 val_loss: 0.034868	recall: 0.479321 precision: 0.922449
epoch-1 step 330700/3451022 - loss: 0.036868 val_loss: 0.035606	recall: 0.490260 precision: 0.879612
epoch-1 step 330800/3451022 - loss: 0.036526 val_loss: 0.037346	recall: 0.517582 precision: 0.909266
epoch-1 step 330900/3451022 - loss: 0.038374 val_loss: 0.040937	recall: 0.529742 precision: 0.911197
epoch-1 step 331000/3451022 - loss: 0.045778 val_loss: 0.039829	recall: 0.515987 precision: 0.886364

checkpoint saved

epoch-1 step 331100/3451022 - loss: 0.040220 val_loss: 0.034767	recall: 0.535320 precision: 0.929119
epoch-1 step 331200/3451022 - loss: 0.038530 val_loss: 0.036607	recall: 0.528365 precision: 0.925926
epoch-1 step 331300/3451022 - loss: 0.038686 val_loss: 0.049830	recall: 0.527655 precision: 0.905123
epoch-1 step 331400/3451022 - loss: 0.036870 val_loss: 0.037257	recall: 0.513751 precision: 0.908560
epoch-1 step 331500/3451022 - loss: 0.035858 val_loss: 0.038724	recall: 0.506438 precision: 0.912959
epoch-1 step 331600/3451022 - loss: 0.041188 val_loss: 0.034459	recall: 0.518644 precision: 0.882692
epoch-1 step 331700/3451022 - loss: 0.036574 val_loss: 0.037908	recall: 0.523915 precision: 0.914563
epoch-1 step 331800/3451022 - loss: 0.038924 val_loss: 0.042189	recall: 0.520788 precision: 0.886406
epoch-1 step 331900/3451022 - loss: 0.035755 val_loss: 0.034436	recall: 0.490022 precision: 0.880478
epoch-1 step 332000/3451022 - loss: 0.035285 val_loss: 0.039893	recall: 0.536530 precision: 0.900383

checkpoint saved

epoch-1 step 332100/3451022 - loss: 0.037978 val_loss: 0.039244	recall: 0.519101 precision: 0.918489

model exported!

epoch-1 step 332200/3451022 - loss: 0.036452 val_loss: 0.045078	recall: 0.494444 precision: 0.875984
epoch-1 step 332300/3451022 - loss: 0.035944 val_loss: 0.034505	recall: 0.520595 precision: 0.910000
epoch-1 step 332400/3451022 - loss: 0.036319 val_loss: 0.035852	recall: 0.548352 precision: 0.941509
epoch-1 step 332500/3451022 - loss: 0.034786 val_loss: 0.037166	recall: 0.534002 precision: 0.924710
epoch-1 step 332600/3451022 - loss: 0.035312 val_loss: 0.035570	recall: 0.514439 precision: 0.904135
epoch-1 step 332700/3451022 - loss: 0.035429 val_loss: 0.042075	recall: 0.524262 precision: 0.911927
epoch-1 step 332800/3451022 - loss: 0.035950 val_loss: 0.035252	recall: 0.530355 precision: 0.911417
epoch-1 step 332900/3451022 - loss: 0.038486 val_loss: 0.034326	recall: 0.530148 precision: 0.899614
epoch-1 step 333000/3451022 - loss: 0.035375 val_loss: 0.038922	recall: 0.517857 precision: 0.888889

checkpoint saved

epoch-1 step 333100/3451022 - loss: 0.036103 val_loss: 0.040236	recall: 0.497840 precision: 0.874763
epoch-1 step 333200/3451022 - loss: 0.035984 val_loss: 0.034535	recall: 0.525627 precision: 0.918095
epoch-1 step 333300/3451022 - loss: 0.035935 val_loss: 0.039995	recall: 0.522926 precision: 0.917625
epoch-1 step 333400/3451022 - loss: 0.035150 val_loss: 0.038334	recall: 0.513904 precision: 0.904110
epoch-1 step 333500/3451022 - loss: 0.038791 val_loss: 0.048957	recall: 0.510383 precision: 0.892925
epoch-1 step 333600/3451022 - loss: 0.035340 val_loss: 0.040231	recall: 0.508399 precision: 0.868069
epoch-1 step 333700/3451022 - loss: 0.046553 val_loss: 0.036638	recall: 0.522752 precision: 0.919922
epoch-1 step 333800/3451022 - loss: 0.036307 val_loss: 0.038191	recall: 0.515317 precision: 0.890359
epoch-1 step 333900/3451022 - loss: 0.035905 val_loss: 0.034461	recall: 0.527684 precision: 0.876173
epoch-1 step 334000/3451022 - loss: 0.035866 val_loss: 0.038176	recall: 0.519016 precision: 0.908023

checkpoint saved

epoch-1 step 334100/3451022 - loss: 0.036123 val_loss: 0.042300	recall: 0.541023 precision: 0.893910

model exported!

epoch-1 step 334200/3451022 - loss: 0.034559 val_loss: 0.035300	recall: 0.514381 precision: 0.894231
epoch-1 step 334300/3451022 - loss: 0.039739 val_loss: 0.033598	recall: 0.525309 precision: 0.877820
epoch-1 step 334400/3451022 - loss: 0.036197 val_loss: 0.034585	recall: 0.556086 precision: 0.899614
epoch-1 step 334500/3451022 - loss: 0.037651 val_loss: 0.046051	recall: 0.560803 precision: 0.903042
epoch-1 step 334600/3451022 - loss: 0.034850 val_loss: 0.035575	recall: 0.524306 precision: 0.898810
epoch-1 step 334700/3451022 - loss: 0.038284 val_loss: 0.035668	recall: 0.509956 precision: 0.883142
epoch-1 step 334800/3451022 - loss: 0.037147 val_loss: 0.061516	recall: 0.540416 precision: 0.881356
epoch-1 step 334900/3451022 - loss: 0.037882 val_loss: 0.035563	recall: 0.547897 precision: 0.916016
epoch-1 step 335000/3451022 - loss: 0.036190 val_loss: 0.039072	recall: 0.554299 precision: 0.899083

checkpoint saved

epoch-1 step 335100/3451022 - loss: 0.036494 val_loss: 0.035514	recall: 0.526196 precision: 0.904110
epoch-1 step 335200/3451022 - loss: 0.034674 val_loss: 0.035841	recall: 0.536501 precision: 0.895551
epoch-1 step 335300/3451022 - loss: 0.039359 val_loss: 0.036739	recall: 0.539773 precision: 0.913462
epoch-1 step 335400/3451022 - loss: 0.039363 val_loss: 0.042155	recall: 0.506772 precision: 0.875244
epoch-1 step 335500/3451022 - loss: 0.035926 val_loss: 0.034269	recall: 0.524831 precision: 0.928144
epoch-1 step 335600/3451022 - loss: 0.034652 val_loss: 0.033872	recall: 0.540416 precision: 0.906977
epoch-1 step 335700/3451022 - loss: 0.034494 val_loss: 0.035692	recall: 0.513083 precision: 0.907445
epoch-1 step 335800/3451022 - loss: 0.036460 val_loss: 0.039074	recall: 0.509052 precision: 0.896811
epoch-1 step 335900/3451022 - loss: 0.039501 val_loss: 0.037489	recall: 0.526894 precision: 0.912548
epoch-1 step 336000/3451022 - loss: 0.034506 val_loss: 0.034236	recall: 0.523810 precision: 0.911368

checkpoint saved

epoch-1 step 336100/3451022 - loss: 0.038477 val_loss: 0.034681	recall: 0.522440 precision: 0.906188

model exported!

epoch-1 step 336200/3451022 - loss: 0.034282 val_loss: 0.035133	recall: 0.517723 precision: 0.895911
epoch-1 step 336300/3451022 - loss: 0.041193 val_loss: 0.035307	recall: 0.524123 precision: 0.917466
epoch-1 step 336400/3451022 - loss: 0.035176 val_loss: 0.034591	recall: 0.551843 precision: 0.914122
epoch-1 step 336500/3451022 - loss: 0.035526 val_loss: 0.036188	recall: 0.528555 precision: 0.911197
epoch-1 step 336600/3451022 - loss: 0.035438 val_loss: 0.036793	recall: 0.512326 precision: 0.893458
epoch-1 step 336700/3451022 - loss: 0.035309 val_loss: 0.038826	recall: 0.533257 precision: 0.890805
epoch-1 step 336800/3451022 - loss: 0.039060 val_loss: 0.037690	recall: 0.508197 precision: 0.902913
epoch-1 step 336900/3451022 - loss: 0.039818 val_loss: 0.036555	recall: 0.509269 precision: 0.898077
epoch-1 step 337000/3451022 - loss: 0.040814 val_loss: 0.036768	recall: 0.538642 precision: 0.877863

checkpoint saved

epoch-1 step 337100/3451022 - loss: 0.038793 val_loss: 0.036665	recall: 0.551111 precision: 0.939394
epoch-1 step 337200/3451022 - loss: 0.037387 val_loss: 0.035848	recall: 0.510497 precision: 0.904110
epoch-1 step 337300/3451022 - loss: 0.040883 val_loss: 0.037733	recall: 0.512739 precision: 0.909605
epoch-1 step 337400/3451022 - loss: 0.037997 val_loss: 0.041643	recall: 0.540113 precision: 0.928155
epoch-1 step 337500/3451022 - loss: 0.035128 val_loss: 0.035335	recall: 0.541231 precision: 0.917323
epoch-1 step 337600/3451022 - loss: 0.037357 val_loss: 0.036765	recall: 0.531719 precision: 0.884837
epoch-1 step 337700/3451022 - loss: 0.037532 val_loss: 0.035256	recall: 0.529686 precision: 0.878378
epoch-1 step 337800/3451022 - loss: 0.039084 val_loss: 0.037128	recall: 0.527027 precision: 0.881356
epoch-1 step 337900/3451022 - loss: 0.035640 val_loss: 0.038390	recall: 0.536558 precision: 0.913793
epoch-1 step 338000/3451022 - loss: 0.038130 val_loss: 0.035325	recall: 0.498426 precision: 0.916988

checkpoint saved

epoch-1 step 338100/3451022 - loss: 0.035754 val_loss: 0.037333	recall: 0.547404 precision: 0.901487

model exported!

epoch-1 step 338200/3451022 - loss: 0.036491 val_loss: 0.046521	recall: 0.503784 precision: 0.896154
epoch-1 step 338300/3451022 - loss: 0.034984 val_loss: 0.034077	recall: 0.513543 precision: 0.882682
epoch-1 step 338400/3451022 - loss: 0.034296 val_loss: 0.035691	recall: 0.490649 precision: 0.901010
epoch-1 step 338500/3451022 - loss: 0.035883 val_loss: 0.035397	recall: 0.553592 precision: 0.909091
epoch-1 step 338600/3451022 - loss: 0.038423 val_loss: 0.036325	recall: 0.524220 precision: 0.883848
epoch-1 step 338700/3451022 - loss: 0.044333 val_loss: 0.039634	recall: 0.527059 precision: 0.923711
epoch-1 step 338800/3451022 - loss: 0.040087 val_loss: 0.036922	recall: 0.523756 precision: 0.902534
epoch-1 step 338900/3451022 - loss: 0.036274 val_loss: 0.036798	recall: 0.478541 precision: 0.892000
epoch-1 step 339000/3451022 - loss: 0.035040 val_loss: 0.036809	recall: 0.539863 precision: 0.902857

checkpoint saved

epoch-1 step 339100/3451022 - loss: 0.035221 val_loss: 0.040084	recall: 0.559102 precision: 0.911368
epoch-1 step 339200/3451022 - loss: 0.041959 val_loss: 0.035690	recall: 0.509534 precision: 0.916190
epoch-1 step 339300/3451022 - loss: 0.036624 val_loss: 0.034992	recall: 0.515453 precision: 0.887833
epoch-1 step 339400/3451022 - loss: 0.035788 val_loss: 0.034767	recall: 0.515952 precision: 0.903661
epoch-1 step 339500/3451022 - loss: 0.035933 val_loss: 0.037063	recall: 0.508929 precision: 0.871893
epoch-1 step 339600/3451022 - loss: 0.038494 val_loss: 0.038910	recall: 0.516830 precision: 0.910134
epoch-1 step 339700/3451022 - loss: 0.037822 val_loss: 0.035345	recall: 0.508179 precision: 0.889313
epoch-1 step 339800/3451022 - loss: 0.038747 val_loss: 0.036499	recall: 0.551066 precision: 0.928166
epoch-1 step 339900/3451022 - loss: 0.035669 val_loss: 0.039911	recall: 0.509698 precision: 0.923828
epoch-1 step 340000/3451022 - loss: 0.034748 val_loss: 0.037571	recall: 0.502703 precision: 0.890805

checkpoint saved

epoch-1 step 340100/3451022 - loss: 0.036152 val_loss: 0.034035	recall: 0.514819 precision: 0.905405

model exported!

epoch-1 step 340200/3451022 - loss: 0.035557 val_loss: 0.035192	recall: 0.527655 precision: 0.903409
epoch-1 step 340300/3451022 - loss: 0.035462 val_loss: 0.040929	recall: 0.496381 precision: 0.923077
epoch-1 step 340400/3451022 - loss: 0.035171 val_loss: 0.034733	recall: 0.496809 precision: 0.899807
epoch-1 step 340500/3451022 - loss: 0.039702 val_loss: 0.035080	recall: 0.511261 precision: 0.893701
epoch-1 step 340600/3451022 - loss: 0.038880 val_loss: 0.042976	recall: 0.536640 precision: 0.917148
epoch-1 step 340700/3451022 - loss: 0.039670 val_loss: 0.037944	recall: 0.526602 precision: 0.918561
epoch-1 step 340800/3451022 - loss: 0.035418 val_loss: 0.037250	recall: 0.512821 precision: 0.909091
epoch-1 step 340900/3451022 - loss: 0.035241 val_loss: 0.048574	recall: 0.505920 precision: 0.916179
epoch-1 step 341000/3451022 - loss: 0.034740 val_loss: 0.037706	recall: 0.496343 precision: 0.916988

checkpoint saved

epoch-1 step 341100/3451022 - loss: 0.037182 val_loss: 0.034629	recall: 0.529143 precision: 0.907843
epoch-1 step 341200/3451022 - loss: 0.033960 val_loss: 0.034017	recall: 0.505039 precision: 0.877432
epoch-1 step 341300/3451022 - loss: 0.034362 val_loss: 0.040479	recall: 0.521499 precision: 0.909615
epoch-1 step 341400/3451022 - loss: 0.035047 val_loss: 0.035963	recall: 0.509804 precision: 0.919450
epoch-1 step 341500/3451022 - loss: 0.036855 val_loss: 0.036921	recall: 0.488372 precision: 0.888462
epoch-1 step 341600/3451022 - loss: 0.035863 val_loss: 0.037869	recall: 0.514286 precision: 0.900000
epoch-1 step 341700/3451022 - loss: 0.034575 val_loss: 0.034952	recall: 0.516484 precision: 0.905588
epoch-1 step 341800/3451022 - loss: 0.034509 val_loss: 0.038186	recall: 0.512141 precision: 0.890595
epoch-1 step 341900/3451022 - loss: 0.040431 val_loss: 0.037516	recall: 0.523918 precision: 0.888031
epoch-1 step 342000/3451022 - loss: 0.041918 val_loss: 0.042875	recall: 0.510248 precision: 0.902672

checkpoint saved

epoch-1 step 342100/3451022 - loss: 0.037836 val_loss: 0.035532	recall: 0.533991 precision: 0.924099

model exported!

epoch-1 step 342200/3451022 - loss: 0.034321 val_loss: 0.038031	recall: 0.521452 precision: 0.897727
epoch-1 step 342300/3451022 - loss: 0.038474 val_loss: 0.037529	recall: 0.521405 precision: 0.918762
epoch-1 step 342400/3451022 - loss: 0.035653 val_loss: 0.034310	recall: 0.498896 precision: 0.888016
epoch-1 step 342500/3451022 - loss: 0.037850 val_loss: 0.037652	recall: 0.527594 precision: 0.915709
epoch-1 step 342600/3451022 - loss: 0.040360 val_loss: 0.036167	recall: 0.523243 precision: 0.897959
epoch-1 step 342700/3451022 - loss: 0.035123 val_loss: 0.036748	recall: 0.513751 precision: 0.910331
epoch-1 step 342800/3451022 - loss: 0.040780 val_loss: 0.037224	recall: 0.506051 precision: 0.909091
epoch-1 step 342900/3451022 - loss: 0.034758 val_loss: 0.038766	recall: 0.519406 precision: 0.902778
epoch-1 step 343000/3451022 - loss: 0.045462 val_loss: 0.036457	recall: 0.511752 precision: 0.937378

checkpoint saved

epoch-1 step 343100/3451022 - loss: 0.036293 val_loss: 0.043761	recall: 0.485067 precision: 0.921722
epoch-1 step 343200/3451022 - loss: 0.034570 val_loss: 0.034837	recall: 0.526316 precision: 0.891841
epoch-1 step 343300/3451022 - loss: 0.036565 val_loss: 0.034470	recall: 0.510753 precision: 0.913462
epoch-1 step 343400/3451022 - loss: 0.035917 val_loss: 0.034283	recall: 0.512876 precision: 0.907021
epoch-1 step 343500/3451022 - loss: 0.035577 val_loss: 0.035506	recall: 0.527027 precision: 0.900000
epoch-1 step 343600/3451022 - loss: 0.036560 val_loss: 0.040088	recall: 0.515710 precision: 0.913628
epoch-1 step 343700/3451022 - loss: 0.036871 val_loss: 0.036576	recall: 0.529545 precision: 0.885932
epoch-1 step 343800/3451022 - loss: 0.036677 val_loss: 0.034601	recall: 0.518478 precision: 0.917308
epoch-1 step 343900/3451022 - loss: 0.036474 val_loss: 0.036873	recall: 0.523164 precision: 0.899029
epoch-1 step 344000/3451022 - loss: 0.035419 val_loss: 0.037031	recall: 0.506257 precision: 0.904472

checkpoint saved

epoch-1 step 344100/3451022 - loss: 0.046978 val_loss: 0.034690	recall: 0.510776 precision: 0.918605

model exported!

epoch-1 step 344200/3451022 - loss: 0.037906 val_loss: 0.041243	recall: 0.497797 precision: 0.902196
epoch-1 step 344300/3451022 - loss: 0.036695 val_loss: 0.042635	recall: 0.471204 precision: 0.885827
epoch-1 step 344400/3451022 - loss: 0.035371 val_loss: 0.052879	recall: 0.525386 precision: 0.924272
epoch-1 step 344500/3451022 - loss: 0.045443 val_loss: 0.043790	recall: 0.503205 precision: 0.898855
epoch-1 step 344600/3451022 - loss: 0.036807 val_loss: 0.042686	recall: 0.545557 precision: 0.920304
epoch-1 step 344700/3451022 - loss: 0.035395 val_loss: 0.035745	recall: 0.514223 precision: 0.914397
epoch-1 step 344800/3451022 - loss: 0.039356 val_loss: 0.036425	recall: 0.533258 precision: 0.923828
epoch-1 step 344900/3451022 - loss: 0.034545 val_loss: 0.036388	recall: 0.543113 precision: 0.908240
epoch-1 step 345000/3451022 - loss: 0.039230 val_loss: 0.040402	recall: 0.537853 precision: 0.926070

checkpoint saved

epoch-1 step 345100/3451022 - loss: 0.043364 val_loss: 0.036044	recall: 0.537853 precision: 0.929688
epoch-2 step 345200/3451022 - loss: 0.043082 val_loss: 0.034255	recall: 0.498378 precision: 0.886538
epoch-2 step 345300/3451022 - loss: 0.035799 val_loss: 0.034346	recall: 0.512792 precision: 0.909270
epoch-2 step 345400/3451022 - loss: 0.034657 val_loss: 0.039329	recall: 0.543839 precision: 0.900000
epoch-2 step 345500/3451022 - loss: 0.039429 val_loss: 0.038816	recall: 0.518960 precision: 0.902072
epoch-2 step 345600/3451022 - loss: 0.041394 val_loss: 0.033944	recall: 0.503205 precision: 0.890359
epoch-2 step 345700/3451022 - loss: 0.035386 val_loss: 0.036487	recall: 0.532100 precision: 0.924386
epoch-2 step 345800/3451022 - loss: 0.035283 val_loss: 0.036796	recall: 0.515660 precision: 0.912871
epoch-2 step 345900/3451022 - loss: 0.035804 val_loss: 0.040736	recall: 0.522602 precision: 0.892655
epoch-2 step 346000/3451022 - loss: 0.035025 val_loss: 0.035369	recall: 0.503254 precision: 0.911591

checkpoint saved

epoch-2 step 346100/3451022 - loss: 0.034831 val_loss: 0.039442	recall: 0.523269 precision: 0.905697

model exported!

epoch-2 step 346200/3451022 - loss: 0.035630 val_loss: 0.035958	recall: 0.517755 precision: 0.902196
epoch-2 step 346300/3451022 - loss: 0.038674 val_loss: 0.035286	recall: 0.528258 precision: 0.921529
epoch-2 step 346400/3451022 - loss: 0.036053 val_loss: 0.034040	recall: 0.519190 precision: 0.927619
epoch-2 step 346500/3451022 - loss: 0.038681 val_loss: 0.035018	recall: 0.500000 precision: 0.899408
epoch-2 step 346600/3451022 - loss: 0.036135 val_loss: 0.039331	recall: 0.484979 precision: 0.888016
epoch-2 step 346700/3451022 - loss: 0.036523 val_loss: 0.034984	recall: 0.508565 precision: 0.897921
epoch-2 step 346800/3451022 - loss: 0.036351 val_loss: 0.034727	recall: 0.515508 precision: 0.895911
epoch-2 step 346900/3451022 - loss: 0.039072 val_loss: 0.035586	recall: 0.531729 precision: 0.923954
epoch-2 step 347000/3451022 - loss: 0.036975 val_loss: 0.035860	recall: 0.549438 precision: 0.940385

checkpoint saved

epoch-2 step 347100/3451022 - loss: 0.036581 val_loss: 0.034555	recall: 0.520179 precision: 0.920635
epoch-2 step 347200/3451022 - loss: 0.034984 val_loss: 0.038301	recall: 0.542197 precision: 0.919608
epoch-2 step 347300/3451022 - loss: 0.037467 val_loss: 0.035586	recall: 0.544725 precision: 0.906489
epoch-2 step 347400/3451022 - loss: 0.035762 val_loss: 0.035755	recall: 0.490649 precision: 0.893788
epoch-2 step 347500/3451022 - loss: 0.035196 val_loss: 0.039105	recall: 0.517919 precision: 0.897796
epoch-2 step 347600/3451022 - loss: 0.041134 val_loss: 0.040735	recall: 0.522196 precision: 0.890438
epoch-2 step 347700/3451022 - loss: 0.041796 val_loss: 0.035060	recall: 0.550459 precision: 0.921305
epoch-2 step 347800/3451022 - loss: 0.034323 val_loss: 0.034996	recall: 0.527559 precision: 0.921415
epoch-2 step 347900/3451022 - loss: 0.034443 val_loss: 0.034751	recall: 0.513158 precision: 0.914062
epoch-2 step 348000/3451022 - loss: 0.035282 val_loss: 0.038786	recall: 0.499445 precision: 0.894632

checkpoint saved

epoch-2 step 348100/3451022 - loss: 0.042370 val_loss: 0.035281	recall: 0.520045 precision: 0.912109

model exported!

epoch-2 step 348200/3451022 - loss: 0.037865 val_loss: 0.034467	recall: 0.513228 precision: 0.913371
epoch-2 step 348300/3451022 - loss: 0.036275 val_loss: 0.036196	recall: 0.530238 precision: 0.917757
epoch-2 step 348400/3451022 - loss: 0.034348 val_loss: 0.047363	recall: 0.515119 precision: 0.905123
epoch-2 step 348500/3451022 - loss: 0.034907 val_loss: 0.036482	recall: 0.545455 precision: 0.898273
epoch-2 step 348600/3451022 - loss: 0.036322 val_loss: 0.036705	recall: 0.515385 precision: 0.914230
epoch-2 step 348700/3451022 - loss: 0.035107 val_loss: 0.043240	recall: 0.526620 precision: 0.893910
epoch-2 step 348800/3451022 - loss: 0.035065 val_loss: 0.035263	recall: 0.496746 precision: 0.875717
epoch-2 step 348900/3451022 - loss: 0.035142 val_loss: 0.036614	recall: 0.504338 precision: 0.874060
epoch-2 step 349000/3451022 - loss: 0.035914 val_loss: 0.035581	recall: 0.526198 precision: 0.905950

checkpoint saved

epoch-2 step 349100/3451022 - loss: 0.036763 val_loss: 0.037561	recall: 0.517582 precision: 0.918129
epoch-2 step 349200/3451022 - loss: 0.037610 val_loss: 0.045244	recall: 0.520810 precision: 0.893822
epoch-2 step 349300/3451022 - loss: 0.035270 val_loss: 0.033946	recall: 0.489947 precision: 0.878558
epoch-2 step 349400/3451022 - loss: 0.035127 val_loss: 0.039575	recall: 0.530495 precision: 0.903922
epoch-2 step 349500/3451022 - loss: 0.037333 val_loss: 0.034748	recall: 0.528428 precision: 0.927593
epoch-2 step 349600/3451022 - loss: 0.035550 val_loss: 0.039833	recall: 0.530565 precision: 0.901961
epoch-2 step 349700/3451022 - loss: 0.046348 val_loss: 0.040272	recall: 0.542453 precision: 0.912698
epoch-2 step 349800/3451022 - loss: 0.038788 val_loss: 0.033684	recall: 0.532741 precision: 0.907372
epoch-2 step 349900/3451022 - loss: 0.035675 val_loss: 0.040178	recall: 0.522356 precision: 0.910646
epoch-2 step 350000/3451022 - loss: 0.037309 val_loss: 0.035720	recall: 0.506494 precision: 0.896552

checkpoint saved

epoch-2 step 350100/3451022 - loss: 0.034800 val_loss: 0.039982	recall: 0.513572 precision: 0.902672

model exported!

epoch-2 step 350200/3451022 - loss: 0.035329 val_loss: 0.041146	recall: 0.501672 precision: 0.905433
epoch-2 step 350300/3451022 - loss: 0.036096 val_loss: 0.034875	recall: 0.537559 precision: 0.896282
epoch-2 step 350400/3451022 - loss: 0.035370 val_loss: 0.036533	recall: 0.552874 precision: 0.910985
epoch-2 step 350500/3451022 - loss: 0.038912 val_loss: 0.034888	recall: 0.573086 precision: 0.913124
epoch-2 step 350600/3451022 - loss: 0.038034 val_loss: 0.035758	recall: 0.537143 precision: 0.895238
epoch-2 step 350700/3451022 - loss: 0.037492 val_loss: 0.036526	recall: 0.534025 precision: 0.885277
epoch-2 step 350800/3451022 - loss: 0.039269 val_loss: 0.036873	recall: 0.519585 precision: 0.903808
epoch-2 step 350900/3451022 - loss: 0.038774 val_loss: 0.034045	recall: 0.527251 precision: 0.884692
epoch-2 step 351000/3451022 - loss: 0.037605 val_loss: 0.038420	recall: 0.509978 precision: 0.907298

checkpoint saved

epoch-2 step 351100/3451022 - loss: 0.036132 val_loss: 0.035620	recall: 0.527957 precision: 0.924670
epoch-2 step 351200/3451022 - loss: 0.040632 val_loss: 0.035264	recall: 0.520000 precision: 0.893910
epoch-2 step 351300/3451022 - loss: 0.041994 val_loss: 0.037859	recall: 0.503842 precision: 0.880998
epoch-2 step 351400/3451022 - loss: 0.035995 val_loss: 0.034011	recall: 0.516880 precision: 0.875740
epoch-2 step 351500/3451022 - loss: 0.036858 val_loss: 0.044209	recall: 0.530752 precision: 0.904854
epoch-2 step 351600/3451022 - loss: 0.054718 val_loss: 0.034867	recall: 0.515487 precision: 0.915521
epoch-2 step 351700/3451022 - loss: 0.035095 val_loss: 0.044527	recall: 0.525892 precision: 0.875479
epoch-2 step 351800/3451022 - loss: 0.035235 val_loss: 0.034681	recall: 0.514052 precision: 0.864173
epoch-2 step 351900/3451022 - loss: 0.040739 val_loss: 0.034575	recall: 0.538111 precision: 0.899240
epoch-2 step 352000/3451022 - loss: 0.036208 val_loss: 0.040247	recall: 0.520971 precision: 0.911197

checkpoint saved

epoch-2 step 352100/3451022 - loss: 0.037631 val_loss: 0.041465	recall: 0.548538 precision: 0.903661

model exported!

epoch-2 step 352200/3451022 - loss: 0.035999 val_loss: 0.037130	recall: 0.506922 precision: 0.886406
epoch-2 step 352300/3451022 - loss: 0.033806 val_loss: 0.037948	recall: 0.536281 precision: 0.911368
epoch-2 step 352400/3451022 - loss: 0.035417 val_loss: 0.042698	recall: 0.505735 precision: 0.916824
epoch-2 step 352500/3451022 - loss: 0.035366 val_loss: 0.035733	recall: 0.523915 precision: 0.880374
epoch-2 step 352600/3451022 - loss: 0.035727 val_loss: 0.035869	recall: 0.501647 precision: 0.863894
epoch-2 step 352700/3451022 - loss: 0.035802 val_loss: 0.038439	recall: 0.484144 precision: 0.892788
epoch-2 step 352800/3451022 - loss: 0.034171 val_loss: 0.035711	recall: 0.534308 precision: 0.918762
epoch-2 step 352900/3451022 - loss: 0.034139 val_loss: 0.033689	recall: 0.534308 precision: 0.899621
epoch-2 step 353000/3451022 - loss: 0.035344 val_loss: 0.035776	recall: 0.565668 precision: 0.905904

checkpoint saved

epoch-2 step 353100/3451022 - loss: 0.037729 val_loss: 0.035485	recall: 0.515513 precision: 0.887064
epoch-2 step 353200/3451022 - loss: 0.035043 val_loss: 0.034474	recall: 0.480208 precision: 0.902153
epoch-2 step 353300/3451022 - loss: 0.035529 val_loss: 0.037240	recall: 0.533851 precision: 0.900749
epoch-2 step 353400/3451022 - loss: 0.035898 val_loss: 0.038295	recall: 0.540066 precision: 0.889693
epoch-2 step 353500/3451022 - loss: 0.038679 val_loss: 0.036039	recall: 0.500000 precision: 0.895327
epoch-2 step 353600/3451022 - loss: 0.034905 val_loss: 0.038718	recall: 0.542590 precision: 0.904669
epoch-2 step 353700/3451022 - loss: 0.034969 val_loss: 0.036322	recall: 0.532328 precision: 0.911439
epoch-2 step 353800/3451022 - loss: 0.041844 val_loss: 0.036210	recall: 0.526257 precision: 0.911025
epoch-2 step 353900/3451022 - loss: 0.035781 val_loss: 0.035092	recall: 0.523699 precision: 0.884766
epoch-2 step 354000/3451022 - loss: 0.033933 val_loss: 0.037474	recall: 0.523810 precision: 0.863551

checkpoint saved

epoch-2 step 354100/3451022 - loss: 0.037371 val_loss: 0.035599	recall: 0.535308 precision: 0.890152

model exported!

epoch-2 step 354200/3451022 - loss: 0.034719 val_loss: 0.034364	recall: 0.517241 precision: 0.897196
epoch-2 step 354300/3451022 - loss: 0.038197 val_loss: 0.035849	recall: 0.514595 precision: 0.906667
epoch-2 step 354400/3451022 - loss: 0.035064 val_loss: 0.038869	recall: 0.525463 precision: 0.900794
epoch-2 step 354500/3451022 - loss: 0.039333 val_loss: 0.035785	recall: 0.511957 precision: 0.904031
epoch-2 step 354600/3451022 - loss: 0.037427 val_loss: 0.047019	recall: 0.509330 precision: 0.908023
epoch-2 step 354700/3451022 - loss: 0.035330 val_loss: 0.036368	recall: 0.526258 precision: 0.914449
epoch-2 step 354800/3451022 - loss: 0.034309 val_loss: 0.034741	recall: 0.523026 precision: 0.891589
epoch-2 step 354900/3451022 - loss: 0.035309 val_loss: 0.036229	recall: 0.537768 precision: 0.912046
epoch-2 step 355000/3451022 - loss: 0.034418 val_loss: 0.034268	recall: 0.497788 precision: 0.892857

checkpoint saved

epoch-2 step 355100/3451022 - loss: 0.038148 val_loss: 0.035146	recall: 0.539813 precision: 0.905697
epoch-2 step 355200/3451022 - loss: 0.040476 val_loss: 0.034535	recall: 0.529680 precision: 0.900971
epoch-2 step 355300/3451022 - loss: 0.038028 val_loss: 0.036998	recall: 0.535714 precision: 0.916031
epoch-2 step 355400/3451022 - loss: 0.035152 val_loss: 0.045565	recall: 0.488017 precision: 0.905051
epoch-2 step 355500/3451022 - loss: 0.040065 val_loss: 0.034834	recall: 0.491892 precision: 0.911824
epoch-2 step 355600/3451022 - loss: 0.035535 val_loss: 0.038808	recall: 0.526882 precision: 0.919325
epoch-2 step 355700/3451022 - loss: 0.035022 val_loss: 0.038143	recall: 0.530590 precision: 0.938976
epoch-2 step 355800/3451022 - loss: 0.035192 val_loss: 0.040862	recall: 0.511236 precision: 0.910000
epoch-2 step 355900/3451022 - loss: 0.034226 val_loss: 0.035551	recall: 0.517241 precision: 0.901804
epoch-2 step 356000/3451022 - loss: 0.036064 val_loss: 0.035378	recall: 0.517817 precision: 0.906433

checkpoint saved

epoch-2 step 356100/3451022 - loss: 0.041793 val_loss: 0.035871	recall: 0.531461 precision: 0.904398

model exported!

epoch-2 step 356200/3451022 - loss: 0.035225 val_loss: 0.036118	recall: 0.517738 precision: 0.894636
epoch-2 step 356300/3451022 - loss: 0.034701 val_loss: 0.039730	recall: 0.535433 precision: 0.929688
epoch-2 step 356400/3451022 - loss: 0.036658 val_loss: 0.038747	recall: 0.526786 precision: 0.925490
epoch-2 step 356500/3451022 - loss: 0.034391 val_loss: 0.042851	recall: 0.539443 precision: 0.895954
epoch-2 step 356600/3451022 - loss: 0.034730 val_loss: 0.036146	recall: 0.529412 precision: 0.901734
epoch-2 step 356700/3451022 - loss: 0.039656 val_loss: 0.035175	recall: 0.517165 precision: 0.917485
epoch-2 step 356800/3451022 - loss: 0.038377 val_loss: 0.035886	recall: 0.508929 precision: 0.913828
epoch-2 step 356900/3451022 - loss: 0.033828 val_loss: 0.035310	recall: 0.551881 precision: 0.897959
epoch-2 step 357000/3451022 - loss: 0.035848 val_loss: 0.036688	recall: 0.542431 precision: 0.913127

checkpoint saved

epoch-2 step 357100/3451022 - loss: 0.034854 val_loss: 0.036343	recall: 0.495717 precision: 0.915020
epoch-2 step 357200/3451022 - loss: 0.035739 val_loss: 0.035242	recall: 0.533637 precision: 0.919450
epoch-2 step 357300/3451022 - loss: 0.036385 val_loss: 0.034253	recall: 0.515499 precision: 0.892644
epoch-2 step 357400/3451022 - loss: 0.035497 val_loss: 0.036511	recall: 0.539773 precision: 0.925926
epoch-2 step 357500/3451022 - loss: 0.035751 val_loss: 0.047637	recall: 0.489164 precision: 0.908046
epoch-2 step 357600/3451022 - loss: 0.056326 val_loss: 0.035595	recall: 0.514161 precision: 0.895636
epoch-2 step 357700/3451022 - loss: 0.038326 val_loss: 0.038203	recall: 0.512793 precision: 0.909263
epoch-2 step 357800/3451022 - loss: 0.038339 val_loss: 0.034522	recall: 0.529867 precision: 0.908918
epoch-2 step 357900/3451022 - loss: 0.035390 val_loss: 0.040375	recall: 0.497868 precision: 0.908560
epoch-2 step 358000/3451022 - loss: 0.039743 val_loss: 0.042233	recall: 0.536876 precision: 0.913284

checkpoint saved

epoch-2 step 358100/3451022 - loss: 0.034250 val_loss: 0.036430	recall: 0.501615 precision: 0.904854

model exported!

epoch-2 step 358200/3451022 - loss: 0.036086 val_loss: 0.034577	recall: 0.530134 precision: 0.899621
epoch-2 step 358300/3451022 - loss: 0.035044 val_loss: 0.036662	recall: 0.553699 precision: 0.899225
epoch-2 step 358400/3451022 - loss: 0.039604 val_loss: 0.036650	recall: 0.549199 precision: 0.907372
epoch-2 step 358500/3451022 - loss: 0.036359 val_loss: 0.035932	recall: 0.540268 precision: 0.894444
epoch-2 step 358600/3451022 - loss: 0.034039 val_loss: 0.035171	recall: 0.523446 precision: 0.909091
epoch-2 step 358700/3451022 - loss: 0.037178 val_loss: 0.037450	recall: 0.504435 precision: 0.895669
epoch-2 step 358800/3451022 - loss: 0.036708 val_loss: 0.035069	recall: 0.522173 precision: 0.895437
epoch-2 step 358900/3451022 - loss: 0.040621 val_loss: 0.039411	recall: 0.502691 precision: 0.913894
epoch-2 step 359000/3451022 - loss: 0.036182 val_loss: 0.041109	recall: 0.526018 precision: 0.885714

checkpoint saved

epoch-2 step 359100/3451022 - loss: 0.035381 val_loss: 0.039127	recall: 0.526316 precision: 0.900383
epoch-2 step 359200/3451022 - loss: 0.036530 val_loss: 0.037192	recall: 0.519423 precision: 0.884688
epoch-2 step 359300/3451022 - loss: 0.036276 val_loss: 0.037608	recall: 0.507527 precision: 0.899048
epoch-2 step 359400/3451022 - loss: 0.034854 val_loss: 0.043224	recall: 0.524917 precision: 0.906310
epoch-2 step 359500/3451022 - loss: 0.034421 val_loss: 0.043358	recall: 0.498920 precision: 0.893617
epoch-2 step 359600/3451022 - loss: 0.036373 val_loss: 0.035190	recall: 0.509847 precision: 0.913725
epoch-2 step 359700/3451022 - loss: 0.037634 val_loss: 0.034907	recall: 0.495050 precision: 0.900000
epoch-2 step 359800/3451022 - loss: 0.034912 val_loss: 0.038846	recall: 0.568102 precision: 0.924242
epoch-2 step 359900/3451022 - loss: 0.036988 val_loss: 0.034998	recall: 0.527559 precision: 0.914230
epoch-2 step 360000/3451022 - loss: 0.034915 val_loss: 0.039710	recall: 0.514541 precision: 0.901961

checkpoint saved

epoch-2 step 360100/3451022 - loss: 0.035007 val_loss: 0.036348	recall: 0.548055 precision: 0.897004

model exported!

epoch-2 step 360200/3451022 - loss: 0.034432 val_loss: 0.036539	recall: 0.544318 precision: 0.912381
epoch-2 step 360300/3451022 - loss: 0.037558 val_loss: 0.040003	recall: 0.480042 precision: 0.903162
epoch-2 step 360400/3451022 - loss: 0.034395 val_loss: 0.037759	recall: 0.517685 precision: 0.914773
epoch-2 step 360500/3451022 - loss: 0.041217 val_loss: 0.035905	recall: 0.528604 precision: 0.909449
epoch-2 step 360600/3451022 - loss: 0.036372 val_loss: 0.040100	recall: 0.535714 precision: 0.890805
epoch-2 step 360700/3451022 - loss: 0.035397 val_loss: 0.037721	recall: 0.506772 precision: 0.883858
epoch-2 step 360800/3451022 - loss: 0.034583 val_loss: 0.036963	recall: 0.534884 precision: 0.898438
epoch-2 step 360900/3451022 - loss: 0.036305 val_loss: 0.034503	recall: 0.529412 precision: 0.912525
epoch-2 step 361000/3451022 - loss: 0.047721 val_loss: 0.034593	recall: 0.500534 precision: 0.893333

checkpoint saved

epoch-2 step 361100/3451022 - loss: 0.037780 val_loss: 0.035056	recall: 0.509259 precision: 0.918367
epoch-2 step 361200/3451022 - loss: 0.035196 val_loss: 0.037418	recall: 0.527397 precision: 0.909449
epoch-2 step 361300/3451022 - loss: 0.034711 val_loss: 0.037060	recall: 0.505985 precision: 0.894231
epoch-2 step 361400/3451022 - loss: 0.036016 val_loss: 0.035684	recall: 0.554802 precision: 0.933460
epoch-2 step 361500/3451022 - loss: 0.034865 val_loss: 0.038915	recall: 0.521300 precision: 0.908203
epoch-2 step 361600/3451022 - loss: 0.041991 val_loss: 0.036119	recall: 0.526498 precision: 0.882239
epoch-2 step 361700/3451022 - loss: 0.035890 val_loss: 0.034462	recall: 0.507027 precision: 0.888258
epoch-2 step 361800/3451022 - loss: 0.034961 val_loss: 0.040936	recall: 0.508715 precision: 0.898077
epoch-2 step 361900/3451022 - loss: 0.040290 val_loss: 0.038373	recall: 0.494080 precision: 0.908911
epoch-2 step 362000/3451022 - loss: 0.038322 val_loss: 0.042305	recall: 0.514754 precision: 0.914563

checkpoint saved

epoch-2 step 362100/3451022 - loss: 0.035914 val_loss: 0.034436	recall: 0.498943 precision: 0.893939

model exported!

epoch-2 step 362200/3451022 - loss: 0.034903 val_loss: 0.036637	recall: 0.516930 precision: 0.891051
epoch-2 step 362300/3451022 - loss: 0.040563 val_loss: 0.034688	recall: 0.524917 precision: 0.913295
epoch-2 step 362400/3451022 - loss: 0.035158 val_loss: 0.040785	recall: 0.487831 precision: 0.888247
epoch-2 step 362500/3451022 - loss: 0.037238 val_loss: 0.039278	recall: 0.507400 precision: 0.897196
epoch-2 step 362600/3451022 - loss: 0.035164 val_loss: 0.035817	recall: 0.495885 precision: 0.911153
epoch-2 step 362700/3451022 - loss: 0.039684 val_loss: 0.035928	recall: 0.496388 precision: 0.910985
epoch-2 step 362800/3451022 - loss: 0.036496 val_loss: 0.038708	recall: 0.500531 precision: 0.905769
epoch-2 step 362900/3451022 - loss: 0.036124 val_loss: 0.035561	recall: 0.523060 precision: 0.906433
epoch-2 step 363000/3451022 - loss: 0.035337 val_loss: 0.034880	recall: 0.514192 precision: 0.897143

checkpoint saved

epoch-2 step 363100/3451022 - loss: 0.034110 val_loss: 0.035320	recall: 0.493492 precision: 0.886940
epoch-2 step 363200/3451022 - loss: 0.036801 val_loss: 0.054034	recall: 0.520925 precision: 0.911368
epoch-2 step 363300/3451022 - loss: 0.035359 val_loss: 0.035700	recall: 0.529010 precision: 0.904669
epoch-2 step 363400/3451022 - loss: 0.035313 val_loss: 0.034427	recall: 0.493048 precision: 0.907480
epoch-2 step 363500/3451022 - loss: 0.034249 val_loss: 0.035389	recall: 0.550234 precision: 0.895437
epoch-2 step 363600/3451022 - loss: 0.036265 val_loss: 0.037529	recall: 0.507088 precision: 0.887405
epoch-2 step 363700/3451022 - loss: 0.035829 val_loss: 0.035061	recall: 0.543722 precision: 0.923810
epoch-2 step 363800/3451022 - loss: 0.037254 val_loss: 0.046535	recall: 0.510393 precision: 0.896552
epoch-2 step 363900/3451022 - loss: 0.038255 val_loss: 0.034435	recall: 0.525843 precision: 0.910506
epoch-2 step 364000/3451022 - loss: 0.038568 val_loss: 0.043777	recall: 0.496166 precision: 0.897030

checkpoint saved

epoch-2 step 364100/3451022 - loss: 0.035890 val_loss: 0.035133	recall: 0.527902 precision: 0.920233

model exported!

epoch-2 step 364200/3451022 - loss: 0.035610 val_loss: 0.039897	recall: 0.520971 precision: 0.895636
epoch-2 step 364300/3451022 - loss: 0.035702 val_loss: 0.036451	recall: 0.510251 precision: 0.890656
epoch-2 step 364400/3451022 - loss: 0.049485 val_loss: 0.042258	recall: 0.488698 precision: 0.878143
epoch-2 step 364500/3451022 - loss: 0.039776 val_loss: 0.034599	recall: 0.513691 precision: 0.903661
epoch-2 step 364600/3451022 - loss: 0.036450 val_loss: 0.040021	recall: 0.530822 precision: 0.884030
epoch-2 step 364700/3451022 - loss: 0.035065 val_loss: 0.040999	recall: 0.508511 precision: 0.912214
epoch-2 step 364800/3451022 - loss: 0.035585 val_loss: 0.035528	recall: 0.523702 precision: 0.892308
epoch-2 step 364900/3451022 - loss: 0.035206 val_loss: 0.035561	recall: 0.512739 precision: 0.901119
epoch-2 step 365000/3451022 - loss: 0.041796 val_loss: 0.038824	recall: 0.535673 precision: 0.898039

checkpoint saved

epoch-2 step 365100/3451022 - loss: 0.038167 val_loss: 0.036570	recall: 0.497291 precision: 0.912525
epoch-2 step 365200/3451022 - loss: 0.039159 val_loss: 0.035954	recall: 0.535918 precision: 0.914397
epoch-2 step 365300/3451022 - loss: 0.034972 val_loss: 0.037056	recall: 0.544828 precision: 0.915058
epoch-2 step 365400/3451022 - loss: 0.037318 val_loss: 0.034552	recall: 0.522752 precision: 0.902299
epoch-2 step 365500/3451022 - loss: 0.034397 val_loss: 0.047528	recall: 0.530286 precision: 0.904483
epoch-2 step 365600/3451022 - loss: 0.037715 val_loss: 0.035048	recall: 0.501584 precision: 0.899621
epoch-2 step 365700/3451022 - loss: 0.034983 val_loss: 0.034430	recall: 0.494143 precision: 0.902724
epoch-2 step 365800/3451022 - loss: 0.036122 val_loss: 0.037111	recall: 0.512277 precision: 0.903543
epoch-2 step 365900/3451022 - loss: 0.035364 val_loss: 0.036119	recall: 0.533181 precision: 0.917323
epoch-2 step 366000/3451022 - loss: 0.036868 val_loss: 0.036196	recall: 0.510181 precision: 0.889546

checkpoint saved

epoch-2 step 366100/3451022 - loss: 0.033562 val_loss: 0.036314	recall: 0.495093 precision: 0.902584

model exported!

epoch-2 step 366200/3451022 - loss: 0.037265 val_loss: 0.037725	recall: 0.537228 precision: 0.925049
epoch-2 step 366300/3451022 - loss: 0.037948 val_loss: 0.040000	recall: 0.516520 precision: 0.907157
epoch-2 step 366400/3451022 - loss: 0.037772 val_loss: 0.041369	recall: 0.534025 precision: 0.890385
epoch-2 step 366500/3451022 - loss: 0.038257 val_loss: 0.041320	recall: 0.507609 precision: 0.912109
epoch-2 step 366600/3451022 - loss: 0.036615 val_loss: 0.035914	recall: 0.497899 precision: 0.918605
epoch-2 step 366700/3451022 - loss: 0.046049 val_loss: 0.040163	recall: 0.549941 precision: 0.910506
epoch-2 step 366800/3451022 - loss: 0.039146 val_loss: 0.043356	recall: 0.520652 precision: 0.912381
epoch-2 step 366900/3451022 - loss: 0.034519 val_loss: 0.036719	recall: 0.516411 precision: 0.920078
epoch-2 step 367000/3451022 - loss: 0.036388 val_loss: 0.034122	recall: 0.514100 precision: 0.913295

checkpoint saved

epoch-2 step 367100/3451022 - loss: 0.037491 val_loss: 0.045941	recall: 0.506982 precision: 0.909441
epoch-2 step 367200/3451022 - loss: 0.036504 val_loss: 0.034727	recall: 0.502165 precision: 0.899225
epoch-2 step 367300/3451022 - loss: 0.034852 val_loss: 0.035345	recall: 0.502183 precision: 0.916335
epoch-2 step 367400/3451022 - loss: 0.038353 val_loss: 0.035567	recall: 0.530795 precision: 0.909789
epoch-2 step 367500/3451022 - loss: 0.034850 val_loss: 0.035970	recall: 0.527105 precision: 0.906746
epoch-2 step 367600/3451022 - loss: 0.033961 val_loss: 0.040090	recall: 0.534078 precision: 0.917466
epoch-2 step 367700/3451022 - loss: 0.038414 val_loss: 0.036651	recall: 0.514381 precision: 0.909980
epoch-2 step 367800/3451022 - loss: 0.037760 val_loss: 0.038301	recall: 0.489583 precision: 0.888469
epoch-2 step 367900/3451022 - loss: 0.035491 val_loss: 0.041754	recall: 0.515590 precision: 0.902534
epoch-2 step 368000/3451022 - loss: 0.036872 val_loss: 0.038038	recall: 0.535308 precision: 0.907336

checkpoint saved

epoch-2 step 368100/3451022 - loss: 0.038380 val_loss: 0.034098	recall: 0.508233 precision: 0.918651

model exported!

epoch-2 step 368200/3451022 - loss: 0.036946 val_loss: 0.038819	recall: 0.513543 precision: 0.922179
epoch-2 step 368300/3451022 - loss: 0.034658 val_loss: 0.037570	recall: 0.501581 precision: 0.901515
epoch-2 step 368400/3451022 - loss: 0.033787 val_loss: 0.040694	recall: 0.538551 precision: 0.914683
epoch-2 step 368500/3451022 - loss: 0.035557 val_loss: 0.039281	recall: 0.518987 precision: 0.868979
epoch-2 step 368600/3451022 - loss: 0.045256 val_loss: 0.035202	recall: 0.530752 precision: 0.928287
epoch-2 step 368700/3451022 - loss: 0.035766 val_loss: 0.040044	recall: 0.517505 precision: 0.923828
epoch-2 step 368800/3451022 - loss: 0.040160 val_loss: 0.036594	recall: 0.509783 precision: 0.889943
epoch-2 step 368900/3451022 - loss: 0.048743 val_loss: 0.037619	recall: 0.506508 precision: 0.898077
epoch-2 step 369000/3451022 - loss: 0.039191 val_loss: 0.037965	recall: 0.530303 precision: 0.915888

checkpoint saved

epoch-2 step 369100/3451022 - loss: 0.034382 val_loss: 0.035610	recall: 0.544258 precision: 0.893910
epoch-2 step 369200/3451022 - loss: 0.040710 val_loss: 0.036857	recall: 0.535147 precision: 0.904215
epoch-2 step 369300/3451022 - loss: 0.035515 val_loss: 0.035765	recall: 0.523269 precision: 0.911067
epoch-2 step 369400/3451022 - loss: 0.034373 val_loss: 0.034808	recall: 0.503261 precision: 0.888676
epoch-2 step 369500/3451022 - loss: 0.033937 val_loss: 0.036535	recall: 0.536145 precision: 0.904472
epoch-2 step 369600/3451022 - loss: 0.039489 val_loss: 0.039455	recall: 0.559579 precision: 0.900376
epoch-2 step 369700/3451022 - loss: 0.033946 val_loss: 0.036538	recall: 0.547018 precision: 0.931641
epoch-2 step 369800/3451022 - loss: 0.036937 val_loss: 0.035403	recall: 0.534653 precision: 0.925714
epoch-2 step 369900/3451022 - loss: 0.039161 val_loss: 0.035760	recall: 0.513843 precision: 0.895753
epoch-2 step 370000/3451022 - loss: 0.035454 val_loss: 0.033679	recall: 0.553288 precision: 0.925996

checkpoint saved

epoch-2 step 370100/3451022 - loss: 0.035125 val_loss: 0.035228	recall: 0.504907 precision: 0.897287

model exported!

epoch-2 step 370200/3451022 - loss: 0.034889 val_loss: 0.035057	recall: 0.504435 precision: 0.904573
epoch-2 step 370300/3451022 - loss: 0.034786 val_loss: 0.039638	recall: 0.500000 precision: 0.901734
epoch-2 step 370400/3451022 - loss: 0.036311 val_loss: 0.035599	recall: 0.530355 precision: 0.906067
epoch-2 step 370500/3451022 - loss: 0.034385 val_loss: 0.034816	recall: 0.499469 precision: 0.898662
epoch-2 step 370600/3451022 - loss: 0.036526 val_loss: 0.037850	recall: 0.504886 precision: 0.913556
epoch-2 step 370700/3451022 - loss: 0.040131 val_loss: 0.044110	recall: 0.530769 precision: 0.916509
epoch-2 step 370800/3451022 - loss: 0.036568 val_loss: 0.037808	recall: 0.510504 precision: 0.906716
epoch-2 step 370900/3451022 - loss: 0.035648 val_loss: 0.035689	recall: 0.506369 precision: 0.888268
epoch-2 step 371000/3451022 - loss: 0.034243 val_loss: 0.039433	recall: 0.548611 precision: 0.923977

checkpoint saved

epoch-2 step 371100/3451022 - loss: 0.049505 val_loss: 0.039504	recall: 0.502714 precision: 0.892100
epoch-2 step 371200/3451022 - loss: 0.037811 val_loss: 0.036457	recall: 0.520131 precision: 0.922780
epoch-2 step 371300/3451022 - loss: 0.043904 val_loss: 0.034453	recall: 0.509934 precision: 0.920319
epoch-2 step 371400/3451022 - loss: 0.042997 val_loss: 0.042318	recall: 0.515801 precision: 0.889105
epoch-2 step 371500/3451022 - loss: 0.038060 val_loss: 0.039604	recall: 0.501611 precision: 0.905039
epoch-2 step 371600/3451022 - loss: 0.035644 val_loss: 0.035293	recall: 0.514469 precision: 0.909091
epoch-2 step 371700/3451022 - loss: 0.035213 val_loss: 0.038773	recall: 0.524211 precision: 0.923933
epoch-2 step 371800/3451022 - loss: 0.038466 val_loss: 0.040818	recall: 0.521311 precision: 0.905123
epoch-2 step 371900/3451022 - loss: 0.040176 val_loss: 0.042018	recall: 0.571762 precision: 0.904059
epoch-2 step 372000/3451022 - loss: 0.034482 val_loss: 0.034451	recall: 0.524752 precision: 0.898305

checkpoint saved

epoch-2 step 372100/3451022 - loss: 0.035444 val_loss: 0.036776	recall: 0.550058 precision: 0.928155

model exported!

epoch-2 step 372200/3451022 - loss: 0.036283 val_loss: 0.034076	recall: 0.503759 precision: 0.910680
epoch-2 step 372300/3451022 - loss: 0.040170 val_loss: 0.037968	recall: 0.499441 precision: 0.879921
epoch-2 step 372400/3451022 - loss: 0.040015 val_loss: 0.039666	recall: 0.514532 precision: 0.905303
epoch-2 step 372500/3451022 - loss: 0.050592 val_loss: 0.034733	recall: 0.509249 precision: 0.914062
epoch-2 step 372600/3451022 - loss: 0.046105 val_loss: 0.042176	recall: 0.535274 precision: 0.905303
epoch-2 step 372700/3451022 - loss: 0.035283 val_loss: 0.041248	recall: 0.518764 precision: 0.921569
epoch-2 step 372800/3451022 - loss: 0.035844 val_loss: 0.035638	recall: 0.525539 precision: 0.906067
epoch-2 step 372900/3451022 - loss: 0.037809 val_loss: 0.046572	recall: 0.507058 precision: 0.896353
epoch-2 step 373000/3451022 - loss: 0.035588 val_loss: 0.044843	recall: 0.499454 precision: 0.889105

checkpoint saved

epoch-2 step 373100/3451022 - loss: 0.037196 val_loss: 0.036175	recall: 0.536806 precision: 0.906310
epoch-2 step 373200/3451022 - loss: 0.035905 val_loss: 0.034881	recall: 0.537383 precision: 0.896686
epoch-2 step 373300/3451022 - loss: 0.034188 val_loss: 0.035075	recall: 0.545877 precision: 0.914397
epoch-2 step 373400/3451022 - loss: 0.036924 val_loss: 0.040291	recall: 0.509868 precision: 0.909980
epoch-2 step 373500/3451022 - loss: 0.034837 val_loss: 0.037565	recall: 0.502756 precision: 0.915663
epoch-2 step 373600/3451022 - loss: 0.037230 val_loss: 0.035337	recall: 0.542254 precision: 0.909449
epoch-2 step 373700/3451022 - loss: 0.036668 val_loss: 0.034764	recall: 0.490426 precision: 0.907480
epoch-2 step 373800/3451022 - loss: 0.046372 val_loss: 0.037390	recall: 0.514439 precision: 0.894052
epoch-2 step 373900/3451022 - loss: 0.034334 val_loss: 0.035198	recall: 0.504692 precision: 0.909774
epoch-2 step 374000/3451022 - loss: 0.038620 val_loss: 0.036490	recall: 0.515575 precision: 0.916031

checkpoint saved

epoch-2 step 374100/3451022 - loss: 0.034694 val_loss: 0.034413	recall: 0.549824 precision: 0.903661

model exported!

epoch-2 step 374200/3451022 - loss: 0.039642 val_loss: 0.037204	recall: 0.495187 precision: 0.897287
epoch-2 step 374300/3451022 - loss: 0.035743 val_loss: 0.039640	recall: 0.516201 precision: 0.914851
epoch-2 step 374400/3451022 - loss: 0.035060 val_loss: 0.047834	recall: 0.486111 precision: 0.892157
epoch-2 step 374500/3451022 - loss: 0.035451 val_loss: 0.041987	recall: 0.507119 precision: 0.886973
epoch-2 step 374600/3451022 - loss: 0.037083 val_loss: 0.035394	recall: 0.496881 precision: 0.910476
epoch-2 step 374700/3451022 - loss: 0.036022 val_loss: 0.042523	recall: 0.542141 precision: 0.915385
epoch-2 step 374800/3451022 - loss: 0.035653 val_loss: 0.035544	recall: 0.531111 precision: 0.901887
epoch-2 step 374900/3451022 - loss: 0.039209 val_loss: 0.034871	recall: 0.515184 precision: 0.889513
epoch-2 step 375000/3451022 - loss: 0.034218 val_loss: 0.035102	recall: 0.508197 precision: 0.917160

checkpoint saved

epoch-2 step 375100/3451022 - loss: 0.036139 val_loss: 0.037069	recall: 0.524887 precision: 0.915187
epoch-2 step 375200/3451022 - loss: 0.034163 val_loss: 0.036890	recall: 0.519957 precision: 0.894249
epoch-2 step 375300/3451022 - loss: 0.034362 val_loss: 0.040083	recall: 0.533851 precision: 0.926782
epoch-2 step 375400/3451022 - loss: 0.034589 val_loss: 0.043657	recall: 0.515323 precision: 0.886719
epoch-2 step 375500/3451022 - loss: 0.038258 val_loss: 0.035118	recall: 0.486258 precision: 0.909091
epoch-2 step 375600/3451022 - loss: 0.035605 val_loss: 0.037127	recall: 0.538547 precision: 0.904315
epoch-2 step 375700/3451022 - loss: 0.040218 val_loss: 0.038346	recall: 0.532328 precision: 0.899818
epoch-2 step 375800/3451022 - loss: 0.039961 val_loss: 0.035724	recall: 0.532721 precision: 0.890595
epoch-2 step 375900/3451022 - loss: 0.034639 val_loss: 0.037655	recall: 0.527873 precision: 0.890595
epoch-2 step 376000/3451022 - loss: 0.034977 val_loss: 0.036914	recall: 0.543578 precision: 0.929412

checkpoint saved

epoch-2 step 376100/3451022 - loss: 0.038112 val_loss: 0.035224	recall: 0.506565 precision: 0.868668

model exported!

epoch-2 step 376200/3451022 - loss: 0.042031 val_loss: 0.039342	recall: 0.516129 precision: 0.919540
epoch-2 step 376300/3451022 - loss: 0.040079 val_loss: 0.037364	recall: 0.503158 precision: 0.917466
epoch-2 step 376400/3451022 - loss: 0.036643 val_loss: 0.038730	recall: 0.505605 precision: 0.900200
epoch-2 step 376500/3451022 - loss: 0.034503 val_loss: 0.037921	recall: 0.532423 precision: 0.906977
epoch-2 step 376600/3451022 - loss: 0.036051 val_loss: 0.039665	recall: 0.506342 precision: 0.895327
epoch-2 step 376700/3451022 - loss: 0.036792 val_loss: 0.042067	recall: 0.525862 precision: 0.915572
epoch-2 step 376800/3451022 - loss: 0.038376 val_loss: 0.040093	recall: 0.523969 precision: 0.916179
epoch-2 step 376900/3451022 - loss: 0.034902 val_loss: 0.036385	recall: 0.508197 precision: 0.920792
epoch-2 step 377000/3451022 - loss: 0.034677 val_loss: 0.035437	recall: 0.537853 precision: 0.913628

checkpoint saved

epoch-2 step 377100/3451022 - loss: 0.035385 val_loss: 0.043204	recall: 0.517582 precision: 0.912791
epoch-2 step 377200/3451022 - loss: 0.035180 val_loss: 0.035316	recall: 0.517699 precision: 0.883019
epoch-2 step 377300/3451022 - loss: 0.034962 val_loss: 0.037305	recall: 0.511828 precision: 0.927875
epoch-2 step 377400/3451022 - loss: 0.034982 val_loss: 0.042499	recall: 0.491525 precision: 0.887189
epoch-2 step 377500/3451022 - loss: 0.041770 val_loss: 0.045539	recall: 0.501057 precision: 0.884328
epoch-2 step 377600/3451022 - loss: 0.034423 val_loss: 0.034510	recall: 0.527746 precision: 0.917323
epoch-2 step 377700/3451022 - loss: 0.035873 val_loss: 0.036675	recall: 0.536866 precision: 0.894434
epoch-2 step 377800/3451022 - loss: 0.036196 val_loss: 0.037599	recall: 0.525460 precision: 0.932692
epoch-2 step 377900/3451022 - loss: 0.037918 val_loss: 0.035715	recall: 0.547646 precision: 0.913793
epoch-2 step 378000/3451022 - loss: 0.039753 val_loss: 0.038987	recall: 0.504396 precision: 0.889535

checkpoint saved

epoch-2 step 378100/3451022 - loss: 0.034298 val_loss: 0.035124	recall: 0.557760 precision: 0.907021

model exported!

epoch-2 step 378200/3451022 - loss: 0.035286 val_loss: 0.039399	recall: 0.515856 precision: 0.912150
epoch-2 step 378300/3451022 - loss: 0.036157 val_loss: 0.036826	recall: 0.540632 precision: 0.928295
epoch-2 step 378400/3451022 - loss: 0.038797 val_loss: 0.036073	recall: 0.535880 precision: 0.902534
epoch-2 step 378500/3451022 - loss: 0.034962 val_loss: 0.037656	recall: 0.500000 precision: 0.895551
epoch-2 step 378600/3451022 - loss: 0.037044 val_loss: 0.036269	recall: 0.543478 precision: 0.925926
epoch-2 step 378700/3451022 - loss: 0.034754 val_loss: 0.034037	recall: 0.529010 precision: 0.918972
epoch-2 step 378800/3451022 - loss: 0.037260 val_loss: 0.034359	recall: 0.507230 precision: 0.887160
epoch-2 step 378900/3451022 - loss: 0.035498 val_loss: 0.035109	recall: 0.508909 precision: 0.897839
epoch-2 step 379000/3451022 - loss: 0.034807 val_loss: 0.040682	recall: 0.517738 precision: 0.906796

checkpoint saved

epoch-2 step 379100/3451022 - loss: 0.034647 val_loss: 0.037614	recall: 0.512514 precision: 0.904031
epoch-2 step 379200/3451022 - loss: 0.041163 val_loss: 0.035141	recall: 0.534155 precision: 0.913793
epoch-2 step 379300/3451022 - loss: 0.039609 val_loss: 0.036325	recall: 0.526602 precision: 0.908240
epoch-2 step 379400/3451022 - loss: 0.045358 val_loss: 0.037324	recall: 0.522503 precision: 0.884758
epoch-2 step 379500/3451022 - loss: 0.034970 val_loss: 0.035941	recall: 0.514444 precision: 0.897287
epoch-2 step 379600/3451022 - loss: 0.036068 val_loss: 0.040769	recall: 0.514541 precision: 0.905512
epoch-2 step 379700/3451022 - loss: 0.035117 val_loss: 0.040954	recall: 0.524070 precision: 0.900376
epoch-2 step 379800/3451022 - loss: 0.034283 val_loss: 0.039383	recall: 0.511777 precision: 0.915709
epoch-2 step 379900/3451022 - loss: 0.034726 val_loss: 0.037101	recall: 0.519252 precision: 0.880597
epoch-2 step 380000/3451022 - loss: 0.042073 val_loss: 0.035172	recall: 0.488445 precision: 0.884030

checkpoint saved

epoch-2 step 380100/3451022 - loss: 0.041993 val_loss: 0.037659	recall: 0.553653 precision: 0.913371

model exported!

epoch-2 step 380200/3451022 - loss: 0.040189 val_loss: 0.037901	recall: 0.508811 precision: 0.925852
epoch-2 step 380300/3451022 - loss: 0.035075 val_loss: 0.037398	recall: 0.528115 precision: 0.912381
epoch-2 step 380400/3451022 - loss: 0.035052 val_loss: 0.035765	recall: 0.541430 precision: 0.920849
epoch-2 step 380500/3451022 - loss: 0.041383 val_loss: 0.035365	recall: 0.487208 precision: 0.870775
epoch-2 step 380600/3451022 - loss: 0.039814 val_loss: 0.033513	recall: 0.510799 precision: 0.890772
epoch-2 step 380700/3451022 - loss: 0.035286 val_loss: 0.040624	recall: 0.536782 precision: 0.887833
epoch-2 step 380800/3451022 - loss: 0.041714 val_loss: 0.037307	recall: 0.513143 precision: 0.912602
epoch-2 step 380900/3451022 - loss: 0.035145 val_loss: 0.035656	recall: 0.510941 precision: 0.906796
epoch-2 step 381000/3451022 - loss: 0.035652 val_loss: 0.035839	recall: 0.497303 precision: 0.898635

checkpoint saved

epoch-2 step 381100/3451022 - loss: 0.041736 val_loss: 0.037476	recall: 0.525242 precision: 0.910615
epoch-2 step 381200/3451022 - loss: 0.034840 val_loss: 0.034441	recall: 0.503326 precision: 0.884990
epoch-2 step 381300/3451022 - loss: 0.035671 val_loss: 0.034134	recall: 0.534989 precision: 0.901141
epoch-2 step 381400/3451022 - loss: 0.036274 val_loss: 0.043571	recall: 0.512304 precision: 0.875717
epoch-2 step 381500/3451022 - loss: 0.034664 val_loss: 0.035852	recall: 0.532731 precision: 0.902486
epoch-2 step 381600/3451022 - loss: 0.037549 val_loss: 0.034230	recall: 0.542825 precision: 0.908752
epoch-2 step 381700/3451022 - loss: 0.035406 val_loss: 0.035896	recall: 0.491749 precision: 0.895792
epoch-2 step 381800/3451022 - loss: 0.034951 val_loss: 0.040649	recall: 0.498403 precision: 0.914062
epoch-2 step 381900/3451022 - loss: 0.041866 val_loss: 0.043630	recall: 0.543427 precision: 0.915020
epoch-2 step 382000/3451022 - loss: 0.035123 val_loss: 0.034151	recall: 0.519168 precision: 0.929412

checkpoint saved

epoch-2 step 382100/3451022 - loss: 0.037390 val_loss: 0.039622	recall: 0.540793 precision: 0.924303

model exported!

epoch-2 step 382200/3451022 - loss: 0.035924 val_loss: 0.036070	recall: 0.487207 precision: 0.897839
epoch-2 step 382300/3451022 - loss: 0.036179 val_loss: 0.035261	recall: 0.519829 precision: 0.901487
epoch-2 step 382400/3451022 - loss: 0.036824 val_loss: 0.045736	recall: 0.559165 precision: 0.907721
epoch-2 step 382500/3451022 - loss: 0.041259 val_loss: 0.039168	recall: 0.502825 precision: 0.904472
epoch-2 step 382600/3451022 - loss: 0.035095 val_loss: 0.034808	recall: 0.545970 precision: 0.907547
epoch-2 step 382700/3451022 - loss: 0.033998 val_loss: 0.044436	recall: 0.563981 precision: 0.906667
epoch-2 step 382800/3451022 - loss: 0.034411 val_loss: 0.034927	recall: 0.529794 precision: 0.931429
epoch-2 step 382900/3451022 - loss: 0.034484 val_loss: 0.034925	recall: 0.528217 precision: 0.906977
epoch-2 step 383000/3451022 - loss: 0.036370 val_loss: 0.034625	recall: 0.547674 precision: 0.914563

checkpoint saved

epoch-2 step 383100/3451022 - loss: 0.034373 val_loss: 0.035565	recall: 0.551064 precision: 0.943534
epoch-2 step 383200/3451022 - loss: 0.038269 val_loss: 0.035846	recall: 0.489904 precision: 0.900391
epoch-2 step 383300/3451022 - loss: 0.035935 val_loss: 0.037285	recall: 0.496774 precision: 0.916667
epoch-2 step 383400/3451022 - loss: 0.037405 val_loss: 0.042071	recall: 0.518559 precision: 0.916988
epoch-2 step 383500/3451022 - loss: 0.035686 val_loss: 0.042403	recall: 0.504301 precision: 0.905405
epoch-2 step 383600/3451022 - loss: 0.034381 val_loss: 0.036717	recall: 0.508004 precision: 0.922481
epoch-2 step 383700/3451022 - loss: 0.035254 val_loss: 0.034721	recall: 0.518307 precision: 0.915152
epoch-2 step 383800/3451022 - loss: 0.035539 val_loss: 0.038663	recall: 0.470711 precision: 0.870406
epoch-2 step 383900/3451022 - loss: 0.044262 val_loss: 0.039173	recall: 0.550177 precision: 0.891013
epoch-2 step 384000/3451022 - loss: 0.034732 val_loss: 0.033307	recall: 0.501618 precision: 0.892514

checkpoint saved

epoch-2 step 384100/3451022 - loss: 0.038259 val_loss: 0.034679	recall: 0.562640 precision: 0.921245

model exported!

epoch-2 step 384200/3451022 - loss: 0.042009 val_loss: 0.036353	recall: 0.512360 precision: 0.895874
epoch-2 step 384300/3451022 - loss: 0.041737 val_loss: 0.037323	recall: 0.513575 precision: 0.884990
epoch-2 step 384400/3451022 - loss: 0.036195 val_loss: 0.034061	recall: 0.539062 precision: 0.906191
epoch-2 step 384500/3451022 - loss: 0.033920 val_loss: 0.035396	recall: 0.541190 precision: 0.907869
epoch-2 step 384600/3451022 - loss: 0.035688 val_loss: 0.038675	recall: 0.517660 precision: 0.888258
epoch-2 step 384700/3451022 - loss: 0.035332 val_loss: 0.039377	recall: 0.524571 precision: 0.912525
epoch-2 step 384800/3451022 - loss: 0.038179 val_loss: 0.034601	recall: 0.522624 precision: 0.893617
epoch-2 step 384900/3451022 - loss: 0.034324 val_loss: 0.041453	recall: 0.523375 precision: 0.907115
epoch-2 step 385000/3451022 - loss: 0.035992 val_loss: 0.037181	recall: 0.498385 precision: 0.915020

checkpoint saved

epoch-2 step 385100/3451022 - loss: 0.035312 val_loss: 0.034990	recall: 0.517052 precision: 0.907336
epoch-2 step 385200/3451022 - loss: 0.035654 val_loss: 0.042031	recall: 0.531915 precision: 0.889513
epoch-2 step 385300/3451022 - loss: 0.035119 val_loss: 0.041115	recall: 0.533490 precision: 0.911647
epoch-2 step 385400/3451022 - loss: 0.036002 val_loss: 0.035071	recall: 0.525832 precision: 0.898039
epoch-2 step 385500/3451022 - loss: 0.034795 val_loss: 0.044411	recall: 0.513544 precision: 0.899209
epoch-2 step 385600/3451022 - loss: 0.039007 val_loss: 0.036396	recall: 0.489154 precision: 0.886051
epoch-2 step 385700/3451022 - loss: 0.035571 val_loss: 0.034661	recall: 0.494670 precision: 0.900971
epoch-2 step 385800/3451022 - loss: 0.044285 val_loss: 0.035293	recall: 0.517204 precision: 0.917939
epoch-2 step 385900/3451022 - loss: 0.040938 val_loss: 0.033792	recall: 0.510734 precision: 0.888016
epoch-2 step 386000/3451022 - loss: 0.033767 val_loss: 0.038420	recall: 0.500000 precision: 0.884906

checkpoint saved

epoch-2 step 386100/3451022 - loss: 0.035218 val_loss: 0.034430	recall: 0.493949 precision: 0.896208

model exported!

epoch-2 step 386200/3451022 - loss: 0.035218 val_loss: 0.035315	recall: 0.515254 precision: 0.938272
epoch-2 step 386300/3451022 - loss: 0.034468 val_loss: 0.034882	recall: 0.502165 precision: 0.899225
epoch-2 step 386400/3451022 - loss: 0.033666 val_loss: 0.037822	recall: 0.539503 precision: 0.929961
epoch-2 step 386500/3451022 - loss: 0.034818 val_loss: 0.036645	recall: 0.519729 precision: 0.911067
epoch-2 step 386600/3451022 - loss: 0.036373 val_loss: 0.037348	recall: 0.570743 precision: 0.918919
epoch-2 step 386700/3451022 - loss: 0.037877 val_loss: 0.034193	recall: 0.502714 precision: 0.892100
epoch-2 step 386800/3451022 - loss: 0.042644 val_loss: 0.034991	recall: 0.542002 precision: 0.914563
epoch-2 step 386900/3451022 - loss: 0.039810 val_loss: 0.035552	recall: 0.534730 precision: 0.939922
epoch-2 step 387000/3451022 - loss: 0.035576 val_loss: 0.039729	recall: 0.483264 precision: 0.920319

checkpoint saved

epoch-2 step 387100/3451022 - loss: 0.035758 val_loss: 0.046857	recall: 0.505688 precision: 0.920904
epoch-2 step 387200/3451022 - loss: 0.034581 val_loss: 0.033928	recall: 0.521265 precision: 0.895131
epoch-2 step 387300/3451022 - loss: 0.040907 val_loss: 0.035013	recall: 0.507384 precision: 0.900749
epoch-2 step 387400/3451022 - loss: 0.037791 val_loss: 0.049278	recall: 0.510730 precision: 0.901515
epoch-2 step 387500/3451022 - loss: 0.035803 val_loss: 0.035491	recall: 0.541667 precision: 0.894837
epoch-2 step 387600/3451022 - loss: 0.034358 val_loss: 0.036565	recall: 0.505959 precision: 0.903288
epoch-2 step 387700/3451022 - loss: 0.035200 val_loss: 0.036850	recall: 0.518152 precision: 0.925344
epoch-2 step 387800/3451022 - loss: 0.044473 val_loss: 0.038450	recall: 0.492818 precision: 0.902834
epoch-2 step 387900/3451022 - loss: 0.036011 val_loss: 0.040160	recall: 0.534699 precision: 0.917969
epoch-2 step 388000/3451022 - loss: 0.041842 val_loss: 0.034401	recall: 0.521205 precision: 0.910331

checkpoint saved

epoch-2 step 388100/3451022 - loss: 0.038561 val_loss: 0.035161	recall: 0.513721 precision: 0.900000

model exported!

epoch-2 step 388200/3451022 - loss: 0.034660 val_loss: 0.036951	recall: 0.495652 precision: 0.883721
epoch-2 step 388300/3451022 - loss: 0.034109 val_loss: 0.035267	recall: 0.526375 precision: 0.916016
epoch-2 step 388400/3451022 - loss: 0.035415 val_loss: 0.035502	recall: 0.537500 precision: 0.918447
epoch-2 step 388500/3451022 - loss: 0.035640 val_loss: 0.035867	recall: 0.538547 precision: 0.895911
epoch-2 step 388600/3451022 - loss: 0.039454 val_loss: 0.035826	recall: 0.544653 precision: 0.928571
epoch-2 step 388700/3451022 - loss: 0.035915 val_loss: 0.038742	recall: 0.538549 precision: 0.901328
epoch-2 step 388800/3451022 - loss: 0.039687 val_loss: 0.035314	recall: 0.522854 precision: 0.923228
epoch-2 step 388900/3451022 - loss: 0.036018 val_loss: 0.035473	recall: 0.528620 precision: 0.923529
epoch-2 step 389000/3451022 - loss: 0.042893 val_loss: 0.038470	recall: 0.538991 precision: 0.902111

checkpoint saved

epoch-2 step 389100/3451022 - loss: 0.053523 val_loss: 0.035981	recall: 0.540387 precision: 0.933202
epoch-2 step 389200/3451022 - loss: 0.036935 val_loss: 0.035267	recall: 0.556593 precision: 0.903409
epoch-2 step 389300/3451022 - loss: 0.035499 val_loss: 0.037698	recall: 0.533557 precision: 0.920849
epoch-2 step 389400/3451022 - loss: 0.035662 val_loss: 0.036767	recall: 0.507511 precision: 0.914894
epoch-2 step 389500/3451022 - loss: 0.041339 val_loss: 0.034883	recall: 0.521882 precision: 0.922631
epoch-2 step 389600/3451022 - loss: 0.037542 val_loss: 0.036180	recall: 0.525084 precision: 0.916342
epoch-2 step 389700/3451022 - loss: 0.035074 val_loss: 0.038946	recall: 0.515487 precision: 0.901354
epoch-2 step 389800/3451022 - loss: 0.036458 val_loss: 0.036566	recall: 0.508602 precision: 0.916667
epoch-2 step 389900/3451022 - loss: 0.036708 val_loss: 0.037793	recall: 0.491323 precision: 0.904192
epoch-2 step 390000/3451022 - loss: 0.035285 val_loss: 0.038861	recall: 0.544532 precision: 0.894444

checkpoint saved

epoch-2 step 390100/3451022 - loss: 0.036118 val_loss: 0.034630	recall: 0.470468 precision: 0.875000

model exported!

epoch-2 step 390200/3451022 - loss: 0.034929 val_loss: 0.034676	recall: 0.506565 precision: 0.918651
epoch-2 step 390300/3451022 - loss: 0.036445 val_loss: 0.035670	recall: 0.503311 precision: 0.923077
epoch-2 step 390400/3451022 - loss: 0.035973 val_loss: 0.035222	recall: 0.483607 precision: 0.897338
epoch-2 step 390500/3451022 - loss: 0.041198 val_loss: 0.037354	recall: 0.515660 precision: 0.866541
epoch-2 step 390600/3451022 - loss: 0.037837 val_loss: 0.034908	recall: 0.502096 precision: 0.905482
epoch-2 step 390700/3451022 - loss: 0.036107 val_loss: 0.039425	recall: 0.498382 precision: 0.905882
epoch-2 step 390800/3451022 - loss: 0.035868 val_loss: 0.036004	recall: 0.524887 precision: 0.904483
epoch-2 step 390900/3451022 - loss: 0.036447 val_loss: 0.040870	recall: 0.511351 precision: 0.916667
epoch-2 step 391000/3451022 - loss: 0.037458 val_loss: 0.035041	recall: 0.543900 precision: 0.908571

checkpoint saved

epoch-2 step 391100/3451022 - loss: 0.034587 val_loss: 0.035591	recall: 0.515873 precision: 0.890411
epoch-2 step 391200/3451022 - loss: 0.036659 val_loss: 0.036787	recall: 0.525696 precision: 0.926415
epoch-2 step 391300/3451022 - loss: 0.040539 val_loss: 0.034175	recall: 0.524430 precision: 0.896104
epoch-2 step 391400/3451022 - loss: 0.034946 val_loss: 0.037317	recall: 0.532967 precision: 0.908240
epoch-2 step 391500/3451022 - loss: 0.034814 val_loss: 0.037762	recall: 0.505519 precision: 0.917836
epoch-2 step 391600/3451022 - loss: 0.035092 val_loss: 0.035843	recall: 0.501615 precision: 0.896154
epoch-2 step 391700/3451022 - loss: 0.035502 val_loss: 0.040700	recall: 0.493222 precision: 0.909615
epoch-2 step 391800/3451022 - loss: 0.035978 val_loss: 0.041961	recall: 0.515453 precision: 0.905039
epoch-2 step 391900/3451022 - loss: 0.040467 val_loss: 0.037061	recall: 0.493802 precision: 0.928155
epoch-2 step 392000/3451022 - loss: 0.034222 val_loss: 0.039508	recall: 0.493631 precision: 0.885714

checkpoint saved

epoch-2 step 392100/3451022 - loss: 0.035563 val_loss: 0.038632	recall: 0.520487 precision: 0.903846

model exported!

epoch-2 step 392200/3451022 - loss: 0.036488 val_loss: 0.034529	recall: 0.506696 precision: 0.900794
epoch-2 step 392300/3451022 - loss: 0.033940 val_loss: 0.051312	recall: 0.513575 precision: 0.897233
epoch-2 step 392400/3451022 - loss: 0.034828 val_loss: 0.038277	recall: 0.500000 precision: 0.916350
epoch-2 step 392500/3451022 - loss: 0.041335 val_loss: 0.036256	recall: 0.508639 precision: 0.878731
epoch-2 step 392600/3451022 - loss: 0.036052 val_loss: 0.033899	recall: 0.486182 precision: 0.908222
epoch-2 step 392700/3451022 - loss: 0.035227 val_loss: 0.052230	recall: 0.519084 precision: 0.915385
epoch-2 step 392800/3451022 - loss: 0.036661 val_loss: 0.034804	recall: 0.481633 precision: 0.909441
epoch-2 step 392900/3451022 - loss: 0.037366 val_loss: 0.039626	recall: 0.520087 precision: 0.907197
epoch-2 step 393000/3451022 - loss: 0.035133 val_loss: 0.037205	recall: 0.505998 precision: 0.906250

checkpoint saved

epoch-2 step 393100/3451022 - loss: 0.035382 val_loss: 0.052294	recall: 0.539631 precision: 0.925512
epoch-2 step 393200/3451022 - loss: 0.035284 val_loss: 0.034475	recall: 0.517660 precision: 0.903661
epoch-2 step 393300/3451022 - loss: 0.035095 val_loss: 0.045675	recall: 0.524444 precision: 0.921875
epoch-2 step 393400/3451022 - loss: 0.034530 val_loss: 0.036411	recall: 0.479233 precision: 0.882353
epoch-2 step 393500/3451022 - loss: 0.034560 val_loss: 0.042571	recall: 0.510270 precision: 0.892250
epoch-2 step 393600/3451022 - loss: 0.037427 val_loss: 0.036073	recall: 0.521289 precision: 0.898810
epoch-2 step 393700/3451022 - loss: 0.033913 val_loss: 0.041457	recall: 0.513216 precision: 0.896154
epoch-2 step 393800/3451022 - loss: 0.034964 val_loss: 0.036479	recall: 0.542703 precision: 0.936567
epoch-2 step 393900/3451022 - loss: 0.037119 val_loss: 0.035111	recall: 0.516578 precision: 0.913043
epoch-2 step 394000/3451022 - loss: 0.035992 val_loss: 0.041607	recall: 0.473520 precision: 0.904762

checkpoint saved

epoch-2 step 394100/3451022 - loss: 0.035359 val_loss: 0.040951	recall: 0.522624 precision: 0.893617

model exported!

epoch-2 step 394200/3451022 - loss: 0.035861 val_loss: 0.043239	recall: 0.496802 precision: 0.920949
epoch-2 step 394300/3451022 - loss: 0.034644 val_loss: 0.036864	recall: 0.525696 precision: 0.924670
epoch-2 step 394400/3451022 - loss: 0.035582 val_loss: 0.033482	recall: 0.504587 precision: 0.909926
epoch-2 step 394500/3451022 - loss: 0.035288 val_loss: 0.035531	recall: 0.493896 precision: 0.888224
epoch-2 step 394600/3451022 - loss: 0.036940 val_loss: 0.034526	recall: 0.530134 precision: 0.916988
epoch-2 step 394700/3451022 - loss: 0.036985 val_loss: 0.041324	recall: 0.530795 precision: 0.913295
epoch-2 step 394800/3451022 - loss: 0.036424 val_loss: 0.046683	recall: 0.511278 precision: 0.889720
epoch-2 step 394900/3451022 - loss: 0.039248 val_loss: 0.038077	recall: 0.512415 precision: 0.900794
epoch-2 step 395000/3451022 - loss: 0.039157 val_loss: 0.035785	recall: 0.516977 precision: 0.909441

checkpoint saved

epoch-2 step 395100/3451022 - loss: 0.035244 val_loss: 0.036900	recall: 0.508811 precision: 0.922156
epoch-2 step 395200/3451022 - loss: 0.035781 val_loss: 0.033918	recall: 0.514009 precision: 0.922631
epoch-2 step 395300/3451022 - loss: 0.035335 val_loss: 0.040765	recall: 0.528139 precision: 0.912150
epoch-2 step 395400/3451022 - loss: 0.034138 val_loss: 0.035545	recall: 0.522453 precision: 0.920849
epoch-2 step 395500/3451022 - loss: 0.038784 val_loss: 0.041589	recall: 0.514253 precision: 0.903808
epoch-2 step 395600/3451022 - loss: 0.035348 val_loss: 0.035341	recall: 0.518478 precision: 0.929825
epoch-2 step 395700/3451022 - loss: 0.039177 val_loss: 0.045880	recall: 0.551282 precision: 0.900952
epoch-2 step 395800/3451022 - loss: 0.035388 val_loss: 0.045479	recall: 0.513605 precision: 0.915152
epoch-2 step 395900/3451022 - loss: 0.036045 val_loss: 0.035542	recall: 0.520386 precision: 0.915094
epoch-2 step 396000/3451022 - loss: 0.034461 val_loss: 0.035376	recall: 0.510870 precision: 0.881801

checkpoint saved

epoch-2 step 396100/3451022 - loss: 0.039823 val_loss: 0.037410	recall: 0.523702 precision: 0.892308

model exported!

epoch-2 step 396200/3451022 - loss: 0.034782 val_loss: 0.038840	recall: 0.538808 precision: 0.905482
epoch-2 step 396300/3451022 - loss: 0.035391 val_loss: 0.037080	recall: 0.554670 precision: 0.908582
epoch-2 step 396400/3451022 - loss: 0.036817 val_loss: 0.036924	recall: 0.524684 precision: 0.904950
epoch-2 step 396500/3451022 - loss: 0.035587 val_loss: 0.034520	recall: 0.523862 precision: 0.907692
epoch-2 step 396600/3451022 - loss: 0.035677 val_loss: 0.034184	recall: 0.502232 precision: 0.887574
epoch-2 step 396700/3451022 - loss: 0.035056 val_loss: 0.038187	recall: 0.546498 precision: 0.918919
epoch-2 step 396800/3451022 - loss: 0.040803 val_loss: 0.043878	recall: 0.533333 precision: 0.905950
epoch-2 step 396900/3451022 - loss: 0.036874 val_loss: 0.034109	recall: 0.541899 precision: 0.925573
epoch-2 step 397000/3451022 - loss: 0.035579 val_loss: 0.034982	recall: 0.519819 precision: 0.879310

checkpoint saved

epoch-2 step 397100/3451022 - loss: 0.035822 val_loss: 0.035991	recall: 0.511931 precision: 0.914729
epoch-2 step 397200/3451022 - loss: 0.039152 val_loss: 0.037179	recall: 0.498389 precision: 0.883810
epoch-2 step 397300/3451022 - loss: 0.035661 val_loss: 0.035034	recall: 0.542088 precision: 0.923518
epoch-2 step 397400/3451022 - loss: 0.037204 val_loss: 0.035676	recall: 0.506878 precision: 0.919386
epoch-2 step 397500/3451022 - loss: 0.035930 val_loss: 0.036654	recall: 0.530187 precision: 0.936047
epoch-2 step 397600/3451022 - loss: 0.040988 val_loss: 0.035055	recall: 0.470524 precision: 0.858566
epoch-2 step 397700/3451022 - loss: 0.035544 val_loss: 0.035287	recall: 0.557491 precision: 0.919540
epoch-2 step 397800/3451022 - loss: 0.034761 val_loss: 0.036038	recall: 0.537768 precision: 0.906844
epoch-2 step 397900/3451022 - loss: 0.036281 val_loss: 0.035001	recall: 0.526667 precision: 0.922179
epoch-2 step 398000/3451022 - loss: 0.035463 val_loss: 0.035937	recall: 0.524138 precision: 0.895874

checkpoint saved

epoch-2 step 398100/3451022 - loss: 0.047983 val_loss: 0.034553	recall: 0.531390 precision: 0.890977

model exported!

epoch-2 step 398200/3451022 - loss: 0.034329 val_loss: 0.036084	recall: 0.533482 precision: 0.913958
epoch-2 step 398300/3451022 - loss: 0.034819 val_loss: 0.038743	recall: 0.523756 precision: 0.899029
epoch-2 step 398400/3451022 - loss: 0.036153 val_loss: 0.035041	recall: 0.544828 precision: 0.929412
epoch-2 step 398500/3451022 - loss: 0.036476 val_loss: 0.034977	recall: 0.538025 precision: 0.915058
epoch-2 step 398600/3451022 - loss: 0.034143 val_loss: 0.034576	recall: 0.514100 precision: 0.908046
epoch-2 step 398700/3451022 - loss: 0.035073 val_loss: 0.037914	recall: 0.526674 precision: 0.895753
epoch-2 step 398800/3451022 - loss: 0.034352 val_loss: 0.039582	recall: 0.510428 precision: 0.908203
epoch-2 step 398900/3451022 - loss: 0.035183 val_loss: 0.034931	recall: 0.514254 precision: 0.905405
epoch-2 step 399000/3451022 - loss: 0.064980 val_loss: 0.035975	recall: 0.520548 precision: 0.887160

checkpoint saved

epoch-2 step 399100/3451022 - loss: 0.045440 val_loss: 0.034969	recall: 0.513751 precision: 0.905039
epoch-2 step 399200/3451022 - loss: 0.041338 val_loss: 0.034198	recall: 0.519509 precision: 0.894434
epoch-2 step 399300/3451022 - loss: 0.033973 val_loss: 0.040880	recall: 0.561176 precision: 0.913793
epoch-2 step 399400/3451022 - loss: 0.035951 val_loss: 0.042305	recall: 0.490850 precision: 0.910180
epoch-2 step 399500/3451022 - loss: 0.036672 val_loss: 0.036119	recall: 0.488197 precision: 0.904573
epoch-2 step 399600/3451022 - loss: 0.039720 val_loss: 0.039581	recall: 0.493048 precision: 0.905697
epoch-2 step 399700/3451022 - loss: 0.049787 val_loss: 0.036446	recall: 0.515917 precision: 0.888469
epoch-2 step 399800/3451022 - loss: 0.036096 val_loss: 0.035216	recall: 0.561503 precision: 0.904587
epoch-2 step 399900/3451022 - loss: 0.034467 val_loss: 0.035041	recall: 0.490644 precision: 0.877323
epoch-2 step 400000/3451022 - loss: 0.035225 val_loss: 0.034701	recall: 0.506849 precision: 0.909263

checkpoint saved

epoch-2 step 400100/3451022 - loss: 0.041959 val_loss: 0.037826	recall: 0.509605 precision: 0.905622

model exported!

epoch-2 step 400200/3451022 - loss: 0.035227 val_loss: 0.036016	recall: 0.528571 precision: 0.876138
epoch-2 step 400300/3451022 - loss: 0.035610 val_loss: 0.038742	recall: 0.522523 precision: 0.900971
epoch-2 step 400400/3451022 - loss: 0.034515 val_loss: 0.035852	recall: 0.483633 precision: 0.901575
epoch-2 step 400500/3451022 - loss: 0.041470 val_loss: 0.034861	recall: 0.538717 precision: 0.915414
epoch-2 step 400600/3451022 - loss: 0.033809 val_loss: 0.046859	recall: 0.500000 precision: 0.869732
epoch-2 step 400700/3451022 - loss: 0.038430 val_loss: 0.036598	recall: 0.529412 precision: 0.910506
epoch-2 step 400800/3451022 - loss: 0.039470 val_loss: 0.036219	recall: 0.515152 precision: 0.882692
epoch-2 step 400900/3451022 - loss: 0.038081 val_loss: 0.037503	recall: 0.533792 precision: 0.896154
epoch-2 step 401000/3451022 - loss: 0.036962 val_loss: 0.038529	recall: 0.508869 precision: 0.882692

checkpoint saved

epoch-2 step 401100/3451022 - loss: 0.035879 val_loss: 0.044197	recall: 0.519016 precision: 0.909804
epoch-2 step 401200/3451022 - loss: 0.035744 val_loss: 0.038484	recall: 0.527211 precision: 0.897683
epoch-2 step 401300/3451022 - loss: 0.042016 val_loss: 0.035746	recall: 0.507812 precision: 0.886940
epoch-2 step 401400/3451022 - loss: 0.034574 val_loss: 0.037911	recall: 0.547018 precision: 0.920849
epoch-2 step 401500/3451022 - loss: 0.034996 val_loss: 0.035281	recall: 0.527397 precision: 0.886756
epoch-2 step 401600/3451022 - loss: 0.035341 val_loss: 0.036024	recall: 0.533958 precision: 0.902970
epoch-2 step 401700/3451022 - loss: 0.035963 val_loss: 0.036084	recall: 0.520763 precision: 0.902724
epoch-2 step 401800/3451022 - loss: 0.035010 val_loss: 0.035749	recall: 0.519252 precision: 0.920078
epoch-2 step 401900/3451022 - loss: 0.036133 val_loss: 0.034529	recall: 0.515152 precision: 0.896422
epoch-2 step 402000/3451022 - loss: 0.034398 val_loss: 0.034720	recall: 0.519641 precision: 0.907843

checkpoint saved

epoch-2 step 402100/3451022 - loss: 0.036947 val_loss: 0.037584	recall: 0.512707 precision: 0.902724

model exported!

epoch-2 step 402200/3451022 - loss: 0.040801 val_loss: 0.044809	recall: 0.510451 precision: 0.880455
epoch-2 step 402300/3451022 - loss: 0.041344 val_loss: 0.035049	recall: 0.528492 precision: 0.894140
epoch-2 step 402400/3451022 - loss: 0.034004 val_loss: 0.034475	recall: 0.533333 precision: 0.918288
epoch-2 step 402500/3451022 - loss: 0.035661 val_loss: 0.040479	recall: 0.502668 precision: 0.905769
epoch-2 step 402600/3451022 - loss: 0.034123 val_loss: 0.043430	recall: 0.542002 precision: 0.898855
epoch-2 step 402700/3451022 - loss: 0.040051 val_loss: 0.035194	recall: 0.551122 precision: 0.873518
epoch-2 step 402800/3451022 - loss: 0.037638 val_loss: 0.036406	recall: 0.596177 precision: 0.922366
epoch-2 step 402900/3451022 - loss: 0.041607 val_loss: 0.036448	recall: 0.511853 precision: 0.909962
epoch-2 step 403000/3451022 - loss: 0.035161 val_loss: 0.036107	recall: 0.501661 precision: 0.902390

checkpoint saved

epoch-2 step 403100/3451022 - loss: 0.034070 val_loss: 0.035323	recall: 0.518640 precision: 0.913127
epoch-2 step 403200/3451022 - loss: 0.036490 val_loss: 0.037307	recall: 0.508830 precision: 0.920160
epoch-2 step 403300/3451022 - loss: 0.035047 val_loss: 0.045136	recall: 0.514806 precision: 0.872587
epoch-2 step 403400/3451022 - loss: 0.035331 val_loss: 0.038935	recall: 0.497436 precision: 0.918561
epoch-2 step 403500/3451022 - loss: 0.037778 val_loss: 0.038633	recall: 0.529876 precision: 0.898662
epoch-2 step 403600/3451022 - loss: 0.036796 val_loss: 0.034829	recall: 0.536842 precision: 0.905325
epoch-2 step 403700/3451022 - loss: 0.036711 val_loss: 0.051724	recall: 0.555426 precision: 0.901515
epoch-2 step 403800/3451022 - loss: 0.034585 val_loss: 0.036654	recall: 0.490835 precision: 0.912879
epoch-2 step 403900/3451022 - loss: 0.043624 val_loss: 0.041386	recall: 0.515017 precision: 0.913215
epoch-2 step 404000/3451022 - loss: 0.034534 val_loss: 0.038972	recall: 0.498357 precision: 0.885214

checkpoint saved

epoch-2 step 404100/3451022 - loss: 0.036920 val_loss: 0.046124	recall: 0.520487 precision: 0.910853

model exported!

epoch-2 step 404200/3451022 - loss: 0.036181 val_loss: 0.044076	recall: 0.500550 precision: 0.910000
epoch-2 step 404300/3451022 - loss: 0.047959 val_loss: 0.034879	recall: 0.535017 precision: 0.910156
epoch-2 step 404400/3451022 - loss: 0.038885 val_loss: 0.035249	recall: 0.541040 precision: 0.923077
epoch-2 step 404500/3451022 - loss: 0.045566 val_loss: 0.036167	recall: 0.529670 precision: 0.887661
epoch-2 step 404600/3451022 - loss: 0.034767 val_loss: 0.037710	recall: 0.524943 precision: 0.895551
epoch-2 step 404700/3451022 - loss: 0.035326 val_loss: 0.039325	recall: 0.522727 precision: 0.888031
epoch-2 step 404800/3451022 - loss: 0.034837 val_loss: 0.033916	recall: 0.523077 precision: 0.910134
epoch-2 step 404900/3451022 - loss: 0.035055 val_loss: 0.046144	recall: 0.532131 precision: 0.920078
epoch-2 step 405000/3451022 - loss: 0.035158 val_loss: 0.037830	recall: 0.503825 precision: 0.893411

checkpoint saved

epoch-2 step 405100/3451022 - loss: 0.036733 val_loss: 0.034797	recall: 0.547648 precision: 0.915323
epoch-2 step 405200/3451022 - loss: 0.041284 val_loss: 0.038700	recall: 0.528509 precision: 0.919847
epoch-2 step 405300/3451022 - loss: 0.061878 val_loss: 0.041399	recall: 0.517280 precision: 0.915187
epoch-2 step 405400/3451022 - loss: 0.036877 val_loss: 0.034966	recall: 0.502793 precision: 0.905433
epoch-2 step 405500/3451022 - loss: 0.035130 val_loss: 0.035334	recall: 0.515284 precision: 0.904215
epoch-2 step 405600/3451022 - loss: 0.035044 val_loss: 0.037546	recall: 0.518919 precision: 0.883978
epoch-2 step 405700/3451022 - loss: 0.039059 val_loss: 0.034214	recall: 0.532058 precision: 0.900952
epoch-2 step 405800/3451022 - loss: 0.043101 val_loss: 0.038306	recall: 0.531067 precision: 0.877907
epoch-2 step 405900/3451022 - loss: 0.037288 val_loss: 0.035503	recall: 0.528345 precision: 0.911937
epoch-2 step 406000/3451022 - loss: 0.043690 val_loss: 0.034600	recall: 0.531357 precision: 0.897881

checkpoint saved

epoch-2 step 406100/3451022 - loss: 0.037577 val_loss: 0.038399	recall: 0.528926 precision: 0.903226

model exported!

epoch-2 step 406200/3451022 - loss: 0.036315 val_loss: 0.044759	recall: 0.529412 precision: 0.916168
epoch-2 step 406300/3451022 - loss: 0.038844 val_loss: 0.036594	recall: 0.523702 precision: 0.920635
epoch-2 step 406400/3451022 - loss: 0.035707 val_loss: 0.035434	recall: 0.528153 precision: 0.896750
epoch-2 step 406500/3451022 - loss: 0.035118 val_loss: 0.038105	recall: 0.542237 precision: 0.911708
epoch-2 step 406600/3451022 - loss: 0.036884 val_loss: 0.035135	recall: 0.531963 precision: 0.892720
epoch-2 step 406700/3451022 - loss: 0.035913 val_loss: 0.034655	recall: 0.509692 precision: 0.908537
epoch-2 step 406800/3451022 - loss: 0.035832 val_loss: 0.040596	recall: 0.513455 precision: 0.901701
epoch-2 step 406900/3451022 - loss: 0.039183 val_loss: 0.038061	recall: 0.540089 precision: 0.930902
epoch-2 step 407000/3451022 - loss: 0.044187 val_loss: 0.035670	recall: 0.531765 precision: 0.900398

checkpoint saved

epoch-2 step 407100/3451022 - loss: 0.035104 val_loss: 0.036593	recall: 0.524076 precision: 0.924901
epoch-2 step 407200/3451022 - loss: 0.036560 val_loss: 0.038355	recall: 0.529002 precision: 0.892368
epoch-2 step 407300/3451022 - loss: 0.035006 val_loss: 0.034746	recall: 0.544318 precision: 0.895327
epoch-2 step 407400/3451022 - loss: 0.035664 val_loss: 0.035569	recall: 0.531746 precision: 0.914230
epoch-2 step 407500/3451022 - loss: 0.033817 val_loss: 0.038893	recall: 0.533410 precision: 0.902534
epoch-2 step 407600/3451022 - loss: 0.035697 val_loss: 0.041890	recall: 0.535918 precision: 0.916179
epoch-2 step 407700/3451022 - loss: 0.036527 val_loss: 0.037456	recall: 0.492358 precision: 0.889546
epoch-2 step 407800/3451022 - loss: 0.034877 val_loss: 0.039023	recall: 0.537554 precision: 0.912568
epoch-2 step 407900/3451022 - loss: 0.043827 val_loss: 0.036001	recall: 0.519466 precision: 0.917485
epoch-2 step 408000/3451022 - loss: 0.036107 val_loss: 0.034550	recall: 0.518560 precision: 0.896887

checkpoint saved

epoch-2 step 408100/3451022 - loss: 0.036874 val_loss: 0.039017	recall: 0.523112 precision: 0.885496

model exported!

epoch-2 step 408200/3451022 - loss: 0.035693 val_loss: 0.035779	recall: 0.502750 precision: 0.923232
epoch-2 step 408300/3451022 - loss: 0.035479 val_loss: 0.035059	recall: 0.522752 precision: 0.919922
epoch-2 step 408400/3451022 - loss: 0.037038 val_loss: 0.034609	recall: 0.490779 precision: 0.917625
epoch-2 step 408500/3451022 - loss: 0.039138 val_loss: 0.038715	recall: 0.528153 precision: 0.893333
epoch-2 step 408600/3451022 - loss: 0.034295 val_loss: 0.035266	recall: 0.519694 precision: 0.925926
epoch-2 step 408700/3451022 - loss: 0.036845 val_loss: 0.039328	recall: 0.532382 precision: 0.894834
epoch-2 step 408800/3451022 - loss: 0.036764 val_loss: 0.045534	recall: 0.505605 precision: 0.880859
epoch-2 step 408900/3451022 - loss: 0.035370 val_loss: 0.044006	recall: 0.530474 precision: 0.909091
epoch-2 step 409000/3451022 - loss: 0.036735 val_loss: 0.038466	recall: 0.523697 precision: 0.875248

checkpoint saved

epoch-2 step 409100/3451022 - loss: 0.042009 val_loss: 0.036224	recall: 0.507543 precision: 0.892045
epoch-2 step 409200/3451022 - loss: 0.042192 val_loss: 0.042600	recall: 0.518477 precision: 0.915020
epoch-2 step 409300/3451022 - loss: 0.038234 val_loss: 0.036672	recall: 0.532887 precision: 0.901887
epoch-2 step 409400/3451022 - loss: 0.034876 val_loss: 0.034245	recall: 0.538462 precision: 0.907157
epoch-2 step 409500/3451022 - loss: 0.035086 val_loss: 0.041981	recall: 0.526776 precision: 0.937743
epoch-2 step 409600/3451022 - loss: 0.035760 val_loss: 0.036428	recall: 0.527056 precision: 0.932950
epoch-2 step 409700/3451022 - loss: 0.038285 val_loss: 0.037335	recall: 0.517778 precision: 0.906615
epoch-2 step 409800/3451022 - loss: 0.035296 val_loss: 0.043259	recall: 0.513631 precision: 0.897143
epoch-2 step 409900/3451022 - loss: 0.035305 val_loss: 0.034899	recall: 0.509209 precision: 0.900383
epoch-2 step 410000/3451022 - loss: 0.034545 val_loss: 0.038362	recall: 0.539754 precision: 0.911153

checkpoint saved

epoch-2 step 410100/3451022 - loss: 0.035213 val_loss: 0.035519	recall: 0.503212 precision: 0.921569

model exported!

epoch-2 step 410200/3451022 - loss: 0.033981 val_loss: 0.035660	recall: 0.498416 precision: 0.905950
epoch-2 step 410300/3451022 - loss: 0.045524 val_loss: 0.033924	recall: 0.552257 precision: 0.917160
epoch-2 step 410400/3451022 - loss: 0.036886 val_loss: 0.056865	recall: 0.521081 precision: 0.934109
epoch-2 step 410500/3451022 - loss: 0.035002 val_loss: 0.042935	recall: 0.511727 precision: 0.903955
epoch-2 step 410600/3451022 - loss: 0.035946 val_loss: 0.036435	recall: 0.492489 precision: 0.896484
epoch-2 step 410700/3451022 - loss: 0.037188 val_loss: 0.045894	recall: 0.478964 precision: 0.863813
epoch-2 step 410800/3451022 - loss: 0.035013 val_loss: 0.035108	recall: 0.521505 precision: 0.916824
epoch-2 step 410900/3451022 - loss: 0.036918 val_loss: 0.035827	recall: 0.515723 precision: 0.919626
epoch-2 step 411000/3451022 - loss: 0.034536 val_loss: 0.038233	recall: 0.488421 precision: 0.902724

checkpoint saved

epoch-2 step 411100/3451022 - loss: 0.036084 val_loss: 0.037976	recall: 0.525054 precision: 0.914611
epoch-2 step 411200/3451022 - loss: 0.035572 val_loss: 0.035593	recall: 0.544843 precision: 0.913534
epoch-2 step 411300/3451022 - loss: 0.036201 val_loss: 0.040720	recall: 0.541814 precision: 0.896686
epoch-2 step 411400/3451022 - loss: 0.035907 val_loss: 0.034889	recall: 0.503247 precision: 0.924453
epoch-2 step 411500/3451022 - loss: 0.041590 val_loss: 0.035884	recall: 0.495745 precision: 0.917323
epoch-2 step 411600/3451022 - loss: 0.033963 val_loss: 0.035079	recall: 0.515812 precision: 0.906130
epoch-2 step 411700/3451022 - loss: 0.034963 val_loss: 0.038924	recall: 0.514192 precision: 0.919922
epoch-2 step 411800/3451022 - loss: 0.038102 val_loss: 0.035860	recall: 0.536935 precision: 0.915414
epoch-2 step 411900/3451022 - loss: 0.035508 val_loss: 0.033612	recall: 0.522124 precision: 0.907692
epoch-2 step 412000/3451022 - loss: 0.035452 val_loss: 0.034102	recall: 0.502146 precision: 0.896552

checkpoint saved

epoch-2 step 412100/3451022 - loss: 0.037038 val_loss: 0.036138	recall: 0.529148 precision: 0.916505

model exported!

epoch-2 step 412200/3451022 - loss: 0.035968 val_loss: 0.039773	recall: 0.522779 precision: 0.882692
epoch-2 step 412300/3451022 - loss: 0.036385 val_loss: 0.038000	recall: 0.522803 precision: 0.891841
epoch-2 step 412400/3451022 - loss: 0.037378 val_loss: 0.041584	recall: 0.561237 precision: 0.904215
epoch-2 step 412500/3451022 - loss: 0.035289 val_loss: 0.035343	recall: 0.532058 precision: 0.916667
epoch-2 step 412600/3451022 - loss: 0.037543 val_loss: 0.037275	recall: 0.530658 precision: 0.903226
epoch-2 step 412700/3451022 - loss: 0.036800 val_loss: 0.034804	recall: 0.495050 precision: 0.892857
epoch-2 step 412800/3451022 - loss: 0.034526 val_loss: 0.036473	recall: 0.531719 precision: 0.905697
epoch-2 step 412900/3451022 - loss: 0.034980 val_loss: 0.034163	recall: 0.539150 precision: 0.930502
epoch-2 step 413000/3451022 - loss: 0.036725 val_loss: 0.034745	recall: 0.530945 precision: 0.900552

checkpoint saved

epoch-2 step 413100/3451022 - loss: 0.036344 val_loss: 0.036257	recall: 0.520925 precision: 0.907869
epoch-2 step 413200/3451022 - loss: 0.035436 val_loss: 0.038883	recall: 0.472988 precision: 0.880903
epoch-2 step 413300/3451022 - loss: 0.035855 val_loss: 0.034781	recall: 0.526549 precision: 0.918919
epoch-2 step 413400/3451022 - loss: 0.037340 val_loss: 0.034598	recall: 0.504918 precision: 0.885057
epoch-2 step 413500/3451022 - loss: 0.038275 val_loss: 0.035063	recall: 0.510497 precision: 0.900585
epoch-2 step 413600/3451022 - loss: 0.034029 val_loss: 0.035469	recall: 0.504907 precision: 0.915020
epoch-2 step 413700/3451022 - loss: 0.036633 val_loss: 0.034568	recall: 0.471241 precision: 0.872897
epoch-2 step 413800/3451022 - loss: 0.035954 val_loss: 0.041058	recall: 0.514130 precision: 0.900952
epoch-2 step 413900/3451022 - loss: 0.037074 val_loss: 0.040180	recall: 0.535274 precision: 0.898496
epoch-2 step 414000/3451022 - loss: 0.035641 val_loss: 0.036098	recall: 0.498911 precision: 0.889320

checkpoint saved

epoch-2 step 414100/3451022 - loss: 0.039070 val_loss: 0.037618	recall: 0.562353 precision: 0.903592

model exported!

epoch-2 step 414200/3451022 - loss: 0.034857 val_loss: 0.034992	recall: 0.543453 precision: 0.898467
epoch-2 step 414300/3451022 - loss: 0.038087 val_loss: 0.042023	recall: 0.500543 precision: 0.888247
epoch-2 step 414400/3451022 - loss: 0.038656 val_loss: 0.035440	recall: 0.532423 precision: 0.889734
epoch-2 step 414500/3451022 - loss: 0.035983 val_loss: 0.035954	recall: 0.530217 precision: 0.889101
epoch-2 step 414600/3451022 - loss: 0.035511 val_loss: 0.041200	recall: 0.534562 precision: 0.902724
epoch-2 step 414700/3451022 - loss: 0.038544 val_loss: 0.038832	recall: 0.492901 precision: 0.905028
epoch-2 step 414800/3451022 - loss: 0.041387 val_loss: 0.034242	recall: 0.523490 precision: 0.923077
epoch-2 step 414900/3451022 - loss: 0.035125 val_loss: 0.034536	recall: 0.546275 precision: 0.920152
epoch-2 step 415000/3451022 - loss: 0.034560 val_loss: 0.035445	recall: 0.535433 precision: 0.911877

checkpoint saved

epoch-2 step 415100/3451022 - loss: 0.040081 val_loss: 0.034851	recall: 0.509595 precision: 0.903592
epoch-2 step 415200/3451022 - loss: 0.034965 val_loss: 0.035399	recall: 0.525188 precision: 0.928030
epoch-2 step 415300/3451022 - loss: 0.036774 val_loss: 0.037030	recall: 0.502662 precision: 0.895636
epoch-2 step 415400/3451022 - loss: 0.036380 val_loss: 0.034758	recall: 0.516447 precision: 0.895437
epoch-2 step 415500/3451022 - loss: 0.034494 val_loss: 0.036302	recall: 0.528670 precision: 0.903922
epoch-2 step 415600/3451022 - loss: 0.036919 val_loss: 0.036507	recall: 0.509956 precision: 0.907480
epoch-2 step 415700/3451022 - loss: 0.037383 val_loss: 0.036699	recall: 0.532276 precision: 0.896947
epoch-2 step 415800/3451022 - loss: 0.036876 val_loss: 0.036832	recall: 0.529609 precision: 0.915058
epoch-2 step 415900/3451022 - loss: 0.036229 val_loss: 0.034956	recall: 0.486928 precision: 0.876471
epoch-2 step 416000/3451022 - loss: 0.037178 val_loss: 0.034023	recall: 0.515991 precision: 0.916667

checkpoint saved

epoch-2 step 416100/3451022 - loss: 0.038000 val_loss: 0.035420	recall: 0.511302 precision: 0.892857

model exported!

epoch-2 step 416200/3451022 - loss: 0.042556 val_loss: 0.034497	recall: 0.511401 precision: 0.912791
epoch-2 step 416300/3451022 - loss: 0.043921 val_loss: 0.035838	recall: 0.520607 precision: 0.903955
epoch-2 step 416400/3451022 - loss: 0.038015 val_loss: 0.040471	recall: 0.497366 precision: 0.916505
epoch-2 step 416500/3451022 - loss: 0.042387 val_loss: 0.036550	recall: 0.526726 precision: 0.913127
epoch-2 step 416600/3451022 - loss: 0.035081 val_loss: 0.041149	recall: 0.506187 precision: 0.894632
epoch-2 step 416700/3451022 - loss: 0.035015 val_loss: 0.038302	recall: 0.516129 precision: 0.880455
epoch-2 step 416800/3451022 - loss: 0.038985 val_loss: 0.038016	recall: 0.532525 precision: 0.925287
epoch-2 step 416900/3451022 - loss: 0.035172 val_loss: 0.036290	recall: 0.529345 precision: 0.910680
epoch-2 step 417000/3451022 - loss: 0.034748 val_loss: 0.033985	recall: 0.524294 precision: 0.890595

checkpoint saved

epoch-2 step 417100/3451022 - loss: 0.035843 val_loss: 0.035139	recall: 0.512903 precision: 0.891589
epoch-2 step 417200/3451022 - loss: 0.034981 val_loss: 0.039790	recall: 0.523482 precision: 0.903162
epoch-2 step 417300/3451022 - loss: 0.033463 val_loss: 0.036884	recall: 0.522727 precision: 0.934236
epoch-2 step 417400/3451022 - loss: 0.038952 val_loss: 0.037537	recall: 0.520518 precision: 0.923372
epoch-2 step 417500/3451022 - loss: 0.036473 val_loss: 0.038521	recall: 0.517609 precision: 0.923810
epoch-2 step 417600/3451022 - loss: 0.037447 val_loss: 0.034710	recall: 0.515118 precision: 0.907298
epoch-2 step 417700/3451022 - loss: 0.033707 val_loss: 0.035460	recall: 0.511161 precision: 0.899804
epoch-2 step 417800/3451022 - loss: 0.035956 val_loss: 0.057574	recall: 0.524664 precision: 0.878049
epoch-2 step 417900/3451022 - loss: 0.034650 val_loss: 0.034945	recall: 0.534368 precision: 0.916350
epoch-2 step 418000/3451022 - loss: 0.034490 val_loss: 0.037580	recall: 0.526726 precision: 0.902672

checkpoint saved

epoch-2 step 418100/3451022 - loss: 0.042595 val_loss: 0.038613	recall: 0.520925 precision: 0.887430

model exported!

epoch-2 step 418200/3451022 - loss: 0.034278 val_loss: 0.036128	recall: 0.540946 precision: 0.921415
epoch-2 step 418300/3451022 - loss: 0.035870 val_loss: 0.048613	recall: 0.518960 precision: 0.872495
epoch-2 step 418400/3451022 - loss: 0.038775 val_loss: 0.034195	recall: 0.518729 precision: 0.889105
epoch-2 step 418500/3451022 - loss: 0.035775 val_loss: 0.036575	recall: 0.514484 precision: 0.886228
epoch-2 step 418600/3451022 - loss: 0.037345 val_loss: 0.039473	recall: 0.525627 precision: 0.906015
epoch-2 step 418700/3451022 - loss: 0.037815 val_loss: 0.036219	recall: 0.467909 precision: 0.898608
epoch-2 step 418800/3451022 - loss: 0.034594 val_loss: 0.035892	recall: 0.538296 precision: 0.950476
epoch-2 step 418900/3451022 - loss: 0.040317 val_loss: 0.037902	recall: 0.493018 precision: 0.892996
epoch-2 step 419000/3451022 - loss: 0.035213 val_loss: 0.040426	recall: 0.518764 precision: 0.916179

checkpoint saved

epoch-2 step 419100/3451022 - loss: 0.035842 val_loss: 0.036240	recall: 0.520607 precision: 0.921305
epoch-2 step 419200/3451022 - loss: 0.035164 val_loss: 0.035394	recall: 0.537246 precision: 0.920696
epoch-2 step 419300/3451022 - loss: 0.037234 val_loss: 0.035949	recall: 0.507937 precision: 0.914286
epoch-2 step 419400/3451022 - loss: 0.036732 val_loss: 0.039378	recall: 0.510248 precision: 0.913127
epoch-2 step 419500/3451022 - loss: 0.038429 val_loss: 0.037401	recall: 0.504228 precision: 0.912046
epoch-2 step 419600/3451022 - loss: 0.037887 val_loss: 0.035010	recall: 0.509351 precision: 0.893822
epoch-2 step 419700/3451022 - loss: 0.036835 val_loss: 0.034850	recall: 0.512528 precision: 0.882353
epoch-2 step 419800/3451022 - loss: 0.037934 val_loss: 0.033800	recall: 0.548538 precision: 0.917808
epoch-2 step 419900/3451022 - loss: 0.034732 val_loss: 0.034262	recall: 0.530011 precision: 0.912281
epoch-2 step 420000/3451022 - loss: 0.034753 val_loss: 0.038982	recall: 0.506024 precision: 0.918489

checkpoint saved

epoch-2 step 420100/3451022 - loss: 0.036306 val_loss: 0.045251	recall: 0.510903 precision: 0.902752

model exported!

epoch-2 step 420200/3451022 - loss: 0.036469 val_loss: 0.037230	recall: 0.497854 precision: 0.913386
epoch-2 step 420300/3451022 - loss: 0.036608 val_loss: 0.036667	recall: 0.528078 precision: 0.926136
epoch-2 step 420400/3451022 - loss: 0.039614 val_loss: 0.042479	recall: 0.526998 precision: 0.910448
epoch-2 step 420500/3451022 - loss: 0.034429 val_loss: 0.034382	recall: 0.520278 precision: 0.889109
epoch-2 step 420600/3451022 - loss: 0.035209 val_loss: 0.041121	recall: 0.526807 precision: 0.914980
epoch-2 step 420700/3451022 - loss: 0.034571 val_loss: 0.035200	recall: 0.538976 precision: 0.913208
epoch-2 step 420800/3451022 - loss: 0.036474 val_loss: 0.038824	recall: 0.493724 precision: 0.888889
epoch-2 step 420900/3451022 - loss: 0.041302 val_loss: 0.036145	recall: 0.528322 precision: 0.913371
epoch-2 step 421000/3451022 - loss: 0.034852 val_loss: 0.041252	recall: 0.526735 precision: 0.904297

checkpoint saved

epoch-2 step 421100/3451022 - loss: 0.036136 val_loss: 0.040456	recall: 0.544066 precision: 0.890385
epoch-2 step 421200/3451022 - loss: 0.036182 val_loss: 0.034387	recall: 0.539665 precision: 0.916509
epoch-2 step 421300/3451022 - loss: 0.034574 val_loss: 0.035949	recall: 0.547897 precision: 0.923228
epoch-2 step 421400/3451022 - loss: 0.043359 val_loss: 0.036174	recall: 0.541520 precision: 0.904297
epoch-2 step 421500/3451022 - loss: 0.034975 val_loss: 0.037439	recall: 0.517554 precision: 0.904950
epoch-2 step 421600/3451022 - loss: 0.037585 val_loss: 0.036134	recall: 0.510571 precision: 0.934236
epoch-2 step 421700/3451022 - loss: 0.035330 val_loss: 0.034628	recall: 0.553241 precision: 0.931774
epoch-2 step 421800/3451022 - loss: 0.034094 val_loss: 0.039018	recall: 0.476190 precision: 0.903733
epoch-2 step 421900/3451022 - loss: 0.034471 val_loss: 0.034150	recall: 0.549296 precision: 0.919450
epoch-2 step 422000/3451022 - loss: 0.035900 val_loss: 0.033953	recall: 0.525683 precision: 0.910985

checkpoint saved

epoch-2 step 422100/3451022 - loss: 0.038375 val_loss: 0.035749	recall: 0.546171 precision: 0.911654

model exported!

epoch-2 step 422200/3451022 - loss: 0.037096 val_loss: 0.036393	recall: 0.494028 precision: 0.878378
epoch-2 step 422300/3451022 - loss: 0.035953 val_loss: 0.036623	recall: 0.542129 precision: 0.910615
epoch-2 step 422400/3451022 - loss: 0.046401 val_loss: 0.035315	recall: 0.544820 precision: 0.924901
epoch-2 step 422500/3451022 - loss: 0.035181 val_loss: 0.043094	recall: 0.530079 precision: 0.903288
epoch-2 step 422600/3451022 - loss: 0.035386 val_loss: 0.039095	recall: 0.518033 precision: 0.911538
epoch-2 step 422700/3451022 - loss: 0.036382 val_loss: 0.036748	recall: 0.534857 precision: 0.905222
epoch-2 step 422800/3451022 - loss: 0.036019 val_loss: 0.036452	recall: 0.499466 precision: 0.894837
epoch-2 step 422900/3451022 - loss: 0.038187 val_loss: 0.039452	recall: 0.501615 precision: 0.908382
epoch-2 step 423000/3451022 - loss: 0.034769 val_loss: 0.035054	recall: 0.525084 precision: 0.911025

checkpoint saved

epoch-2 step 423100/3451022 - loss: 0.036769 val_loss: 0.037196	recall: 0.489164 precision: 0.922179
epoch-2 step 423200/3451022 - loss: 0.037729 val_loss: 0.036990	recall: 0.521142 precision: 0.924953
epoch-2 step 423300/3451022 - loss: 0.035069 val_loss: 0.036957	recall: 0.532646 precision: 0.911765
epoch-2 step 423400/3451022 - loss: 0.036323 val_loss: 0.034709	recall: 0.485374 precision: 0.875000
epoch-2 step 423500/3451022 - loss: 0.042027 val_loss: 0.036740	recall: 0.511211 precision: 0.895874
epoch-2 step 423600/3451022 - loss: 0.035168 val_loss: 0.037115	recall: 0.492473 precision: 0.901575
epoch-2 step 423700/3451022 - loss: 0.034970 val_loss: 0.035575	recall: 0.530934 precision: 0.902486
epoch-2 step 423800/3451022 - loss: 0.034791 val_loss: 0.034768	recall: 0.524590 precision: 0.881890
epoch-2 step 423900/3451022 - loss: 0.039434 val_loss: 0.041103	recall: 0.508830 precision: 0.889961
epoch-2 step 424000/3451022 - loss: 0.037817 val_loss: 0.034998	recall: 0.501109 precision: 0.916836

checkpoint saved

epoch-2 step 424100/3451022 - loss: 0.040165 val_loss: 0.039451	recall: 0.534676 precision: 0.926357

model exported!

epoch-2 step 424200/3451022 - loss: 0.035328 val_loss: 0.035437	recall: 0.525974 precision: 0.925714
epoch-2 step 424300/3451022 - loss: 0.037705 val_loss: 0.035595	recall: 0.503842 precision: 0.908911
epoch-2 step 424400/3451022 - loss: 0.036581 val_loss: 0.035814	recall: 0.519274 precision: 0.899804
epoch-2 step 424500/3451022 - loss: 0.036399 val_loss: 0.035857	recall: 0.533183 precision: 0.922179
epoch-2 step 424600/3451022 - loss: 0.037053 val_loss: 0.035268	recall: 0.523649 precision: 0.909980
epoch-2 step 424700/3451022 - loss: 0.035531 val_loss: 0.038943	recall: 0.510989 precision: 0.897683
epoch-2 step 424800/3451022 - loss: 0.035214 val_loss: 0.037001	recall: 0.528000 precision: 0.904110
epoch-2 step 424900/3451022 - loss: 0.037756 val_loss: 0.034729	recall: 0.525796 precision: 0.924710
epoch-2 step 425000/3451022 - loss: 0.038369 val_loss: 0.037661	recall: 0.500551 precision: 0.911647

checkpoint saved

epoch-2 step 425100/3451022 - loss: 0.042636 val_loss: 0.036267	recall: 0.521405 precision: 0.916988
epoch-2 step 425200/3451022 - loss: 0.034454 val_loss: 0.034298	recall: 0.538106 precision: 0.930140
epoch-2 step 425300/3451022 - loss: 0.035850 val_loss: 0.036073	recall: 0.517582 precision: 0.893738
epoch-2 step 425400/3451022 - loss: 0.035253 val_loss: 0.037222	recall: 0.526429 precision: 0.912150
epoch-2 step 425500/3451022 - loss: 0.036039 val_loss: 0.033991	recall: 0.525959 precision: 0.913725
epoch-2 step 425600/3451022 - loss: 0.038265 val_loss: 0.034318	recall: 0.549476 precision: 0.909441
epoch-2 step 425700/3451022 - loss: 0.034644 val_loss: 0.036918	recall: 0.518438 precision: 0.921002
epoch-2 step 425800/3451022 - loss: 0.039435 val_loss: 0.036111	recall: 0.518307 precision: 0.886497
epoch-2 step 425900/3451022 - loss: 0.039501 val_loss: 0.033708	recall: 0.500000 precision: 0.911243
epoch-2 step 426000/3451022 - loss: 0.054151 val_loss: 0.035081	recall: 0.522075 precision: 0.931102

checkpoint saved

epoch-2 step 426100/3451022 - loss: 0.034377 val_loss: 0.035522	recall: 0.526620 precision: 0.873321

model exported!

epoch-2 step 426200/3451022 - loss: 0.038477 val_loss: 0.034536	recall: 0.521935 precision: 0.928000
epoch-2 step 426300/3451022 - loss: 0.034359 val_loss: 0.037308	recall: 0.523536 precision: 0.892368
epoch-2 step 426400/3451022 - loss: 0.038369 val_loss: 0.040404	recall: 0.520095 precision: 0.888889
epoch-2 step 426500/3451022 - loss: 0.035619 val_loss: 0.034476	recall: 0.552480 precision: 0.931907
epoch-2 step 426600/3451022 - loss: 0.039129 val_loss: 0.034987	recall: 0.541985 precision: 0.922078
epoch-2 step 426700/3451022 - loss: 0.035303 val_loss: 0.042648	recall: 0.539754 precision: 0.923372
epoch-2 step 426800/3451022 - loss: 0.034908 val_loss: 0.036492	recall: 0.522222 precision: 0.903846
epoch-2 step 426900/3451022 - loss: 0.039194 val_loss: 0.035743	recall: 0.488121 precision: 0.874275
epoch-2 step 427000/3451022 - loss: 0.035101 val_loss: 0.034465	recall: 0.539062 precision: 0.913043

checkpoint saved

epoch-2 step 427100/3451022 - loss: 0.035560 val_loss: 0.036468	recall: 0.526256 precision: 0.911067
epoch-2 step 427200/3451022 - loss: 0.042006 val_loss: 0.043857	recall: 0.511706 precision: 0.879310
epoch-2 step 427300/3451022 - loss: 0.036167 val_loss: 0.035499	recall: 0.558113 precision: 0.916824
epoch-2 step 427400/3451022 - loss: 0.037804 val_loss: 0.036613	recall: 0.506550 precision: 0.888889
epoch-2 step 427500/3451022 - loss: 0.034840 val_loss: 0.043939	recall: 0.519774 precision: 0.896686
epoch-2 step 427600/3451022 - loss: 0.036488 val_loss: 0.036048	recall: 0.521300 precision: 0.894231
epoch-2 step 427700/3451022 - loss: 0.035537 val_loss: 0.035518	recall: 0.509290 precision: 0.910156
epoch-2 step 427800/3451022 - loss: 0.035931 val_loss: 0.042123	recall: 0.507384 precision: 0.921456
epoch-2 step 427900/3451022 - loss: 0.035622 val_loss: 0.035395	recall: 0.497303 precision: 0.902153
epoch-2 step 428000/3451022 - loss: 0.035732 val_loss: 0.035851	recall: 0.530355 precision: 0.907843

checkpoint saved

epoch-2 step 428100/3451022 - loss: 0.035653 val_loss: 0.038335	recall: 0.516704 precision: 0.913386

model exported!

epoch-2 step 428200/3451022 - loss: 0.035800 val_loss: 0.035138	recall: 0.512432 precision: 0.904580
epoch-2 step 428300/3451022 - loss: 0.034718 val_loss: 0.034228	recall: 0.505808 precision: 0.910646
epoch-2 step 428400/3451022 - loss: 0.045360 val_loss: 0.035337	recall: 0.517738 precision: 0.877820
epoch-2 step 428500/3451022 - loss: 0.037039 val_loss: 0.035114	recall: 0.515744 precision: 0.894539
epoch-2 step 428600/3451022 - loss: 0.035598 val_loss: 0.034459	recall: 0.512169 precision: 0.904673
epoch-2 step 428700/3451022 - loss: 0.036712 val_loss: 0.047805	recall: 0.534247 precision: 0.903475
epoch-2 step 428800/3451022 - loss: 0.040515 val_loss: 0.034446	recall: 0.506037 precision: 0.886538
epoch-2 step 428900/3451022 - loss: 0.041516 val_loss: 0.045263	recall: 0.538717 precision: 0.905204
epoch-2 step 429000/3451022 - loss: 0.035632 val_loss: 0.036394	recall: 0.492170 precision: 0.878244

checkpoint saved

epoch-2 step 429100/3451022 - loss: 0.036371 val_loss: 0.034127	recall: 0.514286 precision: 0.913534
epoch-2 step 429200/3451022 - loss: 0.054626 val_loss: 0.035645	recall: 0.508108 precision: 0.919765
epoch-2 step 429300/3451022 - loss: 0.037222 val_loss: 0.038425	recall: 0.501106 precision: 0.877907
epoch-2 step 429400/3451022 - loss: 0.038040 val_loss: 0.035177	recall: 0.534961 precision: 0.914611
epoch-2 step 429500/3451022 - loss: 0.034555 val_loss: 0.036095	recall: 0.487261 precision: 0.898239
epoch-2 step 429600/3451022 - loss: 0.034723 val_loss: 0.047262	recall: 0.537079 precision: 0.903592
epoch-2 step 429700/3451022 - loss: 0.033996 val_loss: 0.036172	recall: 0.501059 precision: 0.914894
epoch-2 step 429800/3451022 - loss: 0.041316 val_loss: 0.036137	recall: 0.496957 precision: 0.905730
epoch-2 step 429900/3451022 - loss: 0.034896 val_loss: 0.034780	recall: 0.504444 precision: 0.908000
epoch-2 step 430000/3451022 - loss: 0.034915 val_loss: 0.040474	recall: 0.494856 precision: 0.930368

checkpoint saved

epoch-2 step 430100/3451022 - loss: 0.037867 val_loss: 0.040262	recall: 0.534910 precision: 0.920543

model exported!

epoch-2 step 430200/3451022 - loss: 0.036178 val_loss: 0.034554	recall: 0.499476 precision: 0.888268
epoch-2 step 430300/3451022 - loss: 0.044911 val_loss: 0.039876	recall: 0.493333 precision: 0.894052
epoch-2 step 430400/3451022 - loss: 0.036145 val_loss: 0.043710	recall: 0.497881 precision: 0.903846
epoch-2 step 430500/3451022 - loss: 0.035948 val_loss: 0.036533	recall: 0.529279 precision: 0.905588
epoch-2 step 430600/3451022 - loss: 0.035016 val_loss: 0.044494	recall: 0.513100 precision: 0.919765
epoch-2 step 430700/3451022 - loss: 0.036516 val_loss: 0.035167	recall: 0.528090 precision: 0.900383
epoch-2 step 430800/3451022 - loss: 0.035511 val_loss: 0.040844	recall: 0.495166 precision: 0.884837
epoch-2 step 430900/3451022 - loss: 0.035642 val_loss: 0.036384	recall: 0.495028 precision: 0.887129
epoch-2 step 431000/3451022 - loss: 0.035122 val_loss: 0.038980	recall: 0.510460 precision: 0.920755

checkpoint saved

epoch-2 step 431100/3451022 - loss: 0.034327 val_loss: 0.037353	recall: 0.520231 precision: 0.887574
epoch-2 step 431200/3451022 - loss: 0.034852 val_loss: 0.034453	recall: 0.507853 precision: 0.903166
epoch-2 step 431300/3451022 - loss: 0.034844 val_loss: 0.034557	recall: 0.516093 precision: 0.904669
epoch-2 step 431400/3451022 - loss: 0.034758 val_loss: 0.040072	recall: 0.506757 precision: 0.880626
epoch-2 step 431500/3451022 - loss: 0.036246 val_loss: 0.034486	recall: 0.528761 precision: 0.913958
epoch-2 step 431600/3451022 - loss: 0.034840 val_loss: 0.037331	recall: 0.527273 precision: 0.892308
epoch-2 step 431700/3451022 - loss: 0.040153 val_loss: 0.034107	recall: 0.522676 precision: 0.881453
epoch-2 step 431800/3451022 - loss: 0.039780 val_loss: 0.037014	recall: 0.516779 precision: 0.898833
epoch-2 step 431900/3451022 - loss: 0.034652 val_loss: 0.035441	recall: 0.536782 precision: 0.906796
epoch-2 step 432000/3451022 - loss: 0.034304 val_loss: 0.034982	recall: 0.512195 precision: 0.916667

checkpoint saved

epoch-2 step 432100/3451022 - loss: 0.039631 val_loss: 0.034887	recall: 0.533637 precision: 0.919450

model exported!

epoch-2 step 432200/3451022 - loss: 0.036238 val_loss: 0.037264	recall: 0.547404 precision: 0.938104
epoch-2 step 432300/3451022 - loss: 0.035690 val_loss: 0.034978	recall: 0.498353 precision: 0.890196
epoch-2 step 432400/3451022 - loss: 0.045973 val_loss: 0.034938	recall: 0.506132 precision: 0.884990
epoch-2 step 432500/3451022 - loss: 0.037893 val_loss: 0.037528	recall: 0.529742 precision: 0.907692
epoch-2 step 432600/3451022 - loss: 0.040620 val_loss: 0.035320	recall: 0.523429 precision: 0.932790
epoch-2 step 432700/3451022 - loss: 0.038447 val_loss: 0.040940	recall: 0.540541 precision: 0.930233
epoch-2 step 432800/3451022 - loss: 0.034456 val_loss: 0.035575	recall: 0.550725 precision: 0.925094
epoch-2 step 432900/3451022 - loss: 0.034103 val_loss: 0.036326	recall: 0.528935 precision: 0.906746
epoch-2 step 433000/3451022 - loss: 0.036343 val_loss: 0.034571	recall: 0.532497 precision: 0.908560

checkpoint saved

epoch-2 step 433100/3451022 - loss: 0.036952 val_loss: 0.035670	recall: 0.515660 precision: 0.884837
epoch-2 step 433200/3451022 - loss: 0.035832 val_loss: 0.036665	recall: 0.546060 precision: 0.931818
epoch-2 step 433300/3451022 - loss: 0.036070 val_loss: 0.035200	recall: 0.535365 precision: 0.907749
epoch-2 step 433400/3451022 - loss: 0.035376 val_loss: 0.036468	recall: 0.475322 precision: 0.891348
epoch-2 step 433500/3451022 - loss: 0.037641 val_loss: 0.039367	recall: 0.523385 precision: 0.900383
epoch-2 step 433600/3451022 - loss: 0.036045 val_loss: 0.035015	recall: 0.519608 precision: 0.913793
epoch-2 step 433700/3451022 - loss: 0.035357 val_loss: 0.036171	recall: 0.501066 precision: 0.919765
epoch-2 step 433800/3451022 - loss: 0.035943 val_loss: 0.035018	recall: 0.493018 precision: 0.901768
epoch-2 step 433900/3451022 - loss: 0.038754 val_loss: 0.035422	recall: 0.514317 precision: 0.913894
epoch-2 step 434000/3451022 - loss: 0.037768 val_loss: 0.034589	recall: 0.537961 precision: 0.920223

checkpoint saved

epoch-2 step 434100/3451022 - loss: 0.036575 val_loss: 0.035307	recall: 0.503261 precision: 0.907843

model exported!

epoch-2 step 434200/3451022 - loss: 0.036020 val_loss: 0.034293	recall: 0.511706 precision: 0.898239
epoch-2 step 434300/3451022 - loss: 0.040681 val_loss: 0.035982	recall: 0.506565 precision: 0.892100
epoch-2 step 434400/3451022 - loss: 0.034012 val_loss: 0.033596	recall: 0.501577 precision: 0.906844
epoch-2 step 434500/3451022 - loss: 0.035593 val_loss: 0.033980	recall: 0.532690 precision: 0.915285
epoch-2 step 434600/3451022 - loss: 0.035727 val_loss: 0.037554	recall: 0.535147 precision: 0.899048
epoch-2 step 434700/3451022 - loss: 0.035163 val_loss: 0.035291	recall: 0.520307 precision: 0.925781
epoch-2 step 434800/3451022 - loss: 0.039496 val_loss: 0.034944	recall: 0.556738 precision: 0.925344
epoch-2 step 434900/3451022 - loss: 0.035757 val_loss: 0.037735	recall: 0.518797 precision: 0.904494
epoch-2 step 435000/3451022 - loss: 0.034295 val_loss: 0.036124	recall: 0.518519 precision: 0.908397

checkpoint saved

epoch-2 step 435100/3451022 - loss: 0.039383 val_loss: 0.036463	recall: 0.520134 precision: 0.879017
epoch-2 step 435200/3451022 - loss: 0.035491 val_loss: 0.034445	recall: 0.503219 precision: 0.914230
epoch-2 step 435300/3451022 - loss: 0.037114 val_loss: 0.034646	recall: 0.534884 precision: 0.902804
epoch-2 step 435400/3451022 - loss: 0.034438 val_loss: 0.035264	recall: 0.526953 precision: 0.915870
epoch-2 step 435500/3451022 - loss: 0.040573 val_loss: 0.036010	recall: 0.533623 precision: 0.928302
epoch-2 step 435600/3451022 - loss: 0.034390 val_loss: 0.034703	recall: 0.519423 precision: 0.893130
epoch-2 step 435700/3451022 - loss: 0.035138 val_loss: 0.034491	recall: 0.527991 precision: 0.905838
epoch-2 step 435800/3451022 - loss: 0.035829 val_loss: 0.037696	recall: 0.514831 precision: 0.896679
epoch-2 step 435900/3451022 - loss: 0.038805 val_loss: 0.034521	recall: 0.531080 precision: 0.931166
epoch-2 step 436000/3451022 - loss: 0.035881 val_loss: 0.042902	recall: 0.486716 precision: 0.899804

checkpoint saved

epoch-2 step 436100/3451022 - loss: 0.039762 val_loss: 0.033605	recall: 0.491597 precision: 0.903475

model exported!

epoch-2 step 436200/3451022 - loss: 0.034894 val_loss: 0.035810	recall: 0.489154 precision: 0.898406
epoch-2 step 436300/3451022 - loss: 0.034053 val_loss: 0.057617	recall: 0.512739 precision: 0.936047
epoch-2 step 436400/3451022 - loss: 0.038552 val_loss: 0.042431	recall: 0.498378 precision: 0.907480
epoch-2 step 436500/3451022 - loss: 0.035538 val_loss: 0.035828	recall: 0.509948 precision: 0.927619
epoch-2 step 436600/3451022 - loss: 0.034099 val_loss: 0.035567	recall: 0.520607 precision: 0.926641
epoch-2 step 436700/3451022 - loss: 0.040797 val_loss: 0.033923	recall: 0.514484 precision: 0.888000
epoch-2 step 436800/3451022 - loss: 0.035597 val_loss: 0.034625	recall: 0.502623 precision: 0.912381
epoch-2 step 436900/3451022 - loss: 0.041394 val_loss: 0.036577	recall: 0.529605 precision: 0.906191
epoch-2 step 437000/3451022 - loss: 0.034803 val_loss: 0.035241	recall: 0.519210 precision: 0.913127

checkpoint saved

epoch-2 step 437100/3451022 - loss: 0.037699 val_loss: 0.038305	recall: 0.513598 precision: 0.924670
epoch-2 step 437200/3451022 - loss: 0.037191 val_loss: 0.035614	recall: 0.515184 precision: 0.918762
epoch-2 step 437300/3451022 - loss: 0.036712 val_loss: 0.034606	recall: 0.465739 precision: 0.875252
epoch-2 step 437400/3451022 - loss: 0.038704 val_loss: 0.037155	recall: 0.534386 precision: 0.916828
epoch-2 step 437500/3451022 - loss: 0.036294 val_loss: 0.038569	recall: 0.486800 precision: 0.898635
epoch-2 step 437600/3451022 - loss: 0.037670 val_loss: 0.035223	recall: 0.536476 precision: 0.917466
epoch-2 step 437700/3451022 - loss: 0.036645 val_loss: 0.035160	recall: 0.509868 precision: 0.902913
epoch-2 step 437800/3451022 - loss: 0.036461 val_loss: 0.039860	recall: 0.497845 precision: 0.905882
epoch-2 step 437900/3451022 - loss: 0.035580 val_loss: 0.040294	recall: 0.509290 precision: 0.891013
epoch-2 step 438000/3451022 - loss: 0.035442 val_loss: 0.034875	recall: 0.522272 precision: 0.895038

checkpoint saved

epoch-2 step 438100/3451022 - loss: 0.038154 val_loss: 0.036154	recall: 0.535632 precision: 0.901354

model exported!

epoch-2 step 438200/3451022 - loss: 0.035417 val_loss: 0.038644	recall: 0.511351 precision: 0.906130
epoch-2 step 438300/3451022 - loss: 0.038425 val_loss: 0.035710	recall: 0.514130 precision: 0.907869
epoch-2 step 438400/3451022 - loss: 0.036661 val_loss: 0.033797	recall: 0.509413 precision: 0.896686
epoch-2 step 438500/3451022 - loss: 0.035087 val_loss: 0.035152	recall: 0.533259 precision: 0.902439
epoch-2 step 438600/3451022 - loss: 0.034953 val_loss: 0.035881	recall: 0.512055 precision: 0.890220
epoch-2 step 438700/3451022 - loss: 0.035489 val_loss: 0.036657	recall: 0.529680 precision: 0.920635
epoch-2 step 438800/3451022 - loss: 0.037809 val_loss: 0.035179	recall: 0.537383 precision: 0.888031
epoch-2 step 438900/3451022 - loss: 0.034772 val_loss: 0.035361	recall: 0.560834 precision: 0.901304
epoch-2 step 439000/3451022 - loss: 0.039538 val_loss: 0.034812	recall: 0.523202 precision: 0.891304

checkpoint saved

epoch-2 step 439100/3451022 - loss: 0.034954 val_loss: 0.037162	recall: 0.524130 precision: 0.905039
epoch-2 step 439200/3451022 - loss: 0.034543 val_loss: 0.036772	recall: 0.493737 precision: 0.902672
epoch-2 step 439300/3451022 - loss: 0.041544 val_loss: 0.041396	recall: 0.491304 precision: 0.882812
epoch-2 step 439400/3451022 - loss: 0.040232 val_loss: 0.040358	recall: 0.496829 precision: 0.885122
epoch-2 step 439500/3451022 - loss: 0.040220 val_loss: 0.036596	recall: 0.496304 precision: 0.890152
epoch-2 step 439600/3451022 - loss: 0.036475 val_loss: 0.035040	recall: 0.529095 precision: 0.904236
epoch-2 step 439700/3451022 - loss: 0.034098 val_loss: 0.036072	recall: 0.498899 precision: 0.876209
epoch-2 step 439800/3451022 - loss: 0.036611 val_loss: 0.034782	recall: 0.523269 precision: 0.900391
epoch-2 step 439900/3451022 - loss: 0.034920 val_loss: 0.034972	recall: 0.527072 precision: 0.903409
epoch-2 step 440000/3451022 - loss: 0.037033 val_loss: 0.036117	recall: 0.495177 precision: 0.883365

checkpoint saved

epoch-2 step 440100/3451022 - loss: 0.034831 val_loss: 0.035777	recall: 0.511038 precision: 0.933468

model exported!

epoch-2 step 440200/3451022 - loss: 0.037350 val_loss: 0.035019	recall: 0.558442 precision: 0.925636
epoch-2 step 440300/3451022 - loss: 0.036607 val_loss: 0.035291	recall: 0.531144 precision: 0.923228
epoch-2 step 440400/3451022 - loss: 0.041123 val_loss: 0.035117	recall: 0.510823 precision: 0.914729
epoch-2 step 440500/3451022 - loss: 0.035945 val_loss: 0.036443	recall: 0.515487 precision: 0.899614
epoch-2 step 440600/3451022 - loss: 0.035011 val_loss: 0.035257	recall: 0.508324 precision: 0.889320
epoch-2 step 440700/3451022 - loss: 0.037371 val_loss: 0.037428	recall: 0.529748 precision: 0.885277
epoch-2 step 440800/3451022 - loss: 0.037382 val_loss: 0.034961	recall: 0.544379 precision: 0.907298
epoch-2 step 440900/3451022 - loss: 0.039002 val_loss: 0.037721	recall: 0.540698 precision: 0.906433
epoch-2 step 441000/3451022 - loss: 0.039834 val_loss: 0.035852	recall: 0.490566 precision: 0.883019

checkpoint saved

epoch-2 step 441100/3451022 - loss: 0.034347 val_loss: 0.037189	recall: 0.512959 precision: 0.903042
epoch-2 step 441200/3451022 - loss: 0.036420 val_loss: 0.035479	recall: 0.511111 precision: 0.920000
epoch-2 step 441300/3451022 - loss: 0.034562 val_loss: 0.036321	recall: 0.527273 precision: 0.899225
epoch-2 step 441400/3451022 - loss: 0.035433 val_loss: 0.038635	recall: 0.511628 precision: 0.905882
epoch-2 step 441500/3451022 - loss: 0.038981 val_loss: 0.043980	recall: 0.534884 precision: 0.901961
epoch-2 step 441600/3451022 - loss: 0.038127 val_loss: 0.035265	recall: 0.537611 precision: 0.929254
epoch-2 step 441700/3451022 - loss: 0.035701 val_loss: 0.034907	recall: 0.501096 precision: 0.897839
epoch-2 step 441800/3451022 - loss: 0.037953 val_loss: 0.037486	recall: 0.518313 precision: 0.913894
epoch-2 step 441900/3451022 - loss: 0.041368 val_loss: 0.036221	recall: 0.517202 precision: 0.893069
epoch-2 step 442000/3451022 - loss: 0.034873 val_loss: 0.038017	recall: 0.529545 precision: 0.901354

checkpoint saved

epoch-2 step 442100/3451022 - loss: 0.035675 val_loss: 0.045345	recall: 0.544036 precision: 0.925996

model exported!

epoch-2 step 442200/3451022 - loss: 0.037219 val_loss: 0.035639	recall: 0.526620 precision: 0.899209
epoch-2 step 442300/3451022 - loss: 0.035264 val_loss: 0.037453	recall: 0.548854 precision: 0.890411
epoch-2 step 442400/3451022 - loss: 0.035745 val_loss: 0.040469	recall: 0.509540 precision: 0.900794
epoch-2 step 442500/3451022 - loss: 0.035294 val_loss: 0.035813	recall: 0.508269 precision: 0.905697
epoch-2 step 442600/3451022 - loss: 0.033784 val_loss: 0.037790	recall: 0.554422 precision: 0.927894
epoch-2 step 442700/3451022 - loss: 0.037886 val_loss: 0.034902	recall: 0.538194 precision: 0.902913
epoch-2 step 442800/3451022 - loss: 0.035862 val_loss: 0.037896	recall: 0.515730 precision: 0.907115
epoch-2 step 442900/3451022 - loss: 0.033913 val_loss: 0.038632	recall: 0.512115 precision: 0.926295
epoch-2 step 443000/3451022 - loss: 0.043556 val_loss: 0.037245	recall: 0.517778 precision: 0.911937

checkpoint saved

epoch-2 step 443100/3451022 - loss: 0.035121 val_loss: 0.041716	recall: 0.529282 precision: 0.902072
epoch-2 step 443200/3451022 - loss: 0.034550 val_loss: 0.034881	recall: 0.496774 precision: 0.925852
epoch-2 step 443300/3451022 - loss: 0.035994 val_loss: 0.036626	recall: 0.495816 precision: 0.892655
epoch-2 step 443400/3451022 - loss: 0.034161 val_loss: 0.041146	recall: 0.523026 precision: 0.905123
epoch-2 step 443500/3451022 - loss: 0.035739 val_loss: 0.036391	recall: 0.521837 precision: 0.906615
epoch-2 step 443600/3451022 - loss: 0.038548 val_loss: 0.036367	recall: 0.507104 precision: 0.906250
epoch-2 step 443700/3451022 - loss: 0.039203 val_loss: 0.042206	recall: 0.514658 precision: 0.915058
epoch-2 step 443800/3451022 - loss: 0.045408 val_loss: 0.037499	recall: 0.527778 precision: 0.913462
epoch-2 step 443900/3451022 - loss: 0.045730 val_loss: 0.039363	recall: 0.500552 precision: 0.862857
epoch-2 step 444000/3451022 - loss: 0.035955 val_loss: 0.034571	recall: 0.536806 precision: 0.897727

checkpoint saved

epoch-2 step 444100/3451022 - loss: 0.036377 val_loss: 0.034878	recall: 0.503817 precision: 0.868421

model exported!

epoch-2 step 444200/3451022 - loss: 0.039983 val_loss: 0.035510	recall: 0.544018 precision: 0.911153
epoch-2 step 444300/3451022 - loss: 0.034989 val_loss: 0.035182	recall: 0.521191 precision: 0.890411
epoch-2 step 444400/3451022 - loss: 0.037212 val_loss: 0.035901	recall: 0.517634 precision: 0.881783
epoch-2 step 444500/3451022 - loss: 0.034416 val_loss: 0.036106	recall: 0.518059 precision: 0.882692
epoch-2 step 444600/3451022 - loss: 0.035805 val_loss: 0.034874	recall: 0.552941 precision: 0.916179
epoch-2 step 444700/3451022 - loss: 0.035864 val_loss: 0.036288	recall: 0.522676 precision: 0.909270
epoch-2 step 444800/3451022 - loss: 0.037636 val_loss: 0.040060	recall: 0.543860 precision: 0.913556
epoch-2 step 444900/3451022 - loss: 0.036353 val_loss: 0.036083	recall: 0.532294 precision: 0.896811
epoch-2 step 445000/3451022 - loss: 0.034329 val_loss: 0.037012	recall: 0.528037 precision: 0.905812

checkpoint saved

epoch-2 step 445100/3451022 - loss: 0.035419 val_loss: 0.036286	recall: 0.518771 precision: 0.890625
epoch-2 step 445200/3451022 - loss: 0.036056 val_loss: 0.034994	recall: 0.537455 precision: 0.909457
epoch-2 step 445300/3451022 - loss: 0.035904 val_loss: 0.035102	recall: 0.524798 precision: 0.908184
epoch-2 step 445400/3451022 - loss: 0.035114 val_loss: 0.034871	recall: 0.533843 precision: 0.920904
epoch-2 step 445500/3451022 - loss: 0.035630 val_loss: 0.035836	recall: 0.544066 precision: 0.913215
epoch-2 step 445600/3451022 - loss: 0.034378 val_loss: 0.041465	recall: 0.517714 precision: 0.891732
epoch-2 step 445700/3451022 - loss: 0.034817 val_loss: 0.038463	recall: 0.539535 precision: 0.854512
epoch-2 step 445800/3451022 - loss: 0.038982 val_loss: 0.036575	recall: 0.532646 precision: 0.906433
epoch-2 step 445900/3451022 - loss: 0.036582 val_loss: 0.040576	recall: 0.504940 precision: 0.905512
epoch-2 step 446000/3451022 - loss: 0.037375 val_loss: 0.038519	recall: 0.549488 precision: 0.913043

checkpoint saved

epoch-2 step 446100/3451022 - loss: 0.033927 val_loss: 0.037117	recall: 0.512443 precision: 0.895257

model exported!

epoch-2 step 446200/3451022 - loss: 0.035042 val_loss: 0.034431	recall: 0.543678 precision: 0.923828
epoch-2 step 446300/3451022 - loss: 0.035466 val_loss: 0.038145	recall: 0.501053 precision: 0.940711
epoch-2 step 446400/3451022 - loss: 0.035457 val_loss: 0.039299	recall: 0.516421 precision: 0.923077
epoch-2 step 446500/3451022 - loss: 0.051536 val_loss: 0.035051	recall: 0.514253 precision: 0.891304
epoch-2 step 446600/3451022 - loss: 0.035691 val_loss: 0.033681	recall: 0.499468 precision: 0.912451
epoch-2 step 446700/3451022 - loss: 0.035076 val_loss: 0.035323	recall: 0.530405 precision: 0.919922
epoch-2 step 446800/3451022 - loss: 0.034943 val_loss: 0.035052	recall: 0.510846 precision: 0.916342
epoch-2 step 446900/3451022 - loss: 0.034709 val_loss: 0.034883	recall: 0.509636 precision: 0.915385
epoch-2 step 447000/3451022 - loss: 0.036336 val_loss: 0.035631	recall: 0.515385 precision: 0.891635

checkpoint saved

epoch-2 step 447100/3451022 - loss: 0.034727 val_loss: 0.035526	recall: 0.533333 precision: 0.925490
epoch-2 step 447200/3451022 - loss: 0.037141 val_loss: 0.033970	recall: 0.518805 precision: 0.895038
epoch-2 step 447300/3451022 - loss: 0.039091 val_loss: 0.039951	recall: 0.564014 precision: 0.897248
epoch-2 step 447400/3451022 - loss: 0.036719 val_loss: 0.035943	recall: 0.512568 precision: 0.901923
epoch-2 step 447500/3451022 - loss: 0.041086 val_loss: 0.043859	recall: 0.532009 precision: 0.884404
epoch-2 step 447600/3451022 - loss: 0.036606 val_loss: 0.037184	recall: 0.539701 precision: 0.893333
epoch-2 step 447700/3451022 - loss: 0.037851 val_loss: 0.034134	recall: 0.528365 precision: 0.903042
epoch-2 step 447800/3451022 - loss: 0.035439 val_loss: 0.033778	recall: 0.516093 precision: 0.884030
epoch-2 step 447900/3451022 - loss: 0.036742 val_loss: 0.035134	recall: 0.530055 precision: 0.915094
epoch-2 step 448000/3451022 - loss: 0.034132 val_loss: 0.036759	recall: 0.501111 precision: 0.886051

checkpoint saved

epoch-2 step 448100/3451022 - loss: 0.036411 val_loss: 0.035085	recall: 0.504702 precision: 0.906191

model exported!

epoch-2 step 448200/3451022 - loss: 0.034759 val_loss: 0.037852	recall: 0.526193 precision: 0.900398
epoch-2 step 448300/3451022 - loss: 0.038612 val_loss: 0.042329	recall: 0.498901 precision: 0.891945
epoch-2 step 448400/3451022 - loss: 0.042770 val_loss: 0.040177	recall: 0.515351 precision: 0.891841
epoch-2 step 448500/3451022 - loss: 0.034916 val_loss: 0.037002	recall: 0.529089 precision: 0.914611
epoch-2 step 448600/3451022 - loss: 0.035572 val_loss: 0.037288	recall: 0.512541 precision: 0.891841
epoch-2 step 448700/3451022 - loss: 0.035394 val_loss: 0.037481	recall: 0.544101 precision: 0.906489
epoch-2 step 448800/3451022 - loss: 0.037032 val_loss: 0.034877	recall: 0.512027 precision: 0.890438
epoch-2 step 448900/3451022 - loss: 0.039771 val_loss: 0.035263	recall: 0.505972 precision: 0.911937
epoch-2 step 449000/3451022 - loss: 0.036043 val_loss: 0.039868	recall: 0.506024 precision: 0.904110

checkpoint saved

epoch-2 step 449100/3451022 - loss: 0.036117 val_loss: 0.036399	recall: 0.541899 precision: 0.925573
epoch-2 step 449200/3451022 - loss: 0.036066 val_loss: 0.042607	recall: 0.519001 precision: 0.895131
epoch-2 step 449300/3451022 - loss: 0.035807 val_loss: 0.035548	recall: 0.514501 precision: 0.926499
epoch-2 step 449400/3451022 - loss: 0.038170 val_loss: 0.038127	recall: 0.476956 precision: 0.882937
epoch-2 step 449500/3451022 - loss: 0.033914 val_loss: 0.037593	recall: 0.542002 precision: 0.911025
epoch-2 step 449600/3451022 - loss: 0.040535 val_loss: 0.035948	recall: 0.523454 precision: 0.926415
epoch-2 step 449700/3451022 - loss: 0.036531 val_loss: 0.034707	recall: 0.516376 precision: 0.894140
epoch-2 step 449800/3451022 - loss: 0.037555 val_loss: 0.038762	recall: 0.495604 precision: 0.896620
epoch-2 step 449900/3451022 - loss: 0.033636 val_loss: 0.044882	recall: 0.541002 precision: 0.908222
epoch-2 step 450000/3451022 - loss: 0.035516 val_loss: 0.035340	recall: 0.536151 precision: 0.926923

checkpoint saved

epoch-2 step 450100/3451022 - loss: 0.035876 val_loss: 0.034164	recall: 0.505568 precision: 0.888454

model exported!

epoch-2 step 450200/3451022 - loss: 0.034833 val_loss: 0.054649	recall: 0.518824 precision: 0.901840
epoch-2 step 450300/3451022 - loss: 0.036072 val_loss: 0.036490	recall: 0.531746 precision: 0.898467
epoch-2 step 450400/3451022 - loss: 0.037253 val_loss: 0.035220	recall: 0.532009 precision: 0.919847
epoch-2 step 450500/3451022 - loss: 0.035399 val_loss: 0.038114	recall: 0.515184 precision: 0.911708
epoch-2 step 450600/3451022 - loss: 0.035825 val_loss: 0.037988	recall: 0.552863 precision: 0.921101
epoch-2 step 450700/3451022 - loss: 0.036934 val_loss: 0.035662	recall: 0.514408 precision: 0.911153
epoch-2 step 450800/3451022 - loss: 0.054979 val_loss: 0.035747	recall: 0.516260 precision: 0.903915
epoch-2 step 450900/3451022 - loss: 0.037994 val_loss: 0.036643	recall: 0.542565 precision: 0.908745
epoch-2 step 451000/3451022 - loss: 0.037925 val_loss: 0.040467	recall: 0.480423 precision: 0.873077

checkpoint saved

epoch-2 step 451100/3451022 - loss: 0.036717 val_loss: 0.041774	recall: 0.515744 precision: 0.922330
epoch-2 step 451200/3451022 - loss: 0.039368 val_loss: 0.034123	recall: 0.516520 precision: 0.916016
epoch-2 step 451300/3451022 - loss: 0.045106 val_loss: 0.034598	recall: 0.506145 precision: 0.915152
epoch-2 step 451400/3451022 - loss: 0.035330 val_loss: 0.038080	recall: 0.544565 precision: 0.926063
epoch-2 step 451500/3451022 - loss: 0.039633 val_loss: 0.037991	recall: 0.509804 precision: 0.914062
epoch-2 step 451600/3451022 - loss: 0.036495 val_loss: 0.036926	recall: 0.500532 precision: 0.916179
epoch-2 step 451700/3451022 - loss: 0.038166 val_loss: 0.038970	recall: 0.538198 precision: 0.905950
epoch-2 step 451800/3451022 - loss: 0.036515 val_loss: 0.038323	recall: 0.516199 precision: 0.921002
epoch-2 step 451900/3451022 - loss: 0.035358 val_loss: 0.035859	recall: 0.480129 precision: 0.869650
epoch-2 step 452000/3451022 - loss: 0.040272 val_loss: 0.044012	recall: 0.483170 precision: 0.893574

checkpoint saved

epoch-2 step 452100/3451022 - loss: 0.034833 val_loss: 0.035339	recall: 0.511732 precision: 0.898039

model exported!

epoch-2 step 452200/3451022 - loss: 0.036227 val_loss: 0.039315	recall: 0.524648 precision: 0.908537
epoch-2 step 452300/3451022 - loss: 0.034541 val_loss: 0.036715	recall: 0.529876 precision: 0.902111
epoch-2 step 452400/3451022 - loss: 0.035422 val_loss: 0.037338	recall: 0.496208 precision: 0.874046
epoch-2 step 452500/3451022 - loss: 0.035937 val_loss: 0.037831	recall: 0.524336 precision: 0.892655
epoch-2 step 452600/3451022 - loss: 0.065933 val_loss: 0.038824	recall: 0.510989 precision: 0.894231
epoch-2 step 452700/3451022 - loss: 0.033759 val_loss: 0.043630	recall: 0.554422 precision: 0.897248
epoch-2 step 452800/3451022 - loss: 0.037384 val_loss: 0.041527	recall: 0.556338 precision: 0.890977
epoch-2 step 452900/3451022 - loss: 0.035072 val_loss: 0.037662	recall: 0.517084 precision: 0.888454
epoch-2 step 453000/3451022 - loss: 0.034316 val_loss: 0.034662	recall: 0.546929 precision: 0.905950

checkpoint saved

epoch-2 step 453100/3451022 - loss: 0.039237 val_loss: 0.036486	recall: 0.530405 precision: 0.925344
epoch-2 step 453200/3451022 - loss: 0.035071 val_loss: 0.034108	recall: 0.526846 precision: 0.895437
epoch-2 step 453300/3451022 - loss: 0.036373 val_loss: 0.040945	recall: 0.520270 precision: 0.904110
epoch-2 step 453400/3451022 - loss: 0.038570 val_loss: 0.038798	recall: 0.538895 precision: 0.921002
epoch-2 step 453500/3451022 - loss: 0.035839 val_loss: 0.045925	recall: 0.512352 precision: 0.903409
epoch-2 step 453600/3451022 - loss: 0.034680 val_loss: 0.044847	recall: 0.491342 precision: 0.881553
epoch-2 step 453700/3451022 - loss: 0.033956 val_loss: 0.044518	recall: 0.527473 precision: 0.900563
epoch-2 step 453800/3451022 - loss: 0.035217 val_loss: 0.035064	recall: 0.501073 precision: 0.889524
epoch-2 step 453900/3451022 - loss: 0.034983 val_loss: 0.035081	recall: 0.528773 precision: 0.922348
epoch-2 step 454000/3451022 - loss: 0.033780 val_loss: 0.036013	recall: 0.525571 precision: 0.907895

checkpoint saved

epoch-2 step 454100/3451022 - loss: 0.036576 val_loss: 0.034196	recall: 0.501577 precision: 0.917308

model exported!

epoch-2 step 454200/3451022 - loss: 0.033514 val_loss: 0.048320	recall: 0.486856 precision: 0.907843
epoch-2 step 454300/3451022 - loss: 0.035900 val_loss: 0.037734	recall: 0.519829 precision: 0.930902
epoch-2 step 454400/3451022 - loss: 0.035108 val_loss: 0.036516	recall: 0.492616 precision: 0.906796
epoch-2 step 454500/3451022 - loss: 0.047656 val_loss: 0.036319	recall: 0.495671 precision: 0.892788
epoch-2 step 454600/3451022 - loss: 0.036738 val_loss: 0.035460	recall: 0.520386 precision: 0.913371
epoch-2 step 454700/3451022 - loss: 0.034847 val_loss: 0.034543	recall: 0.530658 precision: 0.915385
epoch-2 step 454800/3451022 - loss: 0.055284 val_loss: 0.034243	recall: 0.527621 precision: 0.893130
epoch-2 step 454900/3451022 - loss: 0.036006 val_loss: 0.034711	recall: 0.544850 precision: 0.923077
epoch-2 step 455000/3451022 - loss: 0.034983 val_loss: 0.036756	recall: 0.494217 precision: 0.907336

checkpoint saved

epoch-2 step 455100/3451022 - loss: 0.034690 val_loss: 0.036478	recall: 0.509534 precision: 0.946850
epoch-2 step 455200/3451022 - loss: 0.038532 val_loss: 0.034173	recall: 0.508475 precision: 0.907258
epoch-2 step 455300/3451022 - loss: 0.034397 val_loss: 0.035067	recall: 0.524017 precision: 0.912548
epoch-2 step 455400/3451022 - loss: 0.034248 val_loss: 0.039126	recall: 0.528281 precision: 0.882798
epoch-2 step 455500/3451022 - loss: 0.037701 val_loss: 0.034279	recall: 0.506608 precision: 0.905512
epoch-2 step 455600/3451022 - loss: 0.039076 val_loss: 0.035764	recall: 0.514408 precision: 0.912879
epoch-2 step 455700/3451022 - loss: 0.033537 val_loss: 0.034826	recall: 0.509847 precision: 0.896154
epoch-2 step 455800/3451022 - loss: 0.037973 val_loss: 0.039004	recall: 0.512326 precision: 0.895131
epoch-2 step 455900/3451022 - loss: 0.036797 val_loss: 0.042852	recall: 0.509626 precision: 0.896414
epoch-2 step 456000/3451022 - loss: 0.035972 val_loss: 0.036456	recall: 0.541489 precision: 0.932234

checkpoint saved

epoch-2 step 456100/3451022 - loss: 0.039351 val_loss: 0.036594	recall: 0.513398 precision: 0.915870

model exported!

epoch-2 step 456200/3451022 - loss: 0.036968 val_loss: 0.040809	recall: 0.502174 precision: 0.902344
epoch-2 step 456300/3451022 - loss: 0.036527 val_loss: 0.036599	recall: 0.519231 precision: 0.918715
epoch-2 step 456400/3451022 - loss: 0.035991 val_loss: 0.040194	recall: 0.543503 precision: 0.928571
epoch-2 step 456500/3451022 - loss: 0.034068 val_loss: 0.035979	recall: 0.526136 precision: 0.913215
epoch-2 step 456600/3451022 - loss: 0.034505 val_loss: 0.038469	recall: 0.505759 precision: 0.916509
epoch-2 step 456700/3451022 - loss: 0.039469 val_loss: 0.036503	recall: 0.492505 precision: 0.907298
epoch-2 step 456800/3451022 - loss: 0.036593 val_loss: 0.033761	recall: 0.518112 precision: 0.912959
epoch-2 step 456900/3451022 - loss: 0.035700 val_loss: 0.034265	recall: 0.470226 precision: 0.914172
epoch-2 step 457000/3451022 - loss: 0.041771 val_loss: 0.039189	recall: 0.511653 precision: 0.923518

checkpoint saved

epoch-2 step 457100/3451022 - loss: 0.035410 val_loss: 0.037049	recall: 0.500544 precision: 0.879541
epoch-2 step 457200/3451022 - loss: 0.035400 val_loss: 0.035800	recall: 0.520810 precision: 0.918651
epoch-2 step 457300/3451022 - loss: 0.040670 val_loss: 0.037435	recall: 0.497807 precision: 0.909820
epoch-2 step 457400/3451022 - loss: 0.041094 val_loss: 0.034752	recall: 0.501594 precision: 0.888889
epoch-2 step 457500/3451022 - loss: 0.036334 val_loss: 0.035532	recall: 0.545154 precision: 0.909926
epoch-2 step 457600/3451022 - loss: 0.036018 val_loss: 0.038219	recall: 0.510520 precision: 0.922000
epoch-2 step 457700/3451022 - loss: 0.035631 val_loss: 0.034150	recall: 0.524946 precision: 0.914934
epoch-2 step 457800/3451022 - loss: 0.038158 val_loss: 0.037716	recall: 0.507761 precision: 0.908730
epoch-2 step 457900/3451022 - loss: 0.035751 val_loss: 0.035556	recall: 0.539576 precision: 0.901304
epoch-2 step 458000/3451022 - loss: 0.038820 val_loss: 0.039568	recall: 0.521935 precision: 0.888889

checkpoint saved

epoch-2 step 458100/3451022 - loss: 0.036566 val_loss: 0.036927	recall: 0.486339 precision: 0.891784

model exported!

epoch-2 step 458200/3451022 - loss: 0.035265 val_loss: 0.035598	recall: 0.543280 precision: 0.901701
epoch-2 step 458300/3451022 - loss: 0.036178 val_loss: 0.035105	recall: 0.498927 precision: 0.892514
epoch-2 step 458400/3451022 - loss: 0.037655 val_loss: 0.038202	recall: 0.518717 precision: 0.923810
epoch-2 step 458500/3451022 - loss: 0.035466 val_loss: 0.034228	recall: 0.509740 precision: 0.888679
epoch-2 step 458600/3451022 - loss: 0.036097 val_loss: 0.035234	recall: 0.519495 precision: 0.907816
epoch-2 step 458700/3451022 - loss: 0.035021 val_loss: 0.034651	recall: 0.553039 precision: 0.902724
epoch-2 step 458800/3451022 - loss: 0.038836 val_loss: 0.036238	recall: 0.529148 precision: 0.902486
epoch-2 step 458900/3451022 - loss: 0.037923 val_loss: 0.035098	recall: 0.542662 precision: 0.913793
epoch-2 step 459000/3451022 - loss: 0.037138 val_loss: 0.035189	recall: 0.535280 precision: 0.890688

checkpoint saved

epoch-2 step 459100/3451022 - loss: 0.035869 val_loss: 0.035538	recall: 0.530000 precision: 0.910305
epoch-2 step 459200/3451022 - loss: 0.035599 val_loss: 0.034424	recall: 0.528027 precision: 0.918129
epoch-2 step 459300/3451022 - loss: 0.035908 val_loss: 0.033730	recall: 0.501092 precision: 0.907115
epoch-2 step 459400/3451022 - loss: 0.036399 val_loss: 0.036843	recall: 0.561677 precision: 0.914230
epoch-2 step 459500/3451022 - loss: 0.042681 val_loss: 0.039963	recall: 0.508791 precision: 0.870301
epoch-2 step 459600/3451022 - loss: 0.036160 val_loss: 0.038121	recall: 0.541766 precision: 0.897233
epoch-2 step 459700/3451022 - loss: 0.034753 val_loss: 0.040546	recall: 0.528129 precision: 0.903733
epoch-2 step 459800/3451022 - loss: 0.034249 val_loss: 0.039599	recall: 0.516022 precision: 0.898077
epoch-2 step 459900/3451022 - loss: 0.037854 val_loss: 0.036712	recall: 0.524444 precision: 0.921875
epoch-2 step 460000/3451022 - loss: 0.036665 val_loss: 0.040021	recall: 0.530108 precision: 0.921495

checkpoint saved

epoch-2 step 460100/3451022 - loss: 0.035642 val_loss: 0.036842	recall: 0.544419 precision: 0.908745

model exported!

epoch-2 step 460200/3451022 - loss: 0.035209 val_loss: 0.038493	recall: 0.538724 precision: 0.882463
epoch-2 step 460300/3451022 - loss: 0.037943 val_loss: 0.038620	recall: 0.527621 precision: 0.919450
epoch-2 step 460400/3451022 - loss: 0.040143 val_loss: 0.039445	recall: 0.550000 precision: 0.909615
epoch-2 step 460500/3451022 - loss: 0.038782 val_loss: 0.034659	recall: 0.543084 precision: 0.908918
epoch-2 step 460600/3451022 - loss: 0.035182 val_loss: 0.038614	recall: 0.496241 precision: 0.905882
epoch-2 step 460700/3451022 - loss: 0.035026 val_loss: 0.039442	recall: 0.486744 precision: 0.884393
epoch-2 step 460800/3451022 - loss: 0.035612 val_loss: 0.034632	recall: 0.538117 precision: 0.917782
epoch-2 step 460900/3451022 - loss: 0.035641 val_loss: 0.039432	recall: 0.516704 precision: 0.900971
epoch-2 step 461000/3451022 - loss: 0.035384 val_loss: 0.035906	recall: 0.519210 precision: 0.900952

checkpoint saved

epoch-2 step 461100/3451022 - loss: 0.036588 val_loss: 0.037199	recall: 0.507378 precision: 0.885149
epoch-2 step 461200/3451022 - loss: 0.037294 val_loss: 0.038173	recall: 0.503735 precision: 0.918288
epoch-2 step 461300/3451022 - loss: 0.042236 val_loss: 0.039238	recall: 0.521081 precision: 0.925144
epoch-2 step 461400/3451022 - loss: 0.035266 val_loss: 0.037479	recall: 0.501111 precision: 0.893069
epoch-2 step 461500/3451022 - loss: 0.034169 val_loss: 0.038680	recall: 0.539792 precision: 0.906977
epoch-2 step 461600/3451022 - loss: 0.036519 val_loss: 0.035843	recall: 0.528736 precision: 0.896686
epoch-2 step 461700/3451022 - loss: 0.040483 val_loss: 0.036856	recall: 0.552941 precision: 0.909091
epoch-2 step 461800/3451022 - loss: 0.035199 val_loss: 0.038329	recall: 0.520455 precision: 0.906931
epoch-2 step 461900/3451022 - loss: 0.035191 val_loss: 0.036448	recall: 0.500000 precision: 0.906000
epoch-2 step 462000/3451022 - loss: 0.038019 val_loss: 0.035662	recall: 0.532571 precision: 0.906615

checkpoint saved

epoch-2 step 462100/3451022 - loss: 0.035020 val_loss: 0.034463	recall: 0.533410 precision: 0.899029

model exported!

epoch-2 step 462200/3451022 - loss: 0.041238 val_loss: 0.039082	recall: 0.536332 precision: 0.904669
epoch-2 step 462300/3451022 - loss: 0.034794 val_loss: 0.036063	recall: 0.510441 precision: 0.883534
epoch-2 step 462400/3451022 - loss: 0.037715 val_loss: 0.035514	recall: 0.552326 precision: 0.929550
epoch-2 step 462500/3451022 - loss: 0.035342 val_loss: 0.035425	recall: 0.556805 precision: 0.930451
epoch-2 step 462600/3451022 - loss: 0.040308 val_loss: 0.035780	recall: 0.520971 precision: 0.932806
epoch-2 step 462700/3451022 - loss: 0.035772 val_loss: 0.041785	recall: 0.523294 precision: 0.897770
epoch-2 step 462800/3451022 - loss: 0.035221 val_loss: 0.038159	recall: 0.521452 precision: 0.901141
epoch-2 step 462900/3451022 - loss: 0.042046 val_loss: 0.035356	recall: 0.537383 precision: 0.907298
epoch-2 step 463000/3451022 - loss: 0.038009 val_loss: 0.036582	recall: 0.515882 precision: 0.914563

checkpoint saved

epoch-2 step 463100/3451022 - loss: 0.044739 val_loss: 0.036963	recall: 0.549654 precision: 0.913628
epoch-2 step 463200/3451022 - loss: 0.036858 val_loss: 0.037814	recall: 0.512514 precision: 0.893738
epoch-2 step 463300/3451022 - loss: 0.047305 val_loss: 0.038582	recall: 0.524943 precision: 0.916832
epoch-2 step 463400/3451022 - loss: 0.037394 val_loss: 0.034050	recall: 0.529680 precision: 0.904483
epoch-2 step 463500/3451022 - loss: 0.036120 val_loss: 0.036139	recall: 0.511161 precision: 0.917836
epoch-2 step 463600/3451022 - loss: 0.037747 val_loss: 0.034516	recall: 0.497286 precision: 0.908730
epoch-2 step 463700/3451022 - loss: 0.035772 val_loss: 0.033871	recall: 0.538983 precision: 0.908571
epoch-2 step 463800/3451022 - loss: 0.035138 val_loss: 0.037178	recall: 0.529279 precision: 0.895238
epoch-2 step 463900/3451022 - loss: 0.038589 val_loss: 0.034545	recall: 0.525084 precision: 0.895437
epoch-2 step 464000/3451022 - loss: 0.035756 val_loss: 0.038791	recall: 0.536036 precision: 0.915385

checkpoint saved

epoch-2 step 464100/3451022 - loss: 0.041758 val_loss: 0.035620	recall: 0.498423 precision: 0.890977

model exported!

epoch-2 step 464200/3451022 - loss: 0.036895 val_loss: 0.037881	recall: 0.514626 precision: 0.901328
epoch-2 step 464300/3451022 - loss: 0.034929 val_loss: 0.039174	recall: 0.508976 precision: 0.916350
epoch-2 step 464400/3451022 - loss: 0.036406 val_loss: 0.033953	recall: 0.508889 precision: 0.906931
epoch-2 step 464500/3451022 - loss: 0.037660 val_loss: 0.036940	recall: 0.526257 precision: 0.911025
epoch-2 step 464600/3451022 - loss: 0.034185 val_loss: 0.035056	recall: 0.513333 precision: 0.918489
epoch-2 step 464700/3451022 - loss: 0.037212 val_loss: 0.037029	recall: 0.568786 precision: 0.930057
epoch-2 step 464800/3451022 - loss: 0.037778 val_loss: 0.034404	recall: 0.525253 precision: 0.928571
epoch-2 step 464900/3451022 - loss: 0.036880 val_loss: 0.034656	recall: 0.508565 precision: 0.906489
epoch-2 step 465000/3451022 - loss: 0.036082 val_loss: 0.036561	recall: 0.497156 precision: 0.895492

checkpoint saved

epoch-2 step 465100/3451022 - loss: 0.036116 val_loss: 0.037808	recall: 0.516376 precision: 0.925636
epoch-2 step 465200/3451022 - loss: 0.037009 val_loss: 0.034468	recall: 0.531148 precision: 0.913534
epoch-2 step 465300/3451022 - loss: 0.036571 val_loss: 0.036577	recall: 0.523179 precision: 0.909789
epoch-2 step 465400/3451022 - loss: 0.033821 val_loss: 0.041285	recall: 0.505376 precision: 0.909091
epoch-2 step 465500/3451022 - loss: 0.036044 val_loss: 0.035197	recall: 0.545351 precision: 0.923225
epoch-2 step 465600/3451022 - loss: 0.035383 val_loss: 0.036607	recall: 0.532805 precision: 0.909266
epoch-2 step 465700/3451022 - loss: 0.036201 val_loss: 0.034165	recall: 0.511450 precision: 0.916016
epoch-2 step 465800/3451022 - loss: 0.034675 val_loss: 0.036709	recall: 0.501066 precision: 0.905588
epoch-2 step 465900/3451022 - loss: 0.035588 val_loss: 0.043400	recall: 0.508475 precision: 0.898876
epoch-2 step 466000/3451022 - loss: 0.035288 val_loss: 0.035487	recall: 0.511013 precision: 0.897485

checkpoint saved

epoch-2 step 466100/3451022 - loss: 0.034438 val_loss: 0.034626	recall: 0.514640 precision: 0.889105

model exported!

epoch-2 step 466200/3451022 - loss: 0.035989 val_loss: 0.035947	recall: 0.516199 precision: 0.912214
epoch-2 step 466300/3451022 - loss: 0.036660 val_loss: 0.037242	recall: 0.534541 precision: 0.921875
epoch-2 step 466400/3451022 - loss: 0.036223 val_loss: 0.036545	recall: 0.514381 precision: 0.904669
epoch-2 step 466500/3451022 - loss: 0.035751 val_loss: 0.041040	recall: 0.518018 precision: 0.898438
epoch-2 step 466600/3451022 - loss: 0.036530 val_loss: 0.041911	recall: 0.533860 precision: 0.900952
epoch-2 step 466700/3451022 - loss: 0.037949 val_loss: 0.035540	recall: 0.519101 precision: 0.895349
epoch-2 step 466800/3451022 - loss: 0.034069 val_loss: 0.034566	recall: 0.517007 precision: 0.915663
epoch-2 step 466900/3451022 - loss: 0.035031 val_loss: 0.037575	recall: 0.534444 precision: 0.904135
epoch-2 step 467000/3451022 - loss: 0.039733 val_loss: 0.034826	recall: 0.524184 precision: 0.911937

checkpoint saved

epoch-2 step 467100/3451022 - loss: 0.043358 val_loss: 0.033835	recall: 0.521547 precision: 0.902486
epoch-2 step 467200/3451022 - loss: 0.034754 val_loss: 0.034757	recall: 0.540888 precision: 0.922311
epoch-2 step 467300/3451022 - loss: 0.036238 val_loss: 0.035720	recall: 0.495177 precision: 0.891892
epoch-2 step 467400/3451022 - loss: 0.034859 val_loss: 0.035415	recall: 0.510591 precision: 0.885880
epoch-2 step 467500/3451022 - loss: 0.035054 val_loss: 0.035779	recall: 0.525539 precision: 0.883588
epoch-2 step 467600/3451022 - loss: 0.036922 val_loss: 0.034988	recall: 0.533869 precision: 0.892514
epoch-2 step 467700/3451022 - loss: 0.034562 val_loss: 0.033723	recall: 0.532872 precision: 0.902344
epoch-2 step 467800/3451022 - loss: 0.034757 val_loss: 0.035244	recall: 0.537037 precision: 0.912963
epoch-2 step 467900/3451022 - loss: 0.037915 val_loss: 0.042600	recall: 0.536806 precision: 0.896030
epoch-2 step 468000/3451022 - loss: 0.035700 val_loss: 0.034500	recall: 0.520971 precision: 0.874074

checkpoint saved

epoch-2 step 468100/3451022 - loss: 0.035163 val_loss: 0.034404	recall: 0.518637 precision: 0.901852

model exported!

epoch-2 step 468200/3451022 - loss: 0.039200 val_loss: 0.035923	recall: 0.538983 precision: 0.919075
epoch-2 step 468300/3451022 - loss: 0.035271 val_loss: 0.039792	recall: 0.508696 precision: 0.889734
epoch-2 step 468400/3451022 - loss: 0.036301 val_loss: 0.034528	recall: 0.504329 precision: 0.896154
epoch-2 step 468500/3451022 - loss: 0.036730 val_loss: 0.039569	recall: 0.492693 precision: 0.895636
epoch-2 step 468600/3451022 - loss: 0.040535 val_loss: 0.036956	recall: 0.524130 precision: 0.886148
epoch-2 step 468700/3451022 - loss: 0.034362 val_loss: 0.035521	recall: 0.534342 precision: 0.914343
epoch-2 step 468800/3451022 - loss: 0.034470 val_loss: 0.035729	recall: 0.495825 precision: 0.896226
epoch-2 step 468900/3451022 - loss: 0.034329 val_loss: 0.041786	recall: 0.574007 precision: 0.901701
epoch-2 step 469000/3451022 - loss: 0.047037 val_loss: 0.037603	recall: 0.512168 precision: 0.890385

checkpoint saved

epoch-2 step 469100/3451022 - loss: 0.039142 val_loss: 0.035916	recall: 0.532222 precision: 0.895327
epoch-2 step 469200/3451022 - loss: 0.036391 val_loss: 0.037041	recall: 0.504264 precision: 0.895833
epoch-2 step 469300/3451022 - loss: 0.039439 val_loss: 0.034443	recall: 0.496674 precision: 0.912424
epoch-2 step 469400/3451022 - loss: 0.036007 val_loss: 0.039796	recall: 0.524444 precision: 0.904215
epoch-2 step 469500/3451022 - loss: 0.036167 val_loss: 0.042155	recall: 0.520971 precision: 0.895636
epoch-2 step 469600/3451022 - loss: 0.036344 val_loss: 0.037553	recall: 0.523438 precision: 0.923228
epoch-2 step 469700/3451022 - loss: 0.036515 val_loss: 0.035441	recall: 0.539954 precision: 0.925636
epoch-2 step 469800/3451022 - loss: 0.037039 val_loss: 0.035059	recall: 0.507295 precision: 0.900398
epoch-2 step 469900/3451022 - loss: 0.035883 val_loss: 0.041875	recall: 0.500000 precision: 0.879845
epoch-2 step 470000/3451022 - loss: 0.035058 val_loss: 0.041392	recall: 0.513843 precision: 0.902724

checkpoint saved

epoch-2 step 470100/3451022 - loss: 0.036465 val_loss: 0.034558	recall: 0.514130 precision: 0.909615

model exported!

epoch-2 step 470200/3451022 - loss: 0.035248 val_loss: 0.036362	recall: 0.531891 precision: 0.903288
epoch-2 step 470300/3451022 - loss: 0.036320 val_loss: 0.048306	recall: 0.515351 precision: 0.898662
epoch-2 step 470400/3451022 - loss: 0.033941 val_loss: 0.034771	recall: 0.537768 precision: 0.919075
epoch-2 step 470500/3451022 - loss: 0.039477 val_loss: 0.036790	recall: 0.508108 precision: 0.916179
epoch-2 step 470600/3451022 - loss: 0.037486 val_loss: 0.039062	recall: 0.494336 precision: 0.909091
epoch-2 step 470700/3451022 - loss: 0.041885 val_loss: 0.041639	recall: 0.535794 precision: 0.902072
epoch-2 step 470800/3451022 - loss: 0.035873 val_loss: 0.038276	recall: 0.532438 precision: 0.913628
epoch-2 step 470900/3451022 - loss: 0.034934 val_loss: 0.042245	recall: 0.479277 precision: 0.912955
epoch-2 step 471000/3451022 - loss: 0.038534 val_loss: 0.037493	recall: 0.506682 precision: 0.895669

checkpoint saved

epoch-2 step 471100/3451022 - loss: 0.038466 val_loss: 0.034623	recall: 0.507353 precision: 0.909605
epoch-2 step 471200/3451022 - loss: 0.037456 val_loss: 0.035609	recall: 0.501035 precision: 0.913208
epoch-2 step 471300/3451022 - loss: 0.036657 val_loss: 0.034509	recall: 0.522371 precision: 0.915686
epoch-2 step 471400/3451022 - loss: 0.034907 val_loss: 0.039086	recall: 0.503973 precision: 0.923077
epoch-2 step 471500/3451022 - loss: 0.035365 val_loss: 0.045471	recall: 0.538976 precision: 0.923664
epoch-2 step 471600/3451022 - loss: 0.034375 val_loss: 0.036618	recall: 0.498353 precision: 0.890196
epoch-2 step 471700/3451022 - loss: 0.036992 val_loss: 0.037322	recall: 0.513398 precision: 0.917625
epoch-2 step 471800/3451022 - loss: 0.035783 val_loss: 0.035985	recall: 0.538198 precision: 0.899048
epoch-2 step 471900/3451022 - loss: 0.035529 val_loss: 0.039681	recall: 0.521935 precision: 0.926148
epoch-2 step 472000/3451022 - loss: 0.035252 val_loss: 0.034040	recall: 0.556064 precision: 0.911820

checkpoint saved

epoch-2 step 472100/3451022 - loss: 0.037288 val_loss: 0.037082	recall: 0.522307 precision: 0.916031

model exported!

epoch-2 step 472200/3451022 - loss: 0.034453 val_loss: 0.035643	recall: 0.551066 precision: 0.916045
epoch-2 step 472300/3451022 - loss: 0.041018 val_loss: 0.034803	recall: 0.501040 precision: 0.918095
epoch-2 step 472400/3451022 - loss: 0.035562 val_loss: 0.034032	recall: 0.531042 precision: 0.917625
epoch-2 step 472500/3451022 - loss: 0.035255 val_loss: 0.034802	recall: 0.524807 precision: 0.884758
epoch-2 step 472600/3451022 - loss: 0.037042 val_loss: 0.034851	recall: 0.545455 precision: 0.916828
epoch-2 step 472700/3451022 - loss: 0.035650 val_loss: 0.053063	recall: 0.507592 precision: 0.906977
epoch-2 step 472800/3451022 - loss: 0.034240 val_loss: 0.039878	recall: 0.536842 precision: 0.916168
epoch-2 step 472900/3451022 - loss: 0.036441 val_loss: 0.035972	recall: 0.533708 precision: 0.909962
epoch-2 step 473000/3451022 - loss: 0.036192 val_loss: 0.042714	recall: 0.560137 precision: 0.917448

checkpoint saved

epoch-2 step 473100/3451022 - loss: 0.034538 val_loss: 0.036567	recall: 0.498963 precision: 0.890741
epoch-2 step 473200/3451022 - loss: 0.035981 val_loss: 0.035822	recall: 0.535556 precision: 0.912879
epoch-2 step 473300/3451022 - loss: 0.034835 val_loss: 0.036589	recall: 0.544622 precision: 0.906667
epoch-2 step 473400/3451022 - loss: 0.035168 val_loss: 0.035795	recall: 0.537611 precision: 0.927481
epoch-2 step 473500/3451022 - loss: 0.035317 val_loss: 0.035275	recall: 0.535874 precision: 0.922780
epoch-2 step 473600/3451022 - loss: 0.035608 val_loss: 0.039645	recall: 0.518764 precision: 0.903846
epoch-2 step 473700/3451022 - loss: 0.034783 val_loss: 0.035310	recall: 0.517354 precision: 0.898305
epoch-2 step 473800/3451022 - loss: 0.039106 val_loss: 0.036114	recall: 0.550228 precision: 0.911153
epoch-2 step 473900/3451022 - loss: 0.036216 val_loss: 0.036222	recall: 0.548766 precision: 0.905039
epoch-2 step 474000/3451022 - loss: 0.036577 val_loss: 0.039545	recall: 0.529809 precision: 0.882022

checkpoint saved

epoch-2 step 474100/3451022 - loss: 0.042061 val_loss: 0.034540	recall: 0.516930 precision: 0.905138

model exported!

epoch-2 step 474200/3451022 - loss: 0.043692 val_loss: 0.037760	recall: 0.543743 precision: 0.900917
epoch-2 step 474300/3451022 - loss: 0.041035 val_loss: 0.040592	recall: 0.504396 precision: 0.889535
epoch-2 step 474400/3451022 - loss: 0.034665 val_loss: 0.035486	recall: 0.487368 precision: 0.904297
epoch-2 step 474500/3451022 - loss: 0.038339 val_loss: 0.034731	recall: 0.516060 precision: 0.918095
epoch-2 step 474600/3451022 - loss: 0.036223 val_loss: 0.035460	recall: 0.540793 precision: 0.882129
epoch-2 step 474700/3451022 - loss: 0.043529 val_loss: 0.041687	recall: 0.518771 precision: 0.899408
epoch-2 step 474800/3451022 - loss: 0.034699 val_loss: 0.050735	recall: 0.544835 precision: 0.893855
epoch-2 step 474900/3451022 - loss: 0.040128 val_loss: 0.039359	recall: 0.526132 precision: 0.897030
epoch-2 step 475000/3451022 - loss: 0.035150 val_loss: 0.035169	recall: 0.547344 precision: 0.927593

checkpoint saved

epoch-2 step 475100/3451022 - loss: 0.034590 val_loss: 0.037067	recall: 0.529876 precision: 0.923379
epoch-2 step 475200/3451022 - loss: 0.035397 val_loss: 0.037240	recall: 0.536313 precision: 0.916031
epoch-2 step 475300/3451022 - loss: 0.042682 val_loss: 0.035620	recall: 0.531073 precision: 0.902111
epoch-2 step 475400/3451022 - loss: 0.034669 val_loss: 0.038795	recall: 0.516968 precision: 0.904950
epoch-2 step 475500/3451022 - loss: 0.036270 val_loss: 0.035176	recall: 0.529481 precision: 0.907071
epoch-2 step 475600/3451022 - loss: 0.034914 val_loss: 0.036057	recall: 0.507848 precision: 0.917004
epoch-2 step 475700/3451022 - loss: 0.039106 val_loss: 0.035471	recall: 0.547674 precision: 0.911025
epoch-2 step 475800/3451022 - loss: 0.035595 val_loss: 0.033867	recall: 0.524324 precision: 0.923810
epoch-2 step 475900/3451022 - loss: 0.036609 val_loss: 0.036354	recall: 0.506711 precision: 0.904192
epoch-2 step 476000/3451022 - loss: 0.038131 val_loss: 0.042424	recall: 0.506997 precision: 0.888679

checkpoint saved

epoch-2 step 476100/3451022 - loss: 0.039685 val_loss: 0.035443	recall: 0.488069 precision: 0.889328

model exported!

epoch-2 step 476200/3451022 - loss: 0.038686 val_loss: 0.035570	recall: 0.514192 precision: 0.918129
epoch-2 step 476300/3451022 - loss: 0.034999 val_loss: 0.035818	recall: 0.521643 precision: 0.902111
epoch-2 step 476400/3451022 - loss: 0.034810 val_loss: 0.034081	recall: 0.513312 precision: 0.907721
epoch-2 step 476500/3451022 - loss: 0.034513 val_loss: 0.034536	recall: 0.495228 precision: 0.906796
epoch-2 step 476600/3451022 - loss: 0.035266 val_loss: 0.035378	recall: 0.514408 precision: 0.900935
epoch-2 step 476700/3451022 - loss: 0.035032 val_loss: 0.036293	recall: 0.515118 precision: 0.894942
epoch-2 step 476800/3451022 - loss: 0.040213 val_loss: 0.036498	recall: 0.519956 precision: 0.891635
epoch-2 step 476900/3451022 - loss: 0.036561 val_loss: 0.036393	recall: 0.512277 precision: 0.908911
epoch-2 step 477000/3451022 - loss: 0.035766 val_loss: 0.035874	recall: 0.507026 precision: 0.862550

checkpoint saved

epoch-2 step 477100/3451022 - loss: 0.038111 val_loss: 0.041052	recall: 0.549944 precision: 0.931559
epoch-2 step 477200/3451022 - loss: 0.037275 val_loss: 0.040109	recall: 0.517954 precision: 0.893058
epoch-2 step 477300/3451022 - loss: 0.040828 val_loss: 0.037514	recall: 0.518519 precision: 0.868217
epoch-2 step 477400/3451022 - loss: 0.035151 val_loss: 0.036695	recall: 0.566467 precision: 0.895833
epoch-2 step 477500/3451022 - loss: 0.037981 val_loss: 0.038472	recall: 0.525109 precision: 0.907547
epoch-2 step 477600/3451022 - loss: 0.039287 val_loss: 0.039934	recall: 0.509476 precision: 0.889105
epoch-2 step 477700/3451022 - loss: 0.036081 val_loss: 0.037695	recall: 0.506682 precision: 0.904573
epoch-2 step 477800/3451022 - loss: 0.037423 val_loss: 0.042606	recall: 0.520474 precision: 0.921756
epoch-2 step 477900/3451022 - loss: 0.034342 val_loss: 0.037395	recall: 0.523915 precision: 0.887006
epoch-2 step 478000/3451022 - loss: 0.035272 val_loss: 0.037122	recall: 0.494692 precision: 0.897881

checkpoint saved

epoch-2 step 478100/3451022 - loss: 0.036654 val_loss: 0.034855	recall: 0.514739 precision: 0.874759

model exported!

epoch-2 step 478200/3451022 - loss: 0.036982 val_loss: 0.036404	recall: 0.541570 precision: 0.910680
epoch-2 step 478300/3451022 - loss: 0.036664 val_loss: 0.037824	recall: 0.521886 precision: 0.922619
epoch-2 step 478400/3451022 - loss: 0.040800 val_loss: 0.037554	recall: 0.510520 precision: 0.903922
epoch-2 step 478500/3451022 - loss: 0.034932 val_loss: 0.040786	recall: 0.553957 precision: 0.922156
epoch-2 step 478600/3451022 - loss: 0.044372 val_loss: 0.038753	recall: 0.530369 precision: 0.905556
epoch-2 step 478700/3451022 - loss: 0.039668 val_loss: 0.040639	recall: 0.527745 precision: 0.885149
epoch-2 step 478800/3451022 - loss: 0.036130 val_loss: 0.034588	recall: 0.521143 precision: 0.895874
epoch-2 step 478900/3451022 - loss: 0.034392 val_loss: 0.041348	recall: 0.536530 precision: 0.914397
epoch-2 step 479000/3451022 - loss: 0.044845 val_loss: 0.035364	recall: 0.519956 precision: 0.917808

checkpoint saved

epoch-2 step 479100/3451022 - loss: 0.035000 val_loss: 0.034844	recall: 0.503247 precision: 0.913556
epoch-2 step 479200/3451022 - loss: 0.041002 val_loss: 0.041555	recall: 0.513245 precision: 0.895954
epoch-2 step 479300/3451022 - loss: 0.035610 val_loss: 0.035394	recall: 0.496802 precision: 0.920949
epoch-2 step 479400/3451022 - loss: 0.036245 val_loss: 0.037250	recall: 0.518152 precision: 0.905769
epoch-2 step 479500/3451022 - loss: 0.034929 val_loss: 0.034875	recall: 0.539906 precision: 0.909091
epoch-2 step 479600/3451022 - loss: 0.036728 val_loss: 0.033911	recall: 0.537870 precision: 0.909091
epoch-2 step 479700/3451022 - loss: 0.040872 val_loss: 0.039053	recall: 0.532887 precision: 0.919231
epoch-2 step 479800/3451022 - loss: 0.038166 val_loss: 0.034270	recall: 0.502208 precision: 0.921053
epoch-2 step 479900/3451022 - loss: 0.037409 val_loss: 0.035349	recall: 0.506550 precision: 0.880455
epoch-2 step 480000/3451022 - loss: 0.036083 val_loss: 0.035050	recall: 0.525253 precision: 0.903475

checkpoint saved

epoch-2 step 480100/3451022 - loss: 0.040301 val_loss: 0.035482	recall: 0.516274 precision: 0.909091

model exported!

epoch-2 step 480200/3451022 - loss: 0.040123 val_loss: 0.034523	recall: 0.521991 precision: 0.880859
epoch-2 step 480300/3451022 - loss: 0.037771 val_loss: 0.036052	recall: 0.524483 precision: 0.911153
epoch-2 step 480400/3451022 - loss: 0.034599 val_loss: 0.034860	recall: 0.525172 precision: 0.887814
epoch-2 step 480500/3451022 - loss: 0.049806 val_loss: 0.039423	recall: 0.513544 precision: 0.902778
epoch-2 step 480600/3451022 - loss: 0.037654 val_loss: 0.041871	recall: 0.528042 precision: 0.927509
epoch-2 step 480700/3451022 - loss: 0.033708 val_loss: 0.056866	recall: 0.521300 precision: 0.895954
epoch-2 step 480800/3451022 - loss: 0.044812 val_loss: 0.036164	recall: 0.529477 precision: 0.898113
epoch-2 step 480900/3451022 - loss: 0.039499 val_loss: 0.034507	recall: 0.496725 precision: 0.888672
epoch-2 step 481000/3451022 - loss: 0.036520 val_loss: 0.035238	recall: 0.514223 precision: 0.919765

checkpoint saved

epoch-2 step 481100/3451022 - loss: 0.047851 val_loss: 0.039014	recall: 0.524741 precision: 0.908367
epoch-2 step 481200/3451022 - loss: 0.037077 val_loss: 0.036090	recall: 0.524609 precision: 0.896750
epoch-2 step 481300/3451022 - loss: 0.034905 val_loss: 0.042191	recall: 0.514640 precision: 0.904950
epoch-2 step 481400/3451022 - loss: 0.035731 val_loss: 0.035769	recall: 0.509413 precision: 0.923695
epoch-2 step 481500/3451022 - loss: 0.043231 val_loss: 0.044882	recall: 0.513859 precision: 0.921606
epoch-2 step 481600/3451022 - loss: 0.036527 val_loss: 0.036687	recall: 0.529742 precision: 0.920078
epoch-2 step 481700/3451022 - loss: 0.035669 val_loss: 0.034290	recall: 0.507042 precision: 0.915851
epoch-2 step 481800/3451022 - loss: 0.045395 val_loss: 0.036368	recall: 0.489224 precision: 0.886719
epoch-2 step 481900/3451022 - loss: 0.034822 val_loss: 0.036435	recall: 0.542519 precision: 0.933333
epoch-2 step 482000/3451022 - loss: 0.035214 val_loss: 0.034269	recall: 0.527714 precision: 0.894325

checkpoint saved

epoch-2 step 482100/3451022 - loss: 0.036043 val_loss: 0.040054	recall: 0.527473 precision: 0.919540

model exported!

epoch-2 step 482200/3451022 - loss: 0.035801 val_loss: 0.034924	recall: 0.517014 precision: 0.885338
epoch-2 step 482300/3451022 - loss: 0.043971 val_loss: 0.035257	recall: 0.513998 precision: 0.923541
epoch-2 step 482400/3451022 - loss: 0.036976 val_loss: 0.037164	recall: 0.555940 precision: 0.934109
epoch-2 step 482500/3451022 - loss: 0.034665 val_loss: 0.035363	recall: 0.502775 precision: 0.886497
epoch-2 step 482600/3451022 - loss: 0.035753 val_loss: 0.036224	recall: 0.511577 precision: 0.913386
epoch-2 step 482700/3451022 - loss: 0.035328 val_loss: 0.039019	recall: 0.519294 precision: 0.902299
epoch-2 step 482800/3451022 - loss: 0.033893 val_loss: 0.034840	recall: 0.524027 precision: 0.905138
epoch-2 step 482900/3451022 - loss: 0.039900 val_loss: 0.036136	recall: 0.535752 precision: 0.917733
epoch-2 step 483000/3451022 - loss: 0.034522 val_loss: 0.040735	recall: 0.502075 precision: 0.904673

checkpoint saved

epoch-2 step 483100/3451022 - loss: 0.035062 val_loss: 0.035832	recall: 0.536199 precision: 0.918605
epoch-2 step 483200/3451022 - loss: 0.036279 val_loss: 0.035341	recall: 0.514640 precision: 0.901381
epoch-2 step 483300/3451022 - loss: 0.035465 val_loss: 0.037974	recall: 0.515017 precision: 0.918651
epoch-2 step 483400/3451022 - loss: 0.035111 val_loss: 0.035530	recall: 0.501106 precision: 0.924490
epoch-2 step 483500/3451022 - loss: 0.035158 val_loss: 0.035763	recall: 0.519912 precision: 0.900383
epoch-2 step 483600/3451022 - loss: 0.035632 val_loss: 0.046878	recall: 0.510710 precision: 0.884766
epoch-2 step 483700/3451022 - loss: 0.034289 val_loss: 0.034185	recall: 0.527778 precision: 0.904762
epoch-2 step 483800/3451022 - loss: 0.050354 val_loss: 0.035758	recall: 0.518313 precision: 0.906796
epoch-2 step 483900/3451022 - loss: 0.036777 val_loss: 0.035217	recall: 0.535068 precision: 0.899240
epoch-2 step 484000/3451022 - loss: 0.035920 val_loss: 0.034092	recall: 0.568209 precision: 0.917625

checkpoint saved

epoch-2 step 484100/3451022 - loss: 0.041161 val_loss: 0.035813	recall: 0.502714 precision: 0.918651

model exported!

epoch-2 step 484200/3451022 - loss: 0.034346 val_loss: 0.040434	recall: 0.507230 precision: 0.913828
epoch-2 step 484300/3451022 - loss: 0.036190 val_loss: 0.034274	recall: 0.513966 precision: 0.889749
epoch-2 step 484400/3451022 - loss: 0.035058 val_loss: 0.035057	recall: 0.527233 precision: 0.921905
epoch-2 step 484500/3451022 - loss: 0.037781 val_loss: 0.039042	recall: 0.500000 precision: 0.903808
epoch-2 step 484600/3451022 - loss: 0.034406 val_loss: 0.042775	recall: 0.531429 precision: 0.901163
epoch-2 step 484700/3451022 - loss: 0.035542 val_loss: 0.039933	recall: 0.531712 precision: 0.924632
epoch-2 step 484800/3451022 - loss: 0.034271 val_loss: 0.035853	recall: 0.512472 precision: 0.902196
epoch-2 step 484900/3451022 - loss: 0.038289 val_loss: 0.034568	recall: 0.525140 precision: 0.905588
epoch-2 step 485000/3451022 - loss: 0.036268 val_loss: 0.044619	recall: 0.534325 precision: 0.903288

checkpoint saved

epoch-2 step 485100/3451022 - loss: 0.036190 val_loss: 0.037953	recall: 0.539977 precision: 0.926441
epoch-2 step 485200/3451022 - loss: 0.036755 val_loss: 0.033925	recall: 0.482869 precision: 0.872340
epoch-2 step 485300/3451022 - loss: 0.035795 val_loss: 0.036915	recall: 0.519694 precision: 0.908222
epoch-2 step 485400/3451022 - loss: 0.037514 val_loss: 0.039965	recall: 0.527508 precision: 0.903882
epoch-2 step 485500/3451022 - loss: 0.036278 val_loss: 0.035006	recall: 0.506051 precision: 0.891473
epoch-2 step 485600/3451022 - loss: 0.037825 val_loss: 0.034512	recall: 0.517857 precision: 0.887189
epoch-2 step 485700/3451022 - loss: 0.038669 val_loss: 0.034658	recall: 0.547126 precision: 0.918919
epoch-2 step 485800/3451022 - loss: 0.036232 val_loss: 0.035450	recall: 0.533257 precision: 0.909980
epoch-2 step 485900/3451022 - loss: 0.034682 val_loss: 0.035421	recall: 0.545455 precision: 0.924855
epoch-2 step 486000/3451022 - loss: 0.037729 val_loss: 0.037783	recall: 0.523269 precision: 0.912871

checkpoint saved

epoch-2 step 486100/3451022 - loss: 0.034607 val_loss: 0.036854	recall: 0.527012 precision: 0.921002

model exported!

epoch-2 step 486200/3451022 - loss: 0.034381 val_loss: 0.034665	recall: 0.530474 precision: 0.909091
epoch-2 step 486300/3451022 - loss: 0.034832 val_loss: 0.039721	recall: 0.517203 precision: 0.910156
epoch-2 step 486400/3451022 - loss: 0.040482 val_loss: 0.034809	recall: 0.511111 precision: 0.898438
epoch-2 step 486500/3451022 - loss: 0.034782 val_loss: 0.039857	recall: 0.520533 precision: 0.923228
epoch-2 step 486600/3451022 - loss: 0.040297 val_loss: 0.034096	recall: 0.501597 precision: 0.904031
epoch-2 step 486700/3451022 - loss: 0.034734 val_loss: 0.035748	recall: 0.482937 precision: 0.896353
epoch-2 step 486800/3451022 - loss: 0.039634 val_loss: 0.036106	recall: 0.478624 precision: 0.901768
epoch-2 step 486900/3451022 - loss: 0.039975 val_loss: 0.038610	recall: 0.537528 precision: 0.913696
epoch-2 step 487000/3451022 - loss: 0.037231 val_loss: 0.053162	recall: 0.524022 precision: 0.916016

checkpoint saved

epoch-2 step 487100/3451022 - loss: 0.036318 val_loss: 0.036548	recall: 0.523555 precision: 0.902214
epoch-2 step 487200/3451022 - loss: 0.034399 val_loss: 0.041152	recall: 0.505330 precision: 0.922179
epoch-2 step 487300/3451022 - loss: 0.035121 val_loss: 0.035876	recall: 0.538122 precision: 0.925856
epoch-2 step 487400/3451022 - loss: 0.035008 val_loss: 0.035232	recall: 0.515676 precision: 0.878453
epoch-2 step 487500/3451022 - loss: 0.037591 val_loss: 0.035344	recall: 0.536151 precision: 0.921606
epoch-2 step 487600/3451022 - loss: 0.036157 val_loss: 0.038172	recall: 0.508269 precision: 0.914683
epoch-2 step 487700/3451022 - loss: 0.033727 val_loss: 0.035894	recall: 0.564103 precision: 0.930147
epoch-2 step 487800/3451022 - loss: 0.036477 val_loss: 0.038509	recall: 0.539227 precision: 0.925996
epoch-2 step 487900/3451022 - loss: 0.041482 val_loss: 0.035745	recall: 0.511088 precision: 0.923664
epoch-2 step 488000/3451022 - loss: 0.039930 val_loss: 0.039566	recall: 0.545455 precision: 0.912281

checkpoint saved

epoch-2 step 488100/3451022 - loss: 0.035919 val_loss: 0.040876	recall: 0.538190 precision: 0.880769

model exported!

epoch-2 step 488200/3451022 - loss: 0.035892 val_loss: 0.037291	recall: 0.511706 precision: 0.898239
epoch-2 step 488300/3451022 - loss: 0.039912 val_loss: 0.035833	recall: 0.511758 precision: 0.870476
epoch-2 step 488400/3451022 - loss: 0.035766 val_loss: 0.041716	recall: 0.496788 precision: 0.900971
epoch-2 step 488500/3451022 - loss: 0.035998 val_loss: 0.039483	recall: 0.489107 precision: 0.883858
epoch-2 step 488600/3451022 - loss: 0.043695 val_loss: 0.043522	recall: 0.505783 precision: 0.900749
epoch-2 step 488700/3451022 - loss: 0.045693 val_loss: 0.034517	recall: 0.512907 precision: 0.877159
epoch-2 step 488800/3451022 - loss: 0.035025 val_loss: 0.044618	recall: 0.548055 precision: 0.928295
epoch-2 step 488900/3451022 - loss: 0.036979 val_loss: 0.034174	recall: 0.525612 precision: 0.900763
epoch-2 step 489000/3451022 - loss: 0.033872 val_loss: 0.035744	recall: 0.512332 precision: 0.899606

checkpoint saved

epoch-2 step 489100/3451022 - loss: 0.037685 val_loss: 0.036002	recall: 0.522803 precision: 0.898662
epoch-2 step 489200/3451022 - loss: 0.037069 val_loss: 0.036148	recall: 0.510520 precision: 0.896887
epoch-2 step 489300/3451022 - loss: 0.034522 val_loss: 0.034066	recall: 0.522075 precision: 0.890772
epoch-2 step 489400/3451022 - loss: 0.040118 val_loss: 0.039472	recall: 0.502769 precision: 0.890196
epoch-2 step 489500/3451022 - loss: 0.041828 val_loss: 0.035983	recall: 0.537181 precision: 0.918406
epoch-2 step 489600/3451022 - loss: 0.034813 val_loss: 0.036471	recall: 0.525164 precision: 0.890538
epoch-2 step 489700/3451022 - loss: 0.038978 val_loss: 0.036110	recall: 0.546577 precision: 0.924099
epoch-2 step 489800/3451022 - loss: 0.043933 val_loss: 0.035848	recall: 0.532669 precision: 0.916190
epoch-2 step 489900/3451022 - loss: 0.036443 val_loss: 0.034531	recall: 0.514532 precision: 0.919231
epoch-2 step 490000/3451022 - loss: 0.039803 val_loss: 0.035352	recall: 0.538717 precision: 0.929389

checkpoint saved

epoch-2 step 490100/3451022 - loss: 0.041591 val_loss: 0.039506	recall: 0.513426 precision: 0.885185

model exported!

epoch-2 step 490200/3451022 - loss: 0.034306 val_loss: 0.036232	recall: 0.538462 precision: 0.919608
epoch-2 step 490300/3451022 - loss: 0.037603 val_loss: 0.034888	recall: 0.513113 precision: 0.894632
epoch-2 step 490400/3451022 - loss: 0.036363 val_loss: 0.033850	recall: 0.530320 precision: 0.902439
epoch-2 step 490500/3451022 - loss: 0.037215 val_loss: 0.037220	recall: 0.531674 precision: 0.916179
epoch-2 step 490600/3451022 - loss: 0.038222 val_loss: 0.033952	recall: 0.529794 precision: 0.915730
epoch-2 step 490700/3451022 - loss: 0.037919 val_loss: 0.037625	recall: 0.507012 precision: 0.917969
epoch-2 step 490800/3451022 - loss: 0.034245 val_loss: 0.035296	recall: 0.524678 precision: 0.942197
epoch-2 step 490900/3451022 - loss: 0.036743 val_loss: 0.035190	recall: 0.495156 precision: 0.900196
epoch-2 step 491000/3451022 - loss: 0.040251 val_loss: 0.033846	recall: 0.524239 precision: 0.902913

checkpoint saved

epoch-2 step 491100/3451022 - loss: 0.038244 val_loss: 0.033923	recall: 0.517838 precision: 0.898687
epoch-2 step 491200/3451022 - loss: 0.038910 val_loss: 0.035189	recall: 0.538288 precision: 0.922780
epoch-2 step 491300/3451022 - loss: 0.037562 val_loss: 0.036108	recall: 0.524076 precision: 0.914062
epoch-2 step 491400/3451022 - loss: 0.035628 val_loss: 0.034324	recall: 0.519423 precision: 0.901734
epoch-2 step 491500/3451022 - loss: 0.035203 val_loss: 0.035098	recall: 0.512168 precision: 0.878558
epoch-2 step 491600/3451022 - loss: 0.036797 val_loss: 0.068987	recall: 0.516304 precision: 0.879630
epoch-2 step 491700/3451022 - loss: 0.038514 val_loss: 0.035014	recall: 0.537313 precision: 0.900000
epoch-2 step 491800/3451022 - loss: 0.036285 val_loss: 0.039922	recall: 0.482646 precision: 0.886454
epoch-2 step 491900/3451022 - loss: 0.034386 val_loss: 0.034372	recall: 0.513100 precision: 0.893536
epoch-2 step 492000/3451022 - loss: 0.036488 val_loss: 0.035121	recall: 0.568102 precision: 0.905380

checkpoint saved

epoch-2 step 492100/3451022 - loss: 0.034253 val_loss: 0.040211	recall: 0.492080 precision: 0.889313

model exported!

epoch-2 step 492200/3451022 - loss: 0.037099 val_loss: 0.034193	recall: 0.515050 precision: 0.922156
epoch-2 step 492300/3451022 - loss: 0.043544 val_loss: 0.036375	recall: 0.527568 precision: 0.915572
epoch-2 step 492400/3451022 - loss: 0.037055 val_loss: 0.035467	recall: 0.507214 precision: 0.889105
epoch-2 step 492500/3451022 - loss: 0.037715 val_loss: 0.036562	recall: 0.511450 precision: 0.889943
epoch-2 step 492600/3451022 - loss: 0.038348 val_loss: 0.035422	recall: 0.550000 precision: 0.914934
epoch-2 step 492700/3451022 - loss: 0.043702 val_loss: 0.042293	recall: 0.516384 precision: 0.903162
epoch-2 step 492800/3451022 - loss: 0.036371 val_loss: 0.038289	recall: 0.513043 precision: 0.911197
epoch-2 step 492900/3451022 - loss: 0.035084 val_loss: 0.037014	recall: 0.506623 precision: 0.891262
epoch-2 step 493000/3451022 - loss: 0.036521 val_loss: 0.034695	recall: 0.517435 precision: 0.903733

checkpoint saved

epoch-2 step 493100/3451022 - loss: 0.034979 val_loss: 0.035434	recall: 0.508929 precision: 0.895874
epoch-2 step 493200/3451022 - loss: 0.034538 val_loss: 0.035973	recall: 0.502208 precision: 0.895669
epoch-2 step 493300/3451022 - loss: 0.036099 val_loss: 0.036270	recall: 0.548864 precision: 0.932432
epoch-2 step 493400/3451022 - loss: 0.036784 val_loss: 0.039027	recall: 0.539414 precision: 0.915870
epoch-2 step 493500/3451022 - loss: 0.041080 val_loss: 0.040504	recall: 0.536782 precision: 0.919291
epoch-2 step 493600/3451022 - loss: 0.035031 val_loss: 0.038009	recall: 0.549488 precision: 0.930636
epoch-2 step 493700/3451022 - loss: 0.036879 val_loss: 0.036089	recall: 0.494092 precision: 0.886320
epoch-2 step 493800/3451022 - loss: 0.039190 val_loss: 0.034760	recall: 0.526196 precision: 0.914851
epoch-2 step 493900/3451022 - loss: 0.039969 val_loss: 0.040306	recall: 0.521837 precision: 0.894434
epoch-2 step 494000/3451022 - loss: 0.036664 val_loss: 0.036207	recall: 0.506667 precision: 0.917505

checkpoint saved

epoch-2 step 494100/3451022 - loss: 0.037038 val_loss: 0.038664	recall: 0.480249 precision: 0.883365

model exported!

epoch-2 step 494200/3451022 - loss: 0.036138 val_loss: 0.037034	recall: 0.553710 precision: 0.929368
epoch-2 step 494300/3451022 - loss: 0.035381 val_loss: 0.036459	recall: 0.532511 precision: 0.925926
epoch-2 step 494400/3451022 - loss: 0.041465 val_loss: 0.035729	recall: 0.525910 precision: 0.905123
epoch-2 step 494500/3451022 - loss: 0.034956 val_loss: 0.050976	recall: 0.525330 precision: 0.908571
epoch-2 step 494600/3451022 - loss: 0.037813 val_loss: 0.035865	recall: 0.510360 precision: 0.900000
epoch-2 step 494700/3451022 - loss: 0.034916 val_loss: 0.035561	recall: 0.511062 precision: 0.875000
epoch-2 step 494800/3451022 - loss: 0.035168 val_loss: 0.035540	recall: 0.534025 precision: 0.922311
epoch-2 step 494900/3451022 - loss: 0.039416 val_loss: 0.035836	recall: 0.526429 precision: 0.922495
epoch-2 step 495000/3451022 - loss: 0.037814 val_loss: 0.036195	recall: 0.501647 precision: 0.889105

checkpoint saved

epoch-2 step 495100/3451022 - loss: 0.042234 val_loss: 0.037428	recall: 0.491667 precision: 0.897338
epoch-2 step 495200/3451022 - loss: 0.035887 val_loss: 0.035848	recall: 0.546369 precision: 0.920904
epoch-2 step 495300/3451022 - loss: 0.035075 val_loss: 0.035714	recall: 0.510707 precision: 0.926214
epoch-2 step 495400/3451022 - loss: 0.036707 val_loss: 0.034755	recall: 0.496241 precision: 0.883365
epoch-2 step 495500/3451022 - loss: 0.035573 val_loss: 0.040577	recall: 0.503247 precision: 0.922619
epoch-2 step 495600/3451022 - loss: 0.037078 val_loss: 0.035736	recall: 0.483701 precision: 0.901961
epoch-2 step 495700/3451022 - loss: 0.034509 val_loss: 0.035437	recall: 0.523649 precision: 0.899420
epoch-2 step 495800/3451022 - loss: 0.042203 val_loss: 0.036743	recall: 0.506522 precision: 0.896154
epoch-2 step 495900/3451022 - loss: 0.033874 val_loss: 0.034807	recall: 0.529543 precision: 0.929550
epoch-2 step 496000/3451022 - loss: 0.035266 val_loss: 0.035132	recall: 0.519362 precision: 0.890625

checkpoint saved

epoch-2 step 496100/3451022 - loss: 0.034316 val_loss: 0.035951	recall: 0.519058 precision: 0.906067

model exported!

epoch-2 step 496200/3451022 - loss: 0.038158 val_loss: 0.040609	recall: 0.529680 precision: 0.885496
epoch-2 step 496300/3451022 - loss: 0.036305 val_loss: 0.034525	recall: 0.533917 precision: 0.905380
epoch-2 step 496400/3451022 - loss: 0.035238 val_loss: 0.035986	recall: 0.526857 precision: 0.895146
epoch-2 step 496500/3451022 - loss: 0.034993 val_loss: 0.037432	recall: 0.527374 precision: 0.907692
epoch-2 step 496600/3451022 - loss: 0.043718 val_loss: 0.034578	recall: 0.543478 precision: 0.887850
epoch-2 step 496700/3451022 - loss: 0.035600 val_loss: 0.038606	recall: 0.480171 precision: 0.906883
epoch-2 step 496800/3451022 - loss: 0.034649 val_loss: 0.035816	recall: 0.504844 precision: 0.907157
epoch-2 step 496900/3451022 - loss: 0.040775 val_loss: 0.035046	recall: 0.503185 precision: 0.901141
epoch-2 step 497000/3451022 - loss: 0.035559 val_loss: 0.034944	recall: 0.504813 precision: 0.904215

checkpoint saved

epoch-2 step 497100/3451022 - loss: 0.036211 val_loss: 0.036271	recall: 0.506383 precision: 0.904943
epoch-2 step 497200/3451022 - loss: 0.034515 val_loss: 0.040363	recall: 0.542334 precision: 0.933071
epoch-2 step 497300/3451022 - loss: 0.037008 val_loss: 0.038709	recall: 0.500000 precision: 0.908915
epoch-2 step 497400/3451022 - loss: 0.034452 val_loss: 0.041163	recall: 0.537162 precision: 0.929825
epoch-2 step 497500/3451022 - loss: 0.034652 val_loss: 0.038895	recall: 0.530093 precision: 0.914172
epoch-2 step 497600/3451022 - loss: 0.036637 val_loss: 0.037776	recall: 0.534730 precision: 0.920304
epoch-2 step 497700/3451022 - loss: 0.036814 val_loss: 0.037184	recall: 0.532584 precision: 0.915058
epoch-2 step 497800/3451022 - loss: 0.039069 val_loss: 0.041227	recall: 0.549714 precision: 0.912713
epoch-2 step 497900/3451022 - loss: 0.040537 val_loss: 0.035186	recall: 0.516055 precision: 0.889328
epoch-2 step 498000/3451022 - loss: 0.040041 val_loss: 0.036446	recall: 0.555811 precision: 0.906191

checkpoint saved

epoch-2 step 498100/3451022 - loss: 0.037270 val_loss: 0.036275	recall: 0.533917 precision: 0.927757

model exported!

epoch-2 step 498200/3451022 - loss: 0.035015 val_loss: 0.043426	recall: 0.497238 precision: 0.875486
epoch-2 step 498300/3451022 - loss: 0.038080 val_loss: 0.036788	recall: 0.510022 precision: 0.903353
epoch-2 step 498400/3451022 - loss: 0.040778 val_loss: 0.040302	recall: 0.506159 precision: 0.898608
epoch-2 step 498500/3451022 - loss: 0.034137 val_loss: 0.036860	recall: 0.515660 precision: 0.922000
epoch-2 step 498600/3451022 - loss: 0.035324 val_loss: 0.036400	recall: 0.522936 precision: 0.888889
epoch-2 step 498700/3451022 - loss: 0.037507 val_loss: 0.036166	recall: 0.514754 precision: 0.895437
epoch-2 step 498800/3451022 - loss: 0.034951 val_loss: 0.034237	recall: 0.528698 precision: 0.908918
epoch-2 step 498900/3451022 - loss: 0.054980 val_loss: 0.040449	recall: 0.488033 precision: 0.908915
epoch-2 step 499000/3451022 - loss: 0.035029 val_loss: 0.036365	recall: 0.520442 precision: 0.921722

checkpoint saved

epoch-2 step 499100/3451022 - loss: 0.044726 val_loss: 0.037870	recall: 0.528129 precision: 0.914513
epoch-2 step 499200/3451022 - loss: 0.035893 val_loss: 0.038776	recall: 0.494670 precision: 0.911591
epoch-2 step 499300/3451022 - loss: 0.040014 val_loss: 0.040038	recall: 0.543554 precision: 0.919450
epoch-2 step 499400/3451022 - loss: 0.036972 val_loss: 0.041673	recall: 0.511327 precision: 0.925781
epoch-2 step 499500/3451022 - loss: 0.035491 val_loss: 0.034001	recall: 0.513751 precision: 0.889524
epoch-2 step 499600/3451022 - loss: 0.035530 val_loss: 0.035934	recall: 0.520249 precision: 0.929499
epoch-2 step 499700/3451022 - loss: 0.034251 val_loss: 0.039315	recall: 0.491694 precision: 0.868885
epoch-2 step 499800/3451022 - loss: 0.035654 val_loss: 0.059164	recall: 0.523810 precision: 0.898833
epoch-2 step 499900/3451022 - loss: 0.036619 val_loss: 0.037679	recall: 0.545351 precision: 0.909263
epoch-2 step 500000/3451022 - loss: 0.035925 val_loss: 0.035140	recall: 0.533035 precision: 0.906667

checkpoint saved

epoch-2 step 500100/3451022 - loss: 0.035237 val_loss: 0.035011	recall: 0.529018 precision: 0.906310

model exported!

epoch-2 step 500200/3451022 - loss: 0.034448 val_loss: 0.035818	recall: 0.494015 precision: 0.906188
epoch-2 step 500300/3451022 - loss: 0.035821 val_loss: 0.039943	recall: 0.507312 precision: 0.912955
epoch-2 step 500400/3451022 - loss: 0.034639 val_loss: 0.039549	recall: 0.556750 precision: 0.928287
epoch-2 step 500500/3451022 - loss: 0.037143 val_loss: 0.042957	recall: 0.542662 precision: 0.913793
epoch-2 step 500600/3451022 - loss: 0.037006 val_loss: 0.040313	recall: 0.516880 precision: 0.868885
epoch-2 step 500700/3451022 - loss: 0.035780 val_loss: 0.035733	recall: 0.540476 precision: 0.915323
epoch-2 step 500800/3451022 - loss: 0.034534 val_loss: 0.035376	recall: 0.527192 precision: 0.906489
epoch-2 step 500900/3451022 - loss: 0.041970 val_loss: 0.034788	recall: 0.497783 precision: 0.880392
epoch-2 step 501000/3451022 - loss: 0.034256 val_loss: 0.036303	recall: 0.544843 precision: 0.918715

checkpoint saved

epoch-2 step 501100/3451022 - loss: 0.035030 val_loss: 0.038105	recall: 0.526012 precision: 0.900990
epoch-2 step 501200/3451022 - loss: 0.036925 val_loss: 0.034942	recall: 0.524698 precision: 0.910476
epoch-2 step 501300/3451022 - loss: 0.035670 val_loss: 0.044647	recall: 0.550117 precision: 0.900763
epoch-2 step 501400/3451022 - loss: 0.034902 val_loss: 0.039492	recall: 0.530806 precision: 0.923711
epoch-2 step 501500/3451022 - loss: 0.038803 val_loss: 0.042621	recall: 0.526376 precision: 0.898239
epoch-2 step 501600/3451022 - loss: 0.034971 val_loss: 0.036293	recall: 0.546638 precision: 0.928177
epoch-2 step 501700/3451022 - loss: 0.035290 val_loss: 0.036320	recall: 0.523921 precision: 0.898000
epoch-2 step 501800/3451022 - loss: 0.036767 val_loss: 0.039340	recall: 0.550000 precision: 0.930451
epoch-2 step 501900/3451022 - loss: 0.036450 val_loss: 0.035430	recall: 0.498922 precision: 0.888676
epoch-2 step 502000/3451022 - loss: 0.035156 val_loss: 0.035685	recall: 0.531961 precision: 0.912639

checkpoint saved

epoch-2 step 502100/3451022 - loss: 0.035699 val_loss: 0.037018	recall: 0.517280 precision: 0.918812

model exported!

epoch-2 step 502200/3451022 - loss: 0.039242 val_loss: 0.034518	recall: 0.559719 precision: 0.908745
epoch-2 step 502300/3451022 - loss: 0.034811 val_loss: 0.038389	recall: 0.488205 precision: 0.915385
epoch-2 step 502400/3451022 - loss: 0.035926 val_loss: 0.035251	recall: 0.521886 precision: 0.875706
epoch-2 step 502500/3451022 - loss: 0.039507 val_loss: 0.035548	recall: 0.491024 precision: 0.909980
epoch-2 step 502600/3451022 - loss: 0.035276 val_loss: 0.037247	recall: 0.521547 precision: 0.905950
epoch-2 step 502700/3451022 - loss: 0.034772 val_loss: 0.035640	recall: 0.528509 precision: 0.921606
epoch-2 step 502800/3451022 - loss: 0.036168 val_loss: 0.038289	recall: 0.524017 precision: 0.921305
epoch-2 step 502900/3451022 - loss: 0.037039 val_loss: 0.036950	recall: 0.527533 precision: 0.914122
epoch-2 step 503000/3451022 - loss: 0.035357 val_loss: 0.036652	recall: 0.575792 precision: 0.920434

checkpoint saved

epoch-2 step 503100/3451022 - loss: 0.034019 val_loss: 0.040931	recall: 0.518313 precision: 0.908560
epoch-2 step 503200/3451022 - loss: 0.044499 val_loss: 0.035832	recall: 0.509434 precision: 0.907115
epoch-2 step 503300/3451022 - loss: 0.042231 val_loss: 0.037519	recall: 0.486373 precision: 0.922465
epoch-2 step 503400/3451022 - loss: 0.034727 val_loss: 0.039593	recall: 0.488565 precision: 0.923379
epoch-2 step 503500/3451022 - loss: 0.034643 val_loss: 0.034016	recall: 0.512987 precision: 0.915058
epoch-2 step 503600/3451022 - loss: 0.035317 val_loss: 0.037074	recall: 0.527149 precision: 0.897881
epoch-2 step 503700/3451022 - loss: 0.037122 val_loss: 0.034788	recall: 0.505870 precision: 0.882682
epoch-2 step 503800/3451022 - loss: 0.037194 val_loss: 0.034840	recall: 0.467871 precision: 0.892720
epoch-2 step 503900/3451022 - loss: 0.037972 val_loss: 0.035536	recall: 0.491718 precision: 0.918762
epoch-2 step 504000/3451022 - loss: 0.040189 val_loss: 0.036921	recall: 0.505857 precision: 0.924125

checkpoint saved

epoch-2 step 504100/3451022 - loss: 0.034634 val_loss: 0.038769	recall: 0.530707 precision: 0.894531

model exported!

epoch-2 step 504200/3451022 - loss: 0.035501 val_loss: 0.037906	recall: 0.497921 precision: 0.895327
epoch-2 step 504300/3451022 - loss: 0.033735 val_loss: 0.036779	recall: 0.495197 precision: 0.900971
epoch-2 step 504400/3451022 - loss: 0.036529 val_loss: 0.035617	recall: 0.484688 precision: 0.900000
epoch-2 step 504500/3451022 - loss: 0.035533 val_loss: 0.041640	recall: 0.520397 precision: 0.916505
epoch-2 step 504600/3451022 - loss: 0.041913 val_loss: 0.037261	recall: 0.524644 precision: 0.919386
epoch-2 step 504700/3451022 - loss: 0.042695 val_loss: 0.040344	recall: 0.503751 precision: 0.905588
epoch-2 step 504800/3451022 - loss: 0.034532 val_loss: 0.036686	recall: 0.491043 precision: 0.906615
epoch-2 step 504900/3451022 - loss: 0.043276 val_loss: 0.035826	recall: 0.536585 precision: 0.930769
epoch-2 step 505000/3451022 - loss: 0.035676 val_loss: 0.037601	recall: 0.469036 precision: 0.900585

checkpoint saved

epoch-2 step 505100/3451022 - loss: 0.034802 val_loss: 0.035381	recall: 0.480869 precision: 0.906433
epoch-2 step 505200/3451022 - loss: 0.034538 val_loss: 0.034172	recall: 0.492834 precision: 0.912245
epoch-2 step 505300/3451022 - loss: 0.041211 val_loss: 0.034255	recall: 0.527099 precision: 0.890485
epoch-2 step 505400/3451022 - loss: 0.036109 val_loss: 0.036438	recall: 0.498320 precision: 0.895372
epoch-2 step 505500/3451022 - loss: 0.036030 val_loss: 0.034871	recall: 0.519694 precision: 0.925926
epoch-2 step 505600/3451022 - loss: 0.038695 val_loss: 0.036302	recall: 0.531320 precision: 0.922330
epoch-2 step 505700/3451022 - loss: 0.038666 val_loss: 0.035752	recall: 0.511918 precision: 0.898406
epoch-2 step 505800/3451022 - loss: 0.035143 val_loss: 0.034179	recall: 0.543353 precision: 0.919765
epoch-2 step 505900/3451022 - loss: 0.034491 val_loss: 0.035650	recall: 0.525196 precision: 0.896750
epoch-2 step 506000/3451022 - loss: 0.040476 val_loss: 0.041685	recall: 0.552901 precision: 0.918715

checkpoint saved

epoch-2 step 506100/3451022 - loss: 0.034792 val_loss: 0.033842	recall: 0.511376 precision: 0.904215

model exported!

epoch-2 step 506200/3451022 - loss: 0.036339 val_loss: 0.038786	recall: 0.521691 precision: 0.886578
epoch-2 step 506300/3451022 - loss: 0.038765 val_loss: 0.039814	recall: 0.525000 precision: 0.898833
epoch-2 step 506400/3451022 - loss: 0.041096 val_loss: 0.034569	recall: 0.530547 precision: 0.932203
epoch-2 step 506500/3451022 - loss: 0.044101 val_loss: 0.041589	recall: 0.514192 precision: 0.905769
epoch-2 step 506600/3451022 - loss: 0.035868 val_loss: 0.043181	recall: 0.530405 precision: 0.918129
epoch-2 step 506700/3451022 - loss: 0.036819 val_loss: 0.037907	recall: 0.511482 precision: 0.914179
epoch-2 step 506800/3451022 - loss: 0.040235 val_loss: 0.034698	recall: 0.524184 precision: 0.897881
epoch-2 step 506900/3451022 - loss: 0.036516 val_loss: 0.034152	recall: 0.508830 precision: 0.891683
epoch-2 step 507000/3451022 - loss: 0.036100 val_loss: 0.034367	recall: 0.530702 precision: 0.897959

checkpoint saved

epoch-2 step 507100/3451022 - loss: 0.034590 val_loss: 0.041209	recall: 0.528064 precision: 0.900391
epoch-2 step 507200/3451022 - loss: 0.035239 val_loss: 0.039206	recall: 0.527559 precision: 0.898467
epoch-2 step 507300/3451022 - loss: 0.035509 val_loss: 0.034308	recall: 0.534545 precision: 0.866405
epoch-2 step 507400/3451022 - loss: 0.039183 val_loss: 0.041604	recall: 0.508696 precision: 0.894837
epoch-2 step 507500/3451022 - loss: 0.048965 val_loss: 0.035044	recall: 0.513605 precision: 0.881323
epoch-2 step 507600/3451022 - loss: 0.035716 val_loss: 0.038363	recall: 0.496296 precision: 0.910680
epoch-2 step 507700/3451022 - loss: 0.039706 val_loss: 0.046418	recall: 0.543153 precision: 0.904215
epoch-2 step 507800/3451022 - loss: 0.033814 val_loss: 0.036137	recall: 0.514444 precision: 0.900778
epoch-2 step 507900/3451022 - loss: 0.035051 val_loss: 0.039082	recall: 0.487421 precision: 0.884030
epoch-2 step 508000/3451022 - loss: 0.034796 val_loss: 0.037157	recall: 0.530043 precision: 0.925094

checkpoint saved

epoch-2 step 508100/3451022 - loss: 0.035107 val_loss: 0.034457	recall: 0.540816 precision: 0.906844

model exported!

epoch-2 step 508200/3451022 - loss: 0.040542 val_loss: 0.036358	recall: 0.520487 precision: 0.912621
epoch-2 step 508300/3451022 - loss: 0.035089 val_loss: 0.038904	recall: 0.511086 precision: 0.888247
epoch-2 step 508400/3451022 - loss: 0.035143 val_loss: 0.034338	recall: 0.472309 precision: 0.893281
epoch-2 step 508500/3451022 - loss: 0.037096 val_loss: 0.037962	recall: 0.508584 precision: 0.909789
epoch-2 step 508600/3451022 - loss: 0.037096 val_loss: 0.034544	recall: 0.506316 precision: 0.923225
epoch-2 step 508700/3451022 - loss: 0.038746 val_loss: 0.039116	recall: 0.530612 precision: 0.923077
epoch-2 step 508800/3451022 - loss: 0.034748 val_loss: 0.035073	recall: 0.542952 precision: 0.919776
epoch-2 step 508900/3451022 - loss: 0.036844 val_loss: 0.035030	recall: 0.531080 precision: 0.932950
epoch-2 step 509000/3451022 - loss: 0.034790 val_loss: 0.035771	recall: 0.490052 precision: 0.915851

checkpoint saved

epoch-2 step 509100/3451022 - loss: 0.036492 val_loss: 0.036960	recall: 0.547619 precision: 0.930636
epoch-2 step 509200/3451022 - loss: 0.035463 val_loss: 0.036832	recall: 0.502188 precision: 0.896484
epoch-2 step 509300/3451022 - loss: 0.034170 val_loss: 0.035491	recall: 0.513602 precision: 0.904215
epoch-2 step 509400/3451022 - loss: 0.040414 val_loss: 0.037765	recall: 0.528217 precision: 0.893130
epoch-2 step 509500/3451022 - loss: 0.033621 val_loss: 0.034972	recall: 0.527907 precision: 0.908000
epoch-2 step 509600/3451022 - loss: 0.034933 val_loss: 0.036579	recall: 0.531323 precision: 0.896282
epoch-2 step 509700/3451022 - loss: 0.034751 val_loss: 0.036772	recall: 0.571262 precision: 0.914019
epoch-2 step 509800/3451022 - loss: 0.052422 val_loss: 0.038316	recall: 0.554632 precision: 0.912109
epoch-2 step 509900/3451022 - loss: 0.037568 val_loss: 0.036187	recall: 0.542601 precision: 0.943470
epoch-2 step 510000/3451022 - loss: 0.034550 val_loss: 0.035495	recall: 0.483563 precision: 0.876923

checkpoint saved

epoch-2 step 510100/3451022 - loss: 0.034677 val_loss: 0.035610	recall: 0.551370 precision: 0.927063

model exported!

epoch-2 step 510200/3451022 - loss: 0.035854 val_loss: 0.038438	recall: 0.552969 precision: 0.929550
epoch-2 step 510300/3451022 - loss: 0.035901 val_loss: 0.034838	recall: 0.538813 precision: 0.909441
epoch-2 step 510400/3451022 - loss: 0.034851 val_loss: 0.042395	recall: 0.496257 precision: 0.900971
epoch-2 step 510500/3451022 - loss: 0.034020 val_loss: 0.044773	recall: 0.521348 precision: 0.885496
epoch-2 step 510600/3451022 - loss: 0.041082 val_loss: 0.036088	recall: 0.528193 precision: 0.903543
epoch-2 step 510700/3451022 - loss: 0.036590 val_loss: 0.035271	recall: 0.542169 precision: 0.939279
epoch-2 step 510800/3451022 - loss: 0.034880 val_loss: 0.035701	recall: 0.544202 precision: 0.918605
epoch-2 step 510900/3451022 - loss: 0.037144 val_loss: 0.037789	recall: 0.497286 precision: 0.892788
epoch-2 step 511000/3451022 - loss: 0.034555 val_loss: 0.036567	recall: 0.534857 precision: 0.896552

checkpoint saved

epoch-2 step 511100/3451022 - loss: 0.035885 val_loss: 0.037237	recall: 0.531561 precision: 0.895522
epoch-2 step 511200/3451022 - loss: 0.043603 val_loss: 0.036293	recall: 0.501584 precision: 0.887850
epoch-2 step 511300/3451022 - loss: 0.041276 val_loss: 0.037458	recall: 0.546286 precision: 0.891791
epoch-2 step 511400/3451022 - loss: 0.038270 val_loss: 0.035326	recall: 0.508197 precision: 0.917160
epoch-2 step 511500/3451022 - loss: 0.037126 val_loss: 0.037839	recall: 0.515084 precision: 0.898635
epoch-2 step 511600/3451022 - loss: 0.052180 val_loss: 0.035593	recall: 0.524973 precision: 0.913124
epoch-2 step 511700/3451022 - loss: 0.036963 val_loss: 0.036610	recall: 0.513684 precision: 0.922495
epoch-2 step 511800/3451022 - loss: 0.036099 val_loss: 0.038683	recall: 0.519042 precision: 0.915547
epoch-2 step 511900/3451022 - loss: 0.036289 val_loss: 0.040164	recall: 0.520092 precision: 0.909639
epoch-2 step 512000/3451022 - loss: 0.037593 val_loss: 0.034560	recall: 0.527253 precision: 0.904580

checkpoint saved

epoch-2 step 512100/3451022 - loss: 0.034654 val_loss: 0.035507	recall: 0.521018 precision: 0.898855

model exported!

epoch-2 step 512200/3451022 - loss: 0.033642 val_loss: 0.037020	recall: 0.509583 precision: 0.898608
epoch-2 step 512300/3451022 - loss: 0.035737 val_loss: 0.035437	recall: 0.560364 precision: 0.937143
epoch-2 step 512400/3451022 - loss: 0.036513 val_loss: 0.037382	recall: 0.537788 precision: 0.924670
epoch-2 step 512500/3451022 - loss: 0.034903 val_loss: 0.034967	recall: 0.508677 precision: 0.900192
epoch-2 step 512600/3451022 - loss: 0.037369 val_loss: 0.035054	recall: 0.521396 precision: 0.918651
epoch-2 step 512700/3451022 - loss: 0.040708 val_loss: 0.036242	recall: 0.512658 precision: 0.920455
epoch-2 step 512800/3451022 - loss: 0.034086 val_loss: 0.034244	recall: 0.540717 precision: 0.929104
epoch-2 step 512900/3451022 - loss: 0.035696 val_loss: 0.034093	recall: 0.521643 precision: 0.909091
epoch-2 step 513000/3451022 - loss: 0.037444 val_loss: 0.035516	recall: 0.522803 precision: 0.903846

checkpoint saved

epoch-2 step 513100/3451022 - loss: 0.036899 val_loss: 0.040735	recall: 0.527211 precision: 0.885714
epoch-2 step 513200/3451022 - loss: 0.046541 val_loss: 0.037574	recall: 0.513033 precision: 0.881874
epoch-2 step 513300/3451022 - loss: 0.036301 val_loss: 0.040292	recall: 0.528324 precision: 0.896078
epoch-2 step 513400/3451022 - loss: 0.042187 val_loss: 0.034759	recall: 0.516704 precision: 0.909804
epoch-2 step 513500/3451022 - loss: 0.034493 val_loss: 0.041540	recall: 0.552154 precision: 0.901852
epoch-2 step 513600/3451022 - loss: 0.034806 val_loss: 0.035375	recall: 0.524831 precision: 0.906433
epoch-2 step 513700/3451022 - loss: 0.036613 val_loss: 0.039355	recall: 0.469409 precision: 0.864078
epoch-2 step 513800/3451022 - loss: 0.034915 val_loss: 0.035497	recall: 0.506550 precision: 0.900971
epoch-2 step 513900/3451022 - loss: 0.044649 val_loss: 0.039157	recall: 0.537825 precision: 0.917339
epoch-2 step 514000/3451022 - loss: 0.035354 val_loss: 0.047302	recall: 0.540089 precision: 0.893186

checkpoint saved

epoch-2 step 514100/3451022 - loss: 0.034201 val_loss: 0.036043	recall: 0.550926 precision: 0.922481

model exported!

epoch-2 step 514200/3451022 - loss: 0.034842 val_loss: 0.037522	recall: 0.516667 precision: 0.902913
epoch-2 step 514300/3451022 - loss: 0.041876 val_loss: 0.041184	recall: 0.496158 precision: 0.881092
epoch-2 step 514400/3451022 - loss: 0.038096 val_loss: 0.039064	recall: 0.546180 precision: 0.917625
epoch-2 step 514500/3451022 - loss: 0.034922 val_loss: 0.039731	recall: 0.513245 precision: 0.904669
epoch-2 step 514600/3451022 - loss: 0.040047 val_loss: 0.036249	recall: 0.521547 precision: 0.902486
epoch-2 step 514700/3451022 - loss: 0.038912 val_loss: 0.036618	recall: 0.540243 precision: 0.899083
epoch-2 step 514800/3451022 - loss: 0.037516 val_loss: 0.035239	recall: 0.532787 precision: 0.895669
epoch-2 step 514900/3451022 - loss: 0.035521 val_loss: 0.035137	recall: 0.509455 precision: 0.882466
epoch-2 step 515000/3451022 - loss: 0.036013 val_loss: 0.035518	recall: 0.534386 precision: 0.913295

checkpoint saved

epoch-2 step 515100/3451022 - loss: 0.037163 val_loss: 0.037461	recall: 0.542857 precision: 0.906489
epoch-2 step 515200/3451022 - loss: 0.038085 val_loss: 0.042267	recall: 0.505908 precision: 0.919922
epoch-2 step 515300/3451022 - loss: 0.035510 val_loss: 0.040184	recall: 0.508343 precision: 0.904950
epoch-2 step 515400/3451022 - loss: 0.035309 val_loss: 0.035907	recall: 0.501591 precision: 0.918447
epoch-2 step 515500/3451022 - loss: 0.040741 val_loss: 0.034735	recall: 0.526375 precision: 0.893333
epoch-2 step 515600/3451022 - loss: 0.035600 val_loss: 0.036294	recall: 0.519819 precision: 0.877629
epoch-2 step 515700/3451022 - loss: 0.034702 val_loss: 0.035169	recall: 0.539792 precision: 0.910506
epoch-2 step 515800/3451022 - loss: 0.035799 val_loss: 0.038775	recall: 0.504405 precision: 0.901575
epoch-2 step 515900/3451022 - loss: 0.041012 val_loss: 0.035486	recall: 0.501636 precision: 0.893204
epoch-2 step 516000/3451022 - loss: 0.035909 val_loss: 0.042871	recall: 0.520717 precision: 0.889101

checkpoint saved

epoch-2 step 516100/3451022 - loss: 0.039652 val_loss: 0.039136	recall: 0.524294 precision: 0.894027

model exported!

epoch-2 step 516200/3451022 - loss: 0.035682 val_loss: 0.043771	recall: 0.546358 precision: 0.914972
epoch-2 step 516300/3451022 - loss: 0.035521 val_loss: 0.038008	recall: 0.526316 precision: 0.914397
epoch-2 step 516400/3451022 - loss: 0.037514 val_loss: 0.034365	recall: 0.507246 precision: 0.890411
epoch-2 step 516500/3451022 - loss: 0.036104 val_loss: 0.036019	recall: 0.508869 precision: 0.900000
epoch-2 step 516600/3451022 - loss: 0.035279 val_loss: 0.035105	recall: 0.518681 precision: 0.912959
epoch-2 step 516700/3451022 - loss: 0.037913 val_loss: 0.035732	recall: 0.486486 precision: 0.876404
epoch-2 step 516800/3451022 - loss: 0.035477 val_loss: 0.035007	recall: 0.520134 precision: 0.913556
epoch-2 step 516900/3451022 - loss: 0.052497 val_loss: 0.034387	recall: 0.546605 precision: 0.908222
epoch-2 step 517000/3451022 - loss: 0.036088 val_loss: 0.036502	recall: 0.503205 precision: 0.898855

checkpoint saved

epoch-2 step 517100/3451022 - loss: 0.037904 val_loss: 0.035681	recall: 0.522652 precision: 0.922027
epoch-2 step 517200/3451022 - loss: 0.044239 val_loss: 0.035483	recall: 0.520900 precision: 0.929254
epoch-2 step 517300/3451022 - loss: 0.035691 val_loss: 0.036109	recall: 0.504865 precision: 0.913894
epoch-2 step 517400/3451022 - loss: 0.035652 val_loss: 0.036365	recall: 0.491694 precision: 0.867188
epoch-2 step 517500/3451022 - loss: 0.034815 val_loss: 0.034930	recall: 0.530795 precision: 0.902857
epoch-2 step 517600/3451022 - loss: 0.034924 val_loss: 0.040496	recall: 0.544432 precision: 0.911488
epoch-2 step 517700/3451022 - loss: 0.036207 val_loss: 0.039301	recall: 0.501657 precision: 0.911647
epoch-2 step 517800/3451022 - loss: 0.036545 val_loss: 0.035061	recall: 0.501665 precision: 0.895050
epoch-2 step 517900/3451022 - loss: 0.039176 val_loss: 0.039732	recall: 0.535556 precision: 0.911153
epoch-2 step 518000/3451022 - loss: 0.035385 val_loss: 0.038800	recall: 0.516022 precision: 0.922925

checkpoint saved

epoch-2 step 518100/3451022 - loss: 0.036865 val_loss: 0.035431	recall: 0.509740 precision: 0.918129

model exported!

epoch-2 step 518200/3451022 - loss: 0.035101 val_loss: 0.037232	recall: 0.524573 precision: 0.933460
epoch-2 step 518300/3451022 - loss: 0.045282 val_loss: 0.037478	recall: 0.510032 precision: 0.923518
epoch-2 step 518400/3451022 - loss: 0.034516 val_loss: 0.035172	recall: 0.512270 precision: 0.926063
epoch-2 step 518500/3451022 - loss: 0.037053 val_loss: 0.043045	recall: 0.514806 precision: 0.913131
epoch-2 step 518600/3451022 - loss: 0.039344 val_loss: 0.035893	recall: 0.552885 precision: 0.905512
epoch-2 step 518700/3451022 - loss: 0.036751 val_loss: 0.039112	recall: 0.518597 precision: 0.920755
epoch-2 step 518800/3451022 - loss: 0.037108 val_loss: 0.043798	recall: 0.541620 precision: 0.915572
epoch-2 step 518900/3451022 - loss: 0.035740 val_loss: 0.035889	recall: 0.508004 precision: 0.893058
epoch-2 step 519000/3451022 - loss: 0.035579 val_loss: 0.037577	recall: 0.542099 precision: 0.905588

checkpoint saved

epoch-2 step 519100/3451022 - loss: 0.043664 val_loss: 0.039818	recall: 0.529210 precision: 0.904110
epoch-2 step 519200/3451022 - loss: 0.037745 val_loss: 0.040835	recall: 0.512000 precision: 0.892430
epoch-2 step 519300/3451022 - loss: 0.039078 val_loss: 0.034258	recall: 0.524249 precision: 0.893701
epoch-2 step 519400/3451022 - loss: 0.035998 val_loss: 0.035252	recall: 0.513543 precision: 0.915058
epoch-2 step 519500/3451022 - loss: 0.036292 val_loss: 0.036189	recall: 0.521505 precision: 0.929119
epoch-2 step 519600/3451022 - loss: 0.036896 val_loss: 0.035124	recall: 0.492616 precision: 0.915686
epoch-2 step 519700/3451022 - loss: 0.038033 val_loss: 0.035251	recall: 0.514477 precision: 0.907662
epoch-2 step 519800/3451022 - loss: 0.040257 val_loss: 0.034398	recall: 0.544186 precision: 0.903475
epoch-2 step 519900/3451022 - loss: 0.038491 val_loss: 0.049492	recall: 0.526559 precision: 0.897638
epoch-2 step 520000/3451022 - loss: 0.035480 val_loss: 0.034961	recall: 0.540571 precision: 0.899240

checkpoint saved

epoch-2 step 520100/3451022 - loss: 0.040600 val_loss: 0.036151	recall: 0.514477 precision: 0.911243

model exported!

epoch-2 step 520200/3451022 - loss: 0.042122 val_loss: 0.035824	recall: 0.515358 precision: 0.897030
epoch-2 step 520300/3451022 - loss: 0.038570 val_loss: 0.037066	recall: 0.532777 precision: 0.883399
epoch-2 step 520400/3451022 - loss: 0.036666 val_loss: 0.036186	recall: 0.511957 precision: 0.898855
epoch-2 step 520500/3451022 - loss: 0.036987 val_loss: 0.037022	recall: 0.507511 precision: 0.913127
epoch-2 step 520600/3451022 - loss: 0.034546 val_loss: 0.035690	recall: 0.495699 precision: 0.898635
epoch-2 step 520700/3451022 - loss: 0.036971 val_loss: 0.035515	recall: 0.516854 precision: 0.893204
epoch-2 step 520800/3451022 - loss: 0.034306 val_loss: 0.039636	recall: 0.521111 precision: 0.912451
epoch-2 step 520900/3451022 - loss: 0.040275 val_loss: 0.038167	recall: 0.513274 precision: 0.906250
epoch-2 step 521000/3451022 - loss: 0.037232 val_loss: 0.039153	recall: 0.518436 precision: 0.913386

checkpoint saved

epoch-2 step 521100/3451022 - loss: 0.035650 val_loss: 0.034636	recall: 0.517544 precision: 0.911197
epoch-2 step 521200/3451022 - loss: 0.037091 val_loss: 0.038927	recall: 0.529545 precision: 0.903101
epoch-2 step 521300/3451022 - loss: 0.034480 val_loss: 0.034722	recall: 0.487568 precision: 0.909274
epoch-2 step 521400/3451022 - loss: 0.048211 val_loss: 0.042146	recall: 0.507246 precision: 0.886940
epoch-2 step 521500/3451022 - loss: 0.041252 val_loss: 0.037241	recall: 0.516741 precision: 0.906067
epoch-2 step 521600/3451022 - loss: 0.034606 val_loss: 0.042430	recall: 0.504338 precision: 0.906433
epoch-2 step 521700/3451022 - loss: 0.035921 val_loss: 0.034445	recall: 0.529025 precision: 0.927063
epoch-2 step 521800/3451022 - loss: 0.034360 val_loss: 0.039769	recall: 0.539773 precision: 0.920543
epoch-2 step 521900/3451022 - loss: 0.035413 val_loss: 0.037591	recall: 0.508324 precision: 0.891051
epoch-2 step 522000/3451022 - loss: 0.044955 val_loss: 0.039496	recall: 0.510615 precision: 0.887379

checkpoint saved

epoch-2 step 522100/3451022 - loss: 0.040329 val_loss: 0.037561	recall: 0.546620 precision: 0.895038

model exported!

epoch-2 step 522200/3451022 - loss: 0.033655 val_loss: 0.037927	recall: 0.527716 precision: 0.913628
epoch-2 step 522300/3451022 - loss: 0.035128 val_loss: 0.037222	recall: 0.534676 precision: 0.922780
epoch-2 step 522400/3451022 - loss: 0.034531 val_loss: 0.038742	recall: 0.521691 precision: 0.930556
epoch-2 step 522500/3451022 - loss: 0.036490 val_loss: 0.034280	recall: 0.529817 precision: 0.913043
epoch-2 step 522600/3451022 - loss: 0.039894 val_loss: 0.041043	recall: 0.535433 precision: 0.888060
epoch-2 step 522700/3451022 - loss: 0.037790 val_loss: 0.045983	recall: 0.538546 precision: 0.922642
epoch-2 step 522800/3451022 - loss: 0.041059 val_loss: 0.035763	recall: 0.496674 precision: 0.880157
epoch-2 step 522900/3451022 - loss: 0.036122 val_loss: 0.035680	recall: 0.485567 precision: 0.916342
epoch-2 step 523000/3451022 - loss: 0.035280 val_loss: 0.035416	recall: 0.506977 precision: 0.900826

checkpoint saved

epoch-2 step 523100/3451022 - loss: 0.034523 val_loss: 0.040021	recall: 0.556314 precision: 0.926136
epoch-2 step 523200/3451022 - loss: 0.044126 val_loss: 0.036627	recall: 0.534216 precision: 0.930769
epoch-2 step 523300/3451022 - loss: 0.040304 val_loss: 0.038113	recall: 0.545035 precision: 0.930966
epoch-2 step 523400/3451022 - loss: 0.034036 val_loss: 0.040519	recall: 0.468517 precision: 0.872763
epoch-2 step 523500/3451022 - loss: 0.034708 val_loss: 0.037611	recall: 0.492585 precision: 0.887405
epoch-2 step 523600/3451022 - loss: 0.036169 val_loss: 0.035878	recall: 0.520742 precision: 0.896617
epoch-2 step 523700/3451022 - loss: 0.041283 val_loss: 0.035773	recall: 0.539160 precision: 0.896226
epoch-2 step 523800/3451022 - loss: 0.037546 val_loss: 0.035955	recall: 0.538639 precision: 0.894636
epoch-2 step 523900/3451022 - loss: 0.035739 val_loss: 0.035023	recall: 0.537313 precision: 0.919708
epoch-2 step 524000/3451022 - loss: 0.036552 val_loss: 0.036189	recall: 0.534325 precision: 0.901544

checkpoint saved

epoch-2 step 524100/3451022 - loss: 0.035913 val_loss: 0.041495	recall: 0.510067 precision: 0.899408

model exported!

epoch-2 step 524200/3451022 - loss: 0.037116 val_loss: 0.035773	recall: 0.506438 precision: 0.893939
epoch-2 step 524300/3451022 - loss: 0.037082 val_loss: 0.042291	recall: 0.511853 precision: 0.911708
epoch-2 step 524400/3451022 - loss: 0.036834 val_loss: 0.034600	recall: 0.545660 precision: 0.911488
epoch-2 step 524500/3451022 - loss: 0.044400 val_loss: 0.037787	recall: 0.510846 precision: 0.902299
epoch-2 step 524600/3451022 - loss: 0.036190 val_loss: 0.033996	recall: 0.507073 precision: 0.920949
epoch-2 step 524700/3451022 - loss: 0.035771 val_loss: 0.036374	recall: 0.520092 precision: 0.891732
epoch-2 step 524800/3451022 - loss: 0.038566 val_loss: 0.036667	recall: 0.507353 precision: 0.914773
epoch-2 step 524900/3451022 - loss: 0.036725 val_loss: 0.038561	recall: 0.562137 precision: 0.920152
epoch-2 step 525000/3451022 - loss: 0.042262 val_loss: 0.035562	recall: 0.506410 precision: 0.909789

checkpoint saved

epoch-2 step 525100/3451022 - loss: 0.035367 val_loss: 0.034121	recall: 0.514983 precision: 0.906250
epoch-2 step 525200/3451022 - loss: 0.035712 val_loss: 0.042800	recall: 0.540782 precision: 0.916667
epoch-2 step 525300/3451022 - loss: 0.036952 val_loss: 0.037500	recall: 0.564042 precision: 0.928433
epoch-2 step 525400/3451022 - loss: 0.034427 val_loss: 0.041188	recall: 0.538724 precision: 0.904398
epoch-2 step 525500/3451022 - loss: 0.033862 val_loss: 0.033587	recall: 0.497890 precision: 0.880597
epoch-2 step 525600/3451022 - loss: 0.041477 val_loss: 0.034728	recall: 0.546392 precision: 0.910305
epoch-2 step 525700/3451022 - loss: 0.035780 val_loss: 0.034636	recall: 0.542662 precision: 0.905123
epoch-2 step 525800/3451022 - loss: 0.042315 val_loss: 0.034734	recall: 0.541570 precision: 0.907157
epoch-2 step 525900/3451022 - loss: 0.034039 val_loss: 0.041845	recall: 0.521265 precision: 0.907021
epoch-2 step 526000/3451022 - loss: 0.037518 val_loss: 0.034006	recall: 0.510684 precision: 0.912214

checkpoint saved

epoch-2 step 526100/3451022 - loss: 0.036805 val_loss: 0.036619	recall: 0.512009 precision: 0.912451

model exported!

epoch-2 step 526200/3451022 - loss: 0.035410 val_loss: 0.033633	recall: 0.500000 precision: 0.907445
epoch-2 step 526300/3451022 - loss: 0.035173 val_loss: 0.035921	recall: 0.531792 precision: 0.918164
epoch-2 step 526400/3451022 - loss: 0.034448 val_loss: 0.036912	recall: 0.504515 precision: 0.892216
epoch-2 step 526500/3451022 - loss: 0.035334 val_loss: 0.035249	recall: 0.539954 precision: 0.909615
epoch-2 step 526600/3451022 - loss: 0.040663 val_loss: 0.035913	recall: 0.534231 precision: 0.910134
epoch-2 step 526700/3451022 - loss: 0.042859 val_loss: 0.038630	recall: 0.538908 precision: 0.908023
epoch-2 step 526800/3451022 - loss: 0.040627 val_loss: 0.034917	recall: 0.513782 precision: 0.871028
epoch-2 step 526900/3451022 - loss: 0.037860 val_loss: 0.035166	recall: 0.519168 precision: 0.892655
epoch-2 step 527000/3451022 - loss: 0.038263 val_loss: 0.043627	recall: 0.531632 precision: 0.914122

checkpoint saved

epoch-2 step 527100/3451022 - loss: 0.034638 val_loss: 0.038770	recall: 0.528078 precision: 0.912313
epoch-2 step 527200/3451022 - loss: 0.034405 val_loss: 0.036357	recall: 0.517396 precision: 0.884837
epoch-2 step 527300/3451022 - loss: 0.034206 val_loss: 0.034303	recall: 0.523915 precision: 0.897143
epoch-2 step 527400/3451022 - loss: 0.041753 val_loss: 0.035153	recall: 0.518944 precision: 0.891519
epoch-2 step 527500/3451022 - loss: 0.036459 val_loss: 0.041834	recall: 0.512987 precision: 0.897727
epoch-2 step 527600/3451022 - loss: 0.040761 val_loss: 0.034264	recall: 0.530635 precision: 0.930902
epoch-2 step 527700/3451022 - loss: 0.035570 val_loss: 0.037420	recall: 0.506229 precision: 0.897590
epoch-2 step 527800/3451022 - loss: 0.037549 val_loss: 0.038335	recall: 0.542484 precision: 0.897297
epoch-2 step 527900/3451022 - loss: 0.037900 val_loss: 0.036969	recall: 0.529213 precision: 0.909266
epoch-2 step 528000/3451022 - loss: 0.034826 val_loss: 0.038688	recall: 0.511752 precision: 0.898687

checkpoint saved

epoch-2 step 528100/3451022 - loss: 0.044700 val_loss: 0.037669	recall: 0.525114 precision: 0.879541

model exported!

epoch-2 step 528200/3451022 - loss: 0.038451 val_loss: 0.036350	recall: 0.518478 precision: 0.900000
epoch-2 step 528300/3451022 - loss: 0.039474 val_loss: 0.034069	recall: 0.525853 precision: 0.903592
epoch-2 step 528400/3451022 - loss: 0.036457 val_loss: 0.034614	recall: 0.512849 precision: 0.912525
epoch-2 step 528500/3451022 - loss: 0.035676 val_loss: 0.033933	recall: 0.489583 precision: 0.898662
epoch-2 step 528600/3451022 - loss: 0.040369 val_loss: 0.035662	recall: 0.500535 precision: 0.905222
epoch-2 step 528700/3451022 - loss: 0.038602 val_loss: 0.041528	recall: 0.482906 precision: 0.893281
epoch-2 step 528800/3451022 - loss: 0.039074 val_loss: 0.034722	recall: 0.512304 precision: 0.894531
epoch-2 step 528900/3451022 - loss: 0.034573 val_loss: 0.034346	recall: 0.515118 precision: 0.927419
epoch-2 step 529000/3451022 - loss: 0.036631 val_loss: 0.035546	recall: 0.477812 precision: 0.902534

checkpoint saved

epoch-2 step 529100/3451022 - loss: 0.035082 val_loss: 0.037936	recall: 0.525806 precision: 0.915730
epoch-2 step 529200/3451022 - loss: 0.034902 val_loss: 0.036440	recall: 0.527559 precision: 0.907157
epoch-2 step 529300/3451022 - loss: 0.038323 val_loss: 0.035000	recall: 0.516866 precision: 0.916988
epoch-2 step 529400/3451022 - loss: 0.035811 val_loss: 0.034467	recall: 0.515247 precision: 0.915888
epoch-2 step 529500/3451022 - loss: 0.035869 val_loss: 0.035858	recall: 0.554007 precision: 0.901701
epoch-2 step 529600/3451022 - loss: 0.044314 val_loss: 0.034651	recall: 0.542316 precision: 0.922348
epoch-2 step 529700/3451022 - loss: 0.036350 val_loss: 0.036712	recall: 0.500000 precision: 0.899048
epoch-2 step 529800/3451022 - loss: 0.039373 val_loss: 0.035637	recall: 0.557432 precision: 0.923507
epoch-2 step 529900/3451022 - loss: 0.036197 val_loss: 0.037128	recall: 0.504301 precision: 0.883239
epoch-2 step 530000/3451022 - loss: 0.037636 val_loss: 0.039736	recall: 0.540909 precision: 0.917148

checkpoint saved

epoch-2 step 530100/3451022 - loss: 0.034950 val_loss: 0.033989	recall: 0.517523 precision: 0.875494

model exported!

epoch-2 step 530200/3451022 - loss: 0.036003 val_loss: 0.034727	recall: 0.534699 precision: 0.910853
epoch-2 step 530300/3451022 - loss: 0.037715 val_loss: 0.035703	recall: 0.512061 precision: 0.891221
epoch-2 step 530400/3451022 - loss: 0.037341 val_loss: 0.035389	recall: 0.507870 precision: 0.923664
epoch-2 step 530500/3451022 - loss: 0.036196 val_loss: 0.035303	recall: 0.536131 precision: 0.900196
epoch-2 step 530600/3451022 - loss: 0.035637 val_loss: 0.035553	recall: 0.519119 precision: 0.903226
epoch-2 step 530700/3451022 - loss: 0.037491 val_loss: 0.036134	recall: 0.535433 precision: 0.901515
epoch-2 step 530800/3451022 - loss: 0.037197 val_loss: 0.037248	recall: 0.525386 precision: 0.918919
epoch-2 step 530900/3451022 - loss: 0.034372 val_loss: 0.035453	recall: 0.534747 precision: 0.908000
epoch-2 step 531000/3451022 - loss: 0.035545 val_loss: 0.035349	recall: 0.529675 precision: 0.920233

checkpoint saved

epoch-2 step 531100/3451022 - loss: 0.035780 val_loss: 0.042676	recall: 0.584634 precision: 0.905204
epoch-2 step 531200/3451022 - loss: 0.034644 val_loss: 0.050845	recall: 0.494748 precision: 0.892045
epoch-2 step 531300/3451022 - loss: 0.037647 val_loss: 0.035384	recall: 0.506024 precision: 0.885057
epoch-2 step 531400/3451022 - loss: 0.041403 val_loss: 0.038112	recall: 0.503191 precision: 0.913127
epoch-2 step 531500/3451022 - loss: 0.043381 val_loss: 0.034612	recall: 0.519397 precision: 0.937743
epoch-2 step 531600/3451022 - loss: 0.034193 val_loss: 0.035313	recall: 0.501053 precision: 0.901515
epoch-2 step 531700/3451022 - loss: 0.036129 val_loss: 0.036790	recall: 0.503282 precision: 0.900196
epoch-2 step 531800/3451022 - loss: 0.036023 val_loss: 0.035628	recall: 0.524537 precision: 0.912713
epoch-2 step 531900/3451022 - loss: 0.035730 val_loss: 0.038026	recall: 0.494192 precision: 0.924901
epoch-2 step 532000/3451022 - loss: 0.034028 val_loss: 0.036801	recall: 0.530543 precision: 0.908915

checkpoint saved

epoch-2 step 532100/3451022 - loss: 0.034721 val_loss: 0.036121	recall: 0.512739 precision: 0.930636

model exported!

epoch-2 step 532200/3451022 - loss: 0.035442 val_loss: 0.037738	recall: 0.492896 precision: 0.882583
epoch-2 step 532300/3451022 - loss: 0.034167 val_loss: 0.034803	recall: 0.526906 precision: 0.919765
epoch-2 step 532400/3451022 - loss: 0.038564 val_loss: 0.034938	recall: 0.511758 precision: 0.908549
epoch-2 step 532500/3451022 - loss: 0.035430 val_loss: 0.038148	recall: 0.543253 precision: 0.907514
epoch-2 step 532600/3451022 - loss: 0.034609 val_loss: 0.042995	recall: 0.494647 precision: 0.883365
epoch-2 step 532700/3451022 - loss: 0.039714 val_loss: 0.043004	recall: 0.530726 precision: 0.911708
epoch-2 step 532800/3451022 - loss: 0.035346 val_loss: 0.037188	recall: 0.540659 precision: 0.928302
epoch-2 step 532900/3451022 - loss: 0.034636 val_loss: 0.037131	recall: 0.523757 precision: 0.925781
epoch-2 step 533000/3451022 - loss: 0.034162 val_loss: 0.035853	recall: 0.498938 precision: 0.888469

checkpoint saved

epoch-2 step 533100/3451022 - loss: 0.036144 val_loss: 0.040199	recall: 0.497849 precision: 0.902534
epoch-2 step 533200/3451022 - loss: 0.036471 val_loss: 0.037232	recall: 0.510893 precision: 0.903661
epoch-2 step 533300/3451022 - loss: 0.035857 val_loss: 0.038124	recall: 0.526030 precision: 0.901487
epoch-2 step 533400/3451022 - loss: 0.034872 val_loss: 0.039566	recall: 0.507198 precision: 0.894531
epoch-2 step 533500/3451022 - loss: 0.035842 val_loss: 0.039045	recall: 0.527655 precision: 0.905123
epoch-2 step 533600/3451022 - loss: 0.040359 val_loss: 0.035818	recall: 0.528474 precision: 0.902724
epoch-2 step 533700/3451022 - loss: 0.034855 val_loss: 0.035240	recall: 0.538288 precision: 0.891791
epoch-2 step 533800/3451022 - loss: 0.036068 val_loss: 0.035589	recall: 0.540113 precision: 0.913958
epoch-2 step 533900/3451022 - loss: 0.041286 val_loss: 0.035579	recall: 0.523310 precision: 0.907071
epoch-2 step 534000/3451022 - loss: 0.047421 val_loss: 0.044857	recall: 0.540000 precision: 0.927273

checkpoint saved

epoch-2 step 534100/3451022 - loss: 0.035833 val_loss: 0.035494	recall: 0.531144 precision: 0.907157

model exported!

epoch-2 step 534200/3451022 - loss: 0.034525 val_loss: 0.041611	recall: 0.529345 precision: 0.919608
epoch-2 step 534300/3451022 - loss: 0.041772 val_loss: 0.033831	recall: 0.536697 precision: 0.905222
epoch-2 step 534400/3451022 - loss: 0.045927 val_loss: 0.035372	recall: 0.520043 precision: 0.917782
epoch-2 step 534500/3451022 - loss: 0.034905 val_loss: 0.036004	recall: 0.513369 precision: 0.892193
epoch-2 step 534600/3451022 - loss: 0.035885 val_loss: 0.037836	recall: 0.553719 precision: 0.928713
epoch-2 step 534700/3451022 - loss: 0.037269 val_loss: 0.050000	recall: 0.533105 precision: 0.899807
epoch-2 step 534800/3451022 - loss: 0.041385 val_loss: 0.034345	recall: 0.507830 precision: 0.878143
epoch-2 step 534900/3451022 - loss: 0.036996 val_loss: 0.041090	recall: 0.517435 precision: 0.879541
epoch-2 step 535000/3451022 - loss: 0.039909 val_loss: 0.033983	recall: 0.558195 precision: 0.921569

checkpoint saved

epoch-2 step 535100/3451022 - loss: 0.042580 val_loss: 0.035481	recall: 0.507279 precision: 0.897030
epoch-2 step 535200/3451022 - loss: 0.035968 val_loss: 0.034439	recall: 0.529347 precision: 0.913958
epoch-2 step 535300/3451022 - loss: 0.034610 val_loss: 0.038042	recall: 0.584541 precision: 0.928983
epoch-2 step 535400/3451022 - loss: 0.035062 val_loss: 0.037204	recall: 0.499439 precision: 0.881188
epoch-2 step 535500/3451022 - loss: 0.035525 val_loss: 0.036353	recall: 0.492489 precision: 0.905325
epoch-2 step 535600/3451022 - loss: 0.038492 val_loss: 0.035117	recall: 0.514412 precision: 0.902724
epoch-2 step 535700/3451022 - loss: 0.035845 val_loss: 0.036325	recall: 0.575294 precision: 0.931429
epoch-2 step 535800/3451022 - loss: 0.033902 val_loss: 0.035013	recall: 0.572282 precision: 0.914122
epoch-2 step 535900/3451022 - loss: 0.035242 val_loss: 0.034961	recall: 0.521886 precision: 0.909980
epoch-2 step 536000/3451022 - loss: 0.035925 val_loss: 0.034654	recall: 0.530201 precision: 0.906310

checkpoint saved

epoch-2 step 536100/3451022 - loss: 0.037425 val_loss: 0.036966	recall: 0.531961 precision: 0.916045

model exported!

epoch-2 step 536200/3451022 - loss: 0.034949 val_loss: 0.034342	recall: 0.524283 precision: 0.935039
epoch-2 step 536300/3451022 - loss: 0.035694 val_loss: 0.036225	recall: 0.532721 precision: 0.904483
epoch-2 step 536400/3451022 - loss: 0.043332 val_loss: 0.039218	recall: 0.538961 precision: 0.918819
epoch-2 step 536500/3451022 - loss: 0.036834 val_loss: 0.034646	recall: 0.526559 precision: 0.899408
epoch-2 step 536600/3451022 - loss: 0.036167 val_loss: 0.034260	recall: 0.505073 precision: 0.896000
epoch-2 step 536700/3451022 - loss: 0.035143 val_loss: 0.037283	recall: 0.536424 precision: 0.922201
epoch-2 step 536800/3451022 - loss: 0.033793 val_loss: 0.044719	recall: 0.533482 precision: 0.924565
epoch-2 step 536900/3451022 - loss: 0.036371 val_loss: 0.037695	recall: 0.500544 precision: 0.884615
epoch-2 step 537000/3451022 - loss: 0.033654 val_loss: 0.034993	recall: 0.510383 precision: 0.905039

checkpoint saved

epoch-2 step 537100/3451022 - loss: 0.036085 val_loss: 0.035482	recall: 0.538025 precision: 0.916828
epoch-2 step 537200/3451022 - loss: 0.035015 val_loss: 0.034442	recall: 0.548864 precision: 0.941520
epoch-2 step 537300/3451022 - loss: 0.034948 val_loss: 0.037194	recall: 0.574186 precision: 0.926070
epoch-2 step 537400/3451022 - loss: 0.034504 val_loss: 0.040493	recall: 0.577960 precision: 0.923221
epoch-2 step 537500/3451022 - loss: 0.036053 val_loss: 0.035599	recall: 0.512568 precision: 0.893333
epoch-2 step 537600/3451022 - loss: 0.037215 val_loss: 0.036947	recall: 0.529279 precision: 0.932540
epoch-2 step 537700/3451022 - loss: 0.039543 val_loss: 0.045093	recall: 0.529478 precision: 0.884470
epoch-2 step 537800/3451022 - loss: 0.040091 val_loss: 0.036720	recall: 0.520548 precision: 0.892368
epoch-2 step 537900/3451022 - loss: 0.035471 val_loss: 0.036154	recall: 0.523969 precision: 0.914397
epoch-2 step 538000/3451022 - loss: 0.036138 val_loss: 0.035065	recall: 0.537705 precision: 0.923077

checkpoint saved

epoch-2 step 538100/3451022 - loss: 0.037429 val_loss: 0.037559	recall: 0.495633 precision: 0.911647

model exported!

epoch-2 step 538200/3451022 - loss: 0.034979 val_loss: 0.048104	recall: 0.493048 precision: 0.883142
epoch-2 step 538300/3451022 - loss: 0.036684 val_loss: 0.034886	recall: 0.493671 precision: 0.928571
epoch-2 step 538400/3451022 - loss: 0.036499 val_loss: 0.042466	recall: 0.518889 precision: 0.908560
epoch-2 step 538500/3451022 - loss: 0.035115 val_loss: 0.049058	recall: 0.525196 precision: 0.889943
epoch-2 step 538600/3451022 - loss: 0.037607 val_loss: 0.035756	recall: 0.530320 precision: 0.907547
epoch-2 step 538700/3451022 - loss: 0.036456 val_loss: 0.036408	recall: 0.523536 precision: 0.910180
epoch-2 step 538800/3451022 - loss: 0.035202 val_loss: 0.036268	recall: 0.537330 precision: 0.913462
epoch-2 step 538900/3451022 - loss: 0.035287 val_loss: 0.043259	recall: 0.522388 precision: 0.878378
epoch-2 step 539000/3451022 - loss: 0.036186 val_loss: 0.035154	recall: 0.537296 precision: 0.902153

checkpoint saved

epoch-2 step 539100/3451022 - loss: 0.033955 val_loss: 0.036123	recall: 0.540476 precision: 0.904382
epoch-2 step 539200/3451022 - loss: 0.039131 val_loss: 0.044474	recall: 0.538375 precision: 0.906844
epoch-2 step 539300/3451022 - loss: 0.034516 val_loss: 0.036394	recall: 0.524917 precision: 0.904580
epoch-2 step 539400/3451022 - loss: 0.040542 val_loss: 0.035206	recall: 0.518722 precision: 0.900574
epoch-2 step 539500/3451022 - loss: 0.036099 val_loss: 0.035859	recall: 0.549539 precision: 0.919075
epoch-2 step 539600/3451022 - loss: 0.034580 val_loss: 0.035620	recall: 0.536643 precision: 0.897233
epoch-2 step 539700/3451022 - loss: 0.040269 val_loss: 0.036737	recall: 0.525028 precision: 0.905950
epoch-2 step 539800/3451022 - loss: 0.036666 val_loss: 0.044473	recall: 0.513363 precision: 0.916501
epoch-2 step 539900/3451022 - loss: 0.034555 val_loss: 0.034391	recall: 0.546498 precision: 0.929688
epoch-2 step 540000/3451022 - loss: 0.038150 val_loss: 0.042539	recall: 0.504961 precision: 0.887597

checkpoint saved

epoch-2 step 540100/3451022 - loss: 0.034303 val_loss: 0.034904	recall: 0.519101 precision: 0.914851

model exported!

epoch-2 step 540200/3451022 - loss: 0.037159 val_loss: 0.034098	recall: 0.545455 precision: 0.923077
epoch-2 step 540300/3451022 - loss: 0.034328 val_loss: 0.034380	recall: 0.544484 precision: 0.896484
epoch-2 step 540400/3451022 - loss: 0.036202 val_loss: 0.035639	recall: 0.530210 precision: 0.875764
epoch-2 step 540500/3451022 - loss: 0.039292 val_loss: 0.034542	recall: 0.550926 precision: 0.898113
epoch-2 step 540600/3451022 - loss: 0.035956 val_loss: 0.036181	recall: 0.521358 precision: 0.903226
epoch-2 step 540700/3451022 - loss: 0.035242 val_loss: 0.036090	recall: 0.538190 precision: 0.908730
epoch-2 step 540800/3451022 - loss: 0.037278 val_loss: 0.034532	recall: 0.504396 precision: 0.892996
epoch-2 step 540900/3451022 - loss: 0.039968 val_loss: 0.039400	recall: 0.552359 precision: 0.933852
epoch-2 step 541000/3451022 - loss: 0.035873 val_loss: 0.035584	recall: 0.523148 precision: 0.888016

checkpoint saved

epoch-2 step 541100/3451022 - loss: 0.041254 val_loss: 0.034200	recall: 0.530055 precision: 0.927342
epoch-2 step 541200/3451022 - loss: 0.036683 val_loss: 0.035743	recall: 0.502165 precision: 0.904483
epoch-2 step 541300/3451022 - loss: 0.040921 val_loss: 0.040109	recall: 0.528239 precision: 0.903409
epoch-2 step 541400/3451022 - loss: 0.034386 val_loss: 0.035228	recall: 0.545455 precision: 0.898876
epoch-2 step 541500/3451022 - loss: 0.036475 val_loss: 0.039213	recall: 0.515801 precision: 0.880539
epoch-2 step 541600/3451022 - loss: 0.034098 val_loss: 0.038335	recall: 0.511211 precision: 0.904762
epoch-2 step 541700/3451022 - loss: 0.034849 val_loss: 0.035325	recall: 0.500542 precision: 0.909449
epoch-2 step 541800/3451022 - loss: 0.038193 val_loss: 0.037760	recall: 0.528825 precision: 0.926214
epoch-2 step 541900/3451022 - loss: 0.038911 val_loss: 0.038228	recall: 0.506051 precision: 0.903733
epoch-2 step 542000/3451022 - loss: 0.034641 val_loss: 0.035073	recall: 0.547537 precision: 0.907021

checkpoint saved

epoch-2 step 542100/3451022 - loss: 0.034366 val_loss: 0.034156	recall: 0.528802 precision: 0.910714

model exported!

epoch-2 step 542200/3451022 - loss: 0.040634 val_loss: 0.045726	recall: 0.525714 precision: 0.901961
epoch-2 step 542300/3451022 - loss: 0.040252 val_loss: 0.036520	recall: 0.525275 precision: 0.890130
epoch-2 step 542400/3451022 - loss: 0.034255 val_loss: 0.038715	recall: 0.506608 precision: 0.884615
epoch-2 step 542500/3451022 - loss: 0.036233 val_loss: 0.036348	recall: 0.517127 precision: 0.906977
epoch-2 step 542600/3451022 - loss: 0.036393 val_loss: 0.038878	recall: 0.508386 precision: 0.918561
epoch-2 step 542700/3451022 - loss: 0.038513 val_loss: 0.036076	recall: 0.521788 precision: 0.903288
epoch-2 step 542800/3451022 - loss: 0.036272 val_loss: 0.035778	recall: 0.533333 precision: 0.915187
epoch-2 step 542900/3451022 - loss: 0.034562 val_loss: 0.037658	recall: 0.521173 precision: 0.895522
epoch-2 step 543000/3451022 - loss: 0.043743 val_loss: 0.035603	recall: 0.526198 precision: 0.897338

checkpoint saved

epoch-2 step 543100/3451022 - loss: 0.035223 val_loss: 0.035087	recall: 0.540698 precision: 0.901163
epoch-2 step 543200/3451022 - loss: 0.038112 val_loss: 0.034483	recall: 0.509372 precision: 0.890173
epoch-2 step 543300/3451022 - loss: 0.034225 val_loss: 0.035318	recall: 0.523438 precision: 0.903661
epoch-2 step 543400/3451022 - loss: 0.037755 val_loss: 0.035239	recall: 0.515453 precision: 0.910331
epoch-2 step 543500/3451022 - loss: 0.038810 val_loss: 0.044708	recall: 0.519694 precision: 0.913462
epoch-2 step 543600/3451022 - loss: 0.034400 val_loss: 0.034902	recall: 0.535519 precision: 0.899083
epoch-2 step 543700/3451022 - loss: 0.037196 val_loss: 0.037766	recall: 0.517954 precision: 0.901515
epoch-2 step 543800/3451022 - loss: 0.038470 val_loss: 0.035625	recall: 0.502169 precision: 0.886973
epoch-2 step 543900/3451022 - loss: 0.040489 val_loss: 0.038202	recall: 0.493989 precision: 0.896825
epoch-2 step 544000/3451022 - loss: 0.035175 val_loss: 0.034363	recall: 0.505556 precision: 0.900990

checkpoint saved

epoch-2 step 544100/3451022 - loss: 0.035476 val_loss: 0.039132	recall: 0.541387 precision: 0.914934

model exported!

epoch-2 step 544200/3451022 - loss: 0.035183 val_loss: 0.036080	recall: 0.524116 precision: 0.910615
epoch-2 step 544300/3451022 - loss: 0.039968 val_loss: 0.041304	recall: 0.530658 precision: 0.884758
epoch-2 step 544400/3451022 - loss: 0.035766 val_loss: 0.052295	recall: 0.501078 precision: 0.897683
epoch-2 step 544500/3451022 - loss: 0.036242 val_loss: 0.035101	recall: 0.519187 precision: 0.893204
epoch-2 step 544600/3451022 - loss: 0.035241 val_loss: 0.035230	recall: 0.544633 precision: 0.918095
epoch-2 step 544700/3451022 - loss: 0.036306 val_loss: 0.037820	recall: 0.525164 precision: 0.914286
epoch-2 step 544800/3451022 - loss: 0.034583 val_loss: 0.038164	recall: 0.507901 precision: 0.900000
epoch-2 step 544900/3451022 - loss: 0.038863 val_loss: 0.033919	recall: 0.467213 precision: 0.868571
epoch-2 step 545000/3451022 - loss: 0.035440 val_loss: 0.040183	recall: 0.545455 precision: 0.895874

checkpoint saved

epoch-2 step 545100/3451022 - loss: 0.037180 val_loss: 0.041526	recall: 0.525296 precision: 0.898711
epoch-2 step 545200/3451022 - loss: 0.039334 val_loss: 0.036813	recall: 0.508753 precision: 0.887405
epoch-2 step 545300/3451022 - loss: 0.035768 val_loss: 0.034605	recall: 0.543359 precision: 0.920074
epoch-2 step 545400/3451022 - loss: 0.034408 val_loss: 0.034785	recall: 0.528281 precision: 0.905039
epoch-2 step 545500/3451022 - loss: 0.035342 val_loss: 0.042098	recall: 0.558511 precision: 0.925926
epoch-2 step 545600/3451022 - loss: 0.037574 val_loss: 0.037873	recall: 0.471384 precision: 0.904192
epoch-2 step 545700/3451022 - loss: 0.036136 val_loss: 0.037936	recall: 0.507182 precision: 0.918000
epoch-2 step 545800/3451022 - loss: 0.038133 val_loss: 0.034929	recall: 0.491597 precision: 0.901734
epoch-2 step 545900/3451022 - loss: 0.040189 val_loss: 0.038651	recall: 0.519042 precision: 0.913793
epoch-2 step 546000/3451022 - loss: 0.035130 val_loss: 0.039440	recall: 0.545752 precision: 0.931227

checkpoint saved

epoch-2 step 546100/3451022 - loss: 0.038839 val_loss: 0.035222	recall: 0.541387 precision: 0.921905

model exported!

epoch-2 step 546200/3451022 - loss: 0.038217 val_loss: 0.042778	recall: 0.493644 precision: 0.904854
epoch-2 step 546300/3451022 - loss: 0.039259 val_loss: 0.034654	recall: 0.520043 precision: 0.914286
epoch-2 step 546400/3451022 - loss: 0.036680 val_loss: 0.035398	recall: 0.512379 precision: 0.927875
epoch-2 step 546500/3451022 - loss: 0.038970 val_loss: 0.035731	recall: 0.504283 precision: 0.907514
epoch-2 step 546600/3451022 - loss: 0.034640 val_loss: 0.037287	recall: 0.486911 precision: 0.911765
epoch-2 step 546700/3451022 - loss: 0.042571 val_loss: 0.040754	recall: 0.545866 precision: 0.937743
epoch-2 step 546800/3451022 - loss: 0.037793 val_loss: 0.040750	recall: 0.509269 precision: 0.887833
epoch-2 step 546900/3451022 - loss: 0.038637 val_loss: 0.037953	recall: 0.521739 precision: 0.921260
epoch-2 step 547000/3451022 - loss: 0.042039 val_loss: 0.035252	recall: 0.529876 precision: 0.914397

checkpoint saved

epoch-2 step 547100/3451022 - loss: 0.042237 val_loss: 0.034165	recall: 0.511038 precision: 0.915020
epoch-2 step 547200/3451022 - loss: 0.035413 val_loss: 0.035312	recall: 0.501124 precision: 0.881423
epoch-2 step 547300/3451022 - loss: 0.035990 val_loss: 0.036110	recall: 0.480810 precision: 0.884314
epoch-2 step 547400/3451022 - loss: 0.035061 val_loss: 0.036155	recall: 0.538375 precision: 0.919075
epoch-2 step 547500/3451022 - loss: 0.046264 val_loss: 0.034282	recall: 0.525424 precision: 0.894231
epoch-2 step 547600/3451022 - loss: 0.037630 val_loss: 0.034316	recall: 0.526316 precision: 0.916179
epoch-2 step 547700/3451022 - loss: 0.039374 val_loss: 0.037969	recall: 0.521598 precision: 0.918251
epoch-2 step 547800/3451022 - loss: 0.036586 val_loss: 0.036332	recall: 0.542056 precision: 0.933602
epoch-2 step 547900/3451022 - loss: 0.037767 val_loss: 0.036600	recall: 0.507322 precision: 0.901487
epoch-2 step 548000/3451022 - loss: 0.039116 val_loss: 0.036424	recall: 0.527559 precision: 0.919608

checkpoint saved

epoch-2 step 548100/3451022 - loss: 0.034311 val_loss: 0.038272	recall: 0.518232 precision: 0.914230

model exported!

epoch-2 step 548200/3451022 - loss: 0.035997 val_loss: 0.036623	recall: 0.565680 precision: 0.926357
epoch-2 step 548300/3451022 - loss: 0.035619 val_loss: 0.037372	recall: 0.497225 precision: 0.887129
epoch-2 step 548400/3451022 - loss: 0.035027 val_loss: 0.045422	recall: 0.496045 precision: 0.888664
epoch-2 step 548500/3451022 - loss: 0.037129 val_loss: 0.033917	recall: 0.550952 precision: 0.930057
epoch-2 step 548600/3451022 - loss: 0.035515 val_loss: 0.033517	recall: 0.513966 precision: 0.896686
epoch-2 step 548700/3451022 - loss: 0.040039 val_loss: 0.037266	recall: 0.522356 precision: 0.914122
epoch-2 step 548800/3451022 - loss: 0.037220 val_loss: 0.037747	recall: 0.530934 precision: 0.907692
epoch-2 step 548900/3451022 - loss: 0.037001 val_loss: 0.033658	recall: 0.538634 precision: 0.912713
epoch-2 step 549000/3451022 - loss: 0.040270 val_loss: 0.036915	recall: 0.516977 precision: 0.904215

checkpoint saved

epoch-2 step 549100/3451022 - loss: 0.036633 val_loss: 0.034309	recall: 0.509978 precision: 0.893204
epoch-2 step 549200/3451022 - loss: 0.035833 val_loss: 0.038175	recall: 0.571602 precision: 0.909266
epoch-2 step 549300/3451022 - loss: 0.039624 val_loss: 0.039569	recall: 0.547786 precision: 0.905588
epoch-2 step 549400/3451022 - loss: 0.035785 val_loss: 0.035831	recall: 0.546067 precision: 0.910112
epoch-2 step 549500/3451022 - loss: 0.041268 val_loss: 0.036348	recall: 0.537915 precision: 0.876448
epoch-2 step 549600/3451022 - loss: 0.042945 val_loss: 0.035692	recall: 0.517475 precision: 0.892996
epoch-2 step 549700/3451022 - loss: 0.038171 val_loss: 0.035037	recall: 0.532584 precision: 0.894340
epoch-2 step 549800/3451022 - loss: 0.035473 val_loss: 0.037665	recall: 0.547018 precision: 0.913793
epoch-2 step 549900/3451022 - loss: 0.036472 val_loss: 0.040301	recall: 0.537598 precision: 0.898687
epoch-2 step 550000/3451022 - loss: 0.038000 val_loss: 0.034626	recall: 0.539488 precision: 0.923810

checkpoint saved

epoch-2 step 550100/3451022 - loss: 0.036013 val_loss: 0.039816	recall: 0.578256 precision: 0.904673

model exported!

epoch-2 step 550200/3451022 - loss: 0.034263 val_loss: 0.037862	recall: 0.545655 precision: 0.915129
epoch-2 step 550300/3451022 - loss: 0.034616 val_loss: 0.040812	recall: 0.547591 precision: 0.894434
epoch-2 step 550400/3451022 - loss: 0.038202 val_loss: 0.035898	recall: 0.527056 precision: 0.925856
epoch-2 step 550500/3451022 - loss: 0.033508 val_loss: 0.035869	recall: 0.530405 precision: 0.916342
epoch-2 step 550600/3451022 - loss: 0.035591 val_loss: 0.037514	recall: 0.556920 precision: 0.930970
epoch-2 step 550700/3451022 - loss: 0.034296 val_loss: 0.034739	recall: 0.553738 precision: 0.913295
epoch-2 step 550800/3451022 - loss: 0.039295 val_loss: 0.035421	recall: 0.543757 precision: 0.892720
epoch-2 step 550900/3451022 - loss: 0.035698 val_loss: 0.035444	recall: 0.519210 precision: 0.918447
epoch-2 step 551000/3451022 - loss: 0.035345 val_loss: 0.047549	recall: 0.525670 precision: 0.890359

checkpoint saved

epoch-2 step 551100/3451022 - loss: 0.044480 val_loss: 0.034689	recall: 0.509540 precision: 0.895464
epoch-2 step 551200/3451022 - loss: 0.035265 val_loss: 0.035420	recall: 0.541814 precision: 0.881226
epoch-2 step 551300/3451022 - loss: 0.044761 val_loss: 0.035288	recall: 0.533869 precision: 0.917160
epoch-2 step 551400/3451022 - loss: 0.039606 val_loss: 0.036541	recall: 0.524571 precision: 0.889535
epoch-2 step 551500/3451022 - loss: 0.035875 val_loss: 0.042138	recall: 0.540445 precision: 0.889961
epoch-2 step 551600/3451022 - loss: 0.034709 val_loss: 0.037618	recall: 0.504918 precision: 0.900585
epoch-2 step 551700/3451022 - loss: 0.036032 val_loss: 0.035276	recall: 0.501106 precision: 0.874517
epoch-2 step 551800/3451022 - loss: 0.035861 val_loss: 0.039089	recall: 0.538895 precision: 0.922780
epoch-2 step 551900/3451022 - loss: 0.035160 val_loss: 0.036061	recall: 0.537079 precision: 0.898496
epoch-2 step 552000/3451022 - loss: 0.034281 val_loss: 0.037604	recall: 0.511785 precision: 0.897638

checkpoint saved

epoch-2 step 552100/3451022 - loss: 0.036432 val_loss: 0.035265	recall: 0.518354 precision: 0.911937

model exported!

epoch-2 step 552200/3451022 - loss: 0.035262 val_loss: 0.034486	recall: 0.534169 precision: 0.919608
epoch-2 step 552300/3451022 - loss: 0.036769 val_loss: 0.040686	recall: 0.521300 precision: 0.922619
epoch-2 step 552400/3451022 - loss: 0.036284 val_loss: 0.034461	recall: 0.515695 precision: 0.889749
epoch-2 step 552500/3451022 - loss: 0.039763 val_loss: 0.039711	recall: 0.514989 precision: 0.925000
epoch-2 step 552600/3451022 - loss: 0.034895 val_loss: 0.036609	recall: 0.509497 precision: 0.906561
epoch-2 step 552700/3451022 - loss: 0.034187 val_loss: 0.038394	recall: 0.526659 precision: 0.913208
epoch-2 step 552800/3451022 - loss: 0.036758 val_loss: 0.046568	recall: 0.501121 precision: 0.890438
epoch-2 step 552900/3451022 - loss: 0.036343 val_loss: 0.034140	recall: 0.514509 precision: 0.889961
epoch-2 step 553000/3451022 - loss: 0.035966 val_loss: 0.040402	recall: 0.521978 precision: 0.901328

checkpoint saved

epoch-2 step 553100/3451022 - loss: 0.034683 val_loss: 0.045130	recall: 0.540066 precision: 0.911111
epoch-2 step 553200/3451022 - loss: 0.036882 val_loss: 0.036637	recall: 0.518805 precision: 0.893333
epoch-2 step 553300/3451022 - loss: 0.035677 val_loss: 0.035213	recall: 0.560917 precision: 0.911765
epoch-2 step 553400/3451022 - loss: 0.036511 val_loss: 0.035195	recall: 0.554779 precision: 0.894737
epoch-2 step 553500/3451022 - loss: 0.039813 val_loss: 0.042409	recall: 0.524130 precision: 0.899807
epoch-2 step 553600/3451022 - loss: 0.035609 val_loss: 0.034837	recall: 0.544696 precision: 0.894325
epoch-2 step 553700/3451022 - loss: 0.035377 val_loss: 0.039456	recall: 0.545888 precision: 0.896282
epoch-2 step 553800/3451022 - loss: 0.033817 val_loss: 0.035235	recall: 0.539773 precision: 0.906489
epoch-2 step 553900/3451022 - loss: 0.034651 val_loss: 0.035358	recall: 0.519630 precision: 0.901804
epoch-2 step 554000/3451022 - loss: 0.039280 val_loss: 0.034758	recall: 0.547945 precision: 0.893855

checkpoint saved

epoch-2 step 554100/3451022 - loss: 0.034992 val_loss: 0.037914	recall: 0.527778 precision: 0.897921

model exported!

epoch-2 step 554200/3451022 - loss: 0.034925 val_loss: 0.035697	recall: 0.521788 precision: 0.901544
epoch-2 step 554300/3451022 - loss: 0.035236 val_loss: 0.041482	recall: 0.506037 precision: 0.909270
epoch-2 step 554400/3451022 - loss: 0.035814 val_loss: 0.036957	recall: 0.511628 precision: 0.897087
epoch-2 step 554500/3451022 - loss: 0.034670 val_loss: 0.035691	recall: 0.513572 precision: 0.922027
epoch-2 step 554600/3451022 - loss: 0.035368 val_loss: 0.041615	recall: 0.530806 precision: 0.888889
epoch-2 step 554700/3451022 - loss: 0.034326 val_loss: 0.033872	recall: 0.516094 precision: 0.914449
epoch-2 step 554800/3451022 - loss: 0.034550 val_loss: 0.038711	recall: 0.519231 precision: 0.886100
epoch-2 step 554900/3451022 - loss: 0.037352 val_loss: 0.038179	recall: 0.526012 precision: 0.871648
epoch-2 step 555000/3451022 - loss: 0.035335 val_loss: 0.039552	recall: 0.529412 precision: 0.908411

checkpoint saved

epoch-2 step 555100/3451022 - loss: 0.040407 val_loss: 0.035510	recall: 0.510117 precision: 0.912381
epoch-2 step 555200/3451022 - loss: 0.034163 val_loss: 0.035557	recall: 0.555429 precision: 0.927481
epoch-2 step 555300/3451022 - loss: 0.036527 val_loss: 0.034798	recall: 0.496681 precision: 0.892644
epoch-2 step 555400/3451022 - loss: 0.036031 val_loss: 0.043761	recall: 0.513636 precision: 0.907631
epoch-2 step 555500/3451022 - loss: 0.035598 val_loss: 0.035680	recall: 0.523699 precision: 0.900596
epoch-2 step 555600/3451022 - loss: 0.034261 val_loss: 0.045491	recall: 0.505580 precision: 0.869482
epoch-2 step 555700/3451022 - loss: 0.038351 val_loss: 0.038671	recall: 0.551181 precision: 0.926276
epoch-2 step 555800/3451022 - loss: 0.042956 val_loss: 0.036492	recall: 0.516609 precision: 0.920408
epoch-2 step 555900/3451022 - loss: 0.038935 val_loss: 0.036571	recall: 0.518973 precision: 0.901163
epoch-2 step 556000/3451022 - loss: 0.034820 val_loss: 0.037266	recall: 0.486428 precision: 0.887129

checkpoint saved

epoch-2 step 556100/3451022 - loss: 0.037572 val_loss: 0.034131	recall: 0.567916 precision: 0.927342

model exported!

epoch-2 step 556200/3451022 - loss: 0.039271 val_loss: 0.035186	recall: 0.515744 precision: 0.916988
epoch-2 step 556300/3451022 - loss: 0.037586 val_loss: 0.045175	recall: 0.489730 precision: 0.891732
epoch-2 step 556400/3451022 - loss: 0.037835 val_loss: 0.037285	recall: 0.520397 precision: 0.899048
epoch-2 step 556500/3451022 - loss: 0.036132 val_loss: 0.036654	recall: 0.517052 precision: 0.888469
epoch-2 step 556600/3451022 - loss: 0.035207 val_loss: 0.043157	recall: 0.543601 precision: 0.914286
epoch-2 step 556700/3451022 - loss: 0.037052 val_loss: 0.038190	recall: 0.512596 precision: 0.893130
epoch-2 step 556800/3451022 - loss: 0.034921 val_loss: 0.035122	recall: 0.559633 precision: 0.907063
epoch-2 step 556900/3451022 - loss: 0.035982 val_loss: 0.036541	recall: 0.528889 precision: 0.899811
epoch-2 step 557000/3451022 - loss: 0.034832 val_loss: 0.035609	recall: 0.556977 precision: 0.937378

checkpoint saved

epoch-2 step 557100/3451022 - loss: 0.039537 val_loss: 0.036191	recall: 0.521064 precision: 0.900383
epoch-2 step 557200/3451022 - loss: 0.036790 val_loss: 0.037806	recall: 0.533490 precision: 0.902584
epoch-2 step 557300/3451022 - loss: 0.049841 val_loss: 0.035289	recall: 0.535398 precision: 0.913208
epoch-2 step 557400/3451022 - loss: 0.035245 val_loss: 0.035084	recall: 0.523652 precision: 0.918919
epoch-2 step 557500/3451022 - loss: 0.038807 val_loss: 0.047386	recall: 0.484688 precision: 0.894737
epoch-2 step 557600/3451022 - loss: 0.042259 val_loss: 0.042143	recall: 0.526995 precision: 0.901606
epoch-2 step 557700/3451022 - loss: 0.042734 val_loss: 0.035349	recall: 0.518398 precision: 0.926499
epoch-2 step 557800/3451022 - loss: 0.034951 val_loss: 0.034518	recall: 0.537058 precision: 0.904031
epoch-2 step 557900/3451022 - loss: 0.034430 val_loss: 0.035058	recall: 0.473904 precision: 0.893701
epoch-2 step 558000/3451022 - loss: 0.036475 val_loss: 0.041504	recall: 0.501684 precision: 0.899396

checkpoint saved

epoch-2 step 558100/3451022 - loss: 0.034522 val_loss: 0.040525	recall: 0.497758 precision: 0.860465

model exported!

epoch-2 step 558200/3451022 - loss: 0.039256 val_loss: 0.035595	recall: 0.496257 precision: 0.904483
epoch-2 step 558300/3451022 - loss: 0.034226 val_loss: 0.039364	recall: 0.529412 precision: 0.919840
epoch-2 step 558400/3451022 - loss: 0.038138 val_loss: 0.034274	recall: 0.525164 precision: 0.917782
epoch-2 step 558500/3451022 - loss: 0.042600 val_loss: 0.034045	recall: 0.516630 precision: 0.926441
epoch-2 step 558600/3451022 - loss: 0.035178 val_loss: 0.033852	recall: 0.542541 precision: 0.935238
epoch-2 step 558700/3451022 - loss: 0.038286 val_loss: 0.039432	recall: 0.510405 precision: 0.899614
epoch-2 step 558800/3451022 - loss: 0.034171 val_loss: 0.049514	recall: 0.507592 precision: 0.900000
epoch-2 step 558900/3451022 - loss: 0.037014 val_loss: 0.037851	recall: 0.503386 precision: 0.872798
epoch-2 step 559000/3451022 - loss: 0.035496 val_loss: 0.035714	recall: 0.491398 precision: 0.887379

checkpoint saved

epoch-2 step 559100/3451022 - loss: 0.039721 val_loss: 0.035463	recall: 0.513730 precision: 0.896208
epoch-2 step 559200/3451022 - loss: 0.035195 val_loss: 0.045102	recall: 0.528814 precision: 0.896552
epoch-2 step 559300/3451022 - loss: 0.035206 val_loss: 0.038921	recall: 0.523282 precision: 0.905950
epoch-2 step 559400/3451022 - loss: 0.034824 val_loss: 0.036921	recall: 0.555556 precision: 0.897196
epoch-2 step 559500/3451022 - loss: 0.034678 val_loss: 0.037790	recall: 0.522596 precision: 0.900200
epoch-2 step 559600/3451022 - loss: 0.035654 val_loss: 0.039294	recall: 0.548425 precision: 0.902111
epoch-2 step 559700/3451022 - loss: 0.034537 val_loss: 0.037434	recall: 0.541190 precision: 0.907869
epoch-2 step 559800/3451022 - loss: 0.034653 val_loss: 0.038929	recall: 0.501092 precision: 0.929150
epoch-2 step 559900/3451022 - loss: 0.037033 val_loss: 0.034294	recall: 0.503198 precision: 0.893939
epoch-2 step 560000/3451022 - loss: 0.035190 val_loss: 0.037184	recall: 0.531111 precision: 0.940945

checkpoint saved

epoch-2 step 560100/3451022 - loss: 0.035118 val_loss: 0.035052	recall: 0.502657 precision: 0.922027

model exported!

epoch-2 step 560200/3451022 - loss: 0.036583 val_loss: 0.037704	recall: 0.529018 precision: 0.923977
epoch-2 step 560300/3451022 - loss: 0.035754 val_loss: 0.036941	recall: 0.526718 precision: 0.911321
epoch-2 step 560400/3451022 - loss: 0.035800 val_loss: 0.034603	recall: 0.524706 precision: 0.899194
epoch-2 step 560500/3451022 - loss: 0.034615 val_loss: 0.036929	recall: 0.551955 precision: 0.916512
epoch-2 step 560600/3451022 - loss: 0.036107 val_loss: 0.040337	recall: 0.502208 precision: 0.895669
epoch-2 step 560700/3451022 - loss: 0.036158 val_loss: 0.037750	recall: 0.519868 precision: 0.916342
epoch-2 step 560800/3451022 - loss: 0.034683 val_loss: 0.037387	recall: 0.524460 precision: 0.923848
epoch-2 step 560900/3451022 - loss: 0.035456 val_loss: 0.036860	recall: 0.534368 precision: 0.902622
epoch-2 step 561000/3451022 - loss: 0.034569 val_loss: 0.039407	recall: 0.495789 precision: 0.895437

checkpoint saved

epoch-2 step 561100/3451022 - loss: 0.034639 val_loss: 0.042076	recall: 0.515220 precision: 0.882239
epoch-2 step 561200/3451022 - loss: 0.041146 val_loss: 0.034893	recall: 0.515924 precision: 0.915254
epoch-2 step 561300/3451022 - loss: 0.037678 val_loss: 0.037163	recall: 0.520408 precision: 0.891262
epoch-2 step 561400/3451022 - loss: 0.034709 val_loss: 0.036987	recall: 0.510293 precision: 0.909266
epoch-2 step 561500/3451022 - loss: 0.039224 val_loss: 0.036059	recall: 0.524022 precision: 0.923228
epoch-2 step 561600/3451022 - loss: 0.035935 val_loss: 0.040404	recall: 0.501574 precision: 0.901887
epoch-2 step 561700/3451022 - loss: 0.036827 val_loss: 0.037093	recall: 0.503151 precision: 0.922929
epoch-2 step 561800/3451022 - loss: 0.037593 val_loss: 0.035483	recall: 0.509677 precision: 0.913295
epoch-2 step 561900/3451022 - loss: 0.036166 val_loss: 0.036307	recall: 0.512821 precision: 0.905512
epoch-2 step 562000/3451022 - loss: 0.038025 val_loss: 0.035820	recall: 0.528749 precision: 0.905405

checkpoint saved

epoch-2 step 562100/3451022 - loss: 0.036923 val_loss: 0.036767	recall: 0.510497 precision: 0.890173

model exported!

epoch-2 step 562200/3451022 - loss: 0.038118 val_loss: 0.036128	recall: 0.507919 precision: 0.896208
epoch-2 step 562300/3451022 - loss: 0.035906 val_loss: 0.037027	recall: 0.539720 precision: 0.904110
epoch-2 step 562400/3451022 - loss: 0.035458 val_loss: 0.042836	recall: 0.529480 precision: 0.914172
epoch-2 step 562500/3451022 - loss: 0.054237 val_loss: 0.042343	recall: 0.551445 precision: 0.908571
epoch-2 step 562600/3451022 - loss: 0.049482 val_loss: 0.036499	recall: 0.547699 precision: 0.907063
epoch-2 step 562700/3451022 - loss: 0.039404 val_loss: 0.043301	recall: 0.534961 precision: 0.918095
epoch-2 step 562800/3451022 - loss: 0.038257 val_loss: 0.038181	recall: 0.532311 precision: 0.932821
epoch-2 step 562900/3451022 - loss: 0.038103 val_loss: 0.034677	recall: 0.525000 precision: 0.913043
epoch-2 step 563000/3451022 - loss: 0.034720 val_loss: 0.035223	recall: 0.522905 precision: 0.903475

checkpoint saved

epoch-2 step 563100/3451022 - loss: 0.036613 val_loss: 0.042349	recall: 0.535832 precision: 0.895028
epoch-2 step 563200/3451022 - loss: 0.036382 val_loss: 0.037182	recall: 0.538877 precision: 0.924074
epoch-2 step 563300/3451022 - loss: 0.036488 val_loss: 0.034832	recall: 0.518805 precision: 0.928713
epoch-2 step 563400/3451022 - loss: 0.035269 val_loss: 0.038193	recall: 0.490281 precision: 0.899010
epoch-2 step 563500/3451022 - loss: 0.036860 val_loss: 0.035087	recall: 0.511777 precision: 0.926357
epoch-2 step 563600/3451022 - loss: 0.036443 val_loss: 0.040605	recall: 0.501654 precision: 0.915493
epoch-2 step 563700/3451022 - loss: 0.037877 val_loss: 0.040310	recall: 0.542045 precision: 0.915547
epoch-2 step 563800/3451022 - loss: 0.037405 val_loss: 0.043540	recall: 0.530864 precision: 0.918447
epoch-2 step 563900/3451022 - loss: 0.037899 val_loss: 0.038291	recall: 0.522321 precision: 0.908738
epoch-2 step 564000/3451022 - loss: 0.038000 val_loss: 0.034410	recall: 0.531818 precision: 0.906977

checkpoint saved

epoch-2 step 564100/3451022 - loss: 0.035089 val_loss: 0.038611	recall: 0.540909 precision: 0.899811

model exported!

epoch-2 step 564200/3451022 - loss: 0.037515 val_loss: 0.036447	recall: 0.519780 precision: 0.902672
epoch-2 step 564300/3451022 - loss: 0.037301 val_loss: 0.041969	recall: 0.516854 precision: 0.909091
epoch-2 step 564400/3451022 - loss: 0.034104 val_loss: 0.040229	recall: 0.518286 precision: 0.934087
epoch-2 step 564500/3451022 - loss: 0.036415 val_loss: 0.035721	recall: 0.525442 precision: 0.903042
epoch-2 step 564600/3451022 - loss: 0.039535 val_loss: 0.039053	recall: 0.531590 precision: 0.920755
epoch-2 step 564700/3451022 - loss: 0.035021 val_loss: 0.035281	recall: 0.533485 precision: 0.917969
epoch-2 step 564800/3451022 - loss: 0.034223 val_loss: 0.039516	recall: 0.500559 precision: 0.890656
epoch-2 step 564900/3451022 - loss: 0.036405 val_loss: 0.037593	recall: 0.509310 precision: 0.906433
epoch-2 step 565000/3451022 - loss: 0.033914 val_loss: 0.035843	recall: 0.536264 precision: 0.919021

checkpoint saved

epoch-2 step 565100/3451022 - loss: 0.042130 val_loss: 0.041080	recall: 0.529548 precision: 0.917671
epoch-2 step 565200/3451022 - loss: 0.036674 val_loss: 0.034477	recall: 0.523216 precision: 0.868421
epoch-2 step 565300/3451022 - loss: 0.037650 val_loss: 0.037064	recall: 0.502744 precision: 0.894531
epoch-2 step 565400/3451022 - loss: 0.037169 val_loss: 0.039504	recall: 0.519231 precision: 0.927481
epoch-2 step 565500/3451022 - loss: 0.034177 val_loss: 0.035506	recall: 0.539261 precision: 0.901544
epoch-2 step 565600/3451022 - loss: 0.044983 val_loss: 0.034723	recall: 0.517058 precision: 0.903166
epoch-2 step 565700/3451022 - loss: 0.045151 val_loss: 0.039186	recall: 0.525901 precision: 0.901544
epoch-2 step 565800/3451022 - loss: 0.035499 val_loss: 0.042629	recall: 0.527485 precision: 0.891304
epoch-2 step 565900/3451022 - loss: 0.043112 val_loss: 0.044282	recall: 0.518272 precision: 0.898273
epoch-2 step 566000/3451022 - loss: 0.035582 val_loss: 0.037529	recall: 0.528684 precision: 0.898662

checkpoint saved

epoch-2 step 566100/3451022 - loss: 0.037847 val_loss: 0.037990	recall: 0.510181 precision: 0.877432

model exported!

epoch-2 step 566200/3451022 - loss: 0.034457 val_loss: 0.038555	recall: 0.505507 precision: 0.903543
epoch-2 step 566300/3451022 - loss: 0.035251 val_loss: 0.034381	recall: 0.540449 precision: 0.925000
epoch-2 step 566400/3451022 - loss: 0.045692 val_loss: 0.034263	recall: 0.506565 precision: 0.886973
epoch-2 step 566500/3451022 - loss: 0.035210 val_loss: 0.035786	recall: 0.541020 precision: 0.922495
epoch-2 step 566600/3451022 - loss: 0.034021 val_loss: 0.035999	recall: 0.532741 precision: 0.895522
epoch-2 step 566700/3451022 - loss: 0.034278 val_loss: 0.044060	recall: 0.531250 precision: 0.924953
epoch-2 step 566800/3451022 - loss: 0.035765 val_loss: 0.037146	recall: 0.542155 precision: 0.911417
epoch-2 step 566900/3451022 - loss: 0.041271 val_loss: 0.035990	recall: 0.493450 precision: 0.875969
epoch-2 step 567000/3451022 - loss: 0.038863 val_loss: 0.042501	recall: 0.519084 precision: 0.888060

checkpoint saved

epoch-2 step 567100/3451022 - loss: 0.034824 val_loss: 0.038275	recall: 0.504886 precision: 0.892514
epoch-2 step 567200/3451022 - loss: 0.036459 val_loss: 0.040397	recall: 0.544118 precision: 0.933981
epoch-2 step 567300/3451022 - loss: 0.036527 val_loss: 0.042820	recall: 0.532382 precision: 0.943580
epoch-2 step 567400/3451022 - loss: 0.040982 val_loss: 0.035615	recall: 0.511931 precision: 0.893939
epoch-2 step 567500/3451022 - loss: 0.037389 val_loss: 0.035487	recall: 0.522173 precision: 0.900574
epoch-2 step 567600/3451022 - loss: 0.034981 val_loss: 0.034427	recall: 0.495114 precision: 0.897638
epoch-2 step 567700/3451022 - loss: 0.041485 val_loss: 0.036375	recall: 0.533409 precision: 0.895437
epoch-2 step 567800/3451022 - loss: 0.036037 val_loss: 0.034932	recall: 0.513800 precision: 0.891344
epoch-2 step 567900/3451022 - loss: 0.034312 val_loss: 0.041302	recall: 0.529284 precision: 0.924242
epoch-2 step 568000/3451022 - loss: 0.044735 val_loss: 0.034349	recall: 0.513661 precision: 0.885122

checkpoint saved

epoch-2 step 568100/3451022 - loss: 0.040330 val_loss: 0.039488	recall: 0.509978 precision: 0.907298

model exported!

epoch-2 step 568200/3451022 - loss: 0.033943 val_loss: 0.037082	recall: 0.497859 precision: 0.879017
epoch-2 step 568300/3451022 - loss: 0.035322 val_loss: 0.035016	recall: 0.540946 precision: 0.914230
epoch-2 step 568400/3451022 - loss: 0.034836 val_loss: 0.037547	recall: 0.500000 precision: 0.899606
epoch-2 step 568500/3451022 - loss: 0.034734 val_loss: 0.033703	recall: 0.522173 precision: 0.905769
epoch-2 step 568600/3451022 - loss: 0.038761 val_loss: 0.037220	recall: 0.506024 precision: 0.895349
epoch-2 step 568700/3451022 - loss: 0.033926 val_loss: 0.035455	recall: 0.519274 precision: 0.892788
epoch-2 step 568800/3451022 - loss: 0.049032 val_loss: 0.037421	recall: 0.524644 precision: 0.907197
epoch-2 step 568900/3451022 - loss: 0.035706 val_loss: 0.036241	recall: 0.508179 precision: 0.922772
epoch-2 step 569000/3451022 - loss: 0.039235 val_loss: 0.038646	recall: 0.500000 precision: 0.914513

checkpoint saved

epoch-2 step 569100/3451022 - loss: 0.038304 val_loss: 0.036507	recall: 0.539313 precision: 0.910280
epoch-2 step 569200/3451022 - loss: 0.038017 val_loss: 0.034781	recall: 0.546091 precision: 0.905222
epoch-2 step 569300/3451022 - loss: 0.045382 val_loss: 0.041380	recall: 0.523446 precision: 0.912548
epoch-2 step 569400/3451022 - loss: 0.036383 val_loss: 0.034963	recall: 0.556461 precision: 0.919231
epoch-2 step 569500/3451022 - loss: 0.038593 val_loss: 0.035623	recall: 0.498309 precision: 0.880478
epoch-2 step 569600/3451022 - loss: 0.040124 val_loss: 0.048995	recall: 0.533480 precision: 0.920455
epoch-2 step 569700/3451022 - loss: 0.036090 val_loss: 0.035566	recall: 0.500000 precision: 0.889109
epoch-2 step 569800/3451022 - loss: 0.036617 val_loss: 0.041450	recall: 0.549438 precision: 0.926136
epoch-2 step 569900/3451022 - loss: 0.043161 val_loss: 0.034869	recall: 0.512959 precision: 0.918762
epoch-2 step 570000/3451022 - loss: 0.035460 val_loss: 0.044957	recall: 0.542411 precision: 0.915254

checkpoint saved

epoch-2 step 570100/3451022 - loss: 0.035577 val_loss: 0.035142	recall: 0.517647 precision: 0.897959

model exported!

epoch-2 step 570200/3451022 - loss: 0.036090 val_loss: 0.037980	recall: 0.533409 precision: 0.897143
epoch-2 step 570300/3451022 - loss: 0.037629 val_loss: 0.042735	recall: 0.512486 precision: 0.909441
epoch-2 step 570400/3451022 - loss: 0.039250 val_loss: 0.034701	recall: 0.513543 precision: 0.913295
epoch-2 step 570500/3451022 - loss: 0.037123 val_loss: 0.038476	recall: 0.524684 precision: 0.903162
epoch-2 step 570600/3451022 - loss: 0.034434 val_loss: 0.035308	recall: 0.502183 precision: 0.905512
epoch-2 step 570700/3451022 - loss: 0.042009 val_loss: 0.036065	recall: 0.541573 precision: 0.919847
epoch-2 step 570800/3451022 - loss: 0.035966 val_loss: 0.036498	recall: 0.529478 precision: 0.901544
epoch-2 step 570900/3451022 - loss: 0.035156 val_loss: 0.036325	recall: 0.542237 precision: 0.909962
epoch-2 step 571000/3451022 - loss: 0.038745 val_loss: 0.034901	recall: 0.540257 precision: 0.902534

checkpoint saved

epoch-2 step 571100/3451022 - loss: 0.036260 val_loss: 0.036242	recall: 0.489595 precision: 0.892216
epoch-2 step 571200/3451022 - loss: 0.036880 val_loss: 0.034902	recall: 0.515186 precision: 0.892788
epoch-2 step 571300/3451022 - loss: 0.035704 val_loss: 0.034300	recall: 0.532887 precision: 0.912214
epoch-2 step 571400/3451022 - loss: 0.038203 val_loss: 0.038677	recall: 0.540138 precision: 0.914563
epoch-2 step 571500/3451022 - loss: 0.037253 val_loss: 0.036179	recall: 0.530892 precision: 0.904483
epoch-2 step 571600/3451022 - loss: 0.040332 val_loss: 0.036078	recall: 0.518201 precision: 0.906367
epoch-2 step 571700/3451022 - loss: 0.036138 val_loss: 0.041402	recall: 0.522777 precision: 0.902622
epoch-2 step 571800/3451022 - loss: 0.038767 val_loss: 0.035118	recall: 0.516234 precision: 0.924419
epoch-2 step 571900/3451022 - loss: 0.034903 val_loss: 0.034208	recall: 0.506159 precision: 0.886275
epoch-2 step 572000/3451022 - loss: 0.036919 val_loss: 0.035335	recall: 0.526082 precision: 0.894340

checkpoint saved

epoch-2 step 572100/3451022 - loss: 0.034781 val_loss: 0.035736	recall: 0.491927 precision: 0.883946

model exported!

epoch-2 step 572200/3451022 - loss: 0.038125 val_loss: 0.039986	recall: 0.500000 precision: 0.900990
epoch-2 step 572300/3451022 - loss: 0.034517 val_loss: 0.034287	recall: 0.541020 precision: 0.917293
epoch-2 step 572400/3451022 - loss: 0.034840 val_loss: 0.039053	recall: 0.500528 precision: 0.923977
epoch-2 step 572500/3451022 - loss: 0.042528 val_loss: 0.037847	recall: 0.527936 precision: 0.893822
epoch-2 step 572600/3451022 - loss: 0.034472 val_loss: 0.033994	recall: 0.524130 precision: 0.922925
epoch-2 step 572700/3451022 - loss: 0.034896 val_loss: 0.036071	recall: 0.512387 precision: 0.888672
epoch-2 step 572800/3451022 - loss: 0.034695 val_loss: 0.035416	recall: 0.517391 precision: 0.911877
epoch-2 step 572900/3451022 - loss: 0.035098 val_loss: 0.034662	recall: 0.527594 precision: 0.910476
epoch-2 step 573000/3451022 - loss: 0.035728 val_loss: 0.037330	recall: 0.494080 precision: 0.894737

checkpoint saved

epoch-2 step 573100/3451022 - loss: 0.042669 val_loss: 0.036438	recall: 0.520900 precision: 0.900000
epoch-2 step 573200/3451022 - loss: 0.039570 val_loss: 0.034588	recall: 0.527105 precision: 0.901381
epoch-2 step 573300/3451022 - loss: 0.035355 val_loss: 0.042335	recall: 0.542431 precision: 0.911368
epoch-2 step 573400/3451022 - loss: 0.040375 val_loss: 0.041801	recall: 0.514317 precision: 0.898077
epoch-2 step 573500/3451022 - loss: 0.036944 val_loss: 0.035532	recall: 0.556713 precision: 0.950593
epoch-2 step 573600/3451022 - loss: 0.035439 val_loss: 0.039798	recall: 0.534141 precision: 0.922053
epoch-2 step 573700/3451022 - loss: 0.036141 val_loss: 0.040957	recall: 0.554422 precision: 0.922642
epoch-2 step 573800/3451022 - loss: 0.038366 val_loss: 0.034014	recall: 0.525351 precision: 0.936538
epoch-2 step 573900/3451022 - loss: 0.035413 val_loss: 0.036140	recall: 0.559226 precision: 0.917757
epoch-2 step 574000/3451022 - loss: 0.037154 val_loss: 0.036888	recall: 0.500000 precision: 0.919132

checkpoint saved

epoch-2 step 574100/3451022 - loss: 0.038407 val_loss: 0.034253	recall: 0.530822 precision: 0.904669

model exported!

epoch-2 step 574200/3451022 - loss: 0.042637 val_loss: 0.035661	recall: 0.503240 precision: 0.917323
epoch-2 step 574300/3451022 - loss: 0.035476 val_loss: 0.034259	recall: 0.539352 precision: 0.924603
epoch-2 step 574400/3451022 - loss: 0.035546 val_loss: 0.035977	recall: 0.517357 precision: 0.891892
epoch-2 step 574500/3451022 - loss: 0.040411 val_loss: 0.034089	recall: 0.529025 precision: 0.896104
epoch-2 step 574600/3451022 - loss: 0.043303 val_loss: 0.035210	recall: 0.542271 precision: 0.885602
epoch-2 step 574700/3451022 - loss: 0.034940 val_loss: 0.034400	recall: 0.566038 precision: 0.933852
epoch-2 step 574800/3451022 - loss: 0.034783 val_loss: 0.036698	recall: 0.520833 precision: 0.915222
epoch-2 step 574900/3451022 - loss: 0.034534 val_loss: 0.035334	recall: 0.567870 precision: 0.875240
epoch-2 step 575000/3451022 - loss: 0.036040 val_loss: 0.043404	recall: 0.535674 precision: 0.884112

checkpoint saved

epoch-2 step 575100/3451022 - loss: 0.044513 val_loss: 0.035010	recall: 0.526147 precision: 0.907919
epoch-2 step 575200/3451022 - loss: 0.037668 val_loss: 0.036643	recall: 0.512651 precision: 0.915521
epoch-2 step 575300/3451022 - loss: 0.036228 val_loss: 0.036123	recall: 0.535880 precision: 0.920477
epoch-2 step 575400/3451022 - loss: 0.034010 val_loss: 0.036718	recall: 0.524194 precision: 0.880077
epoch-2 step 575500/3451022 - loss: 0.038253 val_loss: 0.042202	recall: 0.535433 precision: 0.926070
epoch-2 step 575600/3451022 - loss: 0.040792 val_loss: 0.037716	recall: 0.512195 precision: 0.907662
epoch-2 step 575700/3451022 - loss: 0.035661 val_loss: 0.035770	recall: 0.522624 precision: 0.897087
epoch-2 step 575800/3451022 - loss: 0.069782 val_loss: 0.034624	recall: 0.518797 precision: 0.897770
epoch-2 step 575900/3451022 - loss: 0.035886 val_loss: 0.034188	recall: 0.526735 precision: 0.916832
epoch-2 step 576000/3451022 - loss: 0.035526 val_loss: 0.040825	recall: 0.548837 precision: 0.904215

checkpoint saved

epoch-2 step 576100/3451022 - loss: 0.036232 val_loss: 0.038171	recall: 0.548652 precision: 0.896552

model exported!

epoch-2 step 576200/3451022 - loss: 0.041553 val_loss: 0.035092	recall: 0.564133 precision: 0.913462
epoch-2 step 576300/3451022 - loss: 0.036272 val_loss: 0.036476	recall: 0.525773 precision: 0.905325
epoch-2 step 576400/3451022 - loss: 0.037927 val_loss: 0.040724	recall: 0.528281 precision: 0.908560
epoch-2 step 576500/3451022 - loss: 0.035082 val_loss: 0.038590	recall: 0.521205 precision: 0.891221
epoch-2 step 576600/3451022 - loss: 0.038320 val_loss: 0.040165	recall: 0.503247 precision: 0.911765
epoch-2 step 576700/3451022 - loss: 0.035108 val_loss: 0.036362	recall: 0.527655 precision: 0.906844
epoch-2 step 576800/3451022 - loss: 0.034767 val_loss: 0.036849	recall: 0.521358 precision: 0.922481
epoch-2 step 576900/3451022 - loss: 0.034949 val_loss: 0.038513	recall: 0.528281 precision: 0.901544
epoch-2 step 577000/3451022 - loss: 0.034971 val_loss: 0.037208	recall: 0.501684 precision: 0.876471

checkpoint saved

epoch-2 step 577100/3451022 - loss: 0.042713 val_loss: 0.035985	recall: 0.535068 precision: 0.906130
epoch-2 step 577200/3451022 - loss: 0.039187 val_loss: 0.037715	recall: 0.503198 precision: 0.918288
epoch-2 step 577300/3451022 - loss: 0.035872 val_loss: 0.038568	recall: 0.500548 precision: 0.919517
epoch-2 step 577400/3451022 - loss: 0.038599 val_loss: 0.035625	recall: 0.531469 precision: 0.904762
epoch-2 step 577500/3451022 - loss: 0.035527 val_loss: 0.039429	recall: 0.521643 precision: 0.902111
epoch-2 step 577600/3451022 - loss: 0.036007 val_loss: 0.034858	recall: 0.545977 precision: 0.894539
epoch-2 step 577700/3451022 - loss: 0.035462 val_loss: 0.035546	recall: 0.523148 precision: 0.909457
epoch-2 step 577800/3451022 - loss: 0.036350 val_loss: 0.036993	recall: 0.533937 precision: 0.920078
epoch-2 step 577900/3451022 - loss: 0.034300 val_loss: 0.036864	recall: 0.517621 precision: 0.905588
epoch-2 step 578000/3451022 - loss: 0.035172 val_loss: 0.034746	recall: 0.518152 precision: 0.923529

checkpoint saved

epoch-2 step 578100/3451022 - loss: 0.035805 val_loss: 0.036789	recall: 0.506623 precision: 0.907115

model exported!

epoch-2 step 578200/3451022 - loss: 0.034733 val_loss: 0.037046	recall: 0.526316 precision: 0.917969
epoch-2 step 578300/3451022 - loss: 0.036957 val_loss: 0.035554	recall: 0.533702 precision: 0.907895
epoch-2 step 578400/3451022 - loss: 0.037826 val_loss: 0.034339	recall: 0.544917 precision: 0.911067
epoch-2 step 578500/3451022 - loss: 0.037999 val_loss: 0.035355	recall: 0.523322 precision: 0.884615
epoch-2 step 578600/3451022 - loss: 0.040960 val_loss: 0.035261	recall: 0.523973 precision: 0.882692
epoch-2 step 578700/3451022 - loss: 0.033915 val_loss: 0.039301	recall: 0.505495 precision: 0.907298
epoch-2 step 578800/3451022 - loss: 0.036875 val_loss: 0.035138	recall: 0.551843 precision: 0.915870
epoch-2 step 578900/3451022 - loss: 0.036217 val_loss: 0.044787	recall: 0.548122 precision: 0.901544
epoch-2 step 579000/3451022 - loss: 0.034255 val_loss: 0.034900	recall: 0.500000 precision: 0.896484

checkpoint saved

epoch-2 step 579100/3451022 - loss: 0.035544 val_loss: 0.035263	recall: 0.526498 precision: 0.910359
epoch-2 step 579200/3451022 - loss: 0.043278 val_loss: 0.049935	recall: 0.510248 precision: 0.900952
epoch-2 step 579300/3451022 - loss: 0.035887 val_loss: 0.039218	recall: 0.507743 precision: 0.918000
epoch-2 step 579400/3451022 - loss: 0.039078 val_loss: 0.035562	recall: 0.524972 precision: 0.887430
epoch-2 step 579500/3451022 - loss: 0.036764 val_loss: 0.034379	recall: 0.509719 precision: 0.905950
epoch-2 step 579600/3451022 - loss: 0.035066 val_loss: 0.039375	recall: 0.503304 precision: 0.899606
epoch-2 step 579700/3451022 - loss: 0.036366 val_loss: 0.037715	recall: 0.502640 precision: 0.908397
epoch-2 step 579800/3451022 - loss: 0.038278 val_loss: 0.034676	recall: 0.516484 precision: 0.907336
epoch-2 step 579900/3451022 - loss: 0.035068 val_loss: 0.040857	recall: 0.492585 precision: 0.889101
epoch-2 step 580000/3451022 - loss: 0.035343 val_loss: 0.040366	recall: 0.530922 precision: 0.886940

checkpoint saved

epoch-2 step 580100/3451022 - loss: 0.040806 val_loss: 0.036303	recall: 0.502691 precision: 0.908560

model exported!

epoch-2 step 580200/3451022 - loss: 0.036294 val_loss: 0.034524	recall: 0.543527 precision: 0.917137
epoch-2 step 580300/3451022 - loss: 0.036908 val_loss: 0.039493	recall: 0.516347 precision: 0.887597
epoch-2 step 580400/3451022 - loss: 0.034696 val_loss: 0.036191	recall: 0.504202 precision: 0.928433
epoch-2 step 580500/3451022 - loss: 0.036196 val_loss: 0.034932	recall: 0.512009 precision: 0.917808
epoch-2 step 580600/3451022 - loss: 0.034872 val_loss: 0.036009	recall: 0.489669 precision: 0.906310
epoch-2 step 580700/3451022 - loss: 0.034229 val_loss: 0.035405	recall: 0.543430 precision: 0.922495
epoch-2 step 580800/3451022 - loss: 0.037959 val_loss: 0.039135	recall: 0.492693 precision: 0.911197
epoch-2 step 580900/3451022 - loss: 0.038870 val_loss: 0.034638	recall: 0.505319 precision: 0.925926
epoch-2 step 581000/3451022 - loss: 0.039185 val_loss: 0.035749	recall: 0.497332 precision: 0.901354

checkpoint saved

epoch-2 step 581100/3451022 - loss: 0.040081 val_loss: 0.036472	recall: 0.532453 precision: 0.921905
epoch-2 step 581200/3451022 - loss: 0.036101 val_loss: 0.037829	recall: 0.513843 precision: 0.911591
epoch-2 step 581300/3451022 - loss: 0.042861 val_loss: 0.038857	recall: 0.544444 precision: 0.935115
epoch-2 step 581400/3451022 - loss: 0.036341 val_loss: 0.043377	recall: 0.500000 precision: 0.904135
epoch-2 step 581500/3451022 - loss: 0.037059 val_loss: 0.035022	recall: 0.542793 precision: 0.943249
epoch-2 step 581600/3451022 - loss: 0.040414 val_loss: 0.048598	recall: 0.502703 precision: 0.902913
epoch-2 step 581700/3451022 - loss: 0.034606 val_loss: 0.034409	recall: 0.549708 precision: 0.900383
epoch-2 step 581800/3451022 - loss: 0.035330 val_loss: 0.036825	recall: 0.497291 precision: 0.892996
epoch-2 step 581900/3451022 - loss: 0.035729 val_loss: 0.035503	recall: 0.496809 precision: 0.882798
epoch-2 step 582000/3451022 - loss: 0.036071 val_loss: 0.034453	recall: 0.488268 precision: 0.861933

checkpoint saved

epoch-2 step 582100/3451022 - loss: 0.039517 val_loss: 0.035900	recall: 0.547977 precision: 0.897727

model exported!

epoch-2 step 582200/3451022 - loss: 0.047063 val_loss: 0.035055	recall: 0.533561 precision: 0.898467
epoch-2 step 582300/3451022 - loss: 0.035473 val_loss: 0.034463	recall: 0.523497 precision: 0.912381
epoch-2 step 582400/3451022 - loss: 0.034439 val_loss: 0.034425	recall: 0.485961 precision: 0.862069
epoch-2 step 582500/3451022 - loss: 0.045267 val_loss: 0.036846	recall: 0.531250 precision: 0.931507
epoch-2 step 582600/3451022 - loss: 0.037423 val_loss: 0.035246	recall: 0.515152 precision: 0.900000
epoch-2 step 582700/3451022 - loss: 0.039811 val_loss: 0.036121	recall: 0.514925 precision: 0.914773
epoch-2 step 582800/3451022 - loss: 0.036585 val_loss: 0.036836	recall: 0.571098 precision: 0.926829
epoch-2 step 582900/3451022 - loss: 0.036930 val_loss: 0.035160	recall: 0.514444 precision: 0.892100
epoch-2 step 583000/3451022 - loss: 0.053177 val_loss: 0.040727	recall: 0.521095 precision: 0.894325

checkpoint saved

epoch-2 step 583100/3451022 - loss: 0.036410 val_loss: 0.035351	recall: 0.517799 precision: 0.898876
epoch-2 step 583200/3451022 - loss: 0.036776 val_loss: 0.036896	recall: 0.512486 precision: 0.897338
epoch-2 step 583300/3451022 - loss: 0.034320 val_loss: 0.034850	recall: 0.514501 precision: 0.890335
epoch-2 step 583400/3451022 - loss: 0.037724 val_loss: 0.037249	recall: 0.521984 precision: 0.920477
epoch-2 step 583500/3451022 - loss: 0.039940 val_loss: 0.036405	recall: 0.513598 precision: 0.924670
epoch-2 step 583600/3451022 - loss: 0.036394 val_loss: 0.034672	recall: 0.563892 precision: 0.916190
epoch-2 step 583700/3451022 - loss: 0.036843 val_loss: 0.037283	recall: 0.523702 precision: 0.922465
epoch-2 step 583800/3451022 - loss: 0.035087 val_loss: 0.044380	recall: 0.509351 precision: 0.899029
epoch-2 step 583900/3451022 - loss: 0.035994 val_loss: 0.035232	recall: 0.500539 precision: 0.904483
epoch-2 step 584000/3451022 - loss: 0.035709 val_loss: 0.035420	recall: 0.527991 precision: 0.921456

checkpoint saved

epoch-2 step 584100/3451022 - loss: 0.034157 val_loss: 0.034670	recall: 0.526726 precision: 0.906130

model exported!

epoch-2 step 584200/3451022 - loss: 0.039733 val_loss: 0.039987	recall: 0.498324 precision: 0.892000
epoch-2 step 584300/3451022 - loss: 0.047584 val_loss: 0.042695	recall: 0.515676 precision: 0.891589
epoch-2 step 584400/3451022 - loss: 0.035539 val_loss: 0.037058	recall: 0.528446 precision: 0.918251
epoch-2 step 584500/3451022 - loss: 0.034395 val_loss: 0.038480	recall: 0.515217 precision: 0.915058
epoch-2 step 584600/3451022 - loss: 0.044542 val_loss: 0.040946	recall: 0.546275 precision: 0.914934
epoch-2 step 584700/3451022 - loss: 0.036730 val_loss: 0.037638	recall: 0.503751 precision: 0.917969
epoch-2 step 584800/3451022 - loss: 0.037207 val_loss: 0.035115	recall: 0.526316 precision: 0.907336
epoch-2 step 584900/3451022 - loss: 0.036742 val_loss: 0.040730	recall: 0.488673 precision: 0.881323
epoch-2 step 585000/3451022 - loss: 0.040748 val_loss: 0.035808	recall: 0.517203 precision: 0.901354

checkpoint saved

epoch-2 step 585100/3451022 - loss: 0.035310 val_loss: 0.035021	recall: 0.531250 precision: 0.901768
epoch-2 step 585200/3451022 - loss: 0.036638 val_loss: 0.035348	recall: 0.539933 precision: 0.892193
epoch-2 step 585300/3451022 - loss: 0.036798 val_loss: 0.034950	recall: 0.503759 precision: 0.923228
epoch-2 step 585400/3451022 - loss: 0.036025 val_loss: 0.037197	recall: 0.516977 precision: 0.900763
epoch-2 step 585500/3451022 - loss: 0.034687 val_loss: 0.035490	recall: 0.507345 precision: 0.894422
epoch-2 step 585600/3451022 - loss: 0.034641 val_loss: 0.034425	recall: 0.516165 precision: 0.902534
epoch-2 step 585700/3451022 - loss: 0.044275 val_loss: 0.036201	recall: 0.522173 precision: 0.898855
epoch-2 step 585800/3451022 - loss: 0.040365 val_loss: 0.034613	recall: 0.507642 precision: 0.908203
epoch-2 step 585900/3451022 - loss: 0.039155 val_loss: 0.035114	recall: 0.500000 precision: 0.895349
epoch-2 step 586000/3451022 - loss: 0.035310 val_loss: 0.035208	recall: 0.538043 precision: 0.920074

checkpoint saved

epoch-2 step 586100/3451022 - loss: 0.036745 val_loss: 0.036474	recall: 0.528879 precision: 0.906796

model exported!

epoch-2 step 586200/3451022 - loss: 0.035869 val_loss: 0.039493	recall: 0.507263 precision: 0.890196
epoch-2 step 586300/3451022 - loss: 0.039897 val_loss: 0.034671	recall: 0.519231 precision: 0.894737
epoch-2 step 586400/3451022 - loss: 0.055399 val_loss: 0.035820	recall: 0.547192 precision: 0.910537
epoch-2 step 586500/3451022 - loss: 0.035744 val_loss: 0.037575	recall: 0.538037 precision: 0.917293
epoch-2 step 586600/3451022 - loss: 0.037021 val_loss: 0.043142	recall: 0.520742 precision: 0.915547
epoch-2 step 586700/3451022 - loss: 0.037693 val_loss: 0.034494	recall: 0.498945 precision: 0.916667
epoch-2 step 586800/3451022 - loss: 0.034961 val_loss: 0.035687	recall: 0.526136 precision: 0.918651
epoch-2 step 586900/3451022 - loss: 0.035955 val_loss: 0.034945	recall: 0.505435 precision: 0.904669
epoch-2 step 587000/3451022 - loss: 0.035055 val_loss: 0.037827	recall: 0.518436 precision: 0.899225

checkpoint saved

epoch-2 step 587100/3451022 - loss: 0.035530 val_loss: 0.035507	recall: 0.548766 precision: 0.917485
epoch-2 step 587200/3451022 - loss: 0.038437 val_loss: 0.034178	recall: 0.521173 precision: 0.926641
epoch-2 step 587300/3451022 - loss: 0.036302 val_loss: 0.034391	recall: 0.532407 precision: 0.896686
epoch-2 step 587400/3451022 - loss: 0.035729 val_loss: 0.035018	recall: 0.548538 precision: 0.912451
epoch-2 step 587500/3451022 - loss: 0.034866 val_loss: 0.038660	recall: 0.506173 precision: 0.893069
epoch-2 step 587600/3451022 - loss: 0.035061 val_loss: 0.038042	recall: 0.524838 precision: 0.906716
epoch-2 step 587700/3451022 - loss: 0.039240 val_loss: 0.038824	recall: 0.533101 precision: 0.892996
epoch-2 step 587800/3451022 - loss: 0.037035 val_loss: 0.039590	recall: 0.536364 precision: 0.880597
epoch-2 step 587900/3451022 - loss: 0.037988 val_loss: 0.035786	recall: 0.512304 precision: 0.901575
epoch-2 step 588000/3451022 - loss: 0.035218 val_loss: 0.035948	recall: 0.503759 precision: 0.895038

checkpoint saved

epoch-2 step 588100/3451022 - loss: 0.038662 val_loss: 0.037000	recall: 0.549376 precision: 0.918406

model exported!

epoch-2 step 588200/3451022 - loss: 0.033791 val_loss: 0.035081	recall: 0.563177 precision: 0.921260
epoch-2 step 588300/3451022 - loss: 0.035580 val_loss: 0.037476	recall: 0.550114 precision: 0.889503
epoch-2 step 588400/3451022 - loss: 0.034074 val_loss: 0.037422	recall: 0.562500 precision: 0.939279
epoch-2 step 588500/3451022 - loss: 0.036321 val_loss: 0.037756	recall: 0.521788 precision: 0.915686
epoch-2 step 588600/3451022 - loss: 0.035694 val_loss: 0.057302	recall: 0.520670 precision: 0.894434
epoch-2 step 588700/3451022 - loss: 0.035935 val_loss: 0.035365	recall: 0.545755 precision: 0.933962
epoch-2 step 588800/3451022 - loss: 0.033961 val_loss: 0.050792	recall: 0.546746 precision: 0.893617
epoch-2 step 588900/3451022 - loss: 0.036247 val_loss: 0.037119	recall: 0.546189 precision: 0.904398
epoch-2 step 589000/3451022 - loss: 0.037053 val_loss: 0.036812	recall: 0.527778 precision: 0.885437

checkpoint saved

epoch-2 step 589100/3451022 - loss: 0.035055 val_loss: 0.036833	recall: 0.555940 precision: 0.912879
epoch-2 step 589200/3451022 - loss: 0.035191 val_loss: 0.033731	recall: 0.531144 precision: 0.905405
epoch-2 step 589300/3451022 - loss: 0.035670 val_loss: 0.038459	recall: 0.539261 precision: 0.894636
epoch-2 step 589400/3451022 - loss: 0.034869 val_loss: 0.035012	recall: 0.531844 precision: 0.903226
epoch-2 step 589500/3451022 - loss: 0.044176 val_loss: 0.034566	recall: 0.501104 precision: 0.883268
epoch-2 step 589600/3451022 - loss: 0.041350 val_loss: 0.036215	recall: 0.549199 precision: 0.898876
epoch-2 step 589700/3451022 - loss: 0.036337 val_loss: 0.034501	recall: 0.534722 precision: 0.895349
epoch-2 step 589800/3451022 - loss: 0.036315 val_loss: 0.035199	recall: 0.483471 precision: 0.900000
epoch-2 step 589900/3451022 - loss: 0.037515 val_loss: 0.036596	recall: 0.475789 precision: 0.898608
epoch-2 step 590000/3451022 - loss: 0.045452 val_loss: 0.040538	recall: 0.493631 precision: 0.895954

checkpoint saved

epoch-2 step 590100/3451022 - loss: 0.034394 val_loss: 0.037418	recall: 0.538117 precision: 0.928433

model exported!

epoch-2 step 590200/3451022 - loss: 0.038805 val_loss: 0.035339	recall: 0.519956 precision: 0.910680
epoch-2 step 590300/3451022 - loss: 0.034179 val_loss: 0.038187	recall: 0.532961 precision: 0.920849
epoch-2 step 590400/3451022 - loss: 0.041564 val_loss: 0.038886	recall: 0.530973 precision: 0.916031
epoch-2 step 590500/3451022 - loss: 0.040121 val_loss: 0.035420	recall: 0.540670 precision: 0.902196
epoch-2 step 590600/3451022 - loss: 0.044252 val_loss: 0.040902	recall: 0.553311 precision: 0.909594
epoch-2 step 590700/3451022 - loss: 0.045162 val_loss: 0.036548	recall: 0.527714 precision: 0.906746
epoch-2 step 590800/3451022 - loss: 0.035309 val_loss: 0.034936	recall: 0.482315 precision: 0.891089
epoch-2 step 590900/3451022 - loss: 0.043776 val_loss: 0.046505	recall: 0.561611 precision: 0.911538
epoch-2 step 591000/3451022 - loss: 0.035384 val_loss: 0.038514	recall: 0.522727 precision: 0.903733

checkpoint saved

epoch-2 step 591100/3451022 - loss: 0.035132 val_loss: 0.035053	recall: 0.512432 precision: 0.899431
epoch-2 step 591200/3451022 - loss: 0.036168 val_loss: 0.040755	recall: 0.519914 precision: 0.902804
epoch-2 step 591300/3451022 - loss: 0.039493 val_loss: 0.035633	recall: 0.542197 precision: 0.889943
epoch-2 step 591400/3451022 - loss: 0.039584 val_loss: 0.044974	recall: 0.516347 precision: 0.870722
epoch-2 step 591500/3451022 - loss: 0.042735 val_loss: 0.034603	recall: 0.521595 precision: 0.909266
epoch-2 step 591600/3451022 - loss: 0.036057 val_loss: 0.035507	recall: 0.551762 precision: 0.941729
epoch-2 step 591700/3451022 - loss: 0.035771 val_loss: 0.036949	recall: 0.509677 precision: 0.887640
epoch-2 step 591800/3451022 - loss: 0.034124 val_loss: 0.036696	recall: 0.529867 precision: 0.917625
epoch-2 step 591900/3451022 - loss: 0.039878 val_loss: 0.034328	recall: 0.502691 precision: 0.922925
epoch-2 step 592000/3451022 - loss: 0.035344 val_loss: 0.040267	recall: 0.500000 precision: 0.904762

checkpoint saved

epoch-2 step 592100/3451022 - loss: 0.035194 val_loss: 0.036163	recall: 0.522173 precision: 0.919922

model exported!

epoch-2 step 592200/3451022 - loss: 0.034835 val_loss: 0.037230	recall: 0.482402 precision: 0.885932
epoch-2 step 592300/3451022 - loss: 0.038684 val_loss: 0.040899	recall: 0.518141 precision: 0.896078
epoch-2 step 592400/3451022 - loss: 0.035155 val_loss: 0.039295	recall: 0.490343 precision: 0.865530
epoch-2 step 592500/3451022 - loss: 0.035364 val_loss: 0.034270	recall: 0.571429 precision: 0.936660
epoch-2 step 592600/3451022 - loss: 0.034987 val_loss: 0.035408	recall: 0.509209 precision: 0.916179
epoch-2 step 592700/3451022 - loss: 0.037183 val_loss: 0.043503	recall: 0.480423 precision: 0.906188
epoch-2 step 592800/3451022 - loss: 0.035419 val_loss: 0.034923	recall: 0.554920 precision: 0.927342
epoch-2 step 592900/3451022 - loss: 0.034505 val_loss: 0.042220	recall: 0.518085 precision: 0.911985
epoch-2 step 593000/3451022 - loss: 0.039945 val_loss: 0.035673	recall: 0.516724 precision: 0.887129

checkpoint saved

epoch-2 step 593100/3451022 - loss: 0.034465 val_loss: 0.033977	recall: 0.508457 precision: 0.889094
epoch-2 step 593200/3451022 - loss: 0.034898 val_loss: 0.035787	recall: 0.537313 precision: 0.898273
epoch-2 step 593300/3451022 - loss: 0.035420 val_loss: 0.038245	recall: 0.488889 precision: 0.905882
epoch-2 step 593400/3451022 - loss: 0.044177 val_loss: 0.050342	recall: 0.513304 precision: 0.918651
epoch-2 step 593500/3451022 - loss: 0.033714 val_loss: 0.034612	recall: 0.506064 precision: 0.889535
epoch-2 step 593600/3451022 - loss: 0.035302 val_loss: 0.035157	recall: 0.521691 precision: 0.893333
epoch-2 step 593700/3451022 - loss: 0.039450 val_loss: 0.042382	recall: 0.529809 precision: 0.900574
epoch-2 step 593800/3451022 - loss: 0.035753 val_loss: 0.036936	recall: 0.511161 precision: 0.899804
epoch-2 step 593900/3451022 - loss: 0.034484 val_loss: 0.034601	recall: 0.541231 precision: 0.882576
epoch-2 step 594000/3451022 - loss: 0.038941 val_loss: 0.034614	recall: 0.498904 precision: 0.899209

checkpoint saved

epoch-2 step 594100/3451022 - loss: 0.036080 val_loss: 0.036449	recall: 0.525796 precision: 0.922929

model exported!

epoch-2 step 594200/3451022 - loss: 0.038909 val_loss: 0.035165	recall: 0.494067 precision: 0.894531
epoch-2 step 594300/3451022 - loss: 0.047807 val_loss: 0.034296	recall: 0.536558 precision: 0.933464
epoch-2 step 594400/3451022 - loss: 0.039633 val_loss: 0.035884	recall: 0.525309 precision: 0.887833
epoch-2 step 594500/3451022 - loss: 0.038716 val_loss: 0.035106	recall: 0.520089 precision: 0.901354
epoch-2 step 594600/3451022 - loss: 0.035294 val_loss: 0.035032	recall: 0.512443 precision: 0.902390
epoch-2 step 594700/3451022 - loss: 0.036398 val_loss: 0.034711	recall: 0.507058 precision: 0.894636
epoch-2 step 594800/3451022 - loss: 0.039733 val_loss: 0.034442	recall: 0.522124 precision: 0.902486
epoch-2 step 594900/3451022 - loss: 0.036636 val_loss: 0.040009	recall: 0.502123 precision: 0.922027
epoch-2 step 595000/3451022 - loss: 0.040088 val_loss: 0.037384	recall: 0.541761 precision: 0.932039

checkpoint saved

epoch-2 step 595100/3451022 - loss: 0.037041 val_loss: 0.035657	recall: 0.531646 precision: 0.904110
epoch-2 step 595200/3451022 - loss: 0.039512 val_loss: 0.035977	recall: 0.557358 precision: 0.916190
epoch-2 step 595300/3451022 - loss: 0.040909 val_loss: 0.047519	recall: 0.507812 precision: 0.895669
epoch-2 step 595400/3451022 - loss: 0.036672 val_loss: 0.036324	recall: 0.525967 precision: 0.899811
epoch-2 step 595500/3451022 - loss: 0.036897 val_loss: 0.040035	recall: 0.519058 precision: 0.893822
epoch-2 step 595600/3451022 - loss: 0.037306 val_loss: 0.039955	recall: 0.533632 precision: 0.896422
epoch-2 step 595700/3451022 - loss: 0.040711 val_loss: 0.052252	recall: 0.536756 precision: 0.903733
epoch-2 step 595800/3451022 - loss: 0.034900 val_loss: 0.035417	recall: 0.529944 precision: 0.901923
epoch-2 step 595900/3451022 - loss: 0.049131 val_loss: 0.036620	recall: 0.514069 precision: 0.920543
epoch-2 step 596000/3451022 - loss: 0.034898 val_loss: 0.034849	recall: 0.535260 precision: 0.924152

checkpoint saved

epoch-2 step 596100/3451022 - loss: 0.034954 val_loss: 0.035302	recall: 0.529010 precision: 0.895954

model exported!

epoch-2 step 596200/3451022 - loss: 0.037316 val_loss: 0.036357	recall: 0.556471 precision: 0.934783
epoch-2 step 596300/3451022 - loss: 0.037011 val_loss: 0.035919	recall: 0.553288 precision: 0.931298
epoch-2 step 596400/3451022 - loss: 0.036139 val_loss: 0.040981	recall: 0.560241 precision: 0.897683
epoch-2 step 596500/3451022 - loss: 0.042497 val_loss: 0.053488	recall: 0.512651 precision: 0.920949
epoch-2 step 596600/3451022 - loss: 0.040691 val_loss: 0.035707	recall: 0.510045 precision: 0.901381
epoch-2 step 596700/3451022 - loss: 0.048544 val_loss: 0.034949	recall: 0.528027 precision: 0.904031
epoch-2 step 596800/3451022 - loss: 0.035215 val_loss: 0.035882	recall: 0.497291 precision: 0.908911
epoch-2 step 596900/3451022 - loss: 0.038524 val_loss: 0.036419	recall: 0.511038 precision: 0.904297
epoch-2 step 597000/3451022 - loss: 0.036483 val_loss: 0.044121	recall: 0.526376 precision: 0.901768

checkpoint saved

epoch-2 step 597100/3451022 - loss: 0.042191 val_loss: 0.039142	recall: 0.518440 precision: 0.916201
epoch-2 step 597200/3451022 - loss: 0.034701 val_loss: 0.035672	recall: 0.520971 precision: 0.911197
epoch-2 step 597300/3451022 - loss: 0.036141 val_loss: 0.041491	recall: 0.506908 precision: 0.901701
epoch-2 step 597400/3451022 - loss: 0.039136 val_loss: 0.034357	recall: 0.518478 precision: 0.898305
epoch-2 step 597500/3451022 - loss: 0.035444 val_loss: 0.045480	recall: 0.553991 precision: 0.909441
epoch-2 step 597600/3451022 - loss: 0.035136 val_loss: 0.035574	recall: 0.501691 precision: 0.888224
epoch-2 step 597700/3451022 - loss: 0.037687 val_loss: 0.034374	recall: 0.513843 precision: 0.895753
epoch-2 step 597800/3451022 - loss: 0.041727 val_loss: 0.035296	recall: 0.533333 precision: 0.882129
epoch-2 step 597900/3451022 - loss: 0.037163 val_loss: 0.037333	recall: 0.511732 precision: 0.921529
epoch-2 step 598000/3451022 - loss: 0.033357 val_loss: 0.034591	recall: 0.522503 precision: 0.908397

checkpoint saved

epoch-2 step 598100/3451022 - loss: 0.043648 val_loss: 0.036875	recall: 0.507345 precision: 0.903421

model exported!

epoch-2 step 598200/3451022 - loss: 0.038585 val_loss: 0.035346	recall: 0.534002 precision: 0.919386
epoch-2 step 598300/3451022 - loss: 0.035808 val_loss: 0.041944	recall: 0.540929 precision: 0.914019
epoch-2 step 598400/3451022 - loss: 0.036017 val_loss: 0.034978	recall: 0.506187 precision: 0.916497
epoch-2 step 598500/3451022 - loss: 0.041678 val_loss: 0.038903	recall: 0.518686 precision: 0.906931
epoch-2 step 598600/3451022 - loss: 0.037425 val_loss: 0.036319	recall: 0.501554 precision: 0.916667
epoch-2 step 598700/3451022 - loss: 0.034763 val_loss: 0.043034	recall: 0.525084 precision: 0.900574
epoch-2 step 598800/3451022 - loss: 0.039413 val_loss: 0.035669	recall: 0.512111 precision: 0.884462
epoch-2 step 598900/3451022 - loss: 0.044749 val_loss: 0.036202	recall: 0.513631 precision: 0.911025
epoch-2 step 599000/3451022 - loss: 0.037204 val_loss: 0.035271	recall: 0.510662 precision: 0.897436

checkpoint saved

epoch-2 step 599100/3451022 - loss: 0.036885 val_loss: 0.034975	recall: 0.534483 precision: 0.904669
epoch-2 step 599200/3451022 - loss: 0.035215 val_loss: 0.033793	recall: 0.505155 precision: 0.875000
epoch-2 step 599300/3451022 - loss: 0.036135 val_loss: 0.037426	recall: 0.531034 precision: 0.904110
epoch-2 step 599400/3451022 - loss: 0.034088 val_loss: 0.034655	recall: 0.487321 precision: 0.894737
epoch-2 step 599500/3451022 - loss: 0.036166 val_loss: 0.035082	recall: 0.524719 precision: 0.921105
epoch-2 step 599600/3451022 - loss: 0.036446 val_loss: 0.034963	recall: 0.544419 precision: 0.908745
epoch-2 step 599700/3451022 - loss: 0.039027 val_loss: 0.034493	recall: 0.525109 precision: 0.907547
epoch-2 step 599800/3451022 - loss: 0.034795 val_loss: 0.046444	recall: 0.516166 precision: 0.897590
epoch-2 step 599900/3451022 - loss: 0.040202 val_loss: 0.036202	recall: 0.521311 precision: 0.917308
epoch-2 step 600000/3451022 - loss: 0.038786 val_loss: 0.036025	recall: 0.548847 precision: 0.925926

checkpoint saved

epoch-2 step 600100/3451022 - loss: 0.038911 val_loss: 0.035017	recall: 0.488445 precision: 0.884030

model exported!

epoch-2 step 600200/3451022 - loss: 0.040419 val_loss: 0.033633	recall: 0.503784 precision: 0.924603
epoch-2 step 600300/3451022 - loss: 0.036317 val_loss: 0.034698	recall: 0.512222 precision: 0.920160
epoch-2 step 600400/3451022 - loss: 0.039360 val_loss: 0.035578	recall: 0.512352 precision: 0.912046
epoch-2 step 600500/3451022 - loss: 0.036604 val_loss: 0.034500	recall: 0.503363 precision: 0.883858
epoch-2 step 600600/3451022 - loss: 0.037470 val_loss: 0.034964	recall: 0.506806 precision: 0.909774
epoch-2 step 600700/3451022 - loss: 0.038593 val_loss: 0.037407	recall: 0.524590 precision: 0.921305
epoch-2 step 600800/3451022 - loss: 0.036989 val_loss: 0.039674	recall: 0.510753 precision: 0.916988
epoch-2 step 600900/3451022 - loss: 0.035478 val_loss: 0.041500	recall: 0.518771 precision: 0.902970
epoch-2 step 601000/3451022 - loss: 0.039086 val_loss: 0.036135	recall: 0.509825 precision: 0.891221

checkpoint saved

epoch-2 step 601100/3451022 - loss: 0.036426 val_loss: 0.039322	recall: 0.519294 precision: 0.902299
epoch-2 step 601200/3451022 - loss: 0.036490 val_loss: 0.034867	recall: 0.518847 precision: 0.905222
epoch-2 step 601300/3451022 - loss: 0.038338 val_loss: 0.037002	recall: 0.519190 precision: 0.931166
epoch-2 step 601400/3451022 - loss: 0.035711 val_loss: 0.035104	recall: 0.526549 precision: 0.920696
epoch-2 step 601500/3451022 - loss: 0.037490 val_loss: 0.039098	recall: 0.481092 precision: 0.892788
epoch-2 step 601600/3451022 - loss: 0.036183 val_loss: 0.036749	recall: 0.529809 precision: 0.914563
epoch-2 step 601700/3451022 - loss: 0.033870 val_loss: 0.034463	recall: 0.514806 precision: 0.895050
epoch-2 step 601800/3451022 - loss: 0.038807 val_loss: 0.035952	recall: 0.545455 precision: 0.906977
epoch-2 step 601900/3451022 - loss: 0.037759 val_loss: 0.059539	recall: 0.508734 precision: 0.899614
epoch-2 step 602000/3451022 - loss: 0.035018 val_loss: 0.039339	recall: 0.503212 precision: 0.881801

checkpoint saved

epoch-2 step 602100/3451022 - loss: 0.037409 val_loss: 0.035674	recall: 0.527991 precision: 0.916190

model exported!

epoch-2 step 602200/3451022 - loss: 0.037460 val_loss: 0.035120	recall: 0.533406 precision: 0.915414
epoch-2 step 602300/3451022 - loss: 0.036236 val_loss: 0.034518	recall: 0.526614 precision: 0.894231
epoch-2 step 602400/3451022 - loss: 0.034183 val_loss: 0.036979	recall: 0.531148 precision: 0.905028
epoch-2 step 602500/3451022 - loss: 0.034934 val_loss: 0.038768	recall: 0.561443 precision: 0.936090
epoch-2 step 602600/3451022 - loss: 0.034940 val_loss: 0.036474	recall: 0.511327 precision: 0.931238
epoch-2 step 602700/3451022 - loss: 0.035054 val_loss: 0.035226	recall: 0.544018 precision: 0.926923
epoch-2 step 602800/3451022 - loss: 0.035775 val_loss: 0.041816	recall: 0.521111 precision: 0.907157
epoch-2 step 602900/3451022 - loss: 0.044553 val_loss: 0.033579	recall: 0.505376 precision: 0.888469
epoch-2 step 603000/3451022 - loss: 0.036588 val_loss: 0.039063	recall: 0.509636 precision: 0.901515

checkpoint saved

epoch-2 step 603100/3451022 - loss: 0.038035 val_loss: 0.036267	recall: 0.521837 precision: 0.871028
epoch-2 step 603200/3451022 - loss: 0.034907 val_loss: 0.035836	recall: 0.516571 precision: 0.895050
epoch-2 step 603300/3451022 - loss: 0.040576 val_loss: 0.042799	recall: 0.526919 precision: 0.894942
epoch-2 step 603400/3451022 - loss: 0.035193 val_loss: 0.039155	recall: 0.545045 precision: 0.913208
epoch-2 step 603500/3451022 - loss: 0.036904 val_loss: 0.039057	recall: 0.535675 precision: 0.917293
epoch-2 step 603600/3451022 - loss: 0.038555 val_loss: 0.035655	recall: 0.541855 precision: 0.921154
epoch-2 step 603700/3451022 - loss: 0.039949 val_loss: 0.033414	recall: 0.490986 precision: 0.892100
epoch-2 step 603800/3451022 - loss: 0.037115 val_loss: 0.041390	recall: 0.497354 precision: 0.905588
epoch-2 step 603900/3451022 - loss: 0.040202 val_loss: 0.041645	recall: 0.514477 precision: 0.888462
epoch-2 step 604000/3451022 - loss: 0.036280 val_loss: 0.036255	recall: 0.540816 precision: 0.933464

checkpoint saved

epoch-2 step 604100/3451022 - loss: 0.034906 val_loss: 0.035289	recall: 0.524554 precision: 0.925197

model exported!

epoch-2 step 604200/3451022 - loss: 0.034236 val_loss: 0.036895	recall: 0.522472 precision: 0.909980
epoch-2 step 604300/3451022 - loss: 0.034551 val_loss: 0.036722	recall: 0.512679 precision: 0.899420
epoch-2 step 604400/3451022 - loss: 0.035646 val_loss: 0.035951	recall: 0.555556 precision: 0.894539
epoch-2 step 604500/3451022 - loss: 0.035442 val_loss: 0.035197	recall: 0.507830 precision: 0.891945
epoch-2 step 604600/3451022 - loss: 0.048211 val_loss: 0.035523	recall: 0.527233 precision: 0.932563
epoch-2 step 604700/3451022 - loss: 0.035775 val_loss: 0.036563	recall: 0.523656 precision: 0.932950
epoch-2 step 604800/3451022 - loss: 0.033842 val_loss: 0.039982	recall: 0.531390 precision: 0.922179
epoch-2 step 604900/3451022 - loss: 0.035987 val_loss: 0.034861	recall: 0.519540 precision: 0.898608
epoch-2 step 605000/3451022 - loss: 0.034593 val_loss: 0.038469	recall: 0.513514 precision: 0.886194

checkpoint saved

epoch-2 step 605100/3451022 - loss: 0.035302 val_loss: 0.034238	recall: 0.520697 precision: 0.926357
epoch-2 step 605200/3451022 - loss: 0.051533 val_loss: 0.036412	recall: 0.511628 precision: 0.920152
epoch-2 step 605300/3451022 - loss: 0.035596 val_loss: 0.039632	recall: 0.531317 precision: 0.906077
epoch-2 step 605400/3451022 - loss: 0.035197 val_loss: 0.040419	recall: 0.502183 precision: 0.910891
epoch-2 step 605500/3451022 - loss: 0.035055 val_loss: 0.035618	recall: 0.515778 precision: 0.877778
epoch-2 step 605600/3451022 - loss: 0.038245 val_loss: 0.034591	recall: 0.525140 precision: 0.898662
epoch-2 step 605700/3451022 - loss: 0.035370 val_loss: 0.035841	recall: 0.509583 precision: 0.886275
epoch-2 step 605800/3451022 - loss: 0.038211 val_loss: 0.040427	recall: 0.553882 precision: 0.908745
epoch-2 step 605900/3451022 - loss: 0.037466 val_loss: 0.036846	recall: 0.500000 precision: 0.884615
epoch-2 step 606000/3451022 - loss: 0.034099 val_loss: 0.035944	recall: 0.505959 precision: 0.908560

checkpoint saved

epoch-2 step 606100/3451022 - loss: 0.035986 val_loss: 0.034902	recall: 0.524229 precision: 0.894737

model exported!

epoch-2 step 606200/3451022 - loss: 0.039225 val_loss: 0.035816	recall: 0.539037 precision: 0.940299
epoch-2 step 606300/3451022 - loss: 0.039035 val_loss: 0.047275	recall: 0.507625 precision: 0.892720
epoch-2 step 606400/3451022 - loss: 0.035486 val_loss: 0.037450	recall: 0.516304 precision: 0.920543
epoch-2 step 606500/3451022 - loss: 0.038667 val_loss: 0.038856	recall: 0.487207 precision: 0.904950
epoch-2 step 606600/3451022 - loss: 0.037100 val_loss: 0.034435	recall: 0.532366 precision: 0.906844
epoch-2 step 606700/3451022 - loss: 0.038989 val_loss: 0.038349	recall: 0.536424 precision: 0.910112
epoch-2 step 606800/3451022 - loss: 0.035510 val_loss: 0.037586	recall: 0.507795 precision: 0.888889
epoch-2 step 606900/3451022 - loss: 0.035279 val_loss: 0.034534	recall: 0.534541 precision: 0.916505
epoch-2 step 607000/3451022 - loss: 0.034379 val_loss: 0.034000	recall: 0.503158 precision: 0.898496

checkpoint saved

epoch-2 step 607100/3451022 - loss: 0.035180 val_loss: 0.035288	recall: 0.529412 precision: 0.914062
epoch-2 step 607200/3451022 - loss: 0.038702 val_loss: 0.034573	recall: 0.492030 precision: 0.863806
epoch-2 step 607300/3451022 - loss: 0.042492 val_loss: 0.042274	recall: 0.520352 precision: 0.922027
epoch-2 step 607400/3451022 - loss: 0.034963 val_loss: 0.035496	recall: 0.508056 precision: 0.906130
epoch-2 step 607500/3451022 - loss: 0.044005 val_loss: 0.035928	recall: 0.538642 precision: 0.903733
epoch-2 step 607600/3451022 - loss: 0.038001 val_loss: 0.035311	recall: 0.527840 precision: 0.908046
epoch-2 step 607700/3451022 - loss: 0.037933 val_loss: 0.042879	recall: 0.495506 precision: 0.907407
epoch-2 step 607800/3451022 - loss: 0.034681 val_loss: 0.039271	recall: 0.529545 precision: 0.889313
epoch-2 step 607900/3451022 - loss: 0.035108 val_loss: 0.036345	recall: 0.536723 precision: 0.933202
epoch-2 step 608000/3451022 - loss: 0.035116 val_loss: 0.035727	recall: 0.511803 precision: 0.894934

checkpoint saved

epoch-2 step 608100/3451022 - loss: 0.036195 val_loss: 0.035008	recall: 0.510734 precision: 0.902196

model exported!

epoch-2 step 608200/3451022 - loss: 0.035825 val_loss: 0.037317	recall: 0.511475 precision: 0.903475
epoch-2 step 608300/3451022 - loss: 0.041045 val_loss: 0.034160	recall: 0.541619 precision: 0.904762
epoch-2 step 608400/3451022 - loss: 0.033694 val_loss: 0.034909	recall: 0.523969 precision: 0.919765
epoch-2 step 608500/3451022 - loss: 0.037188 val_loss: 0.036135	recall: 0.537297 precision: 0.910256
epoch-2 step 608600/3451022 - loss: 0.044673 val_loss: 0.041995	recall: 0.536313 precision: 0.910816
epoch-2 step 608700/3451022 - loss: 0.035781 val_loss: 0.034028	recall: 0.548533 precision: 0.913534
epoch-2 step 608800/3451022 - loss: 0.038802 val_loss: 0.035855	recall: 0.520045 precision: 0.921105
epoch-2 step 608900/3451022 - loss: 0.036488 val_loss: 0.038927	recall: 0.508639 precision: 0.916342
epoch-2 step 609000/3451022 - loss: 0.041352 val_loss: 0.036638	recall: 0.509657 precision: 0.924125

checkpoint saved

epoch-2 step 609100/3451022 - loss: 0.035771 val_loss: 0.035035	recall: 0.503817 precision: 0.878327
epoch-2 step 609200/3451022 - loss: 0.038904 val_loss: 0.036212	recall: 0.538551 precision: 0.927565
epoch-2 step 609300/3451022 - loss: 0.048220 val_loss: 0.043237	recall: 0.527253 precision: 0.890977
epoch-2 step 609400/3451022 - loss: 0.034283 val_loss: 0.035212	recall: 0.517970 precision: 0.931559
epoch-2 step 609500/3451022 - loss: 0.035245 val_loss: 0.036639	recall: 0.510965 precision: 0.915521
epoch-2 step 609600/3451022 - loss: 0.039873 val_loss: 0.033713	recall: 0.518947 precision: 0.911275
epoch-2 step 609700/3451022 - loss: 0.035674 val_loss: 0.037069	recall: 0.525000 precision: 0.901119
epoch-2 step 609800/3451022 - loss: 0.038372 val_loss: 0.038270	recall: 0.517514 precision: 0.896282
epoch-2 step 609900/3451022 - loss: 0.039983 val_loss: 0.034293	recall: 0.528814 precision: 0.908738
epoch-2 step 610000/3451022 - loss: 0.035634 val_loss: 0.036527	recall: 0.532895 precision: 0.913534

checkpoint saved

epoch-2 step 610100/3451022 - loss: 0.037997 val_loss: 0.041177	recall: 0.525057 precision: 0.920160

model exported!

epoch-2 step 610200/3451022 - loss: 0.035463 val_loss: 0.044956	recall: 0.515521 precision: 0.889101
epoch-2 step 610300/3451022 - loss: 0.034363 val_loss: 0.035452	recall: 0.497821 precision: 0.889105
epoch-2 step 610400/3451022 - loss: 0.040724 val_loss: 0.041629	recall: 0.490281 precision: 0.895464
epoch-2 step 610500/3451022 - loss: 0.037020 val_loss: 0.035787	recall: 0.514786 precision: 0.896947
epoch-2 step 610600/3451022 - loss: 0.036387 val_loss: 0.037645	recall: 0.526018 precision: 0.908203
epoch-2 step 610700/3451022 - loss: 0.035348 val_loss: 0.035300	recall: 0.522293 precision: 0.921348
epoch-2 step 610800/3451022 - loss: 0.041319 val_loss: 0.035500	recall: 0.501574 precision: 0.898496
epoch-2 step 610900/3451022 - loss: 0.040058 val_loss: 0.037122	recall: 0.479876 precision: 0.885714
epoch-2 step 611000/3451022 - loss: 0.035142 val_loss: 0.034561	recall: 0.504813 precision: 0.925490

checkpoint saved

epoch-2 step 611100/3451022 - loss: 0.036954 val_loss: 0.036013	recall: 0.495717 precision: 0.922311
epoch-2 step 611200/3451022 - loss: 0.036736 val_loss: 0.035049	recall: 0.514722 precision: 0.914729
epoch-2 step 611300/3451022 - loss: 0.035801 val_loss: 0.035943	recall: 0.520833 precision: 0.904762
epoch-2 step 611400/3451022 - loss: 0.049850 val_loss: 0.035444	recall: 0.523707 precision: 0.940039
epoch-2 step 611500/3451022 - loss: 0.034371 val_loss: 0.035809	recall: 0.511111 precision: 0.914513
epoch-2 step 611600/3451022 - loss: 0.036008 val_loss: 0.034089	recall: 0.510941 precision: 0.913894
epoch-2 step 611700/3451022 - loss: 0.036922 val_loss: 0.036786	recall: 0.541958 precision: 0.911765
epoch-2 step 611800/3451022 - loss: 0.034373 val_loss: 0.035834	recall: 0.545147 precision: 0.913043
epoch-2 step 611900/3451022 - loss: 0.035870 val_loss: 0.043835	recall: 0.515812 precision: 0.911368
epoch-2 step 612000/3451022 - loss: 0.036172 val_loss: 0.042796	recall: 0.511983 precision: 0.928854

checkpoint saved

epoch-2 step 612100/3451022 - loss: 0.039764 val_loss: 0.039072	recall: 0.517241 precision: 0.895522

model exported!

epoch-2 step 612200/3451022 - loss: 0.034443 val_loss: 0.035149	recall: 0.509648 precision: 0.880392
epoch-2 step 612300/3451022 - loss: 0.038016 val_loss: 0.037420	recall: 0.510204 precision: 0.911708
epoch-2 step 612400/3451022 - loss: 0.038655 val_loss: 0.040231	recall: 0.492754 precision: 0.908397
epoch-2 step 612500/3451022 - loss: 0.040097 val_loss: 0.039356	recall: 0.511918 precision: 0.911111
epoch-2 step 612600/3451022 - loss: 0.039766 val_loss: 0.034428	recall: 0.542099 precision: 0.910853
epoch-2 step 612700/3451022 - loss: 0.039299 val_loss: 0.040567	recall: 0.519318 precision: 0.890838
epoch-2 step 612800/3451022 - loss: 0.035664 val_loss: 0.035383	recall: 0.533851 precision: 0.930368
epoch-2 step 612900/3451022 - loss: 0.036248 val_loss: 0.040202	recall: 0.533333 precision: 0.910180
epoch-2 step 613000/3451022 - loss: 0.036632 val_loss: 0.037262	recall: 0.542952 precision: 0.921495

checkpoint saved

epoch-2 step 613100/3451022 - loss: 0.036476 val_loss: 0.038676	recall: 0.528736 precision: 0.907298
epoch-2 step 613200/3451022 - loss: 0.035510 val_loss: 0.041062	recall: 0.562044 precision: 0.911243
epoch-2 step 613300/3451022 - loss: 0.037375 val_loss: 0.036783	recall: 0.545872 precision: 0.915385
epoch-2 step 613400/3451022 - loss: 0.037937 val_loss: 0.038212	recall: 0.558324 precision: 0.912963
epoch-2 step 613500/3451022 - loss: 0.037752 val_loss: 0.038582	recall: 0.530973 precision: 0.898876
epoch-2 step 613600/3451022 - loss: 0.034601 val_loss: 0.033719	recall: 0.510369 precision: 0.887776
epoch-2 step 613700/3451022 - loss: 0.034468 val_loss: 0.035431	recall: 0.520000 precision: 0.917647
epoch-2 step 613800/3451022 - loss: 0.037854 val_loss: 0.038214	recall: 0.542237 precision: 0.899621
epoch-2 step 613900/3451022 - loss: 0.038424 val_loss: 0.039471	recall: 0.505946 precision: 0.908738
epoch-2 step 614000/3451022 - loss: 0.051755 val_loss: 0.035327	recall: 0.533482 precision: 0.935421

checkpoint saved

epoch-2 step 614100/3451022 - loss: 0.034801 val_loss: 0.033892	recall: 0.556713 precision: 0.914449

model exported!

epoch-2 step 614200/3451022 - loss: 0.038412 val_loss: 0.041978	recall: 0.527421 precision: 0.875969
epoch-2 step 614300/3451022 - loss: 0.034569 val_loss: 0.037943	recall: 0.552660 precision: 0.920434
epoch-2 step 614400/3451022 - loss: 0.035466 val_loss: 0.036714	recall: 0.530067 precision: 0.920696
epoch-2 step 614500/3451022 - loss: 0.036859 val_loss: 0.035098	recall: 0.494067 precision: 0.899804
epoch-2 step 614600/3451022 - loss: 0.038556 val_loss: 0.035234	recall: 0.511706 precision: 0.901768
epoch-2 step 614700/3451022 - loss: 0.036996 val_loss: 0.036095	recall: 0.489083 precision: 0.896000
epoch-2 step 614800/3451022 - loss: 0.035051 val_loss: 0.034664	recall: 0.514806 precision: 0.888016
epoch-2 step 614900/3451022 - loss: 0.034639 val_loss: 0.034280	recall: 0.536501 precision: 0.926000
epoch-2 step 615000/3451022 - loss: 0.034822 val_loss: 0.035831	recall: 0.536748 precision: 0.909434

checkpoint saved

epoch-2 step 615100/3451022 - loss: 0.035215 val_loss: 0.036231	recall: 0.525330 precision: 0.919075
epoch-2 step 615200/3451022 - loss: 0.035857 val_loss: 0.034440	recall: 0.541520 precision: 0.902534
epoch-2 step 615300/3451022 - loss: 0.036867 val_loss: 0.035549	recall: 0.504484 precision: 0.909091
epoch-2 step 615400/3451022 - loss: 0.036395 val_loss: 0.034300	recall: 0.508287 precision: 0.905512
epoch-2 step 615500/3451022 - loss: 0.036072 val_loss: 0.035702	recall: 0.513015 precision: 0.914894
epoch-2 step 615600/3451022 - loss: 0.039426 val_loss: 0.042683	recall: 0.521552 precision: 0.932563
epoch-2 step 615700/3451022 - loss: 0.037590 val_loss: 0.038618	recall: 0.512432 precision: 0.899431
epoch-2 step 615800/3451022 - loss: 0.035010 val_loss: 0.034720	recall: 0.500541 precision: 0.902534
epoch-2 step 615900/3451022 - loss: 0.035986 val_loss: 0.036016	recall: 0.537705 precision: 0.935361
epoch-2 step 616000/3451022 - loss: 0.035910 val_loss: 0.038753	recall: 0.521219 precision: 0.926499

checkpoint saved

epoch-2 step 616100/3451022 - loss: 0.040506 val_loss: 0.060960	recall: 0.520717 precision: 0.917160

model exported!

epoch-2 step 616200/3451022 - loss: 0.041943 val_loss: 0.034211	recall: 0.518681 precision: 0.899048
epoch-2 step 616300/3451022 - loss: 0.039593 val_loss: 0.036142	recall: 0.511416 precision: 0.888889
epoch-2 step 616400/3451022 - loss: 0.035322 val_loss: 0.042842	recall: 0.536082 precision: 0.921260
epoch-2 step 616500/3451022 - loss: 0.037639 val_loss: 0.035716	recall: 0.522854 precision: 0.914230
epoch-2 step 616600/3451022 - loss: 0.035992 val_loss: 0.034868	recall: 0.539414 precision: 0.921154
epoch-2 step 616700/3451022 - loss: 0.037841 val_loss: 0.051587	recall: 0.513935 precision: 0.895146
epoch-2 step 616800/3451022 - loss: 0.036412 val_loss: 0.035894	recall: 0.513919 precision: 0.909091
epoch-2 step 616900/3451022 - loss: 0.035944 val_loss: 0.041243	recall: 0.524946 precision: 0.908068
epoch-2 step 617000/3451022 - loss: 0.036455 val_loss: 0.034827	recall: 0.531422 precision: 0.925144

checkpoint saved

epoch-2 step 617100/3451022 - loss: 0.035803 val_loss: 0.038302	recall: 0.542662 precision: 0.908571
epoch-2 step 617200/3451022 - loss: 0.037946 val_loss: 0.038252	recall: 0.533030 precision: 0.905222
epoch-2 step 617300/3451022 - loss: 0.035607 val_loss: 0.035984	recall: 0.524076 precision: 0.908738
epoch-2 step 617400/3451022 - loss: 0.036791 val_loss: 0.034882	recall: 0.533800 precision: 0.917836
epoch-2 step 617500/3451022 - loss: 0.034417 val_loss: 0.037632	recall: 0.505959 precision: 0.915686
epoch-2 step 617600/3451022 - loss: 0.034848 val_loss: 0.034602	recall: 0.475052 precision: 0.883946
epoch-2 step 617700/3451022 - loss: 0.041316 val_loss: 0.037226	recall: 0.518764 precision: 0.916179
epoch-2 step 617800/3451022 - loss: 0.038315 val_loss: 0.038110	recall: 0.510504 precision: 0.931034
epoch-2 step 617900/3451022 - loss: 0.034970 val_loss: 0.037283	recall: 0.498364 precision: 0.899606
epoch-2 step 618000/3451022 - loss: 0.034016 val_loss: 0.034933	recall: 0.526432 precision: 0.915709

checkpoint saved

epoch-2 step 618100/3451022 - loss: 0.037466 val_loss: 0.037716	recall: 0.510182 precision: 0.931507

model exported!

epoch-2 step 618200/3451022 - loss: 0.034004 val_loss: 0.034743	recall: 0.530934 precision: 0.911197
epoch-2 step 618300/3451022 - loss: 0.035949 val_loss: 0.038088	recall: 0.531422 precision: 0.912879
epoch-2 step 618400/3451022 - loss: 0.035706 val_loss: 0.040241	recall: 0.494312 precision: 0.895131
epoch-2 step 618500/3451022 - loss: 0.036026 val_loss: 0.036316	recall: 0.545670 precision: 0.916335
epoch-2 step 618600/3451022 - loss: 0.035776 val_loss: 0.035879	recall: 0.498911 precision: 0.908730
epoch-2 step 618700/3451022 - loss: 0.036634 val_loss: 0.044611	recall: 0.529605 precision: 0.911321
epoch-2 step 618800/3451022 - loss: 0.036301 val_loss: 0.040041	recall: 0.543153 precision: 0.914729
epoch-2 step 618900/3451022 - loss: 0.036497 val_loss: 0.034925	recall: 0.515385 precision: 0.862132
epoch-2 step 619000/3451022 - loss: 0.036051 val_loss: 0.040655	recall: 0.537835 precision: 0.905882

checkpoint saved

epoch-2 step 619100/3451022 - loss: 0.039017 val_loss: 0.040251	recall: 0.515556 precision: 0.900971
epoch-2 step 619200/3451022 - loss: 0.035508 val_loss: 0.038731	recall: 0.520501 precision: 0.897839
epoch-2 step 619300/3451022 - loss: 0.035912 val_loss: 0.041396	recall: 0.538813 precision: 0.923679
epoch-2 step 619400/3451022 - loss: 0.038724 val_loss: 0.035405	recall: 0.539535 precision: 0.920635
epoch-2 step 619500/3451022 - loss: 0.037015 val_loss: 0.036202	recall: 0.489947 precision: 0.899029
epoch-2 step 619600/3451022 - loss: 0.035457 val_loss: 0.037177	recall: 0.540873 precision: 0.913043
epoch-2 step 619700/3451022 - loss: 0.039940 val_loss: 0.034472	recall: 0.504494 precision: 0.842402
epoch-2 step 619800/3451022 - loss: 0.034895 val_loss: 0.034849	recall: 0.535179 precision: 0.904483
epoch-2 step 619900/3451022 - loss: 0.037282 val_loss: 0.034670	recall: 0.546746 precision: 0.895349
epoch-2 step 620000/3451022 - loss: 0.033913 val_loss: 0.040297	recall: 0.517660 precision: 0.905405

checkpoint saved

epoch-2 step 620100/3451022 - loss: 0.037688 val_loss: 0.035195	recall: 0.521018 precision: 0.911025

model exported!

epoch-2 step 620200/3451022 - loss: 0.034919 val_loss: 0.039884	recall: 0.559342 precision: 0.931507
epoch-2 step 620300/3451022 - loss: 0.035290 val_loss: 0.034162	recall: 0.523969 precision: 0.919765
epoch-2 step 620400/3451022 - loss: 0.035672 val_loss: 0.040751	recall: 0.524294 precision: 0.900971
epoch-2 step 620500/3451022 - loss: 0.037237 val_loss: 0.041314	recall: 0.542099 precision: 0.914397
epoch-2 step 620600/3451022 - loss: 0.035907 val_loss: 0.035505	recall: 0.527233 precision: 0.928983
epoch-2 step 620700/3451022 - loss: 0.036933 val_loss: 0.035341	recall: 0.527460 precision: 0.911067
epoch-2 step 620800/3451022 - loss: 0.039752 val_loss: 0.039563	recall: 0.498901 precision: 0.886719
epoch-2 step 620900/3451022 - loss: 0.043273 val_loss: 0.035518	recall: 0.521935 precision: 0.900971
epoch-2 step 621000/3451022 - loss: 0.041471 val_loss: 0.035953	recall: 0.517357 precision: 0.891892

checkpoint saved

epoch-2 step 621100/3451022 - loss: 0.035167 val_loss: 0.035694	recall: 0.514130 precision: 0.906130
epoch-2 step 621200/3451022 - loss: 0.035165 val_loss: 0.034154	recall: 0.549944 precision: 0.914179
epoch-2 step 621300/3451022 - loss: 0.034921 val_loss: 0.035512	recall: 0.543820 precision: 0.923664
epoch-2 step 621400/3451022 - loss: 0.035963 val_loss: 0.037355	recall: 0.545346 precision: 0.896078
epoch-2 step 621500/3451022 - loss: 0.038444 val_loss: 0.035604	recall: 0.556933 precision: 0.908088
epoch-2 step 621600/3451022 - loss: 0.037150 val_loss: 0.035687	recall: 0.542182 precision: 0.886029
epoch-2 step 621700/3451022 - loss: 0.036543 val_loss: 0.041038	recall: 0.521689 precision: 0.892578
epoch-2 step 621800/3451022 - loss: 0.046440 val_loss: 0.034487	recall: 0.512222 precision: 0.893411
epoch-2 step 621900/3451022 - loss: 0.034287 val_loss: 0.036427	recall: 0.490176 precision: 0.894340
epoch-2 step 622000/3451022 - loss: 0.037007 val_loss: 0.035062	recall: 0.532669 precision: 0.917939

checkpoint saved

epoch-2 step 622100/3451022 - loss: 0.034784 val_loss: 0.037670	recall: 0.513426 precision: 0.896811

model exported!

epoch-2 step 622200/3451022 - loss: 0.033509 val_loss: 0.035455	recall: 0.509583 precision: 0.879377
epoch-2 step 622300/3451022 - loss: 0.036235 val_loss: 0.060798	recall: 0.516269 precision: 0.899811
epoch-2 step 622400/3451022 - loss: 0.034523 val_loss: 0.034520	recall: 0.526726 precision: 0.907869
epoch-2 step 622500/3451022 - loss: 0.034350 val_loss: 0.035180	recall: 0.521095 precision: 0.883946
epoch-2 step 622600/3451022 - loss: 0.036388 val_loss: 0.035319	recall: 0.510074 precision: 0.894052
epoch-2 step 622700/3451022 - loss: 0.035802 val_loss: 0.034343	recall: 0.506952 precision: 0.896030
epoch-2 step 622800/3451022 - loss: 0.036257 val_loss: 0.034348	recall: 0.517544 precision: 0.904215
epoch-2 step 622900/3451022 - loss: 0.034776 val_loss: 0.034498	recall: 0.535398 precision: 0.941634
epoch-2 step 623000/3451022 - loss: 0.034580 val_loss: 0.039541	recall: 0.481595 precision: 0.925344

checkpoint saved

epoch-2 step 623100/3451022 - loss: 0.035738 val_loss: 0.036329	recall: 0.516496 precision: 0.893701
epoch-2 step 623200/3451022 - loss: 0.034896 val_loss: 0.039018	recall: 0.538895 precision: 0.910476
epoch-2 step 623300/3451022 - loss: 0.035261 val_loss: 0.046119	recall: 0.529609 precision: 0.906310
epoch-2 step 623400/3451022 - loss: 0.035308 val_loss: 0.034766	recall: 0.509868 precision: 0.917160
epoch-2 step 623500/3451022 - loss: 0.036658 val_loss: 0.036070	recall: 0.541096 precision: 0.901141
epoch-2 step 623600/3451022 - loss: 0.033946 val_loss: 0.035916	recall: 0.510846 precision: 0.909266
epoch-2 step 623700/3451022 - loss: 0.037440 val_loss: 0.042606	recall: 0.527650 precision: 0.910537
epoch-2 step 623800/3451022 - loss: 0.036630 val_loss: 0.035907	recall: 0.524664 precision: 0.912281
epoch-2 step 623900/3451022 - loss: 0.035515 val_loss: 0.037278	recall: 0.510337 precision: 0.903661
epoch-2 step 624000/3451022 - loss: 0.035967 val_loss: 0.035318	recall: 0.520352 precision: 0.923828

checkpoint saved

epoch-2 step 624100/3451022 - loss: 0.034933 val_loss: 0.036474	recall: 0.523649 precision: 0.885714

model exported!

epoch-2 step 624200/3451022 - loss: 0.042227 val_loss: 0.039409	recall: 0.540323 precision: 0.914230
epoch-2 step 624300/3451022 - loss: 0.035811 val_loss: 0.041180	recall: 0.512764 precision: 0.911243
epoch-2 step 624400/3451022 - loss: 0.036266 val_loss: 0.034908	recall: 0.551435 precision: 0.909270
epoch-2 step 624500/3451022 - loss: 0.035087 val_loss: 0.040041	recall: 0.534483 precision: 0.899420
epoch-2 step 624600/3451022 - loss: 0.039309 val_loss: 0.051454	recall: 0.505423 precision: 0.904854
epoch-2 step 624700/3451022 - loss: 0.041633 val_loss: 0.036838	recall: 0.539488 precision: 0.913371
epoch-2 step 624800/3451022 - loss: 0.035357 val_loss: 0.037828	recall: 0.509413 precision: 0.900196
epoch-2 step 624900/3451022 - loss: 0.034895 val_loss: 0.034103	recall: 0.538642 precision: 0.914513
epoch-2 step 625000/3451022 - loss: 0.036538 val_loss: 0.039381	recall: 0.527586 precision: 0.887814

checkpoint saved

epoch-2 step 625100/3451022 - loss: 0.045944 val_loss: 0.034941	recall: 0.532328 precision: 0.935606
epoch-2 step 625200/3451022 - loss: 0.034932 val_loss: 0.036011	recall: 0.525309 precision: 0.905039
epoch-2 step 625300/3451022 - loss: 0.034933 val_loss: 0.036529	recall: 0.548533 precision: 0.922201
epoch-2 step 625400/3451022 - loss: 0.042630 val_loss: 0.038635	recall: 0.534214 precision: 0.897177
epoch-2 step 625500/3451022 - loss: 0.036177 val_loss: 0.034277	recall: 0.511312 precision: 0.881092
epoch-2 step 625600/3451022 - loss: 0.037524 val_loss: 0.037141	recall: 0.523112 precision: 0.908023
epoch-2 step 625700/3451022 - loss: 0.039482 val_loss: 0.035726	recall: 0.552846 precision: 0.922481
epoch-2 step 625800/3451022 - loss: 0.039990 val_loss: 0.035642	recall: 0.544289 precision: 0.908560
epoch-2 step 625900/3451022 - loss: 0.034427 val_loss: 0.036811	recall: 0.532058 precision: 0.913127
epoch-2 step 626000/3451022 - loss: 0.034892 val_loss: 0.034793	recall: 0.535714 precision: 0.916031

checkpoint saved

epoch-2 step 626100/3451022 - loss: 0.036394 val_loss: 0.042382	recall: 0.531390 precision: 0.896030

model exported!

epoch-2 step 626200/3451022 - loss: 0.042484 val_loss: 0.037856	recall: 0.499449 precision: 0.889980
epoch-2 step 626300/3451022 - loss: 0.040532 val_loss: 0.034453	recall: 0.557625 precision: 0.885397
epoch-2 step 626400/3451022 - loss: 0.037816 val_loss: 0.038449	recall: 0.525556 precision: 0.914894
epoch-2 step 626500/3451022 - loss: 0.035735 val_loss: 0.040181	recall: 0.546713 precision: 0.906310
epoch-2 step 626600/3451022 - loss: 0.036156 val_loss: 0.036075	recall: 0.536890 precision: 0.907869
epoch-2 step 626700/3451022 - loss: 0.040228 val_loss: 0.039135	recall: 0.539160 precision: 0.897921
epoch-2 step 626800/3451022 - loss: 0.036874 val_loss: 0.041804	recall: 0.527072 precision: 0.896617
epoch-2 step 626900/3451022 - loss: 0.037751 val_loss: 0.036106	recall: 0.539683 precision: 0.922481
epoch-2 step 627000/3451022 - loss: 0.036134 val_loss: 0.034639	recall: 0.547879 precision: 0.905812

checkpoint saved

epoch-2 step 627100/3451022 - loss: 0.036196 val_loss: 0.038110	recall: 0.513684 precision: 0.915572
epoch-2 step 627200/3451022 - loss: 0.035427 val_loss: 0.040441	recall: 0.529736 precision: 0.902439
epoch-2 step 627300/3451022 - loss: 0.033733 val_loss: 0.038255	recall: 0.506792 precision: 0.915094
epoch-2 step 627400/3451022 - loss: 0.038221 val_loss: 0.040770	recall: 0.519868 precision: 0.900574
epoch-2 step 627500/3451022 - loss: 0.038507 val_loss: 0.033944	recall: 0.518059 precision: 0.914343
epoch-2 step 627600/3451022 - loss: 0.036414 val_loss: 0.040700	recall: 0.519553 precision: 0.890805
epoch-2 step 627700/3451022 - loss: 0.039282 val_loss: 0.037335	recall: 0.558087 precision: 0.933333
epoch-2 step 627800/3451022 - loss: 0.034259 val_loss: 0.040896	recall: 0.545559 precision: 0.914894
epoch-2 step 627900/3451022 - loss: 0.038030 val_loss: 0.038373	recall: 0.533792 precision: 0.899614
epoch-2 step 628000/3451022 - loss: 0.034900 val_loss: 0.036514	recall: 0.535308 precision: 0.903846

checkpoint saved

epoch-2 step 628100/3451022 - loss: 0.038702 val_loss: 0.035425	recall: 0.514253 precision: 0.911111

model exported!

epoch-2 step 628200/3451022 - loss: 0.036832 val_loss: 0.036246	recall: 0.502806 precision: 0.888889
epoch-2 step 628300/3451022 - loss: 0.035750 val_loss: 0.034468	recall: 0.517876 precision: 0.921002
epoch-2 step 628400/3451022 - loss: 0.034638 val_loss: 0.042856	recall: 0.534351 precision: 0.929791
epoch-2 step 628500/3451022 - loss: 0.035036 val_loss: 0.041416	recall: 0.515017 precision: 0.893822
epoch-2 step 628600/3451022 - loss: 0.035349 val_loss: 0.040080	recall: 0.529670 precision: 0.923372
epoch-2 step 628700/3451022 - loss: 0.040449 val_loss: 0.036473	recall: 0.526434 precision: 0.898273
epoch-2 step 628800/3451022 - loss: 0.038298 val_loss: 0.036309	recall: 0.521127 precision: 0.900749
epoch-2 step 628900/3451022 - loss: 0.036317 val_loss: 0.038898	recall: 0.518640 precision: 0.897533
epoch-2 step 629000/3451022 - loss: 0.037485 val_loss: 0.036134	recall: 0.519252 precision: 0.904215

checkpoint saved

epoch-2 step 629100/3451022 - loss: 0.042156 val_loss: 0.036134	recall: 0.483701 precision: 0.910891
epoch-2 step 629200/3451022 - loss: 0.037764 val_loss: 0.040008	recall: 0.498403 precision: 0.896552
epoch-2 step 629300/3451022 - loss: 0.034509 val_loss: 0.036068	recall: 0.516484 precision: 0.909091
epoch-2 step 629400/3451022 - loss: 0.039250 val_loss: 0.034791	recall: 0.506479 precision: 0.903661
epoch-2 step 629500/3451022 - loss: 0.038744 val_loss: 0.047991	recall: 0.485567 precision: 0.887006
epoch-2 step 629600/3451022 - loss: 0.035074 val_loss: 0.036875	recall: 0.496718 precision: 0.919028
epoch-2 step 629700/3451022 - loss: 0.036366 val_loss: 0.037977	recall: 0.508161 precision: 0.905039
epoch-2 step 629800/3451022 - loss: 0.038111 val_loss: 0.038358	recall: 0.508039 precision: 0.918605
epoch-2 step 629900/3451022 - loss: 0.046510 val_loss: 0.038656	recall: 0.527072 precision: 0.915547
epoch-2 step 630000/3451022 - loss: 0.035080 val_loss: 0.035342	recall: 0.522272 precision: 0.914230

checkpoint saved

epoch-2 step 630100/3451022 - loss: 0.036910 val_loss: 0.036853	recall: 0.526082 precision: 0.923977

model exported!

epoch-2 step 630200/3451022 - loss: 0.037378 val_loss: 0.035574	recall: 0.508850 precision: 0.916335
epoch-2 step 630300/3451022 - loss: 0.034584 val_loss: 0.035396	recall: 0.516340 precision: 0.901141
epoch-2 step 630400/3451022 - loss: 0.043136 val_loss: 0.037543	recall: 0.518847 precision: 0.894837
epoch-2 step 630500/3451022 - loss: 0.040493 val_loss: 0.035731	recall: 0.498906 precision: 0.885437
epoch-2 step 630600/3451022 - loss: 0.036590 val_loss: 0.038985	recall: 0.534961 precision: 0.918095
epoch-2 step 630700/3451022 - loss: 0.035268 val_loss: 0.043509	recall: 0.525114 precision: 0.891473
epoch-2 step 630800/3451022 - loss: 0.036717 val_loss: 0.038966	recall: 0.534910 precision: 0.896226
epoch-2 step 630900/3451022 - loss: 0.035162 val_loss: 0.040693	recall: 0.531868 precision: 0.920152
epoch-2 step 631000/3451022 - loss: 0.035617 val_loss: 0.035290	recall: 0.551963 precision: 0.928155

checkpoint saved

epoch-2 step 631100/3451022 - loss: 0.052229 val_loss: 0.039014	recall: 0.516421 precision: 0.876923
epoch-2 step 631200/3451022 - loss: 0.036024 val_loss: 0.035678	recall: 0.534463 precision: 0.904398
epoch-2 step 631300/3451022 - loss: 0.037603 val_loss: 0.036268	recall: 0.530303 precision: 0.900735
epoch-2 step 631400/3451022 - loss: 0.034695 val_loss: 0.034595	recall: 0.535874 precision: 0.912214
epoch-2 step 631500/3451022 - loss: 0.034832 val_loss: 0.035874	recall: 0.498918 precision: 0.907480
epoch-2 step 631600/3451022 - loss: 0.035417 val_loss: 0.035660	recall: 0.558891 precision: 0.921905
epoch-2 step 631700/3451022 - loss: 0.035957 val_loss: 0.037552	recall: 0.531868 precision: 0.930769
epoch-2 step 631800/3451022 - loss: 0.037707 val_loss: 0.034869	recall: 0.497207 precision: 0.891784
epoch-2 step 631900/3451022 - loss: 0.035108 val_loss: 0.045183	recall: 0.523482 precision: 0.875479
epoch-2 step 632000/3451022 - loss: 0.034784 val_loss: 0.034279	recall: 0.524571 precision: 0.886100

checkpoint saved

epoch-2 step 632100/3451022 - loss: 0.034908 val_loss: 0.039055	recall: 0.480122 precision: 0.873840

model exported!

epoch-2 step 632200/3451022 - loss: 0.035002 val_loss: 0.035203	recall: 0.495604 precision: 0.905622
epoch-2 step 632300/3451022 - loss: 0.034744 val_loss: 0.036647	recall: 0.515608 precision: 0.917625
epoch-2 step 632400/3451022 - loss: 0.034944 val_loss: 0.035600	recall: 0.484656 precision: 0.892788
epoch-2 step 632500/3451022 - loss: 0.035022 val_loss: 0.035757	recall: 0.526494 precision: 0.894636
epoch-2 step 632600/3451022 - loss: 0.033416 val_loss: 0.034744	recall: 0.502851 precision: 0.883768
epoch-2 step 632700/3451022 - loss: 0.037310 val_loss: 0.035260	recall: 0.498932 precision: 0.896353
epoch-2 step 632800/3451022 - loss: 0.035767 val_loss: 0.034279	recall: 0.524294 precision: 0.909804
epoch-2 step 632900/3451022 - loss: 0.034807 val_loss: 0.042868	recall: 0.517241 precision: 0.904669
epoch-2 step 633000/3451022 - loss: 0.035993 val_loss: 0.039054	recall: 0.522286 precision: 0.880539

checkpoint saved

epoch-2 step 633100/3451022 - loss: 0.037526 val_loss: 0.037909	recall: 0.539150 precision: 0.919847
epoch-2 step 633200/3451022 - loss: 0.038682 val_loss: 0.035391	recall: 0.569544 precision: 0.896226
epoch-2 step 633300/3451022 - loss: 0.049294 val_loss: 0.036783	recall: 0.530934 precision: 0.912959
epoch-2 step 633400/3451022 - loss: 0.035441 val_loss: 0.034951	recall: 0.534730 precision: 0.918561
epoch-2 step 633500/3451022 - loss: 0.036359 val_loss: 0.036457	recall: 0.533958 precision: 0.892368
epoch-2 step 633600/3451022 - loss: 0.037182 val_loss: 0.035431	recall: 0.526796 precision: 0.931452
epoch-2 step 633700/3451022 - loss: 0.034664 val_loss: 0.034600	recall: 0.515660 precision: 0.914683
epoch-2 step 633800/3451022 - loss: 0.039307 val_loss: 0.042935	recall: 0.504255 precision: 0.901141
epoch-2 step 633900/3451022 - loss: 0.035695 val_loss: 0.036941	recall: 0.522876 precision: 0.907372
epoch-2 step 634000/3451022 - loss: 0.034513 val_loss: 0.034412	recall: 0.540839 precision: 0.915888

checkpoint saved

epoch-2 step 634100/3451022 - loss: 0.033810 val_loss: 0.038313	recall: 0.502762 precision: 0.915493

model exported!

epoch-2 step 634200/3451022 - loss: 0.035432 val_loss: 0.034901	recall: 0.554907 precision: 0.916988
epoch-2 step 634300/3451022 - loss: 0.035818 val_loss: 0.041762	recall: 0.549087 precision: 0.919694
epoch-2 step 634400/3451022 - loss: 0.043482 val_loss: 0.038562	recall: 0.535912 precision: 0.927342
epoch-2 step 634500/3451022 - loss: 0.034949 val_loss: 0.036044	recall: 0.516201 precision: 0.890173
epoch-2 step 634600/3451022 - loss: 0.043618 val_loss: 0.035888	recall: 0.517045 precision: 0.917339
epoch-2 step 634700/3451022 - loss: 0.036549 val_loss: 0.035566	recall: 0.534463 precision: 0.920233
epoch-2 step 634800/3451022 - loss: 0.036070 val_loss: 0.037927	recall: 0.528684 precision: 0.902111
epoch-2 step 634900/3451022 - loss: 0.036352 val_loss: 0.041403	recall: 0.518112 precision: 0.918288
epoch-2 step 635000/3451022 - loss: 0.034868 val_loss: 0.034908	recall: 0.519909 precision: 0.908549

checkpoint saved

epoch-2 step 635100/3451022 - loss: 0.042005 val_loss: 0.033933	recall: 0.496809 precision: 0.898077
epoch-2 step 635200/3451022 - loss: 0.037052 val_loss: 0.034416	recall: 0.512959 precision: 0.920543
epoch-2 step 635300/3451022 - loss: 0.034549 val_loss: 0.037608	recall: 0.517204 precision: 0.914449
epoch-2 step 635400/3451022 - loss: 0.037267 val_loss: 0.036575	recall: 0.552480 precision: 0.930097
epoch-2 step 635500/3451022 - loss: 0.042394 val_loss: 0.035097	recall: 0.542793 precision: 0.930502
epoch-2 step 635600/3451022 - loss: 0.037600 val_loss: 0.041226	recall: 0.523112 precision: 0.892308
epoch-2 step 635700/3451022 - loss: 0.035225 val_loss: 0.034099	recall: 0.527412 precision: 0.912713
epoch-2 step 635800/3451022 - loss: 0.038809 val_loss: 0.037285	recall: 0.506682 precision: 0.890411
epoch-2 step 635900/3451022 - loss: 0.035738 val_loss: 0.046129	recall: 0.512379 precision: 0.899811
epoch-2 step 636000/3451022 - loss: 0.036568 val_loss: 0.034548	recall: 0.523915 precision: 0.918129

checkpoint saved

epoch-2 step 636100/3451022 - loss: 0.036959 val_loss: 0.034474	recall: 0.523864 precision: 0.916501

model exported!

epoch-2 step 636200/3451022 - loss: 0.035512 val_loss: 0.035884	recall: 0.516757 precision: 0.907021
epoch-2 step 636300/3451022 - loss: 0.035299 val_loss: 0.038788	recall: 0.526906 precision: 0.916179
epoch-2 step 636400/3451022 - loss: 0.036267 val_loss: 0.035386	recall: 0.522976 precision: 0.901887
epoch-2 step 636500/3451022 - loss: 0.036037 val_loss: 0.037719	recall: 0.518857 precision: 0.909820
epoch-2 step 636600/3451022 - loss: 0.034242 val_loss: 0.038399	recall: 0.556831 precision: 0.918561
epoch-2 step 636700/3451022 - loss: 0.036833 val_loss: 0.034047	recall: 0.531891 precision: 0.908560
epoch-2 step 636800/3451022 - loss: 0.038759 val_loss: 0.040366	recall: 0.534292 precision: 0.923518
epoch-2 step 636900/3451022 - loss: 0.037450 val_loss: 0.036187	recall: 0.492188 precision: 0.882000
epoch-2 step 637000/3451022 - loss: 0.035573 val_loss: 0.040348	recall: 0.527436 precision: 0.919922

checkpoint saved

epoch-2 step 637100/3451022 - loss: 0.042108 val_loss: 0.044455	recall: 0.523395 precision: 0.905838
epoch-2 step 637200/3451022 - loss: 0.040315 val_loss: 0.041381	recall: 0.505411 precision: 0.912109
epoch-2 step 637300/3451022 - loss: 0.035250 val_loss: 0.035220	recall: 0.522440 precision: 0.874759
epoch-2 step 637400/3451022 - loss: 0.035583 val_loss: 0.035509	recall: 0.558517 precision: 0.918095
epoch-2 step 637500/3451022 - loss: 0.034142 val_loss: 0.036031	recall: 0.535955 precision: 0.886617
epoch-2 step 637600/3451022 - loss: 0.037899 val_loss: 0.036726	recall: 0.492408 precision: 0.873077
epoch-2 step 637700/3451022 - loss: 0.041544 val_loss: 0.036075	recall: 0.509189 precision: 0.916342
epoch-2 step 637800/3451022 - loss: 0.036951 val_loss: 0.035221	recall: 0.499459 precision: 0.907662
epoch-2 step 637900/3451022 - loss: 0.035666 val_loss: 0.036461	recall: 0.487234 precision: 0.908730
epoch-2 step 638000/3451022 - loss: 0.033776 val_loss: 0.037333	recall: 0.511931 precision: 0.918288

checkpoint saved

epoch-2 step 638100/3451022 - loss: 0.037222 val_loss: 0.036044	recall: 0.516556 precision: 0.901734

model exported!

epoch-2 step 638200/3451022 - loss: 0.037015 val_loss: 0.033857	recall: 0.534404 precision: 0.930140
epoch-2 step 638300/3451022 - loss: 0.038090 val_loss: 0.052461	recall: 0.520046 precision: 0.909820
epoch-2 step 638400/3451022 - loss: 0.035700 val_loss: 0.038226	recall: 0.528587 precision: 0.929791
epoch-2 step 638500/3451022 - loss: 0.042266 val_loss: 0.040904	recall: 0.511577 precision: 0.904483
epoch-2 step 638600/3451022 - loss: 0.038696 val_loss: 0.039408	recall: 0.486430 precision: 0.884250
epoch-2 step 638700/3451022 - loss: 0.039827 val_loss: 0.036114	recall: 0.522652 precision: 0.918447
epoch-2 step 638800/3451022 - loss: 0.034165 val_loss: 0.037648	recall: 0.520857 precision: 0.905882
epoch-2 step 638900/3451022 - loss: 0.035614 val_loss: 0.040642	recall: 0.518944 precision: 0.881092
epoch-2 step 639000/3451022 - loss: 0.042570 val_loss: 0.034631	recall: 0.536424 precision: 0.929254

checkpoint saved

epoch-2 step 639100/3451022 - loss: 0.038771 val_loss: 0.037968	recall: 0.559538 precision: 0.930769
epoch-2 step 639200/3451022 - loss: 0.034161 val_loss: 0.037550	recall: 0.511278 precision: 0.931507
epoch-2 step 639300/3451022 - loss: 0.038789 val_loss: 0.039313	recall: 0.507642 precision: 0.920792
epoch-2 step 639400/3451022 - loss: 0.034408 val_loss: 0.034014	recall: 0.522652 precision: 0.899240
epoch-2 step 639500/3451022 - loss: 0.035823 val_loss: 0.034804	recall: 0.517723 precision: 0.923372
epoch-2 step 639600/3451022 - loss: 0.034815 val_loss: 0.036664	recall: 0.533702 precision: 0.932432
epoch-2 step 639700/3451022 - loss: 0.037059 val_loss: 0.041925	recall: 0.524294 precision: 0.895753
epoch-2 step 639800/3451022 - loss: 0.038586 val_loss: 0.036795	recall: 0.515429 precision: 0.887795
epoch-2 step 639900/3451022 - loss: 0.037305 val_loss: 0.035941	recall: 0.538117 precision: 0.890538
epoch-2 step 640000/3451022 - loss: 0.033897 val_loss: 0.033916	recall: 0.560894 precision: 0.938318

checkpoint saved

epoch-2 step 640100/3451022 - loss: 0.036210 val_loss: 0.041558	recall: 0.521047 precision: 0.919679

model exported!

epoch-2 step 640200/3451022 - loss: 0.035535 val_loss: 0.036412	recall: 0.492097 precision: 0.908560
epoch-2 step 640300/3451022 - loss: 0.039786 val_loss: 0.034500	recall: 0.512848 precision: 0.898687
epoch-2 step 640400/3451022 - loss: 0.039091 val_loss: 0.036358	recall: 0.542529 precision: 0.900763
epoch-2 step 640500/3451022 - loss: 0.037716 val_loss: 0.034764	recall: 0.537330 precision: 0.911708
epoch-2 step 640600/3451022 - loss: 0.042191 val_loss: 0.035797	recall: 0.510274 precision: 0.912245
epoch-2 step 640700/3451022 - loss: 0.037145 val_loss: 0.043060	recall: 0.500000 precision: 0.898438
epoch-2 step 640800/3451022 - loss: 0.036365 val_loss: 0.035798	recall: 0.537181 precision: 0.920152
epoch-2 step 640900/3451022 - loss: 0.036876 val_loss: 0.039128	recall: 0.538122 precision: 0.896869
epoch-2 step 641000/3451022 - loss: 0.034873 val_loss: 0.037748	recall: 0.552995 precision: 0.917782

checkpoint saved

epoch-2 step 641100/3451022 - loss: 0.035623 val_loss: 0.034636	recall: 0.505543 precision: 0.888889
epoch-2 step 641200/3451022 - loss: 0.036608 val_loss: 0.041409	recall: 0.537415 precision: 0.902857
epoch-2 step 641300/3451022 - loss: 0.043856 val_loss: 0.041179	recall: 0.522602 precision: 0.901141
epoch-2 step 641400/3451022 - loss: 0.035443 val_loss: 0.035304	recall: 0.532131 precision: 0.904215
epoch-2 step 641500/3451022 - loss: 0.038841 val_loss: 0.038731	recall: 0.551522 precision: 0.880374
epoch-2 step 641600/3451022 - loss: 0.034391 val_loss: 0.042919	recall: 0.534169 precision: 0.907157
epoch-2 step 641700/3451022 - loss: 0.034954 val_loss: 0.035391	recall: 0.520000 precision: 0.903475
epoch-2 step 641800/3451022 - loss: 0.034851 val_loss: 0.035594	recall: 0.513483 precision: 0.899606
epoch-2 step 641900/3451022 - loss: 0.039160 val_loss: 0.036127	recall: 0.515289 precision: 0.888672
epoch-2 step 642000/3451022 - loss: 0.034666 val_loss: 0.038016	recall: 0.507726 precision: 0.918164

checkpoint saved

epoch-2 step 642100/3451022 - loss: 0.034437 val_loss: 0.035983	recall: 0.540023 precision: 0.921154

model exported!

epoch-2 step 642200/3451022 - loss: 0.034593 val_loss: 0.034841	recall: 0.542725 precision: 0.903846
epoch-2 step 642300/3451022 - loss: 0.036733 val_loss: 0.036337	recall: 0.531987 precision: 0.911538
epoch-2 step 642400/3451022 - loss: 0.037129 val_loss: 0.036733	recall: 0.486279 precision: 0.878968
epoch-2 step 642500/3451022 - loss: 0.034902 val_loss: 0.038445	recall: 0.504752 precision: 0.905303
epoch-2 step 642600/3451022 - loss: 0.040043 val_loss: 0.038797	recall: 0.510053 precision: 0.923372
epoch-2 step 642700/3451022 - loss: 0.040472 val_loss: 0.034227	recall: 0.501591 precision: 0.902672
epoch-2 step 642800/3451022 - loss: 0.035356 val_loss: 0.033710	recall: 0.516199 precision: 0.881919
epoch-2 step 642900/3451022 - loss: 0.038489 val_loss: 0.037862	recall: 0.543981 precision: 0.905588
epoch-2 step 643000/3451022 - loss: 0.039160 val_loss: 0.036426	recall: 0.551253 precision: 0.906367

checkpoint saved

epoch-2 step 643100/3451022 - loss: 0.041392 val_loss: 0.038424	recall: 0.550228 precision: 0.902622
epoch-2 step 643200/3451022 - loss: 0.038115 val_loss: 0.041079	recall: 0.539977 precision: 0.899614
epoch-2 step 643300/3451022 - loss: 0.034927 val_loss: 0.034987	recall: 0.531603 precision: 0.900574
epoch-2 step 643400/3451022 - loss: 0.043262 val_loss: 0.036214	recall: 0.531868 precision: 0.909774
epoch-2 step 643500/3451022 - loss: 0.033707 val_loss: 0.037045	recall: 0.524515 precision: 0.896686
epoch-2 step 643600/3451022 - loss: 0.042879 val_loss: 0.036349	recall: 0.524444 precision: 0.918288
epoch-2 step 643700/3451022 - loss: 0.035578 val_loss: 0.040608	recall: 0.529944 precision: 0.905405
epoch-2 step 643800/3451022 - loss: 0.033966 val_loss: 0.037295	recall: 0.521595 precision: 0.900574
epoch-2 step 643900/3451022 - loss: 0.043546 val_loss: 0.044772	recall: 0.543700 precision: 0.915870
epoch-2 step 644000/3451022 - loss: 0.042884 val_loss: 0.042966	recall: 0.495745 precision: 0.879245

checkpoint saved

epoch-2 step 644100/3451022 - loss: 0.034130 val_loss: 0.036936	recall: 0.523128 precision: 0.909962

model exported!

epoch-2 step 644200/3451022 - loss: 0.043256 val_loss: 0.038703	recall: 0.528177 precision: 0.929961
epoch-2 step 644300/3451022 - loss: 0.036161 val_loss: 0.035610	recall: 0.532438 precision: 0.911877
epoch-2 step 644400/3451022 - loss: 0.035666 val_loss: 0.041555	recall: 0.519466 precision: 0.889524
epoch-2 step 644500/3451022 - loss: 0.038005 val_loss: 0.034075	recall: 0.509956 precision: 0.884837
epoch-2 step 644600/3451022 - loss: 0.041876 val_loss: 0.033507	recall: 0.532438 precision: 0.899811
epoch-2 step 644700/3451022 - loss: 0.035937 val_loss: 0.036405	recall: 0.556206 precision: 0.924125
epoch-2 step 644800/3451022 - loss: 0.035220 val_loss: 0.035724	recall: 0.525229 precision: 0.896282
epoch-2 step 644900/3451022 - loss: 0.034517 val_loss: 0.033465	recall: 0.555556 precision: 0.904762
epoch-2 step 645000/3451022 - loss: 0.044498 val_loss: 0.034975	recall: 0.521595 precision: 0.927165

checkpoint saved

epoch-2 step 645100/3451022 - loss: 0.034558 val_loss: 0.036684	recall: 0.519101 precision: 0.922156
epoch-2 step 645200/3451022 - loss: 0.036656 val_loss: 0.035295	recall: 0.521111 precision: 0.893333
epoch-2 step 645300/3451022 - loss: 0.033753 val_loss: 0.039172	recall: 0.545249 precision: 0.926923
epoch-2 step 645400/3451022 - loss: 0.034655 val_loss: 0.041707	recall: 0.501597 precision: 0.905769
epoch-2 step 645500/3451022 - loss: 0.035477 val_loss: 0.044008	recall: 0.554176 precision: 0.921201
epoch-2 step 645600/3451022 - loss: 0.041061 val_loss: 0.034834	recall: 0.505155 precision: 0.866405
epoch-2 step 645700/3451022 - loss: 0.038531 val_loss: 0.039426	recall: 0.534699 precision: 0.891841
epoch-2 step 645800/3451022 - loss: 0.035152 val_loss: 0.041958	recall: 0.501647 precision: 0.901381
epoch-2 step 645900/3451022 - loss: 0.035090 val_loss: 0.034387	recall: 0.518640 precision: 0.904398
epoch-2 step 646000/3451022 - loss: 0.036070 val_loss: 0.042669	recall: 0.542469 precision: 0.910646

checkpoint saved

epoch-2 step 646100/3451022 - loss: 0.034610 val_loss: 0.036102	recall: 0.510520 precision: 0.876426

model exported!

epoch-2 step 646200/3451022 - loss: 0.040164 val_loss: 0.035616	recall: 0.550234 precision: 0.911025
epoch-2 step 646300/3451022 - loss: 0.038531 val_loss: 0.036063	recall: 0.528749 precision: 0.925049
epoch-2 step 646400/3451022 - loss: 0.039178 val_loss: 0.037948	recall: 0.505470 precision: 0.907662
epoch-2 step 646500/3451022 - loss: 0.037421 val_loss: 0.033588	recall: 0.526259 precision: 0.926415
epoch-2 step 646600/3451022 - loss: 0.051175 val_loss: 0.035944	recall: 0.511425 precision: 0.898662
epoch-2 step 646700/3451022 - loss: 0.034482 val_loss: 0.035334	recall: 0.501639 precision: 0.896484
epoch-2 step 646800/3451022 - loss: 0.037067 val_loss: 0.037828	recall: 0.529736 precision: 0.895717
epoch-2 step 646900/3451022 - loss: 0.038069 val_loss: 0.041630	recall: 0.523344 precision: 0.919847
epoch-2 step 647000/3451022 - loss: 0.035170 val_loss: 0.035863	recall: 0.529279 precision: 0.914397

checkpoint saved

epoch-2 step 647100/3451022 - loss: 0.042911 val_loss: 0.035601	recall: 0.536866 precision: 0.922772
epoch-2 step 647200/3451022 - loss: 0.039296 val_loss: 0.035638	recall: 0.529143 precision: 0.906067
epoch-2 step 647300/3451022 - loss: 0.044786 val_loss: 0.040443	recall: 0.540839 precision: 0.907407
epoch-2 step 647400/3451022 - loss: 0.036597 val_loss: 0.036975	recall: 0.541057 precision: 0.910985
epoch-2 step 647500/3451022 - loss: 0.038163 val_loss: 0.041034	recall: 0.519694 precision: 0.887850
epoch-2 step 647600/3451022 - loss: 0.040148 val_loss: 0.034922	recall: 0.514989 precision: 0.899065
epoch-2 step 647700/3451022 - loss: 0.035256 val_loss: 0.034515	recall: 0.534937 precision: 0.901544
epoch-2 step 647800/3451022 - loss: 0.034849 val_loss: 0.036847	recall: 0.535513 precision: 0.916988
epoch-2 step 647900/3451022 - loss: 0.036655 val_loss: 0.038306	recall: 0.552601 precision: 0.915709
epoch-2 step 648000/3451022 - loss: 0.038128 val_loss: 0.034770	recall: 0.516930 precision: 0.912351

checkpoint saved

epoch-2 step 648100/3451022 - loss: 0.040154 val_loss: 0.046061	recall: 0.535433 precision: 0.922481

model exported!

epoch-2 step 648200/3451022 - loss: 0.034780 val_loss: 0.035770	recall: 0.519252 precision: 0.929134
epoch-2 step 648300/3451022 - loss: 0.035839 val_loss: 0.036788	recall: 0.505365 precision: 0.916342
epoch-2 step 648400/3451022 - loss: 0.040171 val_loss: 0.035458	recall: 0.523656 precision: 0.918868
epoch-2 step 648500/3451022 - loss: 0.036244 val_loss: 0.034494	recall: 0.504415 precision: 0.915832
epoch-2 step 648600/3451022 - loss: 0.039040 val_loss: 0.045053	recall: 0.522676 precision: 0.916501
epoch-2 step 648700/3451022 - loss: 0.036906 val_loss: 0.035183	recall: 0.514786 precision: 0.870370
epoch-2 step 648800/3451022 - loss: 0.039564 val_loss: 0.043776	recall: 0.509153 precision: 0.882937
epoch-2 step 648900/3451022 - loss: 0.038041 val_loss: 0.035700	recall: 0.494681 precision: 0.901163
epoch-2 step 649000/3451022 - loss: 0.035475 val_loss: 0.036163	recall: 0.521643 precision: 0.912621

checkpoint saved

epoch-2 step 649100/3451022 - loss: 0.035222 val_loss: 0.034343	recall: 0.493392 precision: 0.890656
epoch-2 step 649200/3451022 - loss: 0.036018 val_loss: 0.035441	recall: 0.503282 precision: 0.903733
epoch-2 step 649300/3451022 - loss: 0.035399 val_loss: 0.035673	recall: 0.519729 precision: 0.902153
epoch-2 step 649400/3451022 - loss: 0.035224 val_loss: 0.041777	recall: 0.527523 precision: 0.898438
epoch-2 step 649500/3451022 - loss: 0.034712 val_loss: 0.034895	recall: 0.573581 precision: 0.926966
epoch-2 step 649600/3451022 - loss: 0.047943 val_loss: 0.035730	recall: 0.490731 precision: 0.867052
epoch-2 step 649700/3451022 - loss: 0.039721 val_loss: 0.035367	recall: 0.576968 precision: 0.924670
epoch-2 step 649800/3451022 - loss: 0.037134 val_loss: 0.039614	recall: 0.498915 precision: 0.901961
epoch-2 step 649900/3451022 - loss: 0.036517 val_loss: 0.039484	recall: 0.545151 precision: 0.931429
epoch-2 step 650000/3451022 - loss: 0.043735 val_loss: 0.043438	recall: 0.520131 precision: 0.903592

checkpoint saved

epoch-2 step 650100/3451022 - loss: 0.042686 val_loss: 0.034430	recall: 0.536332 precision: 0.915354

model exported!

epoch-2 step 650200/3451022 - loss: 0.035774 val_loss: 0.035312	recall: 0.502685 precision: 0.908738
epoch-2 step 650300/3451022 - loss: 0.039477 val_loss: 0.037490	recall: 0.515556 precision: 0.888889
epoch-2 step 650400/3451022 - loss: 0.034839 val_loss: 0.038400	recall: 0.549889 precision: 0.939394
epoch-2 step 650500/3451022 - loss: 0.044203 val_loss: 0.035491	recall: 0.564815 precision: 0.925996
epoch-2 step 650600/3451022 - loss: 0.051591 val_loss: 0.035463	recall: 0.507012 precision: 0.903846
epoch-2 step 650700/3451022 - loss: 0.035134 val_loss: 0.034341	recall: 0.532658 precision: 0.909615
epoch-2 step 650800/3451022 - loss: 0.037292 val_loss: 0.035354	recall: 0.518240 precision: 0.902804
epoch-2 step 650900/3451022 - loss: 0.040189 val_loss: 0.038969	recall: 0.523702 precision: 0.890595
epoch-2 step 651000/3451022 - loss: 0.033351 val_loss: 0.033528	recall: 0.540601 precision: 0.940039

checkpoint saved

epoch-2 step 651100/3451022 - loss: 0.035678 val_loss: 0.035667	recall: 0.547929 precision: 0.900778
epoch-2 step 651200/3451022 - loss: 0.034540 val_loss: 0.033736	recall: 0.541570 precision: 0.908915
epoch-2 step 651300/3451022 - loss: 0.034997 val_loss: 0.036607	recall: 0.495604 precision: 0.882583
epoch-2 step 651400/3451022 - loss: 0.034984 val_loss: 0.035297	recall: 0.529801 precision: 0.930233
epoch-2 step 651500/3451022 - loss: 0.038155 val_loss: 0.038041	recall: 0.541424 precision: 0.906250
epoch-2 step 651600/3451022 - loss: 0.035276 val_loss: 0.034525	recall: 0.520000 precision: 0.914062
epoch-2 step 651700/3451022 - loss: 0.039366 val_loss: 0.035961	recall: 0.521991 precision: 0.879142
epoch-2 step 651800/3451022 - loss: 0.035156 val_loss: 0.037508	recall: 0.517435 precision: 0.874525
epoch-2 step 651900/3451022 - loss: 0.037048 val_loss: 0.043617	recall: 0.513083 precision: 0.884314
epoch-2 step 652000/3451022 - loss: 0.036354 val_loss: 0.040358	recall: 0.546999 precision: 0.927063

checkpoint saved

epoch-2 step 652100/3451022 - loss: 0.035227 val_loss: 0.035640	recall: 0.528935 precision: 0.919517

model exported!

epoch-2 step 652200/3451022 - loss: 0.040139 val_loss: 0.034649	recall: 0.527294 precision: 0.893701
epoch-2 step 652300/3451022 - loss: 0.037701 val_loss: 0.035056	recall: 0.553738 precision: 0.913295
epoch-2 step 652400/3451022 - loss: 0.035138 val_loss: 0.035251	recall: 0.521691 precision: 0.896750
epoch-2 step 652500/3451022 - loss: 0.038755 val_loss: 0.036536	recall: 0.540046 precision: 0.900763
epoch-2 step 652600/3451022 - loss: 0.039994 val_loss: 0.034997	recall: 0.516129 precision: 0.923077
epoch-2 step 652700/3451022 - loss: 0.039146 val_loss: 0.035018	recall: 0.506696 precision: 0.900794
epoch-2 step 652800/3451022 - loss: 0.034795 val_loss: 0.040163	recall: 0.498934 precision: 0.917647
epoch-2 step 652900/3451022 - loss: 0.037169 val_loss: 0.037305	recall: 0.510567 precision: 0.894737
epoch-2 step 653000/3451022 - loss: 0.043505 val_loss: 0.036137	recall: 0.528474 precision: 0.909804

checkpoint saved

epoch-2 step 653100/3451022 - loss: 0.035661 val_loss: 0.039087	recall: 0.497225 precision: 0.885375
epoch-2 step 653200/3451022 - loss: 0.035764 val_loss: 0.034948	recall: 0.522995 precision: 0.924386
epoch-2 step 653300/3451022 - loss: 0.040028 val_loss: 0.046713	recall: 0.499478 precision: 0.895131
epoch-2 step 653400/3451022 - loss: 0.036209 val_loss: 0.034826	recall: 0.532658 precision: 0.916667
epoch-2 step 653500/3451022 - loss: 0.036513 val_loss: 0.035765	recall: 0.542141 precision: 0.920696
epoch-2 step 653600/3451022 - loss: 0.035990 val_loss: 0.035762	recall: 0.518519 precision: 0.902394
epoch-2 step 653700/3451022 - loss: 0.038649 val_loss: 0.037923	recall: 0.544931 precision: 0.909615
epoch-2 step 653800/3451022 - loss: 0.034993 val_loss: 0.047490	recall: 0.533947 precision: 0.900971
epoch-2 step 653900/3451022 - loss: 0.036043 val_loss: 0.035005	recall: 0.523862 precision: 0.912959
epoch-2 step 654000/3451022 - loss: 0.037457 val_loss: 0.038832	recall: 0.522173 precision: 0.928994

checkpoint saved

epoch-2 step 654100/3451022 - loss: 0.038802 val_loss: 0.037975	recall: 0.519068 precision: 0.912477

model exported!

epoch-2 step 654200/3451022 - loss: 0.036192 val_loss: 0.038574	recall: 0.503751 precision: 0.917969
epoch-2 step 654300/3451022 - loss: 0.034363 val_loss: 0.037384	recall: 0.539884 precision: 0.934000
epoch-2 step 654400/3451022 - loss: 0.041113 val_loss: 0.036120	recall: 0.494041 precision: 0.906561
epoch-2 step 654500/3451022 - loss: 0.035016 val_loss: 0.037357	recall: 0.488912 precision: 0.916832
epoch-2 step 654600/3451022 - loss: 0.037325 val_loss: 0.039052	recall: 0.514253 precision: 0.884314
epoch-2 step 654700/3451022 - loss: 0.037861 val_loss: 0.036468	recall: 0.532887 precision: 0.903592
epoch-2 step 654800/3451022 - loss: 0.034981 val_loss: 0.034468	recall: 0.543800 precision: 0.921002
epoch-2 step 654900/3451022 - loss: 0.039803 val_loss: 0.040164	recall: 0.521095 precision: 0.896078
epoch-2 step 655000/3451022 - loss: 0.036704 val_loss: 0.037945	recall: 0.577465 precision: 0.928302

checkpoint saved

epoch-2 step 655100/3451022 - loss: 0.048781 val_loss: 0.035067	recall: 0.527877 precision: 0.886454
epoch-2 step 655200/3451022 - loss: 0.040547 val_loss: 0.035410	recall: 0.527902 precision: 0.916667
epoch-2 step 655300/3451022 - loss: 0.037543 val_loss: 0.035108	recall: 0.526674 precision: 0.915187
epoch-2 step 655400/3451022 - loss: 0.035612 val_loss: 0.035399	recall: 0.539286 precision: 0.907816
epoch-2 step 655500/3451022 - loss: 0.034802 val_loss: 0.038430	recall: 0.533947 precision: 0.916996
epoch-2 step 655600/3451022 - loss: 0.036665 val_loss: 0.033839	recall: 0.541520 precision: 0.913215
epoch-2 step 655700/3451022 - loss: 0.035167 val_loss: 0.036452	recall: 0.529083 precision: 0.900952
epoch-2 step 655800/3451022 - loss: 0.037348 val_loss: 0.036033	recall: 0.505820 precision: 0.926357
epoch-2 step 655900/3451022 - loss: 0.035300 val_loss: 0.039722	recall: 0.497758 precision: 0.870588
epoch-2 step 656000/3451022 - loss: 0.036658 val_loss: 0.038213	recall: 0.504972 precision: 0.901381

checkpoint saved

epoch-2 step 656100/3451022 - loss: 0.040760 val_loss: 0.038974	recall: 0.544924 precision: 0.898077

model exported!

epoch-2 step 656200/3451022 - loss: 0.041235 val_loss: 0.035711	recall: 0.526614 precision: 0.911765
epoch-2 step 656300/3451022 - loss: 0.036189 val_loss: 0.039605	recall: 0.523656 precision: 0.918868
epoch-2 step 656400/3451022 - loss: 0.035796 val_loss: 0.035376	recall: 0.519694 precision: 0.899621
epoch-2 step 656500/3451022 - loss: 0.040395 val_loss: 0.039489	recall: 0.547756 precision: 0.926070
epoch-2 step 656600/3451022 - loss: 0.035408 val_loss: 0.038619	recall: 0.479010 precision: 0.882937
epoch-2 step 656700/3451022 - loss: 0.033970 val_loss: 0.034868	recall: 0.524571 precision: 0.921687
epoch-2 step 656800/3451022 - loss: 0.037110 val_loss: 0.042377	recall: 0.535117 precision: 0.888889
epoch-2 step 656900/3451022 - loss: 0.036731 val_loss: 0.038660	recall: 0.572759 precision: 0.931818
epoch-2 step 657000/3451022 - loss: 0.034889 val_loss: 0.043008	recall: 0.535752 precision: 0.912727

checkpoint saved

epoch-2 step 657100/3451022 - loss: 0.036568 val_loss: 0.034051	recall: 0.533557 precision: 0.924419
epoch-2 step 657200/3451022 - loss: 0.037503 val_loss: 0.038757	recall: 0.543601 precision: 0.919540
epoch-2 step 657300/3451022 - loss: 0.043265 val_loss: 0.036235	recall: 0.532328 precision: 0.930320
epoch-2 step 657400/3451022 - loss: 0.034186 val_loss: 0.035154	recall: 0.501691 precision: 0.917526
epoch-2 step 657500/3451022 - loss: 0.036720 val_loss: 0.043564	recall: 0.511086 precision: 0.911067
epoch-2 step 657600/3451022 - loss: 0.035076 val_loss: 0.041744	recall: 0.537946 precision: 0.911153
epoch-2 step 657700/3451022 - loss: 0.034521 val_loss: 0.033779	recall: 0.549618 precision: 0.931608
epoch-2 step 657800/3451022 - loss: 0.036822 val_loss: 0.041093	recall: 0.519001 precision: 0.931774
epoch-2 step 657900/3451022 - loss: 0.038676 val_loss: 0.035150	recall: 0.517089 precision: 0.914230
epoch-2 step 658000/3451022 - loss: 0.040046 val_loss: 0.035131	recall: 0.496888 precision: 0.907197

checkpoint saved

epoch-2 step 658100/3451022 - loss: 0.039338 val_loss: 0.037376	recall: 0.526549 precision: 0.913628

model exported!

epoch-2 step 658200/3451022 - loss: 0.034829 val_loss: 0.036275	recall: 0.535880 precision: 0.907843
epoch-2 step 658300/3451022 - loss: 0.034136 val_loss: 0.035512	recall: 0.506608 precision: 0.901961
epoch-2 step 658400/3451022 - loss: 0.037340 val_loss: 0.039183	recall: 0.528555 precision: 0.899048
epoch-2 step 658500/3451022 - loss: 0.037151 val_loss: 0.034420	recall: 0.500000 precision: 0.892368
epoch-2 step 658600/3451022 - loss: 0.037523 val_loss: 0.036741	recall: 0.520631 precision: 0.871951
epoch-2 step 658700/3451022 - loss: 0.034897 val_loss: 0.037394	recall: 0.515385 precision: 0.908915
epoch-2 step 658800/3451022 - loss: 0.045797 val_loss: 0.040350	recall: 0.511654 precision: 0.925703
epoch-2 step 658900/3451022 - loss: 0.034605 val_loss: 0.041996	recall: 0.538377 precision: 0.924670
epoch-2 step 659000/3451022 - loss: 0.034543 val_loss: 0.034055	recall: 0.545561 precision: 0.913894

checkpoint saved

epoch-2 step 659100/3451022 - loss: 0.036021 val_loss: 0.039687	recall: 0.536830 precision: 0.897388
epoch-2 step 659200/3451022 - loss: 0.036993 val_loss: 0.034687	recall: 0.504292 precision: 0.891841
epoch-2 step 659300/3451022 - loss: 0.038607 val_loss: 0.037812	recall: 0.532511 precision: 0.903042
epoch-2 step 659400/3451022 - loss: 0.040903 val_loss: 0.035947	recall: 0.517954 precision: 0.915385
epoch-2 step 659500/3451022 - loss: 0.036686 val_loss: 0.037637	recall: 0.507058 precision: 0.898077
epoch-2 step 659600/3451022 - loss: 0.035072 val_loss: 0.036277	recall: 0.495298 precision: 0.904580
epoch-2 step 659700/3451022 - loss: 0.036850 val_loss: 0.035315	recall: 0.511727 precision: 0.909091
epoch-2 step 659800/3451022 - loss: 0.038438 val_loss: 0.038745	recall: 0.516447 precision: 0.925344
epoch-2 step 659900/3451022 - loss: 0.034454 val_loss: 0.034290	recall: 0.508734 precision: 0.897881
epoch-2 step 660000/3451022 - loss: 0.036838 val_loss: 0.034300	recall: 0.522703 precision: 0.916667

checkpoint saved

epoch-2 step 660100/3451022 - loss: 0.034208 val_loss: 0.037325	recall: 0.536036 precision: 0.893058

model exported!

epoch-2 step 660200/3451022 - loss: 0.034349 val_loss: 0.037244	recall: 0.536723 precision: 0.911708
epoch-2 step 660300/3451022 - loss: 0.035917 val_loss: 0.043863	recall: 0.544444 precision: 0.914179
epoch-2 step 660400/3451022 - loss: 0.036966 val_loss: 0.036438	recall: 0.520087 precision: 0.915870
epoch-2 step 660500/3451022 - loss: 0.035714 val_loss: 0.039661	recall: 0.522300 precision: 0.874263
epoch-2 step 660600/3451022 - loss: 0.035941 val_loss: 0.035547	recall: 0.558113 precision: 0.918561
epoch-2 step 660700/3451022 - loss: 0.034550 val_loss: 0.037659	recall: 0.552538 precision: 0.910506
epoch-2 step 660800/3451022 - loss: 0.034533 val_loss: 0.035374	recall: 0.513751 precision: 0.876173
epoch-2 step 660900/3451022 - loss: 0.035667 val_loss: 0.035721	recall: 0.525146 precision: 0.905242
epoch-2 step 661000/3451022 - loss: 0.033963 val_loss: 0.034707	recall: 0.532164 precision: 0.890411

checkpoint saved

epoch-2 step 661100/3451022 - loss: 0.036531 val_loss: 0.036493	recall: 0.523973 precision: 0.896484
epoch-2 step 661200/3451022 - loss: 0.036313 val_loss: 0.053428	recall: 0.526835 precision: 0.912713
epoch-2 step 661300/3451022 - loss: 0.060793 val_loss: 0.036859	recall: 0.507970 precision: 0.896811
epoch-2 step 661400/3451022 - loss: 0.036440 val_loss: 0.049624	recall: 0.546821 precision: 0.920233
epoch-2 step 661500/3451022 - loss: 0.035273 val_loss: 0.035280	recall: 0.539339 precision: 0.906130
epoch-2 step 661600/3451022 - loss: 0.035911 val_loss: 0.035518	recall: 0.472000 precision: 0.925490
epoch-2 step 661700/3451022 - loss: 0.036560 val_loss: 0.036562	recall: 0.483804 precision: 0.857407
epoch-2 step 661800/3451022 - loss: 0.035688 val_loss: 0.038658	recall: 0.510293 precision: 0.907514
epoch-2 step 661900/3451022 - loss: 0.039957 val_loss: 0.038808	recall: 0.540571 precision: 0.902672
epoch-2 step 662000/3451022 - loss: 0.038859 val_loss: 0.037652	recall: 0.517084 precision: 0.890196

checkpoint saved

epoch-2 step 662100/3451022 - loss: 0.036260 val_loss: 0.038756	recall: 0.530922 precision: 0.924797

model exported!

epoch-2 step 662200/3451022 - loss: 0.038596 val_loss: 0.034668	recall: 0.486022 precision: 0.886275
epoch-2 step 662300/3451022 - loss: 0.035685 val_loss: 0.035710	recall: 0.516421 precision: 0.887160
epoch-2 step 662400/3451022 - loss: 0.037236 val_loss: 0.036405	recall: 0.484656 precision: 0.914172
epoch-2 step 662500/3451022 - loss: 0.034343 val_loss: 0.034309	recall: 0.538031 precision: 0.935798
epoch-2 step 662600/3451022 - loss: 0.036698 val_loss: 0.035035	recall: 0.516685 precision: 0.914286
epoch-2 step 662700/3451022 - loss: 0.040867 val_loss: 0.035596	recall: 0.529794 precision: 0.933206
epoch-2 step 662800/3451022 - loss: 0.036062 val_loss: 0.034996	recall: 0.505933 precision: 0.907157
epoch-2 step 662900/3451022 - loss: 0.039363 val_loss: 0.035733	recall: 0.507576 precision: 0.916016
epoch-2 step 663000/3451022 - loss: 0.035426 val_loss: 0.041652	recall: 0.524377 precision: 0.932563

checkpoint saved

epoch-2 step 663100/3451022 - loss: 0.040183 val_loss: 0.035309	recall: 0.543632 precision: 0.923848
epoch-2 step 663200/3451022 - loss: 0.035129 val_loss: 0.035260	recall: 0.536476 precision: 0.919231
epoch-2 step 663300/3451022 - loss: 0.036546 val_loss: 0.039549	recall: 0.517660 precision: 0.908915
epoch-2 step 663400/3451022 - loss: 0.037478 val_loss: 0.036351	recall: 0.511931 precision: 0.893939
epoch-2 step 663500/3451022 - loss: 0.038155 val_loss: 0.034912	recall: 0.505656 precision: 0.888668
epoch-2 step 663600/3451022 - loss: 0.035427 val_loss: 0.034632	recall: 0.480256 precision: 0.901804
epoch-2 step 663700/3451022 - loss: 0.034143 val_loss: 0.035084	recall: 0.542393 precision: 0.910331
epoch-2 step 663800/3451022 - loss: 0.035196 val_loss: 0.034816	recall: 0.531080 precision: 0.900185
epoch-2 step 663900/3451022 - loss: 0.042408 val_loss: 0.038674	recall: 0.503842 precision: 0.891262
epoch-2 step 664000/3451022 - loss: 0.035097 val_loss: 0.048202	recall: 0.518797 precision: 0.906191

checkpoint saved

epoch-2 step 664100/3451022 - loss: 0.034068 val_loss: 0.036584	recall: 0.536866 precision: 0.926441

model exported!

epoch-2 step 664200/3451022 - loss: 0.037343 val_loss: 0.037580	recall: 0.516129 precision: 0.916996
epoch-2 step 664300/3451022 - loss: 0.038900 val_loss: 0.034491	recall: 0.517937 precision: 0.888462
epoch-2 step 664400/3451022 - loss: 0.034548 val_loss: 0.038301	recall: 0.542277 precision: 0.919694
epoch-2 step 664500/3451022 - loss: 0.037768 val_loss: 0.038882	recall: 0.539326 precision: 0.923077
epoch-2 step 664600/3451022 - loss: 0.036454 val_loss: 0.054050	recall: 0.531216 precision: 0.918561
epoch-2 step 664700/3451022 - loss: 0.034070 val_loss: 0.035627	recall: 0.498915 precision: 0.903733
epoch-2 step 664800/3451022 - loss: 0.038222 val_loss: 0.035308	recall: 0.539459 precision: 0.939736
epoch-2 step 664900/3451022 - loss: 0.034505 val_loss: 0.039430	recall: 0.566016 precision: 0.912963
epoch-2 step 665000/3451022 - loss: 0.034799 val_loss: 0.036515	recall: 0.561758 precision: 0.899240

checkpoint saved

epoch-2 step 665100/3451022 - loss: 0.035091 val_loss: 0.035089	recall: 0.543023 precision: 0.889524
epoch-2 step 665200/3451022 - loss: 0.034607 val_loss: 0.036943	recall: 0.563549 precision: 0.900383
epoch-2 step 665300/3451022 - loss: 0.034530 val_loss: 0.034701	recall: 0.582742 precision: 0.919776
epoch-2 step 665400/3451022 - loss: 0.035014 val_loss: 0.035033	recall: 0.527273 precision: 0.883810
epoch-2 step 665500/3451022 - loss: 0.037050 val_loss: 0.036187	recall: 0.512623 precision: 0.882798
epoch-2 step 665600/3451022 - loss: 0.035971 val_loss: 0.035435	recall: 0.541150 precision: 0.898876
epoch-2 step 665700/3451022 - loss: 0.042611 val_loss: 0.039907	recall: 0.539443 precision: 0.885714
epoch-2 step 665800/3451022 - loss: 0.041187 val_loss: 0.034401	recall: 0.543938 precision: 0.907236
epoch-2 step 665900/3451022 - loss: 0.038668 val_loss: 0.036875	recall: 0.532184 precision: 0.886973
epoch-2 step 666000/3451022 - loss: 0.034317 val_loss: 0.038272	recall: 0.537399 precision: 0.913894

checkpoint saved

epoch-2 step 666100/3451022 - loss: 0.034269 val_loss: 0.035501	recall: 0.532658 precision: 0.900952

model exported!

epoch-2 step 666200/3451022 - loss: 0.044749 val_loss: 0.035779	recall: 0.540089 precision: 0.920304
epoch-2 step 666300/3451022 - loss: 0.034111 val_loss: 0.041207	recall: 0.501109 precision: 0.877670
epoch-2 step 666400/3451022 - loss: 0.034811 val_loss: 0.036156	recall: 0.552273 precision: 0.906716
epoch-2 step 666500/3451022 - loss: 0.034087 val_loss: 0.036771	recall: 0.511891 precision: 0.909457
epoch-2 step 666600/3451022 - loss: 0.035317 val_loss: 0.034623	recall: 0.531111 precision: 0.922780
epoch-2 step 666700/3451022 - loss: 0.037482 val_loss: 0.040845	recall: 0.527088 precision: 0.912109
epoch-2 step 666800/3451022 - loss: 0.035813 val_loss: 0.036922	recall: 0.509476 precision: 0.875479
epoch-2 step 666900/3451022 - loss: 0.033394 val_loss: 0.035637	recall: 0.513129 precision: 0.889943
epoch-2 step 667000/3451022 - loss: 0.034225 val_loss: 0.036359	recall: 0.517435 precision: 0.927419

checkpoint saved

epoch-2 step 667100/3451022 - loss: 0.035691 val_loss: 0.037837	recall: 0.519438 precision: 0.925000
epoch-2 step 667200/3451022 - loss: 0.035891 val_loss: 0.035658	recall: 0.533776 precision: 0.911153
epoch-2 step 667300/3451022 - loss: 0.034450 val_loss: 0.037457	recall: 0.522026 precision: 0.927593
epoch-2 step 667400/3451022 - loss: 0.037087 val_loss: 0.034656	recall: 0.524775 precision: 0.891013
epoch-2 step 667500/3451022 - loss: 0.035415 val_loss: 0.036601	recall: 0.528129 precision: 0.896686
epoch-2 step 667600/3451022 - loss: 0.035067 val_loss: 0.043311	recall: 0.523438 precision: 0.912451
epoch-2 step 667700/3451022 - loss: 0.036453 val_loss: 0.045765	recall: 0.511551 precision: 0.902913
epoch-2 step 667800/3451022 - loss: 0.039169 val_loss: 0.036153	recall: 0.530187 precision: 0.925287
epoch-2 step 667900/3451022 - loss: 0.041565 val_loss: 0.042347	recall: 0.534503 precision: 0.910359
epoch-2 step 668000/3451022 - loss: 0.036363 val_loss: 0.034222	recall: 0.509518 precision: 0.869981

checkpoint saved

epoch-2 step 668100/3451022 - loss: 0.035985 val_loss: 0.039651	recall: 0.515982 precision: 0.875969

model exported!

epoch-2 step 668200/3451022 - loss: 0.034238 val_loss: 0.036905	recall: 0.527559 precision: 0.919608
epoch-2 step 668300/3451022 - loss: 0.035204 val_loss: 0.035619	recall: 0.499452 precision: 0.883721
epoch-2 step 668400/3451022 - loss: 0.033923 val_loss: 0.033900	recall: 0.529477 precision: 0.894737
epoch-2 step 668500/3451022 - loss: 0.038977 val_loss: 0.034888	recall: 0.487047 precision: 0.912621
epoch-2 step 668600/3451022 - loss: 0.034775 val_loss: 0.035788	recall: 0.547368 precision: 0.900000
epoch-2 step 668700/3451022 - loss: 0.036416 val_loss: 0.037403	recall: 0.543800 precision: 0.903592
epoch-2 step 668800/3451022 - loss: 0.036517 val_loss: 0.035720	recall: 0.514722 precision: 0.907692
epoch-2 step 668900/3451022 - loss: 0.045091 val_loss: 0.035588	recall: 0.508584 precision: 0.906310
epoch-2 step 669000/3451022 - loss: 0.066932 val_loss: 0.035982	recall: 0.528258 precision: 0.885880

checkpoint saved

epoch-2 step 669100/3451022 - loss: 0.037239 val_loss: 0.042445	recall: 0.525253 precision: 0.912281
epoch-2 step 669200/3451022 - loss: 0.035538 val_loss: 0.035924	recall: 0.515358 precision: 0.879612
epoch-2 step 669300/3451022 - loss: 0.035356 val_loss: 0.034753	recall: 0.528814 precision: 0.894837
epoch-2 step 669400/3451022 - loss: 0.034494 val_loss: 0.039252	recall: 0.525683 precision: 0.916190
epoch-2 step 669500/3451022 - loss: 0.035897 val_loss: 0.035800	recall: 0.543280 precision: 0.919075
epoch-2 step 669600/3451022 - loss: 0.034427 val_loss: 0.041486	recall: 0.532397 precision: 0.911275
epoch-2 step 669700/3451022 - loss: 0.040205 val_loss: 0.039407	recall: 0.491189 precision: 0.883168
epoch-2 step 669800/3451022 - loss: 0.039493 val_loss: 0.037135	recall: 0.519780 precision: 0.914894
epoch-2 step 669900/3451022 - loss: 0.036406 val_loss: 0.034623	recall: 0.520624 precision: 0.887833
epoch-2 step 670000/3451022 - loss: 0.035139 val_loss: 0.035854	recall: 0.544101 precision: 0.916988

checkpoint saved

epoch-2 step 670100/3451022 - loss: 0.035455 val_loss: 0.034726	recall: 0.513363 precision: 0.922000

model exported!

epoch-2 step 670200/3451022 - loss: 0.036040 val_loss: 0.036100	recall: 0.512878 precision: 0.912351
epoch-2 step 670300/3451022 - loss: 0.035463 val_loss: 0.035424	recall: 0.529480 precision: 0.889320
epoch-2 step 670400/3451022 - loss: 0.044468 val_loss: 0.039802	recall: 0.500529 precision: 0.892453
epoch-2 step 670500/3451022 - loss: 0.035578 val_loss: 0.035303	recall: 0.512304 precision: 0.905138
epoch-2 step 670600/3451022 - loss: 0.044456 val_loss: 0.034841	recall: 0.493048 precision: 0.891683
epoch-2 step 670700/3451022 - loss: 0.034745 val_loss: 0.036472	recall: 0.502128 precision: 0.918288
epoch-2 step 670800/3451022 - loss: 0.039120 val_loss: 0.036876	recall: 0.512931 precision: 0.908397
epoch-2 step 670900/3451022 - loss: 0.035290 val_loss: 0.037052	recall: 0.537572 precision: 0.928144
epoch-2 step 671000/3451022 - loss: 0.039597 val_loss: 0.038451	recall: 0.554502 precision: 0.900000

checkpoint saved

epoch-2 step 671100/3451022 - loss: 0.035954 val_loss: 0.036532	recall: 0.529210 precision: 0.900585
epoch-2 step 671200/3451022 - loss: 0.037340 val_loss: 0.035901	recall: 0.582126 precision: 0.926923
epoch-2 step 671300/3451022 - loss: 0.039924 val_loss: 0.038222	recall: 0.534132 precision: 0.886680
epoch-2 step 671400/3451022 - loss: 0.034194 val_loss: 0.035382	recall: 0.492257 precision: 0.884692
epoch-2 step 671500/3451022 - loss: 0.037636 val_loss: 0.038987	recall: 0.525404 precision: 0.895669
epoch-2 step 671600/3451022 - loss: 0.035054 val_loss: 0.040773	recall: 0.540387 precision: 0.909962
epoch-2 step 671700/3451022 - loss: 0.035439 val_loss: 0.035657	recall: 0.515251 precision: 0.899240
epoch-2 step 671800/3451022 - loss: 0.033684 val_loss: 0.039043	recall: 0.500548 precision: 0.887379
epoch-2 step 671900/3451022 - loss: 0.037947 val_loss: 0.039655	recall: 0.518559 precision: 0.901328
epoch-2 step 672000/3451022 - loss: 0.037919 val_loss: 0.034770	recall: 0.562430 precision: 0.922509

checkpoint saved

epoch-2 step 672100/3451022 - loss: 0.035333 val_loss: 0.035204	recall: 0.525571 precision: 0.918251

model exported!

epoch-2 step 672200/3451022 - loss: 0.040125 val_loss: 0.036512	recall: 0.515882 precision: 0.898855
epoch-2 step 672300/3451022 - loss: 0.037710 val_loss: 0.035960	recall: 0.533333 precision: 0.895636
epoch-2 step 672400/3451022 - loss: 0.035650 val_loss: 0.035391	recall: 0.545455 precision: 0.929254
epoch-2 step 672500/3451022 - loss: 0.036476 val_loss: 0.046994	recall: 0.529809 precision: 0.902299
epoch-2 step 672600/3451022 - loss: 0.035547 val_loss: 0.039510	recall: 0.554087 precision: 0.905697
epoch-2 step 672700/3451022 - loss: 0.037742 val_loss: 0.035345	recall: 0.527811 precision: 0.899194
epoch-2 step 672800/3451022 - loss: 0.035829 val_loss: 0.041128	recall: 0.527714 precision: 0.908549
epoch-2 step 672900/3451022 - loss: 0.035036 val_loss: 0.039177	recall: 0.532669 precision: 0.937622
epoch-2 step 673000/3451022 - loss: 0.038400 val_loss: 0.037604	recall: 0.536300 precision: 0.910537

checkpoint saved

epoch-2 step 673100/3451022 - loss: 0.035757 val_loss: 0.036549	recall: 0.543919 precision: 0.918251
epoch-2 step 673200/3451022 - loss: 0.038327 val_loss: 0.035247	recall: 0.521437 precision: 0.889328
epoch-2 step 673300/3451022 - loss: 0.036100 val_loss: 0.058904	recall: 0.549828 precision: 0.932039
epoch-2 step 673400/3451022 - loss: 0.035215 val_loss: 0.035472	recall: 0.493989 precision: 0.898608
epoch-2 step 673500/3451022 - loss: 0.037298 val_loss: 0.036641	recall: 0.537671 precision: 0.905769
epoch-2 step 673600/3451022 - loss: 0.035845 val_loss: 0.038919	recall: 0.511062 precision: 0.897087
epoch-2 step 673700/3451022 - loss: 0.038450 val_loss: 0.037004	recall: 0.503425 precision: 0.882000
epoch-2 step 673800/3451022 - loss: 0.037833 val_loss: 0.035450	recall: 0.536047 precision: 0.927565
epoch-2 step 673900/3451022 - loss: 0.035374 val_loss: 0.039439	recall: 0.538547 precision: 0.914611
epoch-2 step 674000/3451022 - loss: 0.036552 val_loss: 0.040463	recall: 0.546296 precision: 0.904215

checkpoint saved

epoch-2 step 674100/3451022 - loss: 0.040284 val_loss: 0.036796	recall: 0.548864 precision: 0.904494

model exported!

epoch-2 step 674200/3451022 - loss: 0.034812 val_loss: 0.035121	recall: 0.519495 precision: 0.893491
epoch-2 step 674300/3451022 - loss: 0.035629 val_loss: 0.034631	recall: 0.533258 precision: 0.920233
epoch-2 step 674400/3451022 - loss: 0.035312 val_loss: 0.035447	recall: 0.496760 precision: 0.898438
epoch-2 step 674500/3451022 - loss: 0.037516 val_loss: 0.039456	recall: 0.527650 precision: 0.865784
epoch-2 step 674600/3451022 - loss: 0.036054 val_loss: 0.037103	recall: 0.542955 precision: 0.904580
epoch-2 step 674700/3451022 - loss: 0.049619 val_loss: 0.036734	recall: 0.564403 precision: 0.914611
epoch-2 step 674800/3451022 - loss: 0.035284 val_loss: 0.035488	recall: 0.526554 precision: 0.904854
epoch-2 step 674900/3451022 - loss: 0.035473 val_loss: 0.035700	recall: 0.500537 precision: 0.899614
epoch-2 step 675000/3451022 - loss: 0.034736 val_loss: 0.035902	recall: 0.504823 precision: 0.912791

checkpoint saved

epoch-2 step 675100/3451022 - loss: 0.042877 val_loss: 0.045766	recall: 0.545055 precision: 0.935849
epoch-2 step 675200/3451022 - loss: 0.036330 val_loss: 0.034369	recall: 0.518223 precision: 0.897436
epoch-2 step 675300/3451022 - loss: 0.038704 val_loss: 0.036403	recall: 0.523649 precision: 0.902913
epoch-2 step 675400/3451022 - loss: 0.035851 val_loss: 0.042840	recall: 0.517321 precision: 0.888889
epoch-2 step 675500/3451022 - loss: 0.039190 val_loss: 0.034904	recall: 0.533485 precision: 0.914397
epoch-2 step 675600/3451022 - loss: 0.035718 val_loss: 0.036501	recall: 0.541667 precision: 0.930368
epoch-2 step 675700/3451022 - loss: 0.046355 val_loss: 0.041379	recall: 0.503378 precision: 0.892216
epoch-2 step 675800/3451022 - loss: 0.037471 val_loss: 0.034257	recall: 0.528446 precision: 0.916509
epoch-2 step 675900/3451022 - loss: 0.035768 val_loss: 0.035950	recall: 0.533257 precision: 0.909980
epoch-2 step 676000/3451022 - loss: 0.035560 val_loss: 0.034003	recall: 0.515487 precision: 0.933868

checkpoint saved

epoch-2 step 676100/3451022 - loss: 0.034841 val_loss: 0.039738	recall: 0.528814 precision: 0.893130

model exported!

epoch-2 step 676200/3451022 - loss: 0.033973 val_loss: 0.043293	recall: 0.508602 precision: 0.914894
epoch-2 step 676300/3451022 - loss: 0.034289 val_loss: 0.036668	recall: 0.538961 precision: 0.917127
epoch-2 step 676400/3451022 - loss: 0.037509 val_loss: 0.034718	recall: 0.520225 precision: 0.886973
epoch-2 step 676500/3451022 - loss: 0.040033 val_loss: 0.046419	recall: 0.502812 precision: 0.890438
epoch-2 step 676600/3451022 - loss: 0.035617 val_loss: 0.036003	recall: 0.526494 precision: 0.913894
epoch-2 step 676700/3451022 - loss: 0.037683 val_loss: 0.041001	recall: 0.542277 precision: 0.923225
epoch-2 step 676800/3451022 - loss: 0.039955 val_loss: 0.037612	recall: 0.552404 precision: 0.901408
epoch-2 step 676900/3451022 - loss: 0.040244 val_loss: 0.040622	recall: 0.512679 precision: 0.890805
epoch-2 step 677000/3451022 - loss: 0.034597 val_loss: 0.036772	recall: 0.532961 precision: 0.912046

checkpoint saved

epoch-2 step 677100/3451022 - loss: 0.033375 val_loss: 0.034012	recall: 0.515284 precision: 0.872458
epoch-2 step 677200/3451022 - loss: 0.035211 val_loss: 0.038541	recall: 0.503409 precision: 0.875494
epoch-2 step 677300/3451022 - loss: 0.038925 val_loss: 0.041189	recall: 0.535673 precision: 0.879079
epoch-2 step 677400/3451022 - loss: 0.040399 val_loss: 0.036657	recall: 0.504310 precision: 0.919450
epoch-2 step 677500/3451022 - loss: 0.037213 val_loss: 0.036151	recall: 0.567232 precision: 0.943609
epoch-2 step 677600/3451022 - loss: 0.036334 val_loss: 0.039421	recall: 0.542955 precision: 0.902857
epoch-2 step 677700/3451022 - loss: 0.040737 val_loss: 0.037314	recall: 0.516094 precision: 0.917939
epoch-2 step 677800/3451022 - loss: 0.034802 val_loss: 0.043705	recall: 0.515017 precision: 0.899029
epoch-2 step 677900/3451022 - loss: 0.037420 val_loss: 0.035903	recall: 0.519294 precision: 0.892045
epoch-2 step 678000/3451022 - loss: 0.036737 val_loss: 0.036778	recall: 0.506243 precision: 0.888446

checkpoint saved

epoch-2 step 678100/3451022 - loss: 0.039797 val_loss: 0.035350	recall: 0.500000 precision: 0.888889

model exported!

epoch-2 step 678200/3451022 - loss: 0.036533 val_loss: 0.036068	recall: 0.538462 precision: 0.923518
epoch-2 step 678300/3451022 - loss: 0.034857 val_loss: 0.041866	recall: 0.543678 precision: 0.900952
epoch-2 step 678400/3451022 - loss: 0.036582 val_loss: 0.037321	recall: 0.506257 precision: 0.888224
epoch-2 step 678500/3451022 - loss: 0.040073 val_loss: 0.038958	recall: 0.515660 precision: 0.903922
epoch-2 step 678600/3451022 - loss: 0.034948 val_loss: 0.036890	recall: 0.550790 precision: 0.929524
epoch-2 step 678700/3451022 - loss: 0.043285 val_loss: 0.035638	recall: 0.521537 precision: 0.905051
epoch-2 step 678800/3451022 - loss: 0.039904 val_loss: 0.035486	recall: 0.527313 precision: 0.887430
epoch-2 step 678900/3451022 - loss: 0.049140 val_loss: 0.035737	recall: 0.516340 precision: 0.882682
epoch-2 step 679000/3451022 - loss: 0.034673 val_loss: 0.034202	recall: 0.524664 precision: 0.908738

checkpoint saved

epoch-2 step 679100/3451022 - loss: 0.035912 val_loss: 0.034799	recall: 0.538902 precision: 0.925344
epoch-2 step 679200/3451022 - loss: 0.035833 val_loss: 0.035574	recall: 0.530337 precision: 0.904215
epoch-2 step 679300/3451022 - loss: 0.043692 val_loss: 0.036470	recall: 0.502651 precision: 0.904580
epoch-2 step 679400/3451022 - loss: 0.038360 val_loss: 0.038678	recall: 0.524283 precision: 0.916988
epoch-2 step 679500/3451022 - loss: 0.044580 val_loss: 0.037303	recall: 0.536996 precision: 0.912381
epoch-2 step 679600/3451022 - loss: 0.036192 val_loss: 0.040927	recall: 0.541713 precision: 0.918868
epoch-2 step 679700/3451022 - loss: 0.035410 val_loss: 0.039604	recall: 0.523549 precision: 0.921002
epoch-2 step 679800/3451022 - loss: 0.036530 val_loss: 0.035373	recall: 0.531501 precision: 0.897485
epoch-2 step 679900/3451022 - loss: 0.045697 val_loss: 0.035448	recall: 0.531987 precision: 0.916828
epoch-2 step 680000/3451022 - loss: 0.035892 val_loss: 0.034516	recall: 0.555430 precision: 0.928166

checkpoint saved

epoch-2 step 680100/3451022 - loss: 0.042176 val_loss: 0.038957	recall: 0.516165 precision: 0.890385

model exported!

epoch-2 step 680200/3451022 - loss: 0.035353 val_loss: 0.034731	recall: 0.525424 precision: 0.885714
epoch-2 step 680300/3451022 - loss: 0.039296 val_loss: 0.035016	recall: 0.532311 precision: 0.915254
epoch-2 step 680400/3451022 - loss: 0.041175 val_loss: 0.035308	recall: 0.528814 precision: 0.901734
epoch-2 step 680500/3451022 - loss: 0.036045 val_loss: 0.035857	recall: 0.535117 precision: 0.912548
epoch-2 step 680600/3451022 - loss: 0.040169 val_loss: 0.042404	recall: 0.534091 precision: 0.914397
epoch-2 step 680700/3451022 - loss: 0.036816 val_loss: 0.038081	recall: 0.552392 precision: 0.913371
epoch-2 step 680800/3451022 - loss: 0.042063 val_loss: 0.036902	recall: 0.495624 precision: 0.869482
epoch-2 step 680900/3451022 - loss: 0.034120 val_loss: 0.034317	recall: 0.499459 precision: 0.900585
epoch-2 step 681000/3451022 - loss: 0.035949 val_loss: 0.034296	recall: 0.513363 precision: 0.902153

checkpoint saved

epoch-2 step 681100/3451022 - loss: 0.039276 val_loss: 0.035848	recall: 0.530435 precision: 0.917293
epoch-2 step 681200/3451022 - loss: 0.033829 val_loss: 0.034526	recall: 0.532239 precision: 0.879845
epoch-2 step 681300/3451022 - loss: 0.036839 val_loss: 0.035203	recall: 0.502183 precision: 0.889749
epoch-2 step 681400/3451022 - loss: 0.041088 val_loss: 0.036558	recall: 0.531216 precision: 0.916824
epoch-2 step 681500/3451022 - loss: 0.035118 val_loss: 0.033965	recall: 0.526077 precision: 0.885496
epoch-2 step 681600/3451022 - loss: 0.034677 val_loss: 0.038411	recall: 0.516199 precision: 0.910476
epoch-2 step 681700/3451022 - loss: 0.036531 val_loss: 0.036679	recall: 0.554670 precision: 0.913696
epoch-2 step 681800/3451022 - loss: 0.037638 val_loss: 0.041432	recall: 0.511211 precision: 0.882012
epoch-2 step 681900/3451022 - loss: 0.039411 val_loss: 0.039404	recall: 0.538983 precision: 0.933464
epoch-2 step 682000/3451022 - loss: 0.048857 val_loss: 0.036334	recall: 0.510451 precision: 0.895753

checkpoint saved

epoch-2 step 682100/3451022 - loss: 0.041639 val_loss: 0.039804	recall: 0.548854 precision: 0.908184

model exported!

epoch-2 step 682200/3451022 - loss: 0.039527 val_loss: 0.040464	recall: 0.517778 precision: 0.920949
epoch-2 step 682300/3451022 - loss: 0.035542 val_loss: 0.035604	recall: 0.538462 precision: 0.894737
epoch-2 step 682400/3451022 - loss: 0.043603 val_loss: 0.040832	recall: 0.515217 precision: 0.897727
epoch-2 step 682500/3451022 - loss: 0.038274 val_loss: 0.035421	recall: 0.545970 precision: 0.916190
epoch-2 step 682600/3451022 - loss: 0.036969 val_loss: 0.033645	recall: 0.503233 precision: 0.899807
epoch-2 step 682700/3451022 - loss: 0.034622 val_loss: 0.034634	recall: 0.505808 precision: 0.902072
epoch-2 step 682800/3451022 - loss: 0.035793 val_loss: 0.035182	recall: 0.544304 precision: 0.897533
epoch-2 step 682900/3451022 - loss: 0.042786 val_loss: 0.036676	recall: 0.522300 precision: 0.881188
epoch-2 step 683000/3451022 - loss: 0.035852 val_loss: 0.036401	recall: 0.561772 precision: 0.906015

checkpoint saved

epoch-2 step 683100/3451022 - loss: 0.042655 val_loss: 0.039339	recall: 0.515081 precision: 0.884462
epoch-2 step 683200/3451022 - loss: 0.037430 val_loss: 0.035139	recall: 0.522067 precision: 0.898148
epoch-2 step 683300/3451022 - loss: 0.036304 val_loss: 0.037645	recall: 0.551163 precision: 0.916828
epoch-2 step 683400/3451022 - loss: 0.034497 val_loss: 0.035585	recall: 0.532955 precision: 0.889943
epoch-2 step 683500/3451022 - loss: 0.043005 val_loss: 0.034187	recall: 0.537939 precision: 0.927734
epoch-2 step 683600/3451022 - loss: 0.035152 val_loss: 0.035847	recall: 0.522114 precision: 0.909774
epoch-2 step 683700/3451022 - loss: 0.035490 val_loss: 0.047461	recall: 0.524887 precision: 0.882129
epoch-2 step 683800/3451022 - loss: 0.034717 val_loss: 0.034688	recall: 0.523864 precision: 0.911067
epoch-2 step 683900/3451022 - loss: 0.041984 val_loss: 0.034314	recall: 0.525806 precision: 0.927894
epoch-2 step 684000/3451022 - loss: 0.037163 val_loss: 0.047532	recall: 0.501096 precision: 0.904950

checkpoint saved

epoch-2 step 684100/3451022 - loss: 0.035387 val_loss: 0.034550	recall: 0.526857 precision: 0.876426

model exported!

epoch-2 step 684200/3451022 - loss: 0.038387 val_loss: 0.039202	recall: 0.513234 precision: 0.877953
epoch-2 step 684300/3451022 - loss: 0.039799 val_loss: 0.036171	recall: 0.494420 precision: 0.887776
epoch-2 step 684400/3451022 - loss: 0.034766 val_loss: 0.034821	recall: 0.562217 precision: 0.922078
epoch-2 step 684500/3451022 - loss: 0.034086 val_loss: 0.036140	recall: 0.536060 precision: 0.915441
epoch-2 step 684600/3451022 - loss: 0.036397 val_loss: 0.035539	recall: 0.528879 precision: 0.906796
epoch-2 step 684700/3451022 - loss: 0.040725 val_loss: 0.034217	recall: 0.517978 precision: 0.903922
epoch-2 step 684800/3451022 - loss: 0.050231 val_loss: 0.036203	recall: 0.512035 precision: 0.901734
epoch-2 step 684900/3451022 - loss: 0.037949 val_loss: 0.035560	recall: 0.523095 precision: 0.902390
epoch-2 step 685000/3451022 - loss: 0.034429 val_loss: 0.034165	recall: 0.493963 precision: 0.898204

checkpoint saved

epoch-2 step 685100/3451022 - loss: 0.043862 val_loss: 0.036847	recall: 0.523649 precision: 0.906433
epoch-2 step 685200/3451022 - loss: 0.037246 val_loss: 0.039675	recall: 0.516830 precision: 0.913628
epoch-2 step 685300/3451022 - loss: 0.036475 val_loss: 0.040006	recall: 0.508475 precision: 0.857143
epoch-2 step 685400/3451022 - loss: 0.041706 val_loss: 0.036047	recall: 0.536095 precision: 0.897030
epoch-2 step 685500/3451022 - loss: 0.037132 val_loss: 0.035528	recall: 0.503151 precision: 0.915870
epoch-2 step 685600/3451022 - loss: 0.037759 val_loss: 0.036205	recall: 0.536854 precision: 0.924242
epoch-2 step 685700/3451022 - loss: 0.036924 val_loss: 0.035120	recall: 0.512500 precision: 0.912801
epoch-2 step 685800/3451022 - loss: 0.036413 val_loss: 0.035039	recall: 0.516854 precision: 0.914513
epoch-2 step 685900/3451022 - loss: 0.037588 val_loss: 0.035139	recall: 0.491753 precision: 0.920849
epoch-2 step 686000/3451022 - loss: 0.035360 val_loss: 0.034553	recall: 0.487207 precision: 0.908549

checkpoint saved

epoch-2 step 686100/3451022 - loss: 0.034677 val_loss: 0.038028	recall: 0.522678 precision: 0.914934

model exported!

epoch-2 step 686200/3451022 - loss: 0.035538 val_loss: 0.034749	recall: 0.525275 precision: 0.905303
epoch-2 step 686300/3451022 - loss: 0.036536 val_loss: 0.034890	recall: 0.527840 precision: 0.934911
epoch-2 step 686400/3451022 - loss: 0.037183 val_loss: 0.036989	recall: 0.517241 precision: 0.923077
epoch-2 step 686500/3451022 - loss: 0.034440 val_loss: 0.051608	recall: 0.527778 precision: 0.909962
epoch-2 step 686600/3451022 - loss: 0.035295 val_loss: 0.034335	recall: 0.561983 precision: 0.906667
epoch-2 step 686700/3451022 - loss: 0.035075 val_loss: 0.034426	recall: 0.542590 precision: 0.877358
epoch-2 step 686800/3451022 - loss: 0.035707 val_loss: 0.033986	recall: 0.533410 precision: 0.899029
epoch-2 step 686900/3451022 - loss: 0.036166 val_loss: 0.034419	recall: 0.526082 precision: 0.908046
epoch-2 step 687000/3451022 - loss: 0.034885 val_loss: 0.035683	recall: 0.522075 precision: 0.914894

checkpoint saved

epoch-2 step 687100/3451022 - loss: 0.037448 val_loss: 0.034665	recall: 0.531144 precision: 0.893333
epoch-2 step 687200/3451022 - loss: 0.035500 val_loss: 0.039130	recall: 0.495772 precision: 0.905405
epoch-2 step 687300/3451022 - loss: 0.036186 val_loss: 0.039010	recall: 0.521692 precision: 0.894052
epoch-2 step 687400/3451022 - loss: 0.037897 val_loss: 0.036646	recall: 0.546838 precision: 0.905039
epoch-2 step 687500/3451022 - loss: 0.036425 val_loss: 0.036181	recall: 0.484753 precision: 0.912871
epoch-2 step 687600/3451022 - loss: 0.036997 val_loss: 0.040208	recall: 0.512000 precision: 0.894212
epoch-2 step 687700/3451022 - loss: 0.040775 val_loss: 0.035563	recall: 0.556220 precision: 0.928144
epoch-2 step 687800/3451022 - loss: 0.034530 val_loss: 0.054847	recall: 0.524017 precision: 0.914286
epoch-2 step 687900/3451022 - loss: 0.038757 val_loss: 0.044991	recall: 0.530612 precision: 0.893130
epoch-2 step 688000/3451022 - loss: 0.039663 val_loss: 0.036073	recall: 0.517723 precision: 0.904315

checkpoint saved

epoch-2 step 688100/3451022 - loss: 0.034884 val_loss: 0.036170	recall: 0.510135 precision: 0.917004

model exported!

epoch-2 step 688200/3451022 - loss: 0.035300 val_loss: 0.034384	recall: 0.517354 precision: 0.908571
epoch-2 step 688300/3451022 - loss: 0.035625 val_loss: 0.036286	recall: 0.520179 precision: 0.908023
epoch-2 step 688400/3451022 - loss: 0.036392 val_loss: 0.038005	recall: 0.509372 precision: 0.905882
epoch-2 step 688500/3451022 - loss: 0.039184 val_loss: 0.038430	recall: 0.537430 precision: 0.905838
epoch-2 step 688600/3451022 - loss: 0.034253 val_loss: 0.036474	recall: 0.525029 precision: 0.889546
epoch-2 step 688700/3451022 - loss: 0.036263 val_loss: 0.038002	recall: 0.514722 precision: 0.902486
epoch-2 step 688800/3451022 - loss: 0.037277 val_loss: 0.040957	recall: 0.530795 precision: 0.901141
epoch-2 step 688900/3451022 - loss: 0.037024 val_loss: 0.035609	recall: 0.513333 precision: 0.883365
epoch-2 step 689000/3451022 - loss: 0.041106 val_loss: 0.034689	recall: 0.523333 precision: 0.912791

checkpoint saved

epoch-2 step 689100/3451022 - loss: 0.036452 val_loss: 0.037713	recall: 0.543554 precision: 0.910506
epoch-2 step 689200/3451022 - loss: 0.040676 val_loss: 0.035067	recall: 0.522084 precision: 0.896887
epoch-2 step 689300/3451022 - loss: 0.040003 val_loss: 0.037050	recall: 0.502193 precision: 0.887597
epoch-2 step 689400/3451022 - loss: 0.037030 val_loss: 0.036250	recall: 0.548235 precision: 0.903101
epoch-2 step 689500/3451022 - loss: 0.034972 val_loss: 0.038288	recall: 0.522321 precision: 0.886364
epoch-2 step 689600/3451022 - loss: 0.037638 val_loss: 0.034193	recall: 0.544696 precision: 0.919517
epoch-2 step 689700/3451022 - loss: 0.038682 val_loss: 0.039894	recall: 0.522404 precision: 0.890130
epoch-2 step 689800/3451022 - loss: 0.035833 val_loss: 0.037091	recall: 0.527072 precision: 0.922631
epoch-2 step 689900/3451022 - loss: 0.035387 val_loss: 0.035842	recall: 0.594891 precision: 0.924386
epoch-2 step 690000/3451022 - loss: 0.037496 val_loss: 0.034267	recall: 0.535039 precision: 0.921456

checkpoint saved

epoch-2 step 690100/3451022 - loss: 0.040854 val_loss: 0.038501	recall: 0.565367 precision: 0.907919

model exported!

epoch-2 step 690200/3451022 - loss: 0.035786 val_loss: 0.035889	recall: 0.517699 precision: 0.903475
epoch-3 step 690300/3451022 - loss: 0.047447 val_loss: 0.035290	recall: 0.511013 precision: 0.892308
epoch-3 step 690400/3451022 - loss: 0.035219 val_loss: 0.036940	recall: 0.516129 precision: 0.898876
epoch-3 step 690500/3451022 - loss: 0.033500 val_loss: 0.035285	recall: 0.533784 precision: 0.936759
epoch-3 step 690600/3451022 - loss: 0.037215 val_loss: 0.035973	recall: 0.516269 precision: 0.918919
epoch-3 step 690700/3451022 - loss: 0.039599 val_loss: 0.045950	recall: 0.509392 precision: 0.869811
epoch-3 step 690800/3451022 - loss: 0.035096 val_loss: 0.035553	recall: 0.501099 precision: 0.917505
epoch-3 step 690900/3451022 - loss: 0.036230 val_loss: 0.038713	recall: 0.522946 precision: 0.924528
epoch-3 step 691000/3451022 - loss: 0.034826 val_loss: 0.034178	recall: 0.527211 precision: 0.915354

checkpoint saved

epoch-3 step 691100/3451022 - loss: 0.037145 val_loss: 0.034365	recall: 0.527907 precision: 0.899010
epoch-3 step 691200/3451022 - loss: 0.039385 val_loss: 0.035472	recall: 0.529343 precision: 0.911111
epoch-3 step 691300/3451022 - loss: 0.042621 val_loss: 0.036587	recall: 0.509455 precision: 0.908730
epoch-3 step 691400/3451022 - loss: 0.039067 val_loss: 0.036152	recall: 0.495717 precision: 0.926000
epoch-3 step 691500/3451022 - loss: 0.034075 val_loss: 0.038000	recall: 0.512304 precision: 0.889320
epoch-3 step 691600/3451022 - loss: 0.035506 val_loss: 0.035292	recall: 0.505631 precision: 0.899800
epoch-3 step 691700/3451022 - loss: 0.035416 val_loss: 0.034411	recall: 0.517761 precision: 0.917939
epoch-3 step 691800/3451022 - loss: 0.035191 val_loss: 0.034643	recall: 0.535196 precision: 0.922929
epoch-3 step 691900/3451022 - loss: 0.038329 val_loss: 0.035474	recall: 0.550691 precision: 0.922780
epoch-3 step 692000/3451022 - loss: 0.040166 val_loss: 0.034276	recall: 0.513187 precision: 0.915686

checkpoint saved

epoch-3 step 692100/3451022 - loss: 0.034657 val_loss: 0.035225	recall: 0.548088 precision: 0.892453

model exported!

epoch-3 step 692200/3451022 - loss: 0.038822 val_loss: 0.039327	recall: 0.497250 precision: 0.909457
epoch-3 step 692300/3451022 - loss: 0.040400 val_loss: 0.040034	recall: 0.523269 precision: 0.888247
epoch-3 step 692400/3451022 - loss: 0.038077 val_loss: 0.040903	recall: 0.540782 precision: 0.911488
epoch-3 step 692500/3451022 - loss: 0.034998 val_loss: 0.035465	recall: 0.517202 precision: 0.911111
epoch-3 step 692600/3451022 - loss: 0.033928 val_loss: 0.034718	recall: 0.556561 precision: 0.914498
epoch-3 step 692700/3451022 - loss: 0.035670 val_loss: 0.034911	recall: 0.512936 precision: 0.899408
epoch-3 step 692800/3451022 - loss: 0.034996 val_loss: 0.037210	recall: 0.515508 precision: 0.930502
epoch-3 step 692900/3451022 - loss: 0.038232 val_loss: 0.037921	recall: 0.516304 precision: 0.884544
epoch-3 step 693000/3451022 - loss: 0.035323 val_loss: 0.034739	recall: 0.545564 precision: 0.910000

checkpoint saved

epoch-3 step 693100/3451022 - loss: 0.046210 val_loss: 0.041206	recall: 0.494824 precision: 0.917466
epoch-3 step 693200/3451022 - loss: 0.037175 val_loss: 0.037733	recall: 0.535963 precision: 0.924000
epoch-3 step 693300/3451022 - loss: 0.035486 val_loss: 0.033887	recall: 0.506051 precision: 0.909091
epoch-3 step 693400/3451022 - loss: 0.036254 val_loss: 0.035830	recall: 0.543084 precision: 0.908918
epoch-3 step 693500/3451022 - loss: 0.036376 val_loss: 0.037315	recall: 0.514029 precision: 0.894531
epoch-3 step 693600/3451022 - loss: 0.037783 val_loss: 0.034077	recall: 0.530201 precision: 0.920388
epoch-3 step 693700/3451022 - loss: 0.035390 val_loss: 0.036645	recall: 0.511828 precision: 0.908397
epoch-3 step 693800/3451022 - loss: 0.037558 val_loss: 0.035211	recall: 0.548837 precision: 0.911197
epoch-3 step 693900/3451022 - loss: 0.039901 val_loss: 0.034427	recall: 0.496767 precision: 0.900391
epoch-3 step 694000/3451022 - loss: 0.043382 val_loss: 0.036889	recall: 0.495028 precision: 0.894212

checkpoint saved

epoch-3 step 694100/3451022 - loss: 0.035213 val_loss: 0.036860	recall: 0.540204 precision: 0.919075

model exported!

epoch-3 step 694200/3451022 - loss: 0.060518 val_loss: 0.036723	recall: 0.540782 precision: 0.913208
epoch-3 step 694300/3451022 - loss: 0.037575 val_loss: 0.037018	recall: 0.505543 precision: 0.885437
epoch-3 step 694400/3451022 - loss: 0.037765 val_loss: 0.038209	recall: 0.525918 precision: 0.931166
epoch-3 step 694500/3451022 - loss: 0.035135 val_loss: 0.036896	recall: 0.535260 precision: 0.906067
epoch-3 step 694600/3451022 - loss: 0.036772 val_loss: 0.036595	recall: 0.509825 precision: 0.892925
epoch-3 step 694700/3451022 - loss: 0.033779 val_loss: 0.034459	recall: 0.516779 precision: 0.922156
epoch-3 step 694800/3451022 - loss: 0.035369 val_loss: 0.045257	recall: 0.522989 precision: 0.899209
epoch-3 step 694900/3451022 - loss: 0.038575 val_loss: 0.034556	recall: 0.520652 precision: 0.912381
epoch-3 step 695000/3451022 - loss: 0.036292 val_loss: 0.040997	recall: 0.499480 precision: 0.935673

checkpoint saved

epoch-3 step 695100/3451022 - loss: 0.039180 val_loss: 0.034756	recall: 0.524946 precision: 0.908068
epoch-3 step 695200/3451022 - loss: 0.037279 val_loss: 0.035393	recall: 0.533181 precision: 0.908382
epoch-3 step 695300/3451022 - loss: 0.040230 val_loss: 0.038934	recall: 0.478307 precision: 0.881092
epoch-3 step 695400/3451022 - loss: 0.041862 val_loss: 0.035682	recall: 0.512088 precision: 0.892720
epoch-3 step 695500/3451022 - loss: 0.037671 val_loss: 0.034949	recall: 0.523446 precision: 0.926641
epoch-3 step 695600/3451022 - loss: 0.037015 val_loss: 0.035639	recall: 0.510090 precision: 0.917339
epoch-3 step 695700/3451022 - loss: 0.037533 val_loss: 0.036481	recall: 0.534860 precision: 0.936248
epoch-3 step 695800/3451022 - loss: 0.037747 val_loss: 0.035976	recall: 0.530973 precision: 0.897196
epoch-3 step 695900/3451022 - loss: 0.039478 val_loss: 0.033468	recall: 0.545455 precision: 0.897727
epoch-3 step 696000/3451022 - loss: 0.035666 val_loss: 0.036594	recall: 0.512821 precision: 0.898876

checkpoint saved

epoch-3 step 696100/3451022 - loss: 0.037283 val_loss: 0.035772	recall: 0.540230 precision: 0.928854

model exported!

epoch-3 step 696200/3451022 - loss: 0.041408 val_loss: 0.035838	recall: 0.542683 precision: 0.897177
epoch-3 step 696300/3451022 - loss: 0.036867 val_loss: 0.036552	recall: 0.491892 precision: 0.885214
epoch-3 step 696400/3451022 - loss: 0.035537 val_loss: 0.037166	recall: 0.525581 precision: 0.895050
epoch-3 step 696500/3451022 - loss: 0.037187 val_loss: 0.037645	recall: 0.548864 precision: 0.932432
epoch-3 step 696600/3451022 - loss: 0.035260 val_loss: 0.035246	recall: 0.527497 precision: 0.898662
epoch-3 step 696700/3451022 - loss: 0.039553 val_loss: 0.039721	recall: 0.527412 precision: 0.905838
epoch-3 step 696800/3451022 - loss: 0.039360 val_loss: 0.036481	recall: 0.516977 precision: 0.911197
epoch-3 step 696900/3451022 - loss: 0.036364 val_loss: 0.036351	recall: 0.504175 precision: 0.902804
epoch-3 step 697000/3451022 - loss: 0.037182 val_loss: 0.035413	recall: 0.512326 precision: 0.907021

checkpoint saved

epoch-3 step 697100/3451022 - loss: 0.035654 val_loss: 0.035471	recall: 0.540351 precision: 0.913043
epoch-3 step 697200/3451022 - loss: 0.034852 val_loss: 0.035112	recall: 0.547537 precision: 0.910476
epoch-3 step 697300/3451022 - loss: 0.034278 val_loss: 0.033622	recall: 0.555822 precision: 0.900778
epoch-3 step 697400/3451022 - loss: 0.036073 val_loss: 0.034500	recall: 0.505933 precision: 0.889943
epoch-3 step 697500/3451022 - loss: 0.043644 val_loss: 0.037112	recall: 0.532315 precision: 0.909639
epoch-3 step 697600/3451022 - loss: 0.038259 val_loss: 0.038097	recall: 0.522573 precision: 0.924152
epoch-3 step 697700/3451022 - loss: 0.035210 val_loss: 0.037238	recall: 0.543113 precision: 0.909944
epoch-3 step 697800/3451022 - loss: 0.035825 val_loss: 0.034774	recall: 0.522905 precision: 0.898273
epoch-3 step 697900/3451022 - loss: 0.038683 val_loss: 0.043014	recall: 0.545958 precision: 0.935484
epoch-3 step 698000/3451022 - loss: 0.036137 val_loss: 0.036376	recall: 0.532203 precision: 0.895437

checkpoint saved

epoch-3 step 698100/3451022 - loss: 0.038549 val_loss: 0.035024	recall: 0.568027 precision: 0.934701

model exported!

epoch-3 step 698200/3451022 - loss: 0.042344 val_loss: 0.035881	recall: 0.536105 precision: 0.917603
epoch-3 step 698300/3451022 - loss: 0.035226 val_loss: 0.037011	recall: 0.513129 precision: 0.901923
epoch-3 step 698400/3451022 - loss: 0.035974 val_loss: 0.035723	recall: 0.524752 precision: 0.922631
epoch-3 step 698500/3451022 - loss: 0.036011 val_loss: 0.044119	recall: 0.501672 precision: 0.870406
epoch-3 step 698600/3451022 - loss: 0.034080 val_loss: 0.034506	recall: 0.542012 precision: 0.899804
epoch-3 step 698700/3451022 - loss: 0.035050 val_loss: 0.035065	recall: 0.532497 precision: 0.891221
epoch-3 step 698800/3451022 - loss: 0.043344 val_loss: 0.035729	recall: 0.537659 precision: 0.915187
epoch-3 step 698900/3451022 - loss: 0.040407 val_loss: 0.042708	recall: 0.507246 precision: 0.875000
epoch-3 step 699000/3451022 - loss: 0.036092 val_loss: 0.034065	recall: 0.557358 precision: 0.930368

checkpoint saved

epoch-3 step 699100/3451022 - loss: 0.034276 val_loss: 0.050475	recall: 0.498357 precision: 0.863378
epoch-3 step 699200/3451022 - loss: 0.036868 val_loss: 0.034739	recall: 0.579812 precision: 0.935606
epoch-3 step 699300/3451022 - loss: 0.034791 val_loss: 0.033875	recall: 0.506667 precision: 0.887160
epoch-3 step 699400/3451022 - loss: 0.035890 val_loss: 0.035648	recall: 0.482759 precision: 0.880157
epoch-3 step 699500/3451022 - loss: 0.039535 val_loss: 0.038788	recall: 0.504792 precision: 0.902857
epoch-3 step 699600/3451022 - loss: 0.035364 val_loss: 0.035644	recall: 0.505411 precision: 0.912109
epoch-3 step 699700/3451022 - loss: 0.037110 val_loss: 0.035072	recall: 0.521405 precision: 0.892857
epoch-3 step 699800/3451022 - loss: 0.040033 val_loss: 0.034467	recall: 0.529349 precision: 0.906764
epoch-3 step 699900/3451022 - loss: 0.047211 val_loss: 0.037654	recall: 0.522124 precision: 0.895636
epoch-3 step 700000/3451022 - loss: 0.036866 val_loss: 0.035278	recall: 0.536364 precision: 0.916505

checkpoint saved

epoch-3 step 700100/3451022 - loss: 0.037816 val_loss: 0.034422	recall: 0.500000 precision: 0.897177

model exported!

epoch-3 step 700200/3451022 - loss: 0.037216 val_loss: 0.035802	recall: 0.545665 precision: 0.916505
epoch-3 step 700300/3451022 - loss: 0.039433 val_loss: 0.036985	recall: 0.507848 precision: 0.909639
epoch-3 step 700400/3451022 - loss: 0.034404 val_loss: 0.039094	recall: 0.534054 precision: 0.926829
epoch-3 step 700500/3451022 - loss: 0.035780 val_loss: 0.035255	recall: 0.553066 precision: 0.926877
epoch-3 step 700600/3451022 - loss: 0.035534 val_loss: 0.036033	recall: 0.491979 precision: 0.898438
epoch-3 step 700700/3451022 - loss: 0.034207 val_loss: 0.036194	recall: 0.511161 precision: 0.877395
epoch-3 step 700800/3451022 - loss: 0.034833 val_loss: 0.039621	recall: 0.544643 precision: 0.929524
epoch-3 step 700900/3451022 - loss: 0.035758 val_loss: 0.039372	recall: 0.534937 precision: 0.917485
epoch-3 step 701000/3451022 - loss: 0.036678 val_loss: 0.035388	recall: 0.502188 precision: 0.919840

checkpoint saved

epoch-3 step 701100/3451022 - loss: 0.036073 val_loss: 0.035733	recall: 0.540601 precision: 0.927481
epoch-3 step 701200/3451022 - loss: 0.037911 val_loss: 0.036859	recall: 0.502720 precision: 0.898833
epoch-3 step 701300/3451022 - loss: 0.035443 val_loss: 0.037004	recall: 0.517594 precision: 0.888889
epoch-3 step 701400/3451022 - loss: 0.035002 val_loss: 0.044251	recall: 0.515873 precision: 0.880077
epoch-3 step 701500/3451022 - loss: 0.034257 val_loss: 0.036595	recall: 0.502165 precision: 0.913386
epoch-3 step 701600/3451022 - loss: 0.034862 val_loss: 0.037620	recall: 0.535274 precision: 0.926357
epoch-3 step 701700/3451022 - loss: 0.049214 val_loss: 0.035323	recall: 0.510823 precision: 0.921875
epoch-3 step 701800/3451022 - loss: 0.039232 val_loss: 0.038192	recall: 0.528539 precision: 0.909627
epoch-3 step 701900/3451022 - loss: 0.035569 val_loss: 0.041510	recall: 0.514989 precision: 0.904135
epoch-3 step 702000/3451022 - loss: 0.034974 val_loss: 0.045089	recall: 0.524390 precision: 0.882463

checkpoint saved

epoch-3 step 702100/3451022 - loss: 0.035080 val_loss: 0.041879	recall: 0.547148 precision: 0.914397

model exported!

epoch-3 step 702200/3451022 - loss: 0.038413 val_loss: 0.034377	recall: 0.541336 precision: 0.915709
epoch-3 step 702300/3451022 - loss: 0.035650 val_loss: 0.035428	recall: 0.530320 precision: 0.905838
epoch-3 step 702400/3451022 - loss: 0.044744 val_loss: 0.037920	recall: 0.518560 precision: 0.903922
epoch-3 step 702500/3451022 - loss: 0.035204 val_loss: 0.034379	recall: 0.523322 precision: 0.905512
epoch-3 step 702600/3451022 - loss: 0.039617 val_loss: 0.034417	recall: 0.552009 precision: 0.905039
epoch-3 step 702700/3451022 - loss: 0.035535 val_loss: 0.038338	recall: 0.543405 precision: 0.914611
epoch-3 step 702800/3451022 - loss: 0.037580 val_loss: 0.034360	recall: 0.503867 precision: 0.883721
epoch-3 step 702900/3451022 - loss: 0.033733 val_loss: 0.036943	recall: 0.526140 precision: 0.897533
epoch-3 step 703000/3451022 - loss: 0.035929 val_loss: 0.047841	recall: 0.511931 precision: 0.895636

checkpoint saved

epoch-3 step 703100/3451022 - loss: 0.047097 val_loss: 0.035496	recall: 0.530303 precision: 0.926276
epoch-3 step 703200/3451022 - loss: 0.035178 val_loss: 0.045754	recall: 0.534722 precision: 0.888462
epoch-3 step 703300/3451022 - loss: 0.035725 val_loss: 0.040821	recall: 0.544751 precision: 0.923221
epoch-3 step 703400/3451022 - loss: 0.036661 val_loss: 0.035064	recall: 0.516164 precision: 0.910646
epoch-3 step 703500/3451022 - loss: 0.035932 val_loss: 0.039572	recall: 0.550289 precision: 0.917148
epoch-3 step 703600/3451022 - loss: 0.035795 val_loss: 0.040278	recall: 0.497788 precision: 0.889328
epoch-3 step 703700/3451022 - loss: 0.036695 val_loss: 0.041274	recall: 0.524664 precision: 0.900000
epoch-3 step 703800/3451022 - loss: 0.040396 val_loss: 0.036217	recall: 0.542448 precision: 0.921348
epoch-3 step 703900/3451022 - loss: 0.035032 val_loss: 0.035981	recall: 0.556442 precision: 0.936660
epoch-3 step 704000/3451022 - loss: 0.034906 val_loss: 0.036377	recall: 0.514722 precision: 0.900763

checkpoint saved

epoch-3 step 704100/3451022 - loss: 0.035017 val_loss: 0.043472	recall: 0.509351 precision: 0.900778

model exported!

epoch-3 step 704200/3451022 - loss: 0.034217 val_loss: 0.037386	recall: 0.521396 precision: 0.909627
epoch-3 step 704300/3451022 - loss: 0.035003 val_loss: 0.034859	recall: 0.589525 precision: 0.921905
epoch-3 step 704400/3451022 - loss: 0.035260 val_loss: 0.035837	recall: 0.539884 precision: 0.908560
epoch-3 step 704500/3451022 - loss: 0.041920 val_loss: 0.035447	recall: 0.561167 precision: 0.919118
epoch-3 step 704600/3451022 - loss: 0.036187 val_loss: 0.034455	recall: 0.542002 precision: 0.923529
epoch-3 step 704700/3451022 - loss: 0.037750 val_loss: 0.037217	recall: 0.503191 precision: 0.894140
epoch-3 step 704800/3451022 - loss: 0.036093 val_loss: 0.035922	recall: 0.517052 precision: 0.907336
epoch-3 step 704900/3451022 - loss: 0.035414 val_loss: 0.035903	recall: 0.578216 precision: 0.929236
epoch-3 step 705000/3451022 - loss: 0.043382 val_loss: 0.036076	recall: 0.488649 precision: 0.874275

checkpoint saved

epoch-3 step 705100/3451022 - loss: 0.034557 val_loss: 0.037088	recall: 0.520408 precision: 0.887814
epoch-3 step 705200/3451022 - loss: 0.043792 val_loss: 0.035546	recall: 0.519509 precision: 0.906615
epoch-3 step 705300/3451022 - loss: 0.034818 val_loss: 0.034307	recall: 0.516571 precision: 0.879377
epoch-3 step 705400/3451022 - loss: 0.035602 val_loss: 0.037808	recall: 0.539954 precision: 0.914894
epoch-3 step 705500/3451022 - loss: 0.037493 val_loss: 0.034680	recall: 0.527436 precision: 0.909266
epoch-3 step 705600/3451022 - loss: 0.042444 val_loss: 0.035223	recall: 0.507073 precision: 0.899614
epoch-3 step 705700/3451022 - loss: 0.042208 val_loss: 0.035174	recall: 0.529083 precision: 0.907869
epoch-3 step 705800/3451022 - loss: 0.034977 val_loss: 0.036816	recall: 0.502825 precision: 0.884692
epoch-3 step 705900/3451022 - loss: 0.041937 val_loss: 0.036348	recall: 0.511206 precision: 0.903774
epoch-3 step 706000/3451022 - loss: 0.041282 val_loss: 0.036037	recall: 0.530636 precision: 0.901768

checkpoint saved

epoch-3 step 706100/3451022 - loss: 0.036290 val_loss: 0.035837	recall: 0.480973 precision: 0.873321

model exported!

epoch-3 step 706200/3451022 - loss: 0.034395 val_loss: 0.036036	recall: 0.533109 precision: 0.915222
epoch-3 step 706300/3451022 - loss: 0.034881 val_loss: 0.033882	recall: 0.536830 precision: 0.916190
epoch-3 step 706400/3451022 - loss: 0.041268 val_loss: 0.036540	recall: 0.522678 precision: 0.902985
epoch-3 step 706500/3451022 - loss: 0.036554 val_loss: 0.043611	recall: 0.520518 precision: 0.914611
epoch-3 step 706600/3451022 - loss: 0.035225 val_loss: 0.036456	recall: 0.495125 precision: 0.897839
epoch-3 step 706700/3451022 - loss: 0.035634 val_loss: 0.036645	recall: 0.504228 precision: 0.915547
epoch-3 step 706800/3451022 - loss: 0.036538 val_loss: 0.034785	recall: 0.552480 precision: 0.937378
epoch-3 step 706900/3451022 - loss: 0.037812 val_loss: 0.034591	recall: 0.524855 precision: 0.900794
epoch-3 step 707000/3451022 - loss: 0.043223 val_loss: 0.036659	recall: 0.524349 precision: 0.900778

checkpoint saved

epoch-3 step 707100/3451022 - loss: 0.035190 val_loss: 0.034062	recall: 0.559719 precision: 0.929961
epoch-3 step 707200/3451022 - loss: 0.035677 val_loss: 0.035552	recall: 0.532872 precision: 0.902344
epoch-3 step 707300/3451022 - loss: 0.039580 val_loss: 0.037257	recall: 0.533101 precision: 0.889535
epoch-3 step 707400/3451022 - loss: 0.039740 val_loss: 0.045792	recall: 0.517241 precision: 0.909091
epoch-3 step 707500/3451022 - loss: 0.036595 val_loss: 0.036128	recall: 0.507987 precision: 0.876838
epoch-3 step 707600/3451022 - loss: 0.039925 val_loss: 0.044897	recall: 0.495614 precision: 0.881092
epoch-3 step 707700/3451022 - loss: 0.036464 val_loss: 0.034389	recall: 0.502685 precision: 0.889734
epoch-3 step 707800/3451022 - loss: 0.048986 val_loss: 0.036797	recall: 0.504464 precision: 0.886275
epoch-3 step 707900/3451022 - loss: 0.035931 val_loss: 0.039592	recall: 0.513034 precision: 0.933586
epoch-3 step 708000/3451022 - loss: 0.037454 val_loss: 0.040386	recall: 0.492569 precision: 0.892308

checkpoint saved

epoch-3 step 708100/3451022 - loss: 0.039397 val_loss: 0.039465	recall: 0.517582 precision: 0.914563

model exported!

epoch-3 step 708200/3451022 - loss: 0.036052 val_loss: 0.035345	recall: 0.527936 precision: 0.907843
epoch-3 step 708300/3451022 - loss: 0.036572 val_loss: 0.036214	recall: 0.529675 precision: 0.918447
epoch-3 step 708400/3451022 - loss: 0.038542 val_loss: 0.034087	recall: 0.504255 precision: 0.908046
epoch-3 step 708500/3451022 - loss: 0.034137 val_loss: 0.041070	recall: 0.500000 precision: 0.889749
epoch-3 step 708600/3451022 - loss: 0.034028 val_loss: 0.038177	recall: 0.531429 precision: 0.915354
epoch-3 step 708700/3451022 - loss: 0.040704 val_loss: 0.041469	recall: 0.486911 precision: 0.915354
epoch-3 step 708800/3451022 - loss: 0.034485 val_loss: 0.034799	recall: 0.526316 precision: 0.912548
epoch-3 step 708900/3451022 - loss: 0.035096 val_loss: 0.036642	recall: 0.523060 precision: 0.915354
epoch-3 step 709000/3451022 - loss: 0.036184 val_loss: 0.036518	recall: 0.505411 precision: 0.901544

checkpoint saved

epoch-3 step 709100/3451022 - loss: 0.035562 val_loss: 0.036921	recall: 0.521387 precision: 0.891304
epoch-3 step 709200/3451022 - loss: 0.035269 val_loss: 0.035637	recall: 0.540230 precision: 0.916179
epoch-3 step 709300/3451022 - loss: 0.035075 val_loss: 0.036459	recall: 0.535632 precision: 0.906615
epoch-3 step 709400/3451022 - loss: 0.035888 val_loss: 0.039464	recall: 0.540632 precision: 0.917625
epoch-3 step 709500/3451022 - loss: 0.035251 val_loss: 0.047057	recall: 0.518837 precision: 0.895911
epoch-3 step 709600/3451022 - loss: 0.043959 val_loss: 0.036474	recall: 0.525028 precision: 0.911197
epoch-3 step 709700/3451022 - loss: 0.042107 val_loss: 0.042234	recall: 0.534699 precision: 0.898662
epoch-3 step 709800/3451022 - loss: 0.036740 val_loss: 0.034639	recall: 0.519001 precision: 0.896811
epoch-3 step 709900/3451022 - loss: 0.038400 val_loss: 0.037782	recall: 0.550058 precision: 0.919231
epoch-3 step 710000/3451022 - loss: 0.035886 val_loss: 0.034175	recall: 0.518919 precision: 0.910816

checkpoint saved

epoch-3 step 710100/3451022 - loss: 0.036476 val_loss: 0.034510	recall: 0.546380 precision: 0.918251

model exported!

epoch-3 step 710200/3451022 - loss: 0.038493 val_loss: 0.034689	recall: 0.501080 precision: 0.920635
epoch-3 step 710300/3451022 - loss: 0.036271 val_loss: 0.035837	recall: 0.507761 precision: 0.899804
epoch-3 step 710400/3451022 - loss: 0.035802 val_loss: 0.037123	recall: 0.506928 precision: 0.867589
epoch-3 step 710500/3451022 - loss: 0.047554 val_loss: 0.034523	recall: 0.548276 precision: 0.931641
epoch-3 step 710600/3451022 - loss: 0.034886 val_loss: 0.037184	recall: 0.516201 precision: 0.898833
epoch-3 step 710700/3451022 - loss: 0.035104 val_loss: 0.036312	recall: 0.524377 precision: 0.916667
epoch-3 step 710800/3451022 - loss: 0.035388 val_loss: 0.035728	recall: 0.521047 precision: 0.896282
epoch-3 step 710900/3451022 - loss: 0.034148 val_loss: 0.035527	recall: 0.522222 precision: 0.930693
epoch-3 step 711000/3451022 - loss: 0.038136 val_loss: 0.035511	recall: 0.533258 precision: 0.907869

checkpoint saved

epoch-3 step 711100/3451022 - loss: 0.035746 val_loss: 0.035423	recall: 0.542212 precision: 0.912000
epoch-3 step 711200/3451022 - loss: 0.035895 val_loss: 0.037795	recall: 0.527174 precision: 0.916824
epoch-3 step 711300/3451022 - loss: 0.035316 val_loss: 0.034816	recall: 0.544622 precision: 0.927875
epoch-3 step 711400/3451022 - loss: 0.038919 val_loss: 0.043669	recall: 0.517634 precision: 0.885214
epoch-3 step 711500/3451022 - loss: 0.037793 val_loss: 0.041969	recall: 0.545561 precision: 0.913894
epoch-3 step 711600/3451022 - loss: 0.035293 val_loss: 0.034333	recall: 0.528492 precision: 0.918447
epoch-3 step 711700/3451022 - loss: 0.035340 val_loss: 0.036317	recall: 0.537430 precision: 0.930368
epoch-3 step 711800/3451022 - loss: 0.042871 val_loss: 0.035540	recall: 0.530035 precision: 0.885827
epoch-3 step 711900/3451022 - loss: 0.035338 val_loss: 0.039279	recall: 0.532796 precision: 0.904297
epoch-3 step 712000/3451022 - loss: 0.036556 val_loss: 0.033839	recall: 0.539683 precision: 0.929688

checkpoint saved

epoch-3 step 712100/3451022 - loss: 0.036590 val_loss: 0.034567	recall: 0.560714 precision: 0.895437

model exported!

epoch-3 step 712200/3451022 - loss: 0.034649 val_loss: 0.035200	recall: 0.522124 precision: 0.911197
epoch-3 step 712300/3451022 - loss: 0.034825 val_loss: 0.036094	recall: 0.550406 precision: 0.903042
epoch-3 step 712400/3451022 - loss: 0.036189 val_loss: 0.036392	recall: 0.519101 precision: 0.885057
epoch-3 step 712500/3451022 - loss: 0.039116 val_loss: 0.037949	recall: 0.530023 precision: 0.887814
epoch-3 step 712600/3451022 - loss: 0.033874 val_loss: 0.035674	recall: 0.517045 precision: 0.908184
epoch-3 step 712700/3451022 - loss: 0.035165 val_loss: 0.039585	recall: 0.521300 precision: 0.902913
epoch-3 step 712800/3451022 - loss: 0.044290 val_loss: 0.036119	recall: 0.542035 precision: 0.919325
epoch-3 step 712900/3451022 - loss: 0.038629 val_loss: 0.034488	recall: 0.526198 precision: 0.912959
epoch-3 step 713000/3451022 - loss: 0.034776 val_loss: 0.034311	recall: 0.543307 precision: 0.921756

checkpoint saved

epoch-3 step 713100/3451022 - loss: 0.035146 val_loss: 0.036091	recall: 0.523918 precision: 0.918164
epoch-3 step 713200/3451022 - loss: 0.037898 val_loss: 0.037535	recall: 0.520455 precision: 0.899804
epoch-3 step 713300/3451022 - loss: 0.036595 val_loss: 0.038936	recall: 0.500000 precision: 0.916155
epoch-3 step 713400/3451022 - loss: 0.049273 val_loss: 0.035116	recall: 0.545455 precision: 0.934911
epoch-3 step 713500/3451022 - loss: 0.034631 val_loss: 0.035566	recall: 0.517475 precision: 0.900000
epoch-3 step 713600/3451022 - loss: 0.034711 val_loss: 0.038215	recall: 0.555425 precision: 0.895437
epoch-3 step 713700/3451022 - loss: 0.035948 val_loss: 0.035208	recall: 0.525785 precision: 0.893333
epoch-3 step 713800/3451022 - loss: 0.035788 val_loss: 0.039302	recall: 0.534541 precision: 0.920078
epoch-3 step 713900/3451022 - loss: 0.037817 val_loss: 0.036584	recall: 0.530093 precision: 0.903353
epoch-3 step 714000/3451022 - loss: 0.035561 val_loss: 0.035466	recall: 0.520999 precision: 0.880998

checkpoint saved

epoch-3 step 714100/3451022 - loss: 0.035723 val_loss: 0.036258	recall: 0.526018 precision: 0.895954

model exported!

epoch-3 step 714200/3451022 - loss: 0.039610 val_loss: 0.035905	recall: 0.514607 precision: 0.901575
epoch-3 step 714300/3451022 - loss: 0.037647 val_loss: 0.033837	recall: 0.534884 precision: 0.909091
epoch-3 step 714400/3451022 - loss: 0.038016 val_loss: 0.041553	recall: 0.524076 precision: 0.901734
epoch-3 step 714500/3451022 - loss: 0.035259 val_loss: 0.040780	recall: 0.548931 precision: 0.922495
epoch-3 step 714600/3451022 - loss: 0.035750 val_loss: 0.042152	recall: 0.527936 precision: 0.885277
epoch-3 step 714700/3451022 - loss: 0.034555 val_loss: 0.035830	recall: 0.543453 precision: 0.921415
epoch-3 step 714800/3451022 - loss: 0.035350 val_loss: 0.037198	recall: 0.517162 precision: 0.865900
epoch-3 step 714900/3451022 - loss: 0.044422 val_loss: 0.040538	recall: 0.528235 precision: 0.898000
epoch-3 step 715000/3451022 - loss: 0.035731 val_loss: 0.037593	recall: 0.553409 precision: 0.924099

checkpoint saved

epoch-3 step 715100/3451022 - loss: 0.035760 val_loss: 0.034549	recall: 0.489384 precision: 0.905697
epoch-3 step 715200/3451022 - loss: 0.041202 val_loss: 0.035775	recall: 0.561176 precision: 0.915547
epoch-3 step 715300/3451022 - loss: 0.037421 val_loss: 0.040587	recall: 0.552693 precision: 0.890566
epoch-3 step 715400/3451022 - loss: 0.042475 val_loss: 0.041412	recall: 0.527294 precision: 0.908000
epoch-3 step 715500/3451022 - loss: 0.036542 val_loss: 0.034433	recall: 0.512352 precision: 0.893258
epoch-3 step 715600/3451022 - loss: 0.038829 val_loss: 0.039832	recall: 0.532100 precision: 0.915730
epoch-3 step 715700/3451022 - loss: 0.034510 val_loss: 0.036110	recall: 0.527088 precision: 0.899807
epoch-3 step 715800/3451022 - loss: 0.036800 val_loss: 0.040273	recall: 0.552347 precision: 0.880998
epoch-3 step 715900/3451022 - loss: 0.035694 val_loss: 0.034976	recall: 0.511416 precision: 0.903226
epoch-3 step 716000/3451022 - loss: 0.034117 val_loss: 0.035350	recall: 0.532690 precision: 0.915285

checkpoint saved

epoch-3 step 716100/3451022 - loss: 0.035947 val_loss: 0.043898	recall: 0.525959 precision: 0.894434

model exported!

epoch-3 step 716200/3451022 - loss: 0.050034 val_loss: 0.039549	recall: 0.542469 precision: 0.897004
epoch-3 step 716300/3451022 - loss: 0.039464 val_loss: 0.037847	recall: 0.564735 precision: 0.882466
epoch-3 step 716400/3451022 - loss: 0.042381 val_loss: 0.042225	recall: 0.511186 precision: 0.889105
epoch-3 step 716500/3451022 - loss: 0.041338 val_loss: 0.035990	recall: 0.555152 precision: 0.919679
epoch-3 step 716600/3451022 - loss: 0.043512 val_loss: 0.034232	recall: 0.548533 precision: 0.915254
epoch-3 step 716700/3451022 - loss: 0.041502 val_loss: 0.034556	recall: 0.536974 precision: 0.916505
epoch-3 step 716800/3451022 - loss: 0.036320 val_loss: 0.036442	recall: 0.541769 precision: 0.876740
epoch-3 step 716900/3451022 - loss: 0.036898 val_loss: 0.038182	recall: 0.523969 precision: 0.909091
epoch-3 step 717000/3451022 - loss: 0.036343 val_loss: 0.034490	recall: 0.534807 precision: 0.906367

checkpoint saved

epoch-3 step 717100/3451022 - loss: 0.035250 val_loss: 0.043428	recall: 0.544944 precision: 0.911654
epoch-3 step 717200/3451022 - loss: 0.039540 val_loss: 0.039265	recall: 0.527533 precision: 0.900376
epoch-3 step 717300/3451022 - loss: 0.039299 val_loss: 0.036094	recall: 0.513015 precision: 0.899240
epoch-3 step 717400/3451022 - loss: 0.038609 val_loss: 0.035788	recall: 0.516022 precision: 0.889524
epoch-3 step 717500/3451022 - loss: 0.038537 val_loss: 0.033843	recall: 0.525210 precision: 0.938086
epoch-3 step 717600/3451022 - loss: 0.043711 val_loss: 0.035352	recall: 0.525404 precision: 0.902778
epoch-3 step 717700/3451022 - loss: 0.035491 val_loss: 0.036506	recall: 0.522034 precision: 0.913043
epoch-3 step 717800/3451022 - loss: 0.036899 val_loss: 0.037660	recall: 0.509434 precision: 0.915254
epoch-3 step 717900/3451022 - loss: 0.035463 val_loss: 0.038419	recall: 0.521691 precision: 0.921415
epoch-3 step 718000/3451022 - loss: 0.035457 val_loss: 0.036223	recall: 0.494143 precision: 0.899225

checkpoint saved

epoch-3 step 718100/3451022 - loss: 0.034665 val_loss: 0.036769	recall: 0.540724 precision: 0.919231

model exported!

epoch-3 step 718200/3451022 - loss: 0.034156 val_loss: 0.035883	recall: 0.505435 precision: 0.911765
epoch-3 step 718300/3451022 - loss: 0.034564 val_loss: 0.038223	recall: 0.525000 precision: 0.913043
epoch-3 step 718400/3451022 - loss: 0.040024 val_loss: 0.036527	recall: 0.520487 precision: 0.902111
epoch-3 step 718500/3451022 - loss: 0.035324 val_loss: 0.048046	recall: 0.520270 precision: 0.888462
epoch-3 step 718600/3451022 - loss: 0.034661 val_loss: 0.034545	recall: 0.541336 precision: 0.919231
epoch-3 step 718700/3451022 - loss: 0.037571 val_loss: 0.036731	recall: 0.510857 precision: 0.901210
epoch-3 step 718800/3451022 - loss: 0.049781 val_loss: 0.036359	recall: 0.543527 precision: 0.910280
epoch-3 step 718900/3451022 - loss: 0.036503 val_loss: 0.039770	recall: 0.497162 precision: 0.858824
epoch-3 step 719000/3451022 - loss: 0.036161 val_loss: 0.037185	recall: 0.530934 precision: 0.895636

checkpoint saved

epoch-3 step 719100/3451022 - loss: 0.034113 val_loss: 0.038230	recall: 0.527293 precision: 0.918251
epoch-3 step 719200/3451022 - loss: 0.036325 val_loss: 0.036541	recall: 0.529412 precision: 0.930417
epoch-3 step 719300/3451022 - loss: 0.038160 val_loss: 0.036566	recall: 0.503800 precision: 0.888889
epoch-3 step 719400/3451022 - loss: 0.036236 val_loss: 0.035402	recall: 0.532967 precision: 0.904851
epoch-3 step 719500/3451022 - loss: 0.037451 val_loss: 0.052202	recall: 0.513843 precision: 0.897485
epoch-3 step 719600/3451022 - loss: 0.040553 val_loss: 0.036627	recall: 0.512931 precision: 0.898113
epoch-3 step 719700/3451022 - loss: 0.034916 val_loss: 0.040546	recall: 0.540909 precision: 0.917148
epoch-3 step 719800/3451022 - loss: 0.035511 val_loss: 0.039743	recall: 0.513684 precision: 0.903704
epoch-3 step 719900/3451022 - loss: 0.034985 val_loss: 0.040746	recall: 0.494028 precision: 0.911824
epoch-3 step 720000/3451022 - loss: 0.039879 val_loss: 0.039427	recall: 0.532366 precision: 0.912046

checkpoint saved

epoch-3 step 720100/3451022 - loss: 0.036245 val_loss: 0.037976	recall: 0.530726 precision: 0.891182

model exported!

epoch-3 step 720200/3451022 - loss: 0.036531 val_loss: 0.034181	recall: 0.546821 precision: 0.925636
epoch-3 step 720300/3451022 - loss: 0.034484 val_loss: 0.038669	recall: 0.525785 precision: 0.908915
epoch-3 step 720400/3451022 - loss: 0.034530 val_loss: 0.041674	recall: 0.499464 precision: 0.910156
epoch-3 step 720500/3451022 - loss: 0.037501 val_loss: 0.037184	recall: 0.491821 precision: 0.887795
epoch-3 step 720600/3451022 - loss: 0.035830 val_loss: 0.034570	recall: 0.524752 precision: 0.903409
epoch-3 step 720700/3451022 - loss: 0.033625 val_loss: 0.034288	recall: 0.572929 precision: 0.917757
epoch-3 step 720800/3451022 - loss: 0.034398 val_loss: 0.036828	recall: 0.560234 precision: 0.897004
epoch-3 step 720900/3451022 - loss: 0.036590 val_loss: 0.034862	recall: 0.500000 precision: 0.903543
epoch-3 step 721000/3451022 - loss: 0.045686 val_loss: 0.038808	recall: 0.530162 precision: 0.906746

checkpoint saved

epoch-3 step 721100/3451022 - loss: 0.035648 val_loss: 0.033303	recall: 0.550773 precision: 0.934457
epoch-3 step 721200/3451022 - loss: 0.036288 val_loss: 0.034795	recall: 0.518477 precision: 0.911417
epoch-3 step 721300/3451022 - loss: 0.040504 val_loss: 0.039021	recall: 0.532558 precision: 0.894531
epoch-3 step 721400/3451022 - loss: 0.034624 val_loss: 0.038718	recall: 0.529680 precision: 0.883810
epoch-3 step 721500/3451022 - loss: 0.038758 val_loss: 0.034312	recall: 0.513691 precision: 0.900192
epoch-3 step 721600/3451022 - loss: 0.033699 val_loss: 0.036316	recall: 0.547018 precision: 0.901701
epoch-3 step 721700/3451022 - loss: 0.035576 val_loss: 0.034822	recall: 0.508734 precision: 0.892720
epoch-3 step 721800/3451022 - loss: 0.036294 val_loss: 0.034534	recall: 0.498378 precision: 0.881453
epoch-3 step 721900/3451022 - loss: 0.039136 val_loss: 0.034444	recall: 0.554770 precision: 0.914563
epoch-3 step 722000/3451022 - loss: 0.040014 val_loss: 0.038068	recall: 0.494541 precision: 0.881323

checkpoint saved

epoch-3 step 722100/3451022 - loss: 0.042439 val_loss: 0.039036	recall: 0.522453 precision: 0.898305

model exported!

epoch-3 step 722200/3451022 - loss: 0.037808 val_loss: 0.036247	recall: 0.523605 precision: 0.919021
epoch-3 step 722300/3451022 - loss: 0.037497 val_loss: 0.037585	recall: 0.510315 precision: 0.896947
epoch-3 step 722400/3451022 - loss: 0.037710 val_loss: 0.035133	recall: 0.547344 precision: 0.915058
epoch-3 step 722500/3451022 - loss: 0.034483 val_loss: 0.036582	recall: 0.525785 precision: 0.881579
epoch-3 step 722600/3451022 - loss: 0.036610 val_loss: 0.035551	recall: 0.520904 precision: 0.929435
epoch-3 step 722700/3451022 - loss: 0.041151 val_loss: 0.034884	recall: 0.534730 precision: 0.930902
epoch-3 step 722800/3451022 - loss: 0.038849 val_loss: 0.041218	recall: 0.517084 precision: 0.890196
epoch-3 step 722900/3451022 - loss: 0.038065 val_loss: 0.038013	recall: 0.531603 precision: 0.919922
epoch-3 step 723000/3451022 - loss: 0.034962 val_loss: 0.043834	recall: 0.500000 precision: 0.876923

checkpoint saved

epoch-3 step 723100/3451022 - loss: 0.034984 val_loss: 0.037951	recall: 0.496855 precision: 0.906310
epoch-3 step 723200/3451022 - loss: 0.044310 val_loss: 0.043361	recall: 0.506750 precision: 0.920755
epoch-3 step 723300/3451022 - loss: 0.040707 val_loss: 0.036702	recall: 0.519397 precision: 0.914611
epoch-3 step 723400/3451022 - loss: 0.057980 val_loss: 0.038213	recall: 0.527231 precision: 0.893910
epoch-3 step 723500/3451022 - loss: 0.042312 val_loss: 0.037609	recall: 0.506494 precision: 0.928571
epoch-3 step 723600/3451022 - loss: 0.039003 val_loss: 0.034928	recall: 0.526498 precision: 0.880539
epoch-3 step 723700/3451022 - loss: 0.035399 val_loss: 0.034509	recall: 0.519860 precision: 0.886454
epoch-3 step 723800/3451022 - loss: 0.035330 val_loss: 0.037121	recall: 0.561707 precision: 0.908582
epoch-3 step 723900/3451022 - loss: 0.037871 val_loss: 0.037055	recall: 0.556086 precision: 0.911937
epoch-3 step 724000/3451022 - loss: 0.040968 val_loss: 0.038728	recall: 0.526316 precision: 0.888031

checkpoint saved

epoch-3 step 724100/3451022 - loss: 0.034196 val_loss: 0.036754	recall: 0.531561 precision: 0.916031

model exported!

epoch-3 step 724200/3451022 - loss: 0.033800 val_loss: 0.041584	recall: 0.553311 precision: 0.909594
epoch-3 step 724300/3451022 - loss: 0.034899 val_loss: 0.038719	recall: 0.545763 precision: 0.928846
epoch-3 step 724400/3451022 - loss: 0.037753 val_loss: 0.040977	recall: 0.538202 precision: 0.902072
epoch-3 step 724500/3451022 - loss: 0.039215 val_loss: 0.040448	recall: 0.560947 precision: 0.913295
epoch-3 step 724600/3451022 - loss: 0.036048 val_loss: 0.035357	recall: 0.547592 precision: 0.914019
epoch-3 step 724700/3451022 - loss: 0.047339 val_loss: 0.036230	recall: 0.521935 precision: 0.908023
epoch-3 step 724800/3451022 - loss: 0.037251 val_loss: 0.035233	recall: 0.527313 precision: 0.889098
epoch-3 step 724900/3451022 - loss: 0.037062 val_loss: 0.035443	recall: 0.531492 precision: 0.930368
epoch-3 step 725000/3451022 - loss: 0.037423 val_loss: 0.035341	recall: 0.501059 precision: 0.922027

checkpoint saved

epoch-3 step 725100/3451022 - loss: 0.035935 val_loss: 0.035167	recall: 0.521837 precision: 0.903101
epoch-3 step 725200/3451022 - loss: 0.036220 val_loss: 0.033998	recall: 0.520397 precision: 0.887218
epoch-3 step 725300/3451022 - loss: 0.038677 val_loss: 0.036089	recall: 0.496166 precision: 0.864504
epoch-3 step 725400/3451022 - loss: 0.035604 val_loss: 0.041979	recall: 0.498891 precision: 0.875486
epoch-3 step 725500/3451022 - loss: 0.036631 val_loss: 0.037268	recall: 0.505972 precision: 0.906615
epoch-3 step 725600/3451022 - loss: 0.035504 val_loss: 0.037773	recall: 0.505459 precision: 0.918651
epoch-3 step 725700/3451022 - loss: 0.038675 val_loss: 0.035048	recall: 0.514256 precision: 0.922348
epoch-3 step 725800/3451022 - loss: 0.041575 val_loss: 0.034680	recall: 0.515453 precision: 0.899807
epoch-3 step 725900/3451022 - loss: 0.035230 val_loss: 0.042346	recall: 0.504435 precision: 0.885214
epoch-3 step 726000/3451022 - loss: 0.038694 val_loss: 0.036208	recall: 0.490870 precision: 0.903162

checkpoint saved

epoch-3 step 726100/3451022 - loss: 0.035804 val_loss: 0.034872	recall: 0.555681 precision: 0.921642

model exported!

epoch-3 step 726200/3451022 - loss: 0.035879 val_loss: 0.034182	recall: 0.571767 precision: 0.939571
epoch-3 step 726300/3451022 - loss: 0.040739 val_loss: 0.036949	recall: 0.529343 precision: 0.900200
epoch-3 step 726400/3451022 - loss: 0.034712 val_loss: 0.039320	recall: 0.568743 precision: 0.901304
epoch-3 step 726500/3451022 - loss: 0.038537 val_loss: 0.034531	recall: 0.535550 precision: 0.917485
epoch-3 step 726600/3451022 - loss: 0.034263 val_loss: 0.034696	recall: 0.518600 precision: 0.901141
epoch-3 step 726700/3451022 - loss: 0.042576 val_loss: 0.046150	recall: 0.527621 precision: 0.930417
epoch-3 step 726800/3451022 - loss: 0.035797 val_loss: 0.036781	recall: 0.556818 precision: 0.924528
epoch-3 step 726900/3451022 - loss: 0.035320 val_loss: 0.034305	recall: 0.531510 precision: 0.878193
epoch-3 step 727000/3451022 - loss: 0.035777 val_loss: 0.034960	recall: 0.502812 precision: 0.912245

checkpoint saved

epoch-3 step 727100/3451022 - loss: 0.037441 val_loss: 0.042644	recall: 0.544601 precision: 0.885496
epoch-3 step 727200/3451022 - loss: 0.034964 val_loss: 0.037384	recall: 0.541899 precision: 0.932692
epoch-3 step 727300/3451022 - loss: 0.034847 val_loss: 0.034206	recall: 0.520046 precision: 0.884990
epoch-3 step 727400/3451022 - loss: 0.038256 val_loss: 0.037067	recall: 0.541667 precision: 0.916190
epoch-3 step 727500/3451022 - loss: 0.038843 val_loss: 0.037628	recall: 0.536585 precision: 0.909774
epoch-3 step 727600/3451022 - loss: 0.037147 val_loss: 0.036369	recall: 0.568946 precision: 0.926415
epoch-3 step 727700/3451022 - loss: 0.035497 val_loss: 0.033762	recall: 0.527313 precision: 0.911368
epoch-3 step 727800/3451022 - loss: 0.041365 val_loss: 0.038102	recall: 0.528773 precision: 0.911985
epoch-3 step 727900/3451022 - loss: 0.038801 val_loss: 0.033847	recall: 0.537102 precision: 0.876923
epoch-3 step 728000/3451022 - loss: 0.039492 val_loss: 0.034701	recall: 0.523697 precision: 0.903885

checkpoint saved

epoch-3 step 728100/3451022 - loss: 0.036329 val_loss: 0.038501	recall: 0.509434 precision: 0.922201

model exported!

epoch-3 step 728200/3451022 - loss: 0.037232 val_loss: 0.036654	recall: 0.530055 precision: 0.929119
epoch-3 step 728300/3451022 - loss: 0.038076 val_loss: 0.034623	recall: 0.508179 precision: 0.919132
epoch-3 step 728400/3451022 - loss: 0.033471 val_loss: 0.033348	recall: 0.528620 precision: 0.912791
epoch-3 step 728500/3451022 - loss: 0.035808 val_loss: 0.037043	recall: 0.543353 precision: 0.902111
epoch-3 step 728600/3451022 - loss: 0.038127 val_loss: 0.035536	recall: 0.495925 precision: 0.845238
epoch-3 step 728700/3451022 - loss: 0.038837 val_loss: 0.040692	recall: 0.534183 precision: 0.907480
epoch-3 step 728800/3451022 - loss: 0.040342 val_loss: 0.035955	recall: 0.534699 precision: 0.930693
epoch-3 step 728900/3451022 - loss: 0.036047 val_loss: 0.035009	recall: 0.527936 precision: 0.907843
epoch-3 step 729000/3451022 - loss: 0.036272 val_loss: 0.034095	recall: 0.514884 precision: 0.905039

checkpoint saved

epoch-3 step 729100/3451022 - loss: 0.036865 val_loss: 0.040892	recall: 0.515952 precision: 0.910680
epoch-3 step 729200/3451022 - loss: 0.034706 val_loss: 0.034625	recall: 0.522701 precision: 0.899800
epoch-3 step 729300/3451022 - loss: 0.035925 val_loss: 0.035187	recall: 0.538644 precision: 0.897030
epoch-3 step 729400/3451022 - loss: 0.037077 val_loss: 0.035749	recall: 0.516841 precision: 0.910020
epoch-3 step 729500/3451022 - loss: 0.035186 val_loss: 0.038035	recall: 0.526786 precision: 0.887218
epoch-3 step 729600/3451022 - loss: 0.035071 val_loss: 0.040589	recall: 0.518771 precision: 0.890625
epoch-3 step 729700/3451022 - loss: 0.035368 val_loss: 0.040631	recall: 0.517897 precision: 0.902534
epoch-3 step 729800/3451022 - loss: 0.035978 val_loss: 0.036427	recall: 0.535874 precision: 0.900188
epoch-3 step 729900/3451022 - loss: 0.035842 val_loss: 0.040837	recall: 0.553364 precision: 0.915547
epoch-3 step 730000/3451022 - loss: 0.040361 val_loss: 0.035820	recall: 0.529282 precision: 0.908918

checkpoint saved

epoch-3 step 730100/3451022 - loss: 0.038017 val_loss: 0.035810	recall: 0.527523 precision: 0.901961

model exported!

epoch-3 step 730200/3451022 - loss: 0.038586 val_loss: 0.042090	recall: 0.549327 precision: 0.924528
epoch-3 step 730300/3451022 - loss: 0.035715 val_loss: 0.037774	recall: 0.543142 precision: 0.904236
epoch-3 step 730400/3451022 - loss: 0.033942 val_loss: 0.035638	recall: 0.528620 precision: 0.898855
epoch-3 step 730500/3451022 - loss: 0.033604 val_loss: 0.034396	recall: 0.520087 precision: 0.908918
epoch-3 step 730600/3451022 - loss: 0.035234 val_loss: 0.035024	recall: 0.499455 precision: 0.889320
epoch-3 step 730700/3451022 - loss: 0.041532 val_loss: 0.033843	recall: 0.511732 precision: 0.894531
epoch-3 step 730800/3451022 - loss: 0.035857 val_loss: 0.035203	recall: 0.551370 precision: 0.913043
epoch-3 step 730900/3451022 - loss: 0.038472 val_loss: 0.039096	recall: 0.538634 precision: 0.933981
epoch-3 step 731000/3451022 - loss: 0.036618 val_loss: 0.033691	recall: 0.563177 precision: 0.934132

checkpoint saved

epoch-3 step 731100/3451022 - loss: 0.044968 val_loss: 0.041742	recall: 0.495680 precision: 0.916168
epoch-3 step 731200/3451022 - loss: 0.033532 val_loss: 0.035039	recall: 0.564626 precision: 0.937853
epoch-3 step 731300/3451022 - loss: 0.035633 val_loss: 0.041925	recall: 0.549412 precision: 0.917485
epoch-3 step 731400/3451022 - loss: 0.037906 val_loss: 0.035476	recall: 0.550173 precision: 0.915547
epoch-3 step 731500/3451022 - loss: 0.035713 val_loss: 0.034777	recall: 0.550575 precision: 0.921154
epoch-3 step 731600/3451022 - loss: 0.034686 val_loss: 0.044669	recall: 0.549065 precision: 0.917969
epoch-3 step 731700/3451022 - loss: 0.044379 val_loss: 0.035669	recall: 0.526082 precision: 0.911538
epoch-3 step 731800/3451022 - loss: 0.034463 val_loss: 0.036459	recall: 0.501080 precision: 0.900971
epoch-3 step 731900/3451022 - loss: 0.035057 val_loss: 0.035188	recall: 0.517007 precision: 0.915663
epoch-3 step 732000/3451022 - loss: 0.039757 val_loss: 0.036912	recall: 0.517318 precision: 0.909627

checkpoint saved

epoch-3 step 732100/3451022 - loss: 0.037714 val_loss: 0.036112	recall: 0.540410 precision: 0.894212

model exported!

epoch-3 step 732200/3451022 - loss: 0.036660 val_loss: 0.033992	recall: 0.534404 precision: 0.903101
epoch-3 step 732300/3451022 - loss: 0.047534 val_loss: 0.036139	recall: 0.503911 precision: 0.898406
epoch-3 step 732400/3451022 - loss: 0.033785 val_loss: 0.036084	recall: 0.516609 precision: 0.887795
epoch-3 step 732500/3451022 - loss: 0.037976 val_loss: 0.034255	recall: 0.501131 precision: 0.889558
epoch-3 step 732600/3451022 - loss: 0.034825 val_loss: 0.034036	recall: 0.553452 precision: 0.915285
epoch-3 step 732700/3451022 - loss: 0.035979 val_loss: 0.040267	recall: 0.527072 precision: 0.905123
epoch-3 step 732800/3451022 - loss: 0.034684 val_loss: 0.036632	recall: 0.543253 precision: 0.907514
epoch-3 step 732900/3451022 - loss: 0.035177 val_loss: 0.037261	recall: 0.536613 precision: 0.901923
epoch-3 step 733000/3451022 - loss: 0.034508 val_loss: 0.037695	recall: 0.506064 precision: 0.896484

checkpoint saved

epoch-3 step 733100/3451022 - loss: 0.042011 val_loss: 0.034401	recall: 0.518560 precision: 0.912871
epoch-3 step 733200/3451022 - loss: 0.038478 val_loss: 0.033934	recall: 0.550056 precision: 0.924386
epoch-3 step 733300/3451022 - loss: 0.035122 val_loss: 0.034353	recall: 0.521253 precision: 0.915521
epoch-3 step 733400/3451022 - loss: 0.043071 val_loss: 0.039056	recall: 0.537939 precision: 0.913462
epoch-3 step 733500/3451022 - loss: 0.035202 val_loss: 0.038075	recall: 0.561916 precision: 0.921456
epoch-3 step 733600/3451022 - loss: 0.038737 val_loss: 0.035972	recall: 0.502165 precision: 0.875472
epoch-3 step 733700/3451022 - loss: 0.033967 val_loss: 0.034169	recall: 0.536313 precision: 0.924855
epoch-3 step 733800/3451022 - loss: 0.034519 val_loss: 0.042826	recall: 0.512459 precision: 0.904398
epoch-3 step 733900/3451022 - loss: 0.035232 val_loss: 0.034376	recall: 0.523699 precision: 0.906000
epoch-3 step 734000/3451022 - loss: 0.036887 val_loss: 0.035997	recall: 0.501669 precision: 0.887795

checkpoint saved

epoch-3 step 734100/3451022 - loss: 0.049363 val_loss: 0.037272	recall: 0.534778 precision: 0.921415

model exported!

epoch-3 step 734200/3451022 - loss: 0.037460 val_loss: 0.034215	recall: 0.552480 precision: 0.930097
epoch-3 step 734300/3451022 - loss: 0.033944 val_loss: 0.034722	recall: 0.498932 precision: 0.910331
epoch-3 step 734400/3451022 - loss: 0.035517 val_loss: 0.041453	recall: 0.516949 precision: 0.913858
epoch-3 step 734500/3451022 - loss: 0.034992 val_loss: 0.035352	recall: 0.526316 precision: 0.914286
epoch-3 step 734600/3451022 - loss: 0.033912 val_loss: 0.035870	recall: 0.549312 precision: 0.930097
epoch-3 step 734700/3451022 - loss: 0.036611 val_loss: 0.036068	recall: 0.540387 precision: 0.906489
epoch-3 step 734800/3451022 - loss: 0.034216 val_loss: 0.033963	recall: 0.522602 precision: 0.913295
epoch-3 step 734900/3451022 - loss: 0.035262 val_loss: 0.035786	recall: 0.516892 precision: 0.896484
epoch-3 step 735000/3451022 - loss: 0.034591 val_loss: 0.037553	recall: 0.520487 precision: 0.919765

checkpoint saved

epoch-3 step 735100/3451022 - loss: 0.034985 val_loss: 0.036120	recall: 0.495754 precision: 0.887833
epoch-3 step 735200/3451022 - loss: 0.036010 val_loss: 0.034807	recall: 0.529345 precision: 0.916016
epoch-3 step 735300/3451022 - loss: 0.037072 val_loss: 0.039710	recall: 0.496842 precision: 0.907692
epoch-3 step 735400/3451022 - loss: 0.037287 val_loss: 0.039452	recall: 0.521311 precision: 0.901701
epoch-3 step 735500/3451022 - loss: 0.042092 val_loss: 0.037649	recall: 0.542334 precision: 0.908046
epoch-3 step 735600/3451022 - loss: 0.035342 val_loss: 0.036424	recall: 0.495166 precision: 0.886538
epoch-3 step 735700/3451022 - loss: 0.035332 val_loss: 0.035539	recall: 0.524283 precision: 0.901328
epoch-3 step 735800/3451022 - loss: 0.035757 val_loss: 0.041658	recall: 0.507279 precision: 0.881323
epoch-3 step 735900/3451022 - loss: 0.035417 val_loss: 0.043826	recall: 0.531216 precision: 0.927342
epoch-3 step 736000/3451022 - loss: 0.034328 val_loss: 0.037685	recall: 0.494553 precision: 0.879845

checkpoint saved

epoch-3 step 736100/3451022 - loss: 0.035353 val_loss: 0.034772	recall: 0.516930 precision: 0.905138

model exported!

epoch-3 step 736200/3451022 - loss: 0.035791 val_loss: 0.042173	recall: 0.545143 precision: 0.903409
epoch-3 step 736300/3451022 - loss: 0.039466 val_loss: 0.035391	recall: 0.509269 precision: 0.889524
epoch-3 step 736400/3451022 - loss: 0.040208 val_loss: 0.037937	recall: 0.502697 precision: 0.915521
epoch-3 step 736500/3451022 - loss: 0.038155 val_loss: 0.035158	recall: 0.553431 precision: 0.924812
epoch-3 step 736600/3451022 - loss: 0.036515 val_loss: 0.037288	recall: 0.539891 precision: 0.930320
epoch-3 step 736700/3451022 - loss: 0.035877 val_loss: 0.036469	recall: 0.511206 precision: 0.907197
epoch-3 step 736800/3451022 - loss: 0.034496 val_loss: 0.042176	recall: 0.520000 precision: 0.899065
epoch-3 step 736900/3451022 - loss: 0.035835 val_loss: 0.035562	recall: 0.518232 precision: 0.879925
epoch-3 step 737000/3451022 - loss: 0.037432 val_loss: 0.038801	recall: 0.540929 precision: 0.910615

checkpoint saved

epoch-3 step 737100/3451022 - loss: 0.034660 val_loss: 0.039204	recall: 0.494118 precision: 0.905882
epoch-3 step 737200/3451022 - loss: 0.037991 val_loss: 0.035486	recall: 0.543646 precision: 0.935361
epoch-3 step 737300/3451022 - loss: 0.033873 val_loss: 0.042127	recall: 0.531492 precision: 0.914449
epoch-3 step 737400/3451022 - loss: 0.038479 val_loss: 0.034709	recall: 0.541136 precision: 0.912109
epoch-3 step 737500/3451022 - loss: 0.034712 val_loss: 0.035899	recall: 0.510917 precision: 0.900000
epoch-3 step 737600/3451022 - loss: 0.034817 val_loss: 0.036359	recall: 0.530892 precision: 0.899225
epoch-3 step 737700/3451022 - loss: 0.039274 val_loss: 0.035768	recall: 0.531215 precision: 0.884688
epoch-3 step 737800/3451022 - loss: 0.036062 val_loss: 0.036965	recall: 0.555940 precision: 0.900935
epoch-3 step 737900/3451022 - loss: 0.034626 val_loss: 0.035712	recall: 0.530108 precision: 0.923221
epoch-3 step 738000/3451022 - loss: 0.038068 val_loss: 0.034027	recall: 0.514029 precision: 0.891051

checkpoint saved

epoch-3 step 738100/3451022 - loss: 0.034569 val_loss: 0.037705	recall: 0.525556 precision: 0.907869

model exported!

epoch-3 step 738200/3451022 - loss: 0.036915 val_loss: 0.036697	recall: 0.512735 precision: 0.911417
epoch-3 step 738300/3451022 - loss: 0.035710 val_loss: 0.036300	recall: 0.534562 precision: 0.908023
epoch-3 step 738400/3451022 - loss: 0.034357 val_loss: 0.038078	recall: 0.494983 precision: 0.886228
epoch-3 step 738500/3451022 - loss: 0.035557 val_loss: 0.035703	recall: 0.515186 precision: 0.896282
epoch-3 step 738600/3451022 - loss: 0.034928 val_loss: 0.045844	recall: 0.527421 precision: 0.884540
epoch-3 step 738700/3451022 - loss: 0.035271 val_loss: 0.035630	recall: 0.536697 precision: 0.910506
epoch-3 step 738800/3451022 - loss: 0.039808 val_loss: 0.040724	recall: 0.513453 precision: 0.910537
epoch-3 step 738900/3451022 - loss: 0.037469 val_loss: 0.035980	recall: 0.525727 precision: 0.923379
epoch-3 step 739000/3451022 - loss: 0.034720 val_loss: 0.036521	recall: 0.538291 precision: 0.915094

checkpoint saved

epoch-3 step 739100/3451022 - loss: 0.036461 val_loss: 0.036591	recall: 0.512472 precision: 0.900398
epoch-3 step 739200/3451022 - loss: 0.037945 val_loss: 0.034255	recall: 0.524184 precision: 0.901354
epoch-3 step 739300/3451022 - loss: 0.038413 val_loss: 0.035074	recall: 0.483971 precision: 0.914062
epoch-3 step 739400/3451022 - loss: 0.034514 val_loss: 0.035461	recall: 0.501075 precision: 0.882576
epoch-3 step 739500/3451022 - loss: 0.036665 val_loss: 0.033701	recall: 0.521739 precision: 0.916031
epoch-3 step 739600/3451022 - loss: 0.038788 val_loss: 0.034687	recall: 0.506593 precision: 0.905697
epoch-3 step 739700/3451022 - loss: 0.036291 val_loss: 0.035039	recall: 0.525796 precision: 0.915870
epoch-3 step 739800/3451022 - loss: 0.041441 val_loss: 0.036306	recall: 0.510684 precision: 0.921002
epoch-3 step 739900/3451022 - loss: 0.036492 val_loss: 0.038018	recall: 0.513274 precision: 0.913386
epoch-3 step 740000/3451022 - loss: 0.036198 val_loss: 0.040528	recall: 0.509072 precision: 0.913793

checkpoint saved

epoch-3 step 740100/3451022 - loss: 0.033951 val_loss: 0.040473	recall: 0.529412 precision: 0.919075

model exported!

epoch-3 step 740200/3451022 - loss: 0.034045 val_loss: 0.035976	recall: 0.509804 precision: 0.921260
epoch-3 step 740300/3451022 - loss: 0.048595 val_loss: 0.034673	recall: 0.539090 precision: 0.907662
epoch-3 step 740400/3451022 - loss: 0.034458 val_loss: 0.036666	recall: 0.517052 precision: 0.902111
epoch-3 step 740500/3451022 - loss: 0.035939 val_loss: 0.036446	recall: 0.537705 precision: 0.924812
epoch-3 step 740600/3451022 - loss: 0.040090 val_loss: 0.038555	recall: 0.544643 precision: 0.902033
epoch-3 step 740700/3451022 - loss: 0.035566 val_loss: 0.036677	recall: 0.502720 precision: 0.890173
epoch-3 step 740800/3451022 - loss: 0.034331 val_loss: 0.037032	recall: 0.536165 precision: 0.908560
epoch-3 step 740900/3451022 - loss: 0.034794 val_loss: 0.036571	recall: 0.507480 precision: 0.866405
epoch-3 step 741000/3451022 - loss: 0.038141 val_loss: 0.040603	recall: 0.528935 precision: 0.892578

checkpoint saved

epoch-3 step 741100/3451022 - loss: 0.034687 val_loss: 0.035977	recall: 0.534831 precision: 0.894737
epoch-3 step 741200/3451022 - loss: 0.036997 val_loss: 0.035084	recall: 0.521064 precision: 0.910853
epoch-3 step 741300/3451022 - loss: 0.041847 val_loss: 0.038721	recall: 0.585018 precision: 0.930057
epoch-3 step 741400/3451022 - loss: 0.038977 val_loss: 0.044786	recall: 0.579559 precision: 0.936210
epoch-3 step 741500/3451022 - loss: 0.034694 val_loss: 0.035231	recall: 0.527253 precision: 0.896030
epoch-3 step 741600/3451022 - loss: 0.038097 val_loss: 0.037872	recall: 0.555684 precision: 0.946640
epoch-3 step 741700/3451022 - loss: 0.035480 val_loss: 0.034948	recall: 0.537844 precision: 0.926877
epoch-3 step 741800/3451022 - loss: 0.035702 val_loss: 0.034006	recall: 0.558926 precision: 0.921154
epoch-3 step 741900/3451022 - loss: 0.036216 val_loss: 0.044128	recall: 0.515487 precision: 0.891013
epoch-3 step 742000/3451022 - loss: 0.042472 val_loss: 0.036533	recall: 0.525442 precision: 0.915222

checkpoint saved

epoch-3 step 742100/3451022 - loss: 0.039444 val_loss: 0.039662	recall: 0.532350 precision: 0.916016

model exported!

epoch-3 step 742200/3451022 - loss: 0.036843 val_loss: 0.046420	recall: 0.511261 precision: 0.888454
epoch-3 step 742300/3451022 - loss: 0.036203 val_loss: 0.037802	recall: 0.488372 precision: 0.900585
epoch-3 step 742400/3451022 - loss: 0.034729 val_loss: 0.035063	recall: 0.546171 precision: 0.896488
epoch-3 step 742500/3451022 - loss: 0.035485 val_loss: 0.038421	recall: 0.511086 precision: 0.886538
epoch-3 step 742600/3451022 - loss: 0.034410 val_loss: 0.034725	recall: 0.532597 precision: 0.902622
epoch-3 step 742700/3451022 - loss: 0.035657 val_loss: 0.039141	recall: 0.527748 precision: 0.911654
epoch-3 step 742800/3451022 - loss: 0.035126 val_loss: 0.041006	recall: 0.537757 precision: 0.895238
epoch-3 step 742900/3451022 - loss: 0.038105 val_loss: 0.038175	recall: 0.558382 precision: 0.904494
epoch-3 step 743000/3451022 - loss: 0.035860 val_loss: 0.038837	recall: 0.528814 precision: 0.888046

checkpoint saved

epoch-3 step 743100/3451022 - loss: 0.034927 val_loss: 0.036632	recall: 0.512277 precision: 0.887814
epoch-3 step 743200/3451022 - loss: 0.037153 val_loss: 0.034483	recall: 0.549550 precision: 0.925996
epoch-3 step 743300/3451022 - loss: 0.037168 val_loss: 0.035591	recall: 0.531963 precision: 0.908382
epoch-3 step 743400/3451022 - loss: 0.034750 val_loss: 0.043093	recall: 0.531940 precision: 0.906931
epoch-3 step 743500/3451022 - loss: 0.034979 val_loss: 0.034507	recall: 0.527473 precision: 0.930233
epoch-3 step 743600/3451022 - loss: 0.038093 val_loss: 0.036250	recall: 0.516022 precision: 0.919291
epoch-3 step 743700/3451022 - loss: 0.040534 val_loss: 0.038326	recall: 0.509249 precision: 0.919450
epoch-3 step 743800/3451022 - loss: 0.036154 val_loss: 0.041743	recall: 0.503834 precision: 0.879541
epoch-3 step 743900/3451022 - loss: 0.035506 val_loss: 0.035866	recall: 0.520833 precision: 0.903042
epoch-3 step 744000/3451022 - loss: 0.035186 val_loss: 0.036664	recall: 0.509761 precision: 0.905588

checkpoint saved

epoch-3 step 744100/3451022 - loss: 0.034156 val_loss: 0.036487	recall: 0.515541 precision: 0.930368

model exported!

epoch-3 step 744200/3451022 - loss: 0.036723 val_loss: 0.044306	recall: 0.504875 precision: 0.903101
epoch-3 step 744300/3451022 - loss: 0.038906 val_loss: 0.039672	recall: 0.520219 precision: 0.906667
epoch-3 step 744400/3451022 - loss: 0.035011 val_loss: 0.041163	recall: 0.536782 precision: 0.901544
epoch-3 step 744500/3451022 - loss: 0.036762 val_loss: 0.035123	recall: 0.530405 precision: 0.914563
epoch-3 step 744600/3451022 - loss: 0.036381 val_loss: 0.037086	recall: 0.508399 precision: 0.897233
epoch-3 step 744700/3451022 - loss: 0.036693 val_loss: 0.034242	recall: 0.543023 precision: 0.892925
epoch-3 step 744800/3451022 - loss: 0.035833 val_loss: 0.034302	recall: 0.530134 precision: 0.922330
epoch-3 step 744900/3451022 - loss: 0.035902 val_loss: 0.034989	recall: 0.531501 precision: 0.904483
epoch-3 step 745000/3451022 - loss: 0.033837 val_loss: 0.047005	recall: 0.525612 precision: 0.899048

checkpoint saved

epoch-3 step 745100/3451022 - loss: 0.036045 val_loss: 0.034952	recall: 0.515744 precision: 0.927734
epoch-3 step 745200/3451022 - loss: 0.035917 val_loss: 0.042354	recall: 0.535461 precision: 0.898810
epoch-3 step 745300/3451022 - loss: 0.036902 val_loss: 0.034710	recall: 0.497219 precision: 0.904858
epoch-3 step 745400/3451022 - loss: 0.036591 val_loss: 0.035461	recall: 0.535477 precision: 0.918251
epoch-3 step 745500/3451022 - loss: 0.036323 val_loss: 0.037048	recall: 0.524807 precision: 0.924272
epoch-3 step 745600/3451022 - loss: 0.034806 val_loss: 0.038969	recall: 0.550296 precision: 0.897683
epoch-3 step 745700/3451022 - loss: 0.035896 val_loss: 0.035330	recall: 0.546591 precision: 0.904135
epoch-3 step 745800/3451022 - loss: 0.037600 val_loss: 0.033959	recall: 0.510615 precision: 0.901381
epoch-3 step 745900/3451022 - loss: 0.036973 val_loss: 0.034821	recall: 0.523590 precision: 0.888672
epoch-3 step 746000/3451022 - loss: 0.035324 val_loss: 0.036302	recall: 0.500524 precision: 0.903592

checkpoint saved

epoch-3 step 746100/3451022 - loss: 0.036601 val_loss: 0.035278	recall: 0.536047 precision: 0.900391

model exported!

epoch-3 step 746200/3451022 - loss: 0.041545 val_loss: 0.034663	recall: 0.503212 precision: 0.883459
epoch-3 step 746300/3451022 - loss: 0.035784 val_loss: 0.035261	recall: 0.533024 precision: 0.889749
epoch-3 step 746400/3451022 - loss: 0.035268 val_loss: 0.036735	recall: 0.543269 precision: 0.902196
epoch-3 step 746500/3451022 - loss: 0.035769 val_loss: 0.034989	recall: 0.529478 precision: 0.884470
epoch-3 step 746600/3451022 - loss: 0.035229 val_loss: 0.034381	recall: 0.513948 precision: 0.882136
epoch-3 step 746700/3451022 - loss: 0.035493 val_loss: 0.037018	recall: 0.535635 precision: 0.928571
epoch-3 step 746800/3451022 - loss: 0.034239 val_loss: 0.038847	recall: 0.516667 precision: 0.894231
epoch-3 step 746900/3451022 - loss: 0.034299 val_loss: 0.043833	recall: 0.540894 precision: 0.913444
epoch-3 step 747000/3451022 - loss: 0.039401 val_loss: 0.041018	recall: 0.511864 precision: 0.888235

checkpoint saved

epoch-3 step 747100/3451022 - loss: 0.044835 val_loss: 0.040965	recall: 0.543182 precision: 0.931774
epoch-3 step 747200/3451022 - loss: 0.036132 val_loss: 0.034198	recall: 0.517127 precision: 0.917647
epoch-3 step 747300/3451022 - loss: 0.039446 val_loss: 0.035459	recall: 0.523060 precision: 0.911765
epoch-3 step 747400/3451022 - loss: 0.036172 val_loss: 0.035278	recall: 0.535477 precision: 0.916509
epoch-3 step 747500/3451022 - loss: 0.037098 val_loss: 0.038866	recall: 0.518561 precision: 0.886905
epoch-3 step 747600/3451022 - loss: 0.038692 val_loss: 0.036142	recall: 0.494994 precision: 0.900810
epoch-3 step 747700/3451022 - loss: 0.034417 val_loss: 0.033915	recall: 0.526549 precision: 0.922481
epoch-3 step 747800/3451022 - loss: 0.033536 val_loss: 0.038203	recall: 0.521143 precision: 0.888889
epoch-3 step 747900/3451022 - loss: 0.037788 val_loss: 0.037482	recall: 0.553965 precision: 0.916211
epoch-3 step 748000/3451022 - loss: 0.039472 val_loss: 0.035510	recall: 0.537778 precision: 0.925430

checkpoint saved

epoch-3 step 748100/3451022 - loss: 0.034719 val_loss: 0.036378	recall: 0.548280 precision: 0.913124

model exported!

epoch-3 step 748200/3451022 - loss: 0.038085 val_loss: 0.041916	recall: 0.515419 precision: 0.908738
epoch-3 step 748300/3451022 - loss: 0.036266 val_loss: 0.036236	recall: 0.519318 precision: 0.882239
epoch-3 step 748400/3451022 - loss: 0.036397 val_loss: 0.035091	recall: 0.554651 precision: 0.913793
epoch-3 step 748500/3451022 - loss: 0.036107 val_loss: 0.035091	recall: 0.532294 precision: 0.919231
epoch-3 step 748600/3451022 - loss: 0.037331 val_loss: 0.038549	recall: 0.512878 precision: 0.899804
epoch-3 step 748700/3451022 - loss: 0.035060 val_loss: 0.038148	recall: 0.535461 precision: 0.904192
epoch-3 step 748800/3451022 - loss: 0.036105 val_loss: 0.040629	recall: 0.544393 precision: 0.897881
epoch-3 step 748900/3451022 - loss: 0.034819 val_loss: 0.034390	recall: 0.538198 precision: 0.907692
epoch-3 step 749000/3451022 - loss: 0.034942 val_loss: 0.034733	recall: 0.519737 precision: 0.896030

checkpoint saved

epoch-3 step 749100/3451022 - loss: 0.038154 val_loss: 0.034347	recall: 0.532438 precision: 0.924272
epoch-3 step 749200/3451022 - loss: 0.034395 val_loss: 0.035493	recall: 0.528539 precision: 0.892100
epoch-3 step 749300/3451022 - loss: 0.036086 val_loss: 0.035371	recall: 0.578419 precision: 0.927565
epoch-3 step 749400/3451022 - loss: 0.035195 val_loss: 0.034506	recall: 0.520174 precision: 0.913793
epoch-3 step 749500/3451022 - loss: 0.034439 val_loss: 0.042666	recall: 0.526869 precision: 0.907445
epoch-3 step 749600/3451022 - loss: 0.034070 val_loss: 0.034487	recall: 0.523862 precision: 0.905950
epoch-3 step 749700/3451022 - loss: 0.039337 val_loss: 0.038807	recall: 0.554273 precision: 0.930233
epoch-3 step 749800/3451022 - loss: 0.039391 val_loss: 0.036062	recall: 0.545984 precision: 0.916016
epoch-3 step 749900/3451022 - loss: 0.034980 val_loss: 0.038374	recall: 0.495082 precision: 0.889980
epoch-3 step 750000/3451022 - loss: 0.036503 val_loss: 0.038116	recall: 0.540636 precision: 0.900000

checkpoint saved

epoch-3 step 750100/3451022 - loss: 0.035444 val_loss: 0.036122	recall: 0.511364 precision: 0.896414

model exported!

epoch-3 step 750200/3451022 - loss: 0.035796 val_loss: 0.036906	recall: 0.523596 precision: 0.885932
epoch-3 step 750300/3451022 - loss: 0.035504 val_loss: 0.034542	recall: 0.546189 precision: 0.913127
epoch-3 step 750400/3451022 - loss: 0.035721 val_loss: 0.036760	recall: 0.542393 precision: 0.908560
epoch-3 step 750500/3451022 - loss: 0.034555 val_loss: 0.043968	recall: 0.504396 precision: 0.875954
epoch-3 step 750600/3451022 - loss: 0.034416 val_loss: 0.040244	recall: 0.518805 precision: 0.917808
epoch-3 step 750700/3451022 - loss: 0.041463 val_loss: 0.035160	recall: 0.530269 precision: 0.900952
epoch-3 step 750800/3451022 - loss: 0.037858 val_loss: 0.037405	recall: 0.515676 precision: 0.884972
epoch-3 step 750900/3451022 - loss: 0.040622 val_loss: 0.037012	recall: 0.493841 precision: 0.887324
epoch-3 step 751000/3451022 - loss: 0.035455 val_loss: 0.037447	recall: 0.521064 precision: 0.909091

checkpoint saved

epoch-3 step 751100/3451022 - loss: 0.036630 val_loss: 0.035193	recall: 0.540793 precision: 0.915187
epoch-3 step 751200/3451022 - loss: 0.035404 val_loss: 0.035628	recall: 0.536557 precision: 0.902778
epoch-3 step 751300/3451022 - loss: 0.034690 val_loss: 0.039126	recall: 0.534778 precision: 0.896750
epoch-3 step 751400/3451022 - loss: 0.035496 val_loss: 0.045308	recall: 0.551163 precision: 0.918605
epoch-3 step 751500/3451022 - loss: 0.047706 val_loss: 0.035853	recall: 0.535963 precision: 0.898833
epoch-3 step 751600/3451022 - loss: 0.036167 val_loss: 0.034340	recall: 0.571259 precision: 0.925000
epoch-3 step 751700/3451022 - loss: 0.034428 val_loss: 0.036703	recall: 0.550415 precision: 0.900971
epoch-3 step 751800/3451022 - loss: 0.046379 val_loss: 0.033978	recall: 0.492616 precision: 0.919291
epoch-3 step 751900/3451022 - loss: 0.036837 val_loss: 0.035861	recall: 0.532164 precision: 0.906375
epoch-3 step 752000/3451022 - loss: 0.065485 val_loss: 0.035843	recall: 0.520642 precision: 0.906188

checkpoint saved

epoch-3 step 752100/3451022 - loss: 0.038000 val_loss: 0.036558	recall: 0.538895 precision: 0.910476

model exported!

epoch-3 step 752200/3451022 - loss: 0.044976 val_loss: 0.034548	recall: 0.547727 precision: 0.911153
epoch-3 step 752300/3451022 - loss: 0.036776 val_loss: 0.042585	recall: 0.526726 precision: 0.904398
epoch-3 step 752400/3451022 - loss: 0.036058 val_loss: 0.036179	recall: 0.548652 precision: 0.901734
epoch-3 step 752500/3451022 - loss: 0.036913 val_loss: 0.034562	recall: 0.496753 precision: 0.905325
epoch-3 step 752600/3451022 - loss: 0.038086 val_loss: 0.038359	recall: 0.535461 precision: 0.897030
epoch-3 step 752700/3451022 - loss: 0.037613 val_loss: 0.037227	recall: 0.552723 precision: 0.898305
epoch-3 step 752800/3451022 - loss: 0.036193 val_loss: 0.038100	recall: 0.516274 precision: 0.903733
epoch-3 step 752900/3451022 - loss: 0.037141 val_loss: 0.035917	recall: 0.542529 precision: 0.905950
epoch-3 step 753000/3451022 - loss: 0.039288 val_loss: 0.035096	recall: 0.511186 precision: 0.889105

checkpoint saved

epoch-3 step 753100/3451022 - loss: 0.039170 val_loss: 0.041728	recall: 0.514541 precision: 0.901961
epoch-3 step 753200/3451022 - loss: 0.036541 val_loss: 0.036039	recall: 0.519252 precision: 0.927308
epoch-3 step 753300/3451022 - loss: 0.036553 val_loss: 0.043407	recall: 0.547646 precision: 0.908571
epoch-3 step 753400/3451022 - loss: 0.035331 val_loss: 0.035216	recall: 0.543624 precision: 0.929254
epoch-3 step 753500/3451022 - loss: 0.044605 val_loss: 0.038854	recall: 0.523385 precision: 0.927022
epoch-3 step 753600/3451022 - loss: 0.035284 val_loss: 0.036086	recall: 0.533120 precision: 0.915596
epoch-3 step 753700/3451022 - loss: 0.037526 val_loss: 0.036183	recall: 0.488197 precision: 0.861742
epoch-3 step 753800/3451022 - loss: 0.035098 val_loss: 0.035758	recall: 0.485169 precision: 0.877395
epoch-3 step 753900/3451022 - loss: 0.035841 val_loss: 0.038252	recall: 0.520690 precision: 0.897030
epoch-3 step 754000/3451022 - loss: 0.041307 val_loss: 0.037607	recall: 0.525366 precision: 0.869403

checkpoint saved

epoch-3 step 754100/3451022 - loss: 0.038267 val_loss: 0.039083	recall: 0.510248 precision: 0.906130

model exported!

epoch-3 step 754200/3451022 - loss: 0.035947 val_loss: 0.041602	recall: 0.530223 precision: 0.941620
epoch-3 step 754300/3451022 - loss: 0.033932 val_loss: 0.034239	recall: 0.510823 precision: 0.890566
epoch-3 step 754400/3451022 - loss: 0.037652 val_loss: 0.042243	recall: 0.547866 precision: 0.929550
epoch-3 step 754500/3451022 - loss: 0.035412 val_loss: 0.039511	recall: 0.513543 precision: 0.929412
epoch-3 step 754600/3451022 - loss: 0.046850 val_loss: 0.034714	recall: 0.494565 precision: 0.895669
epoch-3 step 754700/3451022 - loss: 0.036240 val_loss: 0.040667	recall: 0.524590 precision: 0.909091
epoch-3 step 754800/3451022 - loss: 0.035276 val_loss: 0.035874	recall: 0.503165 precision: 0.901701
epoch-3 step 754900/3451022 - loss: 0.043018 val_loss: 0.039092	recall: 0.543839 precision: 0.919840
epoch-3 step 755000/3451022 - loss: 0.035284 val_loss: 0.043301	recall: 0.496815 precision: 0.886364

checkpoint saved

epoch-3 step 755100/3451022 - loss: 0.040227 val_loss: 0.038355	recall: 0.529933 precision: 0.905303
epoch-3 step 755200/3451022 - loss: 0.040513 val_loss: 0.037037	recall: 0.541345 precision: 0.919476
epoch-3 step 755300/3451022 - loss: 0.033832 val_loss: 0.038092	recall: 0.518847 precision: 0.928571
epoch-3 step 755400/3451022 - loss: 0.036459 val_loss: 0.035802	recall: 0.514092 precision: 0.919355
epoch-3 step 755500/3451022 - loss: 0.038628 val_loss: 0.037878	recall: 0.569106 precision: 0.926276
epoch-3 step 755600/3451022 - loss: 0.042979 val_loss: 0.037905	recall: 0.500000 precision: 0.895349
epoch-3 step 755700/3451022 - loss: 0.036869 val_loss: 0.043037	recall: 0.498371 precision: 0.905325
epoch-3 step 755800/3451022 - loss: 0.043028 val_loss: 0.039052	recall: 0.537946 precision: 0.904315
epoch-3 step 755900/3451022 - loss: 0.037539 val_loss: 0.035425	recall: 0.536117 precision: 0.915222
epoch-3 step 756000/3451022 - loss: 0.040566 val_loss: 0.035340	recall: 0.524168 precision: 0.917293

checkpoint saved

epoch-3 step 756100/3451022 - loss: 0.035877 val_loss: 0.045476	recall: 0.490831 precision: 0.893910

model exported!

epoch-3 step 756200/3451022 - loss: 0.035601 val_loss: 0.036671	recall: 0.502128 precision: 0.927308
epoch-3 step 756300/3451022 - loss: 0.036365 val_loss: 0.035980	recall: 0.515952 precision: 0.910680
epoch-3 step 756400/3451022 - loss: 0.037997 val_loss: 0.038029	recall: 0.523962 precision: 0.912801
epoch-3 step 756500/3451022 - loss: 0.034749 val_loss: 0.036259	recall: 0.522404 precision: 0.917466
epoch-3 step 756600/3451022 - loss: 0.036347 val_loss: 0.035817	recall: 0.507870 precision: 0.892989
epoch-3 step 756700/3451022 - loss: 0.035774 val_loss: 0.038430	recall: 0.527746 precision: 0.894434
epoch-3 step 756800/3451022 - loss: 0.036958 val_loss: 0.037303	recall: 0.514221 precision: 0.889764
epoch-3 step 756900/3451022 - loss: 0.038712 val_loss: 0.041162	recall: 0.498941 precision: 0.895437
epoch-3 step 757000/3451022 - loss: 0.034505 val_loss: 0.038473	recall: 0.557625 precision: 0.922929

checkpoint saved

epoch-3 step 757100/3451022 - loss: 0.036075 val_loss: 0.034896	recall: 0.530405 precision: 0.918129
epoch-3 step 757200/3451022 - loss: 0.036615 val_loss: 0.035864	recall: 0.516556 precision: 0.908738
epoch-3 step 757300/3451022 - loss: 0.035881 val_loss: 0.034809	recall: 0.541758 precision: 0.906250
epoch-3 step 757400/3451022 - loss: 0.034357 val_loss: 0.038663	recall: 0.540839 precision: 0.940499
epoch-3 step 757500/3451022 - loss: 0.034135 val_loss: 0.035685	recall: 0.509029 precision: 0.879142
epoch-3 step 757600/3451022 - loss: 0.035382 val_loss: 0.034189	recall: 0.560976 precision: 0.927063
epoch-3 step 757700/3451022 - loss: 0.034290 val_loss: 0.034744	recall: 0.522854 precision: 0.889943
epoch-3 step 757800/3451022 - loss: 0.041777 val_loss: 0.041724	recall: 0.536313 precision: 0.924855
epoch-3 step 757900/3451022 - loss: 0.036301 val_loss: 0.036126	recall: 0.538186 precision: 0.905622
epoch-3 step 758000/3451022 - loss: 0.035006 val_loss: 0.039581	recall: 0.516347 precision: 0.905138

checkpoint saved

epoch-3 step 758100/3451022 - loss: 0.034775 val_loss: 0.034202	recall: 0.543820 precision: 0.939806

model exported!

epoch-3 step 758200/3451022 - loss: 0.037049 val_loss: 0.033781	recall: 0.526018 precision: 0.902913
epoch-3 step 758300/3451022 - loss: 0.038235 val_loss: 0.034463	recall: 0.514226 precision: 0.920755
epoch-3 step 758400/3451022 - loss: 0.038687 val_loss: 0.038535	recall: 0.519252 precision: 0.893939
epoch-3 step 758500/3451022 - loss: 0.036351 val_loss: 0.035684	recall: 0.546318 precision: 0.889749
epoch-3 step 758600/3451022 - loss: 0.040081 val_loss: 0.036376	recall: 0.525727 precision: 0.919765
epoch-3 step 758700/3451022 - loss: 0.034758 val_loss: 0.034994	recall: 0.519337 precision: 0.916179
epoch-3 step 758800/3451022 - loss: 0.038257 val_loss: 0.033930	recall: 0.533035 precision: 0.884758
epoch-3 step 758900/3451022 - loss: 0.035755 val_loss: 0.036129	recall: 0.508021 precision: 0.920543
epoch-3 step 759000/3451022 - loss: 0.037169 val_loss: 0.036965	recall: 0.542889 precision: 0.905838

checkpoint saved

epoch-3 step 759100/3451022 - loss: 0.034594 val_loss: 0.039261	recall: 0.512249 precision: 0.893204
epoch-3 step 759200/3451022 - loss: 0.037431 val_loss: 0.046819	recall: 0.522084 precision: 0.903922
epoch-3 step 759300/3451022 - loss: 0.036648 val_loss: 0.038741	recall: 0.536527 precision: 0.883629
epoch-3 step 759400/3451022 - loss: 0.034057 val_loss: 0.035521	recall: 0.555297 precision: 0.908571
epoch-3 step 759500/3451022 - loss: 0.037802 val_loss: 0.040869	recall: 0.553738 precision: 0.909789
epoch-3 step 759600/3451022 - loss: 0.038362 val_loss: 0.035070	recall: 0.546605 precision: 0.881262
epoch-3 step 759700/3451022 - loss: 0.037700 val_loss: 0.035517	recall: 0.515952 precision: 0.905405
epoch-3 step 759800/3451022 - loss: 0.037170 val_loss: 0.035361	recall: 0.557452 precision: 0.914179
epoch-3 step 759900/3451022 - loss: 0.043308 val_loss: 0.040591	recall: 0.522491 precision: 0.895257
epoch-3 step 760000/3451022 - loss: 0.034198 val_loss: 0.036587	recall: 0.534247 precision: 0.905222

checkpoint saved

epoch-3 step 760100/3451022 - loss: 0.034880 val_loss: 0.034583	recall: 0.534584 precision: 0.892368

model exported!

epoch-3 step 760200/3451022 - loss: 0.045321 val_loss: 0.039679	recall: 0.537017 precision: 0.890110
epoch-3 step 760300/3451022 - loss: 0.035022 val_loss: 0.035939	recall: 0.553409 precision: 0.908582
epoch-3 step 760400/3451022 - loss: 0.038459 val_loss: 0.033809	recall: 0.525386 precision: 0.903226
epoch-3 step 760500/3451022 - loss: 0.040102 val_loss: 0.037525	recall: 0.547733 precision: 0.905325
epoch-3 step 760600/3451022 - loss: 0.038593 val_loss: 0.035365	recall: 0.534857 precision: 0.891429
epoch-3 step 760700/3451022 - loss: 0.038475 val_loss: 0.036518	recall: 0.540023 precision: 0.897004
epoch-3 step 760800/3451022 - loss: 0.035322 val_loss: 0.041148	recall: 0.551683 precision: 0.896484
epoch-3 step 760900/3451022 - loss: 0.044098 val_loss: 0.040206	recall: 0.537853 precision: 0.899811
epoch-3 step 761000/3451022 - loss: 0.034464 val_loss: 0.034541	recall: 0.502347 precision: 0.859438

checkpoint saved

epoch-3 step 761100/3451022 - loss: 0.048198 val_loss: 0.034851	recall: 0.503158 precision: 0.913958
epoch-3 step 761200/3451022 - loss: 0.034151 val_loss: 0.039971	recall: 0.536697 precision: 0.919450
epoch-3 step 761300/3451022 - loss: 0.035592 val_loss: 0.038188	recall: 0.520533 precision: 0.905405
epoch-3 step 761400/3451022 - loss: 0.036665 val_loss: 0.038237	recall: 0.505285 precision: 0.919231
epoch-3 step 761500/3451022 - loss: 0.039602 val_loss: 0.035579	recall: 0.494949 precision: 0.896341
epoch-3 step 761600/3451022 - loss: 0.038390 val_loss: 0.034716	recall: 0.540632 precision: 0.922929
epoch-3 step 761700/3451022 - loss: 0.043096 val_loss: 0.035031	recall: 0.527352 precision: 0.921606
epoch-3 step 761800/3451022 - loss: 0.035268 val_loss: 0.035201	recall: 0.519466 precision: 0.901544
epoch-3 step 761900/3451022 - loss: 0.038484 val_loss: 0.037248	recall: 0.519651 precision: 0.915385
epoch-3 step 762000/3451022 - loss: 0.035906 val_loss: 0.035247	recall: 0.504994 precision: 0.902778

checkpoint saved

epoch-3 step 762100/3451022 - loss: 0.036196 val_loss: 0.035468	recall: 0.554410 precision: 0.930769

model exported!

epoch-3 step 762200/3451022 - loss: 0.038763 val_loss: 0.038293	recall: 0.523810 precision: 0.904110
epoch-3 step 762300/3451022 - loss: 0.034763 val_loss: 0.036074	recall: 0.537514 precision: 0.919540
epoch-3 step 762400/3451022 - loss: 0.035508 val_loss: 0.037648	recall: 0.494054 precision: 0.901381
epoch-3 step 762500/3451022 - loss: 0.035365 val_loss: 0.035705	recall: 0.512486 precision: 0.918288
epoch-3 step 762600/3451022 - loss: 0.035424 val_loss: 0.034296	recall: 0.514950 precision: 0.892514
epoch-3 step 762700/3451022 - loss: 0.041608 val_loss: 0.057098	recall: 0.523164 precision: 0.895551
epoch-3 step 762800/3451022 - loss: 0.035069 val_loss: 0.036086	recall: 0.531080 precision: 0.918868
epoch-3 step 762900/3451022 - loss: 0.035598 val_loss: 0.041534	recall: 0.517014 precision: 0.914563
epoch-3 step 763000/3451022 - loss: 0.040073 val_loss: 0.034162	recall: 0.531111 precision: 0.922780

checkpoint saved

epoch-3 step 763100/3451022 - loss: 0.046953 val_loss: 0.035055	recall: 0.511302 precision: 0.915222
epoch-3 step 763200/3451022 - loss: 0.035179 val_loss: 0.040913	recall: 0.543298 precision: 0.894531
epoch-3 step 763300/3451022 - loss: 0.036020 val_loss: 0.034424	recall: 0.546821 precision: 0.909615
epoch-3 step 763400/3451022 - loss: 0.034135 val_loss: 0.038968	recall: 0.561343 precision: 0.913371
epoch-3 step 763500/3451022 - loss: 0.034398 val_loss: 0.035650	recall: 0.497849 precision: 0.906067
epoch-3 step 763600/3451022 - loss: 0.034795 val_loss: 0.035523	recall: 0.519466 precision: 0.886148
epoch-3 step 763700/3451022 - loss: 0.034941 val_loss: 0.043216	recall: 0.519912 precision: 0.891841
epoch-3 step 763800/3451022 - loss: 0.037279 val_loss: 0.035411	recall: 0.543527 precision: 0.931166
epoch-3 step 763900/3451022 - loss: 0.041144 val_loss: 0.037048	recall: 0.534730 precision: 0.913371
epoch-3 step 764000/3451022 - loss: 0.035577 val_loss: 0.036458	recall: 0.529944 precision: 0.878277

checkpoint saved

epoch-3 step 764100/3451022 - loss: 0.035317 val_loss: 0.034883	recall: 0.487404 precision: 0.893574

model exported!

epoch-3 step 764200/3451022 - loss: 0.036629 val_loss: 0.039389	recall: 0.492600 precision: 0.899614
epoch-3 step 764300/3451022 - loss: 0.041589 val_loss: 0.037877	recall: 0.530769 precision: 0.909605
epoch-3 step 764400/3451022 - loss: 0.036299 val_loss: 0.045328	recall: 0.521300 precision: 0.902913
epoch-3 step 764500/3451022 - loss: 0.035890 val_loss: 0.036058	recall: 0.513234 precision: 0.908350
epoch-3 step 764600/3451022 - loss: 0.036955 val_loss: 0.036597	recall: 0.523543 precision: 0.912109
epoch-3 step 764700/3451022 - loss: 0.035059 val_loss: 0.036570	recall: 0.533860 precision: 0.904398
epoch-3 step 764800/3451022 - loss: 0.038896 val_loss: 0.034824	recall: 0.545861 precision: 0.934866
epoch-3 step 764900/3451022 - loss: 0.036430 val_loss: 0.034511	recall: 0.536281 precision: 0.931102
epoch-3 step 765000/3451022 - loss: 0.035691 val_loss: 0.039231	recall: 0.546075 precision: 0.917782

checkpoint saved

epoch-3 step 765100/3451022 - loss: 0.035579 val_loss: 0.034826	recall: 0.495208 precision: 0.908203
epoch-3 step 765200/3451022 - loss: 0.035675 val_loss: 0.044119	recall: 0.511838 precision: 0.893701
epoch-3 step 765300/3451022 - loss: 0.042817 val_loss: 0.034716	recall: 0.536612 precision: 0.916045
epoch-3 step 765400/3451022 - loss: 0.041061 val_loss: 0.034990	recall: 0.521542 precision: 0.901961
epoch-3 step 765500/3451022 - loss: 0.035182 val_loss: 0.035202	recall: 0.534368 precision: 0.899254
epoch-3 step 765600/3451022 - loss: 0.036646 val_loss: 0.034500	recall: 0.504320 precision: 0.896353
epoch-3 step 765700/3451022 - loss: 0.036800 val_loss: 0.037916	recall: 0.521081 precision: 0.906015
epoch-3 step 765800/3451022 - loss: 0.036101 val_loss: 0.036932	recall: 0.542237 precision: 0.935039
epoch-3 step 765900/3451022 - loss: 0.036769 val_loss: 0.043837	recall: 0.503386 precision: 0.908350
epoch-3 step 766000/3451022 - loss: 0.034310 val_loss: 0.038087	recall: 0.518018 precision: 0.871212

checkpoint saved

epoch-3 step 766100/3451022 - loss: 0.034207 val_loss: 0.034511	recall: 0.559538 precision: 0.927203

model exported!

epoch-3 step 766200/3451022 - loss: 0.041622 val_loss: 0.035080	recall: 0.521348 precision: 0.900971
epoch-3 step 766300/3451022 - loss: 0.037953 val_loss: 0.035578	recall: 0.525481 precision: 0.902724
epoch-3 step 766400/3451022 - loss: 0.037558 val_loss: 0.035745	recall: 0.514069 precision: 0.899621
epoch-3 step 766500/3451022 - loss: 0.061432 val_loss: 0.036290	recall: 0.527273 precision: 0.930189
epoch-3 step 766600/3451022 - loss: 0.037623 val_loss: 0.035917	recall: 0.532823 precision: 0.891941
epoch-3 step 766700/3451022 - loss: 0.034351 val_loss: 0.038416	recall: 0.534231 precision: 0.908397
epoch-3 step 766800/3451022 - loss: 0.035379 val_loss: 0.035420	recall: 0.531390 precision: 0.902857
epoch-3 step 766900/3451022 - loss: 0.035694 val_loss: 0.041302	recall: 0.529010 precision: 0.928144
epoch-3 step 767000/3451022 - loss: 0.035913 val_loss: 0.035047	recall: 0.535117 precision: 0.932039

checkpoint saved

epoch-3 step 767100/3451022 - loss: 0.038634 val_loss: 0.038278	recall: 0.528761 precision: 0.922780
epoch-3 step 767200/3451022 - loss: 0.035248 val_loss: 0.037315	recall: 0.516667 precision: 0.920792
epoch-3 step 767300/3451022 - loss: 0.035511 val_loss: 0.035279	recall: 0.536215 precision: 0.905325
epoch-3 step 767400/3451022 - loss: 0.035329 val_loss: 0.034837	recall: 0.528217 precision: 0.893130
epoch-3 step 767500/3451022 - loss: 0.035772 val_loss: 0.035580	recall: 0.484581 precision: 0.874751
epoch-3 step 767600/3451022 - loss: 0.035974 val_loss: 0.035210	recall: 0.543757 precision: 0.915521
epoch-3 step 767700/3451022 - loss: 0.037368 val_loss: 0.044151	recall: 0.529954 precision: 0.896686
epoch-3 step 767800/3451022 - loss: 0.034449 val_loss: 0.035829	recall: 0.531573 precision: 0.890385
epoch-3 step 767900/3451022 - loss: 0.034511 val_loss: 0.035121	recall: 0.504357 precision: 0.900778
epoch-3 step 768000/3451022 - loss: 0.038522 val_loss: 0.035328	recall: 0.520624 precision: 0.898077

checkpoint saved

epoch-3 step 768100/3451022 - loss: 0.035613 val_loss: 0.038499	recall: 0.496862 precision: 0.892857

model exported!

epoch-3 step 768200/3451022 - loss: 0.040237 val_loss: 0.042210	recall: 0.530752 precision: 0.904854
epoch-3 step 768300/3451022 - loss: 0.035038 val_loss: 0.034517	recall: 0.513730 precision: 0.903421
epoch-3 step 768400/3451022 - loss: 0.039644 val_loss: 0.039826	recall: 0.515118 precision: 0.888031
epoch-3 step 768500/3451022 - loss: 0.040057 val_loss: 0.035029	recall: 0.564380 precision: 0.896750
epoch-3 step 768600/3451022 - loss: 0.034474 val_loss: 0.034821	recall: 0.539273 precision: 0.886320
epoch-3 step 768700/3451022 - loss: 0.036224 val_loss: 0.038048	recall: 0.540946 precision: 0.910680
epoch-3 step 768800/3451022 - loss: 0.037236 val_loss: 0.034206	recall: 0.524377 precision: 0.904673
epoch-3 step 768900/3451022 - loss: 0.034656 val_loss: 0.042971	recall: 0.546404 precision: 0.918129
epoch-3 step 769000/3451022 - loss: 0.034643 val_loss: 0.035368	recall: 0.528144 precision: 0.890909

checkpoint saved

epoch-3 step 769100/3451022 - loss: 0.036541 val_loss: 0.035433	recall: 0.525532 precision: 0.932075
epoch-3 step 769200/3451022 - loss: 0.036420 val_loss: 0.033889	recall: 0.510112 precision: 0.890196
epoch-3 step 769300/3451022 - loss: 0.035070 val_loss: 0.035428	recall: 0.527436 precision: 0.914563
epoch-3 step 769400/3451022 - loss: 0.034501 val_loss: 0.036461	recall: 0.537246 precision: 0.911877
epoch-3 step 769500/3451022 - loss: 0.035713 val_loss: 0.036534	recall: 0.513636 precision: 0.888016
epoch-3 step 769600/3451022 - loss: 0.034009 val_loss: 0.037460	recall: 0.519767 precision: 0.919753
epoch-3 step 769700/3451022 - loss: 0.034863 val_loss: 0.035221	recall: 0.538549 precision: 0.906489
epoch-3 step 769800/3451022 - loss: 0.036161 val_loss: 0.037347	recall: 0.539313 precision: 0.910280
epoch-3 step 769900/3451022 - loss: 0.040404 val_loss: 0.034595	recall: 0.533721 precision: 0.908911
epoch-3 step 770000/3451022 - loss: 0.039570 val_loss: 0.036019	recall: 0.522552 precision: 0.933202

checkpoint saved

epoch-3 step 770100/3451022 - loss: 0.036045 val_loss: 0.035196	recall: 0.562720 precision: 0.926641

model exported!

epoch-3 step 770200/3451022 - loss: 0.035080 val_loss: 0.034368	recall: 0.529002 precision: 0.890625
epoch-3 step 770300/3451022 - loss: 0.034156 val_loss: 0.038068	recall: 0.510393 precision: 0.880478
epoch-3 step 770400/3451022 - loss: 0.035176 val_loss: 0.034532	recall: 0.526807 precision: 0.886275
epoch-3 step 770500/3451022 - loss: 0.034888 val_loss: 0.040295	recall: 0.534620 precision: 0.921722
epoch-3 step 770600/3451022 - loss: 0.044069 val_loss: 0.039847	recall: 0.554348 precision: 0.901768
epoch-3 step 770700/3451022 - loss: 0.039035 val_loss: 0.040977	recall: 0.546180 precision: 0.921154
epoch-3 step 770800/3451022 - loss: 0.034583 val_loss: 0.034826	recall: 0.521640 precision: 0.880769
epoch-3 step 770900/3451022 - loss: 0.039392 val_loss: 0.036146	recall: 0.534231 precision: 0.899811
epoch-3 step 771000/3451022 - loss: 0.036531 val_loss: 0.034244	recall: 0.555940 precision: 0.932302

checkpoint saved

epoch-3 step 771100/3451022 - loss: 0.039302 val_loss: 0.037090	recall: 0.527215 precision: 0.916512
epoch-3 step 771200/3451022 - loss: 0.038264 val_loss: 0.034565	recall: 0.503378 precision: 0.886905
epoch-3 step 771300/3451022 - loss: 0.052802 val_loss: 0.034642	recall: 0.529867 precision: 0.907197
epoch-3 step 771400/3451022 - loss: 0.035930 val_loss: 0.040887	recall: 0.537931 precision: 0.908738
epoch-3 step 771500/3451022 - loss: 0.034755 val_loss: 0.033967	recall: 0.509351 precision: 0.913215
epoch-3 step 771600/3451022 - loss: 0.035174 val_loss: 0.036233	recall: 0.544332 precision: 0.908240
epoch-3 step 771700/3451022 - loss: 0.035622 val_loss: 0.035177	recall: 0.532872 precision: 0.904110
epoch-3 step 771800/3451022 - loss: 0.035339 val_loss: 0.036451	recall: 0.462656 precision: 0.883168
epoch-3 step 771900/3451022 - loss: 0.035828 val_loss: 0.038387	recall: 0.550857 precision: 0.921606
epoch-3 step 772000/3451022 - loss: 0.035895 val_loss: 0.036187	recall: 0.504844 precision: 0.914230

checkpoint saved

epoch-3 step 772100/3451022 - loss: 0.035152 val_loss: 0.036502	recall: 0.534463 precision: 0.892453

model exported!

epoch-3 step 772200/3451022 - loss: 0.037526 val_loss: 0.034419	recall: 0.520833 precision: 0.906489
epoch-3 step 772300/3451022 - loss: 0.036689 val_loss: 0.041577	recall: 0.500000 precision: 0.902778
epoch-3 step 772400/3451022 - loss: 0.035782 val_loss: 0.034673	recall: 0.509912 precision: 0.900778
epoch-3 step 772500/3451022 - loss: 0.037800 val_loss: 0.035699	recall: 0.496192 precision: 0.904762
epoch-3 step 772600/3451022 - loss: 0.034749 val_loss: 0.034163	recall: 0.506104 precision: 0.917505
epoch-3 step 772700/3451022 - loss: 0.042887 val_loss: 0.039217	recall: 0.507692 precision: 0.886756
epoch-3 step 772800/3451022 - loss: 0.034889 val_loss: 0.035757	recall: 0.528302 precision: 0.911877
epoch-3 step 772900/3451022 - loss: 0.034554 val_loss: 0.039367	recall: 0.543840 precision: 0.931559
epoch-3 step 773000/3451022 - loss: 0.036260 val_loss: 0.042022	recall: 0.538288 precision: 0.910476

checkpoint saved

epoch-3 step 773100/3451022 - loss: 0.035232 val_loss: 0.036051	recall: 0.570447 precision: 0.920518
epoch-3 step 773200/3451022 - loss: 0.036910 val_loss: 0.034869	recall: 0.530201 precision: 0.896030
epoch-3 step 773300/3451022 - loss: 0.036141 val_loss: 0.035284	recall: 0.529412 precision: 0.940039
epoch-3 step 773400/3451022 - loss: 0.034163 val_loss: 0.037386	recall: 0.539519 precision: 0.918129
epoch-3 step 773500/3451022 - loss: 0.035866 val_loss: 0.038032	recall: 0.502242 precision: 0.875000
epoch-3 step 773600/3451022 - loss: 0.036301 val_loss: 0.034888	recall: 0.523230 precision: 0.918447
epoch-3 step 773700/3451022 - loss: 0.034145 val_loss: 0.037231	recall: 0.500528 precision: 0.899431
epoch-3 step 773800/3451022 - loss: 0.034387 val_loss: 0.036670	recall: 0.536697 precision: 0.905222
epoch-3 step 773900/3451022 - loss: 0.035809 val_loss: 0.035038	recall: 0.506967 precision: 0.918447
epoch-3 step 774000/3451022 - loss: 0.036385 val_loss: 0.034465	recall: 0.527809 precision: 0.890805

checkpoint saved

epoch-3 step 774100/3451022 - loss: 0.034328 val_loss: 0.043089	recall: 0.530162 precision: 0.908549

model exported!

epoch-3 step 774200/3451022 - loss: 0.039065 val_loss: 0.034736	recall: 0.506982 precision: 0.897338
epoch-3 step 774300/3451022 - loss: 0.034709 val_loss: 0.041904	recall: 0.520170 precision: 0.915888
epoch-3 step 774400/3451022 - loss: 0.039961 val_loss: 0.039616	recall: 0.517544 precision: 0.927308
epoch-3 step 774500/3451022 - loss: 0.039699 val_loss: 0.037070	recall: 0.527719 precision: 0.916667
epoch-3 step 774600/3451022 - loss: 0.034989 val_loss: 0.034174	recall: 0.490870 precision: 0.883946
epoch-3 step 774700/3451022 - loss: 0.037833 val_loss: 0.036184	recall: 0.500562 precision: 0.870841
epoch-3 step 774800/3451022 - loss: 0.034554 val_loss: 0.035626	recall: 0.535179 precision: 0.913386
epoch-3 step 774900/3451022 - loss: 0.043047 val_loss: 0.037257	recall: 0.485804 precision: 0.900585
epoch-3 step 775000/3451022 - loss: 0.036405 val_loss: 0.039324	recall: 0.532805 precision: 0.890359

checkpoint saved

epoch-3 step 775100/3451022 - loss: 0.034179 val_loss: 0.036198	recall: 0.506077 precision: 0.879079
epoch-3 step 775200/3451022 - loss: 0.034567 val_loss: 0.035968	recall: 0.511706 precision: 0.886100
epoch-3 step 775300/3451022 - loss: 0.034508 val_loss: 0.038723	recall: 0.509317 precision: 0.930057
epoch-3 step 775400/3451022 - loss: 0.035730 val_loss: 0.034202	recall: 0.544202 precision: 0.940476
epoch-3 step 775500/3451022 - loss: 0.035407 val_loss: 0.035908	recall: 0.519909 precision: 0.892578
epoch-3 step 775600/3451022 - loss: 0.036642 val_loss: 0.035599	recall: 0.531003 precision: 0.907514
epoch-3 step 775700/3451022 - loss: 0.036104 val_loss: 0.040777	recall: 0.523344 precision: 0.899254
epoch-3 step 775800/3451022 - loss: 0.036105 val_loss: 0.034817	recall: 0.505447 precision: 0.873823
epoch-3 step 775900/3451022 - loss: 0.035099 val_loss: 0.037972	recall: 0.525612 precision: 0.887218
epoch-3 step 776000/3451022 - loss: 0.034439 val_loss: 0.046210	recall: 0.526906 precision: 0.903846

checkpoint saved

epoch-3 step 776100/3451022 - loss: 0.034427 val_loss: 0.038103	recall: 0.539171 precision: 0.908738

model exported!

epoch-3 step 776200/3451022 - loss: 0.034965 val_loss: 0.033435	recall: 0.581882 precision: 0.919266
epoch-3 step 776300/3451022 - loss: 0.035440 val_loss: 0.042657	recall: 0.530445 precision: 0.898810
epoch-3 step 776400/3451022 - loss: 0.034629 val_loss: 0.035062	recall: 0.534483 precision: 0.901163
epoch-3 step 776500/3451022 - loss: 0.038679 val_loss: 0.034197	recall: 0.538462 precision: 0.905882
epoch-3 step 776600/3451022 - loss: 0.036830 val_loss: 0.052544	recall: 0.520624 precision: 0.892925
epoch-3 step 776700/3451022 - loss: 0.038264 val_loss: 0.040881	recall: 0.500536 precision: 0.886148
epoch-3 step 776800/3451022 - loss: 0.035438 val_loss: 0.035246	recall: 0.501111 precision: 0.887795
epoch-3 step 776900/3451022 - loss: 0.038709 val_loss: 0.034298	recall: 0.522472 precision: 0.899420
epoch-3 step 777000/3451022 - loss: 0.035084 val_loss: 0.034782	recall: 0.537931 precision: 0.896552

checkpoint saved

epoch-3 step 777100/3451022 - loss: 0.041606 val_loss: 0.037149	recall: 0.554133 precision: 0.906667
epoch-3 step 777200/3451022 - loss: 0.035122 val_loss: 0.042034	recall: 0.514840 precision: 0.868979
epoch-3 step 777300/3451022 - loss: 0.036063 val_loss: 0.039283	recall: 0.528953 precision: 0.903042
epoch-3 step 777400/3451022 - loss: 0.034939 val_loss: 0.033691	recall: 0.515254 precision: 0.913828
epoch-3 step 777500/3451022 - loss: 0.036546 val_loss: 0.039731	recall: 0.517817 precision: 0.892514
epoch-3 step 777600/3451022 - loss: 0.036891 val_loss: 0.035505	recall: 0.498320 precision: 0.891784
epoch-3 step 777700/3451022 - loss: 0.038370 val_loss: 0.034467	recall: 0.519406 precision: 0.902778
epoch-3 step 777800/3451022 - loss: 0.038125 val_loss: 0.033886	recall: 0.536036 precision: 0.924272
epoch-3 step 777900/3451022 - loss: 0.034474 val_loss: 0.034570	recall: 0.522629 precision: 0.932692
epoch-3 step 778000/3451022 - loss: 0.035505 val_loss: 0.037657	recall: 0.509719 precision: 0.923679

checkpoint saved

epoch-3 step 778100/3451022 - loss: 0.034865 val_loss: 0.034289	recall: 0.563314 precision: 0.908397

model exported!

epoch-3 step 778200/3451022 - loss: 0.036870 val_loss: 0.037750	recall: 0.511628 precision: 0.911243
epoch-3 step 778300/3451022 - loss: 0.035700 val_loss: 0.034902	recall: 0.526667 precision: 0.896030
epoch-3 step 778400/3451022 - loss: 0.038675 val_loss: 0.035784	recall: 0.509150 precision: 0.904398
epoch-3 step 778500/3451022 - loss: 0.034814 val_loss: 0.036155	recall: 0.557692 precision: 0.909804
epoch-3 step 778600/3451022 - loss: 0.036874 val_loss: 0.036435	recall: 0.518240 precision: 0.906191
epoch-3 step 778700/3451022 - loss: 0.034334 val_loss: 0.038452	recall: 0.535593 precision: 0.915058
epoch-3 step 778800/3451022 - loss: 0.036644 val_loss: 0.034481	recall: 0.521111 precision: 0.928713
epoch-3 step 778900/3451022 - loss: 0.037579 val_loss: 0.036859	recall: 0.569930 precision: 0.920904
epoch-3 step 779000/3451022 - loss: 0.035973 val_loss: 0.035262	recall: 0.509978 precision: 0.900196

checkpoint saved

epoch-3 step 779100/3451022 - loss: 0.034695 val_loss: 0.039971	recall: 0.522702 precision: 0.892250
epoch-3 step 779200/3451022 - loss: 0.035922 val_loss: 0.034897	recall: 0.525656 precision: 0.909270
epoch-3 step 779300/3451022 - loss: 0.036476 val_loss: 0.042526	recall: 0.515882 precision: 0.919922
epoch-3 step 779400/3451022 - loss: 0.036840 val_loss: 0.035614	recall: 0.511312 precision: 0.905812
epoch-3 step 779500/3451022 - loss: 0.034684 val_loss: 0.036379	recall: 0.493827 precision: 0.909091
epoch-3 step 779600/3451022 - loss: 0.040209 val_loss: 0.037372	recall: 0.539278 precision: 0.949533
epoch-3 step 779700/3451022 - loss: 0.040618 val_loss: 0.037154	recall: 0.495208 precision: 0.899420
epoch-3 step 779800/3451022 - loss: 0.040530 val_loss: 0.035037	recall: 0.504742 precision: 0.924710
epoch-3 step 779900/3451022 - loss: 0.038746 val_loss: 0.033899	recall: 0.504246 precision: 0.901328
epoch-3 step 780000/3451022 - loss: 0.035143 val_loss: 0.035783	recall: 0.497315 precision: 0.904297

checkpoint saved

epoch-3 step 780100/3451022 - loss: 0.034448 val_loss: 0.038377	recall: 0.494092 precision: 0.912698

model exported!

epoch-3 step 780200/3451022 - loss: 0.039984 val_loss: 0.034894	recall: 0.520742 precision: 0.922631
epoch-3 step 780300/3451022 - loss: 0.039261 val_loss: 0.034895	recall: 0.541327 precision: 0.895954
epoch-3 step 780400/3451022 - loss: 0.035051 val_loss: 0.035972	recall: 0.536773 precision: 0.936782
epoch-3 step 780500/3451022 - loss: 0.037025 val_loss: 0.034553	recall: 0.526940 precision: 0.903882
epoch-3 step 780600/3451022 - loss: 0.037657 val_loss: 0.040500	recall: 0.513605 precision: 0.884766
epoch-3 step 780700/3451022 - loss: 0.039383 val_loss: 0.040980	recall: 0.534002 precision: 0.882136
epoch-3 step 780800/3451022 - loss: 0.041818 val_loss: 0.037993	recall: 0.510989 precision: 0.884030
epoch-3 step 780900/3451022 - loss: 0.036402 val_loss: 0.035493	recall: 0.496249 precision: 0.878558
epoch-3 step 781000/3451022 - loss: 0.035068 val_loss: 0.035772	recall: 0.533721 precision: 0.889535

checkpoint saved

epoch-3 step 781100/3451022 - loss: 0.034790 val_loss: 0.036655	recall: 0.530945 precision: 0.907236
epoch-3 step 781200/3451022 - loss: 0.033883 val_loss: 0.037199	recall: 0.510893 precision: 0.889943
epoch-3 step 781300/3451022 - loss: 0.036053 val_loss: 0.044993	recall: 0.522752 precision: 0.918129
epoch-3 step 781400/3451022 - loss: 0.036158 val_loss: 0.034575	recall: 0.516593 precision: 0.898077
epoch-3 step 781500/3451022 - loss: 0.036070 val_loss: 0.035069	recall: 0.493122 precision: 0.922772
epoch-3 step 781600/3451022 - loss: 0.036774 val_loss: 0.036398	recall: 0.541758 precision: 0.921495
epoch-3 step 781700/3451022 - loss: 0.047023 val_loss: 0.036782	recall: 0.512247 precision: 0.926782
epoch-3 step 781800/3451022 - loss: 0.035558 val_loss: 0.037376	recall: 0.497854 precision: 0.895753
epoch-3 step 781900/3451022 - loss: 0.039202 val_loss: 0.034851	recall: 0.527088 precision: 0.905039
epoch-3 step 782000/3451022 - loss: 0.036243 val_loss: 0.035158	recall: 0.505297 precision: 0.903409

checkpoint saved

epoch-3 step 782100/3451022 - loss: 0.035356 val_loss: 0.035211	recall: 0.510293 precision: 0.909266

model exported!

epoch-3 step 782200/3451022 - loss: 0.041188 val_loss: 0.034601	recall: 0.545151 precision: 0.929658
epoch-3 step 782300/3451022 - loss: 0.039991 val_loss: 0.035481	recall: 0.528953 precision: 0.906489
epoch-3 step 782400/3451022 - loss: 0.035408 val_loss: 0.037016	recall: 0.557979 precision: 0.920455
epoch-3 step 782500/3451022 - loss: 0.035579 val_loss: 0.040868	recall: 0.511602 precision: 0.890385
epoch-3 step 782600/3451022 - loss: 0.034435 val_loss: 0.038857	recall: 0.524194 precision: 0.897436
epoch-3 step 782700/3451022 - loss: 0.038172 val_loss: 0.037293	recall: 0.522552 precision: 0.901328
epoch-3 step 782800/3451022 - loss: 0.037184 val_loss: 0.039854	recall: 0.525785 precision: 0.901923
epoch-3 step 782900/3451022 - loss: 0.035371 val_loss: 0.035571	recall: 0.506623 precision: 0.896484
epoch-3 step 783000/3451022 - loss: 0.037189 val_loss: 0.039358	recall: 0.502691 precision: 0.915686

checkpoint saved

epoch-3 step 783100/3451022 - loss: 0.036026 val_loss: 0.035297	recall: 0.540138 precision: 0.914563
epoch-3 step 783200/3451022 - loss: 0.034995 val_loss: 0.035821	recall: 0.521265 precision: 0.903592
epoch-3 step 783300/3451022 - loss: 0.036163 val_loss: 0.036808	recall: 0.521935 precision: 0.899225
epoch-3 step 783400/3451022 - loss: 0.034159 val_loss: 0.040477	recall: 0.550228 precision: 0.918095
epoch-3 step 783500/3451022 - loss: 0.038790 val_loss: 0.035781	recall: 0.529480 precision: 0.898039
epoch-3 step 783600/3451022 - loss: 0.036407 val_loss: 0.036364	recall: 0.489774 precision: 0.902778
epoch-3 step 783700/3451022 - loss: 0.040919 val_loss: 0.042944	recall: 0.493576 precision: 0.893411
epoch-3 step 783800/3451022 - loss: 0.039379 val_loss: 0.036066	recall: 0.517876 precision: 0.908745
epoch-3 step 783900/3451022 - loss: 0.034947 val_loss: 0.035832	recall: 0.527842 precision: 0.899209
epoch-3 step 784000/3451022 - loss: 0.037589 val_loss: 0.035697	recall: 0.553311 precision: 0.921495

checkpoint saved

epoch-3 step 784100/3451022 - loss: 0.034570 val_loss: 0.038537	recall: 0.518868 precision: 0.871287

model exported!

epoch-3 step 784200/3451022 - loss: 0.034764 val_loss: 0.036198	recall: 0.514286 precision: 0.877193
epoch-3 step 784300/3451022 - loss: 0.034614 val_loss: 0.038045	recall: 0.509825 precision: 0.906796
epoch-3 step 784400/3451022 - loss: 0.035859 val_loss: 0.034877	recall: 0.539090 precision: 0.904110
epoch-3 step 784500/3451022 - loss: 0.034769 val_loss: 0.034783	recall: 0.518729 precision: 0.880539
epoch-3 step 784600/3451022 - loss: 0.035360 val_loss: 0.038457	recall: 0.542986 precision: 0.888889
epoch-3 step 784700/3451022 - loss: 0.035901 val_loss: 0.040102	recall: 0.584726 precision: 0.922787
epoch-3 step 784800/3451022 - loss: 0.035310 val_loss: 0.034796	recall: 0.507378 precision: 0.888668
epoch-3 step 784900/3451022 - loss: 0.034345 val_loss: 0.036675	recall: 0.530337 precision: 0.895636
epoch-3 step 785000/3451022 - loss: 0.036073 val_loss: 0.035376	recall: 0.507230 precision: 0.904762

checkpoint saved

epoch-3 step 785100/3451022 - loss: 0.034744 val_loss: 0.035752	recall: 0.503928 precision: 0.896208
epoch-3 step 785200/3451022 - loss: 0.035717 val_loss: 0.039021	recall: 0.548571 precision: 0.937500
epoch-3 step 785300/3451022 - loss: 0.041232 val_loss: 0.035835	recall: 0.525892 precision: 0.897839
epoch-3 step 785400/3451022 - loss: 0.034239 val_loss: 0.035157	recall: 0.518438 precision: 0.919231
epoch-3 step 785500/3451022 - loss: 0.035639 val_loss: 0.042182	recall: 0.526254 precision: 0.889546
epoch-3 step 785600/3451022 - loss: 0.035320 val_loss: 0.035503	recall: 0.537415 precision: 0.906310
epoch-3 step 785700/3451022 - loss: 0.034965 val_loss: 0.034362	recall: 0.496868 precision: 0.899811
epoch-3 step 785800/3451022 - loss: 0.035864 val_loss: 0.034187	recall: 0.500000 precision: 0.907692
epoch-3 step 785900/3451022 - loss: 0.036200 val_loss: 0.034092	recall: 0.529481 precision: 0.894422
epoch-3 step 786000/3451022 - loss: 0.042941 val_loss: 0.034966	recall: 0.539503 precision: 0.915709

checkpoint saved

epoch-3 step 786100/3451022 - loss: 0.035809 val_loss: 0.035498	recall: 0.553757 precision: 0.917625

model exported!

epoch-3 step 786200/3451022 - loss: 0.034658 val_loss: 0.036898	recall: 0.527449 precision: 0.900735
epoch-3 step 786300/3451022 - loss: 0.035533 val_loss: 0.036222	recall: 0.526201 precision: 0.925144
epoch-3 step 786400/3451022 - loss: 0.036916 val_loss: 0.035602	recall: 0.515220 precision: 0.910359
epoch-3 step 786500/3451022 - loss: 0.035481 val_loss: 0.035256	recall: 0.515419 precision: 0.884688
epoch-3 step 786600/3451022 - loss: 0.036543 val_loss: 0.036113	recall: 0.514851 precision: 0.917647
epoch-3 step 786700/3451022 - loss: 0.036790 val_loss: 0.034259	recall: 0.560859 precision: 0.912621
epoch-3 step 786800/3451022 - loss: 0.035603 val_loss: 0.041708	recall: 0.523965 precision: 0.907547
epoch-3 step 786900/3451022 - loss: 0.037411 val_loss: 0.034693	recall: 0.560517 precision: 0.908571
epoch-3 step 787000/3451022 - loss: 0.036025 val_loss: 0.034804	recall: 0.508251 precision: 0.916667

checkpoint saved

epoch-3 step 787100/3451022 - loss: 0.042170 val_loss: 0.035976	recall: 0.524022 precision: 0.921415
epoch-3 step 787200/3451022 - loss: 0.036359 val_loss: 0.034840	recall: 0.508324 precision: 0.908730
epoch-3 step 787300/3451022 - loss: 0.036577 val_loss: 0.043023	recall: 0.525366 precision: 0.910156
epoch-3 step 787400/3451022 - loss: 0.037920 val_loss: 0.035278	recall: 0.536215 precision: 0.903543
epoch-3 step 787500/3451022 - loss: 0.035222 val_loss: 0.035402	recall: 0.525229 precision: 0.908730
epoch-3 step 787600/3451022 - loss: 0.038386 val_loss: 0.038103	recall: 0.522422 precision: 0.915521
epoch-3 step 787700/3451022 - loss: 0.040907 val_loss: 0.034633	recall: 0.507830 precision: 0.904382
epoch-3 step 787800/3451022 - loss: 0.036414 val_loss: 0.034992	recall: 0.511732 precision: 0.889320
epoch-3 step 787900/3451022 - loss: 0.037358 val_loss: 0.034767	recall: 0.539181 precision: 0.900391
epoch-3 step 788000/3451022 - loss: 0.046700 val_loss: 0.049389	recall: 0.500530 precision: 0.914729

checkpoint saved

epoch-3 step 788100/3451022 - loss: 0.038087 val_loss: 0.035252	recall: 0.549884 precision: 0.923977

model exported!

epoch-3 step 788200/3451022 - loss: 0.037660 val_loss: 0.040429	recall: 0.526082 precision: 0.916828
epoch-3 step 788300/3451022 - loss: 0.036111 val_loss: 0.034024	recall: 0.534198 precision: 0.911469
epoch-3 step 788400/3451022 - loss: 0.036489 val_loss: 0.036840	recall: 0.539863 precision: 0.915058
epoch-3 step 788500/3451022 - loss: 0.036121 val_loss: 0.035179	recall: 0.530769 precision: 0.920000
epoch-3 step 788600/3451022 - loss: 0.043724 val_loss: 0.035666	recall: 0.514673 precision: 0.880309
epoch-3 step 788700/3451022 - loss: 0.039452 val_loss: 0.036084	recall: 0.517467 precision: 0.909789
epoch-3 step 788800/3451022 - loss: 0.047604 val_loss: 0.038183	recall: 0.528139 precision: 0.903704
epoch-3 step 788900/3451022 - loss: 0.035991 val_loss: 0.039319	recall: 0.518600 precision: 0.911538
epoch-3 step 789000/3451022 - loss: 0.036728 val_loss: 0.034508	recall: 0.504474 precision: 0.868979

checkpoint saved

epoch-3 step 789100/3451022 - loss: 0.035419 val_loss: 0.037364	recall: 0.542316 precision: 0.931166
epoch-3 step 789200/3451022 - loss: 0.035154 val_loss: 0.036811	recall: 0.508909 precision: 0.919517
epoch-3 step 789300/3451022 - loss: 0.038862 val_loss: 0.034952	recall: 0.542491 precision: 0.922772
epoch-3 step 789400/3451022 - loss: 0.035646 val_loss: 0.039601	recall: 0.547235 precision: 0.891182
epoch-3 step 789500/3451022 - loss: 0.037601 val_loss: 0.034874	recall: 0.512514 precision: 0.912791
epoch-3 step 789600/3451022 - loss: 0.035396 val_loss: 0.038410	recall: 0.499461 precision: 0.885277
epoch-3 step 789700/3451022 - loss: 0.035954 val_loss: 0.038793	recall: 0.545665 precision: 0.905950
epoch-3 step 789800/3451022 - loss: 0.034015 val_loss: 0.034578	recall: 0.525346 precision: 0.936345
epoch-3 step 789900/3451022 - loss: 0.035439 val_loss: 0.035754	recall: 0.520737 precision: 0.884540
epoch-3 step 790000/3451022 - loss: 0.037246 val_loss: 0.043394	recall: 0.506479 precision: 0.928713

checkpoint saved

epoch-3 step 790100/3451022 - loss: 0.037235 val_loss: 0.034803	recall: 0.540387 precision: 0.916988

model exported!

epoch-3 step 790200/3451022 - loss: 0.038905 val_loss: 0.042483	recall: 0.541528 precision: 0.914019
epoch-3 step 790300/3451022 - loss: 0.042903 val_loss: 0.035762	recall: 0.513843 precision: 0.916996
epoch-3 step 790400/3451022 - loss: 0.037564 val_loss: 0.036056	recall: 0.530120 precision: 0.897959
epoch-3 step 790500/3451022 - loss: 0.038636 val_loss: 0.037096	recall: 0.508830 precision: 0.920160
epoch-3 step 790600/3451022 - loss: 0.035413 val_loss: 0.035327	recall: 0.527211 precision: 0.904669
epoch-3 step 790700/3451022 - loss: 0.037047 val_loss: 0.035830	recall: 0.533708 precision: 0.916988
epoch-3 step 790800/3451022 - loss: 0.034067 val_loss: 0.037851	recall: 0.524083 precision: 0.880539
epoch-3 step 790900/3451022 - loss: 0.039873 val_loss: 0.041613	recall: 0.500000 precision: 0.915323
epoch-3 step 791000/3451022 - loss: 0.037002 val_loss: 0.035383	recall: 0.516026 precision: 0.902804

checkpoint saved

epoch-3 step 791100/3451022 - loss: 0.050377 val_loss: 0.035676	recall: 0.520742 precision: 0.905123
epoch-3 step 791200/3451022 - loss: 0.035477 val_loss: 0.038333	recall: 0.534653 precision: 0.920455
epoch-3 step 791300/3451022 - loss: 0.034693 val_loss: 0.036671	recall: 0.554802 precision: 0.921201
epoch-3 step 791400/3451022 - loss: 0.034990 val_loss: 0.037898	recall: 0.520352 precision: 0.899240
epoch-3 step 791500/3451022 - loss: 0.034488 val_loss: 0.037516	recall: 0.536165 precision: 0.908560
epoch-3 step 791600/3451022 - loss: 0.037575 val_loss: 0.036439	recall: 0.512443 precision: 0.904192
epoch-3 step 791700/3451022 - loss: 0.038715 val_loss: 0.039591	recall: 0.524283 precision: 0.922330
epoch-3 step 791800/3451022 - loss: 0.033554 val_loss: 0.035170	recall: 0.549217 precision: 0.917757
epoch-3 step 791900/3451022 - loss: 0.037499 val_loss: 0.035394	recall: 0.496296 precision: 0.900192
epoch-3 step 792000/3451022 - loss: 0.035460 val_loss: 0.035138	recall: 0.522084 precision: 0.860075

checkpoint saved

epoch-3 step 792100/3451022 - loss: 0.036061 val_loss: 0.036531	recall: 0.503876 precision: 0.900990

model exported!

epoch-3 step 792200/3451022 - loss: 0.034384 val_loss: 0.042810	recall: 0.533030 precision: 0.898273
epoch-3 step 792300/3451022 - loss: 0.040156 val_loss: 0.036112	recall: 0.539339 precision: 0.916667
epoch-3 step 792400/3451022 - loss: 0.043672 val_loss: 0.035691	recall: 0.539238 precision: 0.928571
epoch-3 step 792500/3451022 - loss: 0.036559 val_loss: 0.035126	recall: 0.507675 precision: 0.876894